% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Moderation, Interaction, Mediation, and Time-Varying Treatments Clarified Using Causal Directed Acyclic Graphs (DAGs) and Single World Intervention Graphs (SWIGs)},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Moderation, Interaction, Mediation, and Time-Varying Treatments
Clarified Using Causal Directed Acyclic Graphs (DAGs) and Single World
Intervention Graphs (SWIGs)}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-05-21}
\begin{document}
\maketitle
\begin{abstract}
The analysis of `moderation', `interaction', `mediation', and
`longitudinal growth' is widespread in the human sciences, yet confusion
persists. We leverage decades of advancements in causal inference to
explain why the quantities derived from statistical models are often
ambiguous, despite model sophistication. We emphasise the necessity of
(1) clearly stating a causal question and (2) assessing the
identifiability of the question with available data before statistical
analysis. Without these steps, confusion is inevitable. Properly framing
and addressing causal questions, especially in settings with
heterogeneous and multiple treatments, reveals the limitations of
popular methods and guides researchers towards more effective
approaches.

\textbf{KEYWORDS}: \emph{Causal Inference}; \emph{SWIGs}; \emph{DAGs};
\emph{Evolution}; \emph{Mediation}; \emph{Longitudinal Growth};
\emph{Time-varying Treatments}
\end{abstract}

\subsection{Introduction}\label{introduction}

Human scientists apply statistical models to data and report
`interaction', `moderation', and `mediation' using both cross-sectional
and time-series data. What do these concepts mean? It is generally
unclear. The confidence with which investigators report their findings
does not make the concepts any clearer.

Several decades of progress in causal inference offer hope for better.
Here we explain the importance of stating a clearly defined causal
question at the outset and examine what is needed for identifying
complex treatment effects from data. We demonstrate that thoughtful use
of graphical causal models greatly eases this burden.

We begin by clarifying basic concepts and graphical conventions.

\subsubsection{Terminology}\label{terminology}

\textbf{Causality}: A cause, \(A\), affects an outcome, \(Y\), if
changing the cause from one level, \(A_i = a^*\), to another level,
\(A_i = a\), results in a different outcome. We write this as
\(Y_i(a^*) - Y_i(a) \neq 0\). This quantity represents the contrast for
individual \(i\) between measurable outcomes under two states of the
world: one where \(A = a^*\) and the other where \(A = a\). We call the
variable of interest, \(A\), a `treatment' or an `exposure'. We refer to
the outcome under treatment, \(Y(A = a)\), as the potential or
counterfactual outcome. The terms ``potential outcome'' and
``counterfactual outcome'' are interchangeable. The observed outcome is
given as \(Y|A=a\). At the individual level, we can generally observe at
most \(Y_i|A_i =a\) or \(Y_i|A_i =a^*\), but not both.

\textbf{Causal Inference}: We cannot observe individual causal effects,
but we can compute average treatment effects by aggregating individual
observations by treatment conditions. For a binary treatment, we express
this as the difference in mean outcomes by treatment condition:
\(E[Y(1)] - E[Y(0)]\) or equivalently as the mean difference in outcomes
by treatment condition \(E[Y(1) - Y(0)]\). This counterfactual contrast
represents the quantity (on the difference scale) that we obtain for a
sample population from an ideally conducted randomised controlled trial
---an `experiment'. Ideal experiments imply the following assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Causal Consistency}: Treatment levels remain consistent within
  the treatment arms to be compared (implied by ``control'').
\item
  \textbf{Exchangeability}: Covariates that might affect outcomes under
  treatment are balanced across all arms (implied by `randomisation').
\item
  \textbf{Positivity}: Each covariate that might affect treatment in the
  target population has a non-zero probability of being observed within
  each treatment condition to be compared (implied by the combination of
  randomisation and a clearly defined target population).
\end{enumerate}

Of course, experiments as realised often deviate from the ideal, leading
to potential failure of these assumptions. In observational or
``real-world'' settings, none of these assumptions are guaranteed, and
worse, only the positivity assumption can be verified by data. To
understand the causal effects of interventions using real-world data, we
must:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{State a well-defined intervention.}
\item
  \textbf{State a well-defined outcome.}
\item
  \textbf{Clarify the target population.}
\item
  \textbf{Ensure treatments to be compared satisfy causal consistency.}
\item
  \textbf{Evaluate whether treatment groups, conditional on measured
  covariates, are exchangeable.} This means differences must be
  ignorable, confounding covariates across treatment levels must be
  balanced, all backdoor paths between treatments and outcomes must be
  closed, treatments and outcomes must be d-separated, and there must be
  no unmeasured confounding. Although terminology varies, the goal
  remains the same: ensuring non-random ``real-world'' data can be
  modelled to emulate a randomised controlled experiment.
\item
  \textbf{Check if the positivity assumption is satisfied.}
\item
  \textbf{Clearly communicate the reasoning, evidence, and
  decision-makeing that inform steps 1-6.}
\end{enumerate}

\textbf{Confounding}: Treatment and outcome are associated independently
of causality.

\subsubsection{Meaning of Symbols}\label{meaning-of-symbols}

To clarify the concepts of interaction, moderation, and mediation, we
will use causal graphical methods. For a review of causal directed
acyclic graphs (\citeproc{ref-pearl}{\textbf{pearl?}}); McElreath
(\citeproc{ref-mcelreath2020}{2020}); Neal
(\citeproc{ref-neal2020introduction}{2020}); Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}). For a review of single world
intervention graphs see Richardson and Robins
(\citeproc{ref-richardson2013swigsprimer}{2013a}). I will assume some
familarity with causal DAGs when introducing single world interventiong
graphs.

\textbf{\(A\)}: Denotes the ``treatment'' or ``exposure'' - a random
variable. This is the variable for which we seek to understand the
effect of intervening on it. It is the ``cause.''

\textbf{\(\bar{A}\)}: Denotes a sequence of treatments.

\textbf{\(Y\)}: Denotes the outcome or response, measured at the end of
study -- the ``effect.''

\textbf{\(L\)}: Denotes a measured confounder or set of confounders --
variables required for conditional exchangeability.

\textbf{\(U\)}: Denotes an unmeasured confounder or confounders.

\textbf{\(\mathcal{R}\)}: Denotes chance assignment to treatment
condition, as when treatment assignment is randomised.

\textbf{\(\mathcal{G}\)}: Denotes a graph, here, a causal directed
acyclic graph.

Table~\ref{tbl-terminologylocalconventions} reports our graphical
conventions.

\begin{table}

\caption{\label{tbl-terminologylocalconventions}Terminology}

\centering{

\terminologylocalconventions

}

\end{table}%

\subsubsection{Elements of Causal
Graphs}\label{elements-of-causal-graphs}

\textbf{Node}: A node or vertex represents characteristics or features
of units within a population on a causal diagram, which we call a
``variable.'' In causal directed acyclic graphs (DAGs), we draw nodes
with respect to the \emph{target population}, which is the population
for whom investigators seek causal inferences
(\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020}). A time-indexed
node, \(X_t\), denotes relative chronology.

\textbf{Edge without an Arrow} (\(\association\)): This path indicates
association without asserting causality.

\textbf{Arrow} (\(\rightarrowNEW\)): This denotes a causal relationship
from the node at the base of the arrow (a `parent') to the node at the
tip of the arrow (a `child'). In causal DAGs, we refrain from drawing an
arrow from treatment to outcome to avoid asserting a causal path from
\(A\) to \(Y\). Our purpose is to ascertain whether causality can be
identified for this path. All other nodes and paths, including the
absence of nodes and paths, are typically assumed.

\textbf{Red Arrow} (\(\rightarrowred\)): This path represents a
non-causal association between the treatment and outcome. Despite the
arrows, this path is associational and may flow against time.

\textbf{Dashed Arrow} (\(\rightarrowdotted\)): This denotes a true
association between the treatment and outcome that becomes partially
obscured when conditioning on a mediator, assuming \(A\) causes \(Y\).

\textbf{Dashed Red Arrow} (\(\rightarrowdottedred\)): This highlights
over-conditioning bias from conditioning on a mediator.

\textbf{Open Blue Arrow} (\(\rightarrowblue\)): This highlights effect
modification, which occurs when the levels of the effect of treatment
vary within levels of a covariate. We do not assess the causal effect of
the effect-modifier on the outcome, recognising that it may be
incoherent to consider intervening on the effect-modifier.

\textbf{Boxed Variable} \(\boxed{X}\): This indicates conditioning or
adjustment for \(X\).

\textbf{Red-Boxed Variable} \(\boxedred{X}\): This highlights the source
of confounding bias from adjustment.

\textbf{Dashed Circle} \(\circledotted{X}\): This indicates no
adjustment is made for a variable (implied for unmeasured confounders).

\textbf{\(\big(\mathcal{R} \rightarrow A\big)\)}: This denotes
randomisation into the treatment condition.

\textbf{Node Splitting} \(\switbasic\): This is used in Single World
Intervention Graphs (SWIGs) to denote counterfactual histories that
arise following interventions. Node splitting allows investigators to
separately evaluate identification for each counterfactual to be
contrasted. All causal DAGs can be restated using SWIGs. However, each
SWIG may encode at most one level of treatment or one sequence of
treatments. To avoid proliferating graphs, we may use a Single World
Intervention Template to denote the graph-valued function from which
multiple SWIGs may be generated.

\textbf{Green Dashed Arrow} \(\rightarrowdottedgreen\): This indicates
dependency in dynamic sequential treatment strategies where the `natural
value' of a treatment value under a specific treatment regime depends on
the values obtained from the counterfactual histories that precede the
node in a SWIG. Dynamic strategies enable flexible, realistic causal
inferences but impose stronger identification assumptions. For example,
arrows to the ``natural value'' of the treatment may compromise
sequential exchangeability, threatening identification (refer to
Richardson and Robins (\citeproc{ref-richardson2013}{2013b})).

Table~\ref{tbl-terminologylocalconventions} reports our graphical
conventions.

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologygeneral

}

\end{table}%

\newpage{}

\subsection{Part 1: Interaction}\label{part-1-interaction}

In causal data science, we think of interaction in two ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Interaction as Effect-Modification of a Single Intervention}:
  We examine how the effect of one intervention varies across different
  strata of the population. For example, we ask if religious service
  attendance affects charitable giving differently among people born in
  Australia versus those born in Egypt. We do not intervene on
  birthplace.
\item
  \textbf{Interaction as the Combined Effect of a Double Intervention}:
  We consider how administering two treatments together affects outcomes
  compared to each treatment alone. For example, we ask if the combined
  effect of religious service attendance and wealth on charitable giving
  differs from the effect of either factor alone.
\end{enumerate}

When interested in a single intervention, we use `effect-modification'
and `moderation' interchangeably. When focusing on a double
intervention, we use the term `interaction'. Note that `interaction'
also applies to biological synergisms and other contexts, but we
restrict our discussion to heterogeneity and double interventions.

For both effect-modification and double intervention interactions, we
must specify the scale at which we measure contrasts. Evidence of
interaction on one scale may not appear on another. Effect-modification
is often termed `effect-measure modification'. We will restrict our
analysis to causal contrasts on the additive scale.

Before applying statistical models to data, we explicitly define our
causal questions, the scale of measurement, and the target population.
We specify if we are interested in single intervention contrasts across
covariate levels or double intervention contrasts. Addressing
interaction questions underscores the importance of clearly stating
causal questions before data analysis. The term ``interaction'' does not
clarify a target of interest. Without a target, we cannot now how to
interpret the results of our statitical models, even when they are
unconfounded.

\subsubsection{Effect-Modification}\label{effect-modification}

The `sharp-null hypothesis' states that there is no effect of the
exposure on the outcome for any unit in the target population. Unless
the `sharp-null hypothesis' is false, there may be effect-modification.
For any study worth conducting, we cannot evaluate whether the
sharp-null hypothesis is false (otherwise, why conduct the study?).
Therefore, we must assume that treatment effects may be heterogeneous.

\begin{table}

\caption{\label{tbl-terminologyeffectmodification}Conventions for
representing effect modification}

\centering{

\terminologyeffectmodification

}

\end{table}%

Table~\ref{tbl-terminologyeffectmodification} presents our graphical
conventions for describing effect modification. We assume no confounding
of the treatment on the outcome and that \(A\) has been randomised
(i.e.~\(\mathcal{R} \rightarrowNEW A\)). To simplify, we do not include
randomisation in our graphs. We draw an open blue arrow to highlight our
interest in effect modification. This convention is specific to this
article. Refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), pp.~126-127, for a discussion
of ``noncausal'' arrows. According to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), essentially all arrows are
non-causal until proven causal, or in their words, `\ldots{} arrows
simply encode, via d-separation, the conditional independencies
satisfied by the variables on the diagram and on the associated SWIG'.
This is correct. However, our purpose here is to underscore that
effect-modification inherently avoids causal interpretations for the
variables investigators use to qualitatively evaluate treatment-effect
heterogeneity.

\begin{table}

\caption{\label{tbl-terminologyeffectmodificationtypes}Effect
Modification}

\centering{

\terminologyeffectmodificationtypes

}

\end{table}%

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}1\),
we represent that \(Z\) is a direct effect modifier for the effect of
\(A\) on \(Y\). The open arrow indicates that we are not attributing
causality to \(Z\). Because our estimand does not involve intervening on
\(Z\), there is no need to close its backdoor paths.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}2\),
we represent that \(Z\) is an unobserved direct effect modifier of \(A\)
to \(Y\). When the distribution of direct effect modifiers \(Z\) differs
between two populations and effect modification is non-linear, marginal
treatment effects between populations will generally differ and will not
easily transport from one population to another (see Appendix X). The
concept of an average treatment effect has no meaning without a
population over which the effect marginalises. This point, although
obvious, has profound implications for generalising research.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}3\),
we present two candidate effect modifiers. Whether a variable is an
effect modifier also depends on which other variables are included in
the model. Here, \(Z\) is a direct effect modifier and \(G\), a
descendant of \(Z\), is an indirect effect modifier. Suppose we are
interested in whether treatment effects vary (on the difference scale)
within levels of \(G\). For example, imagine \(Z\) is childhood
deprivation, \(G\) is educational achievement, \(A\) is a government
educational initiative, and \(Y\) is recycling. If we condition on
\(Z\), we would not observe effect modification by education \(G\) for
the effect of the government initiative \(A\) on recycling behaviour
\(Y\).

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}4\),
we present the same causal structure. However, we do not condition on
the direct effect modifier \(Z\), but rather condition only on \(G\),
the indirect effect modifier. In this scenario, we would find that the
effectiveness of the government initiative \(A\) on recycling behaviour
\(Y\) varies by educational achievement \(G\). Thus, we observe \(G\) as
an effect modifier.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}5\),
we add another variable to our model, depression, denoted by \(B\). We
imagine \(B\) to be a stable trait or that investigators measured
childhood depression (that is, \(B\) precedes \(G\)). Suppose we do not
condition on the direct effect modifier \(Z\) (childhood deprivation),
but we condition on educational attainment (\(G\)) and depression
(\(B\)). In this graph, \(G\) is a collider of \(Z\) and \(B\). Thus,
conditioning on \(G\) (but not \(Z\)) opens a path from
\(B \association G \association Z \association Y\), and investigators
would find evidence for effect modification by depression on the
effectiveness of the government intervention \(A\) on recycling (\(Y\)).

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}6\),
we will not find evidence for effect modification for \(B\) and \(G\)
because conditioning on \(Z\) blocks the flow of information that was
open in \(\mathcal{G}4\) and \(\mathcal{G}5\).

Using causal directed acyclic graphs, we can demonstrate that the
concept of `effect modifier' cannot be stated without reference to an
assumed causal order and an explicit statement about which variables
within that order are modelled
(\citeproc{ref-vanderweele2012}{VanderWeele 2012}). Without a clear
understanding of effect modification, investigators and policymakers
might make incorrect decisions. For example, they might think that
religious people are more receptive to government promotion of
recycling. However, investigators have only randomised the treatment.
Estimating conditional associations between the treatment and other
variables measured at baseline does not address the question of whether
treatment effects would vary if investigators intervened on other
measured variables. More fundamentally, whether a variable is an `effect
modifier' cannot be stated without reference to its position in the
assumed causal order (\citeproc{ref-suzuki2013counterfactual}{Suzuki
\emph{et al.} 2013}; \citeproc{ref-vanderweele2012}{VanderWeele 2012};
\citeproc{ref-vanderweele2007}{VanderWeele and Robins 2007}).

\subsubsection{Worked Example Showing Scale
Dependence}\label{worked-example-showing-scale-dependence}

We are interested in whether treatment varies across levels of another
variable, an effect modifier. Here, we explain how the presence or
absence of effect modification can depend on the scale used to measure
the effect. Specifically, an effect modifier on the ratio scale may not
be an effect modifier on the difference scale, and vice versa.

Individual treatment effects are not observed. We obtain the average
outcomes in each group as follows: \[
\mathbb{E}[Y \mid Z = 1, T = 0] = \mu_{01}, \quad \mathbb{E}[Y \mid Z = 1, T = 1] = \mu_{11}
\] \[
\mathbb{E}[Y \mid Z = 0, T = 0] = \mu_{00}, \quad \mathbb{E}[Y \mid Z = 0, T = 1] = \mu_{10}
\]

The treatment effect on the difference scale (absolute scale) for each
group is: \[
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01}
\] \[
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00}
\]

The treatment effect on the ratio scale (relative scale) for each group
is: \[
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}}
\] \[
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}}
\]

No Effect Modification on the Difference Scale: \[
\text{ATE}_{Z = 1} = \text{ATE}_{Z = 0} \implies \mu_{11} - \mu_{01} = \mu_{10} - \mu_{00}
\]

Effect Modification on the Ratio Scale: \[
\text{RR}_{Z = 1} \neq \text{RR}_{Z = 0} \implies \frac{\mu_{11}}{\mu_{01}} \neq \frac{\mu_{10}}{\mu_{00}}
\]

Next an example. C onsider the following hypothetical data:

Group 0: - \(\mu_{00} = 5\) - \(\mu_{01} = 15\)

Group 1: - \(\mu_{10} = 10\) - \(\mu_{11} = 20\)

We calculate the treatment effects on the difference and ratio scales
for each group:

Difference Scale: \[
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00} = 10 - 5 = 5
\] \[
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01} = 20 - 15 = 5
\]

Both groups have the same treatment effect on the difference scale,
\(\text{ATE}_{Z = 0} = \text{ATE}_{Z = 1} = 5\). We conclude there is no
effect modification on the difference scale.

Ratio Scale: \[
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}} = \frac{10}{5} = 2.00
\] \[
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}} = \frac{20}{15} \approx 1.33
\]

The treatment effect on the ratio scale is different for the two groups,
\(\text{RR}_{Z = 0} = 2 \neq \text{RR}_{Z = 1} \approx 1.33\). Hence, we
find evidence for effect modification on the ratio scale. This
discrepancy arises because the two scales measure different aspects of
the treatment effect: the absolute difference in outcomes versus the
relative change in outcomes.

\subsubsection{Introducing Single World Intevention
Graphs}\label{introducing-single-world-intevention-graphs}

Investigators are often interested in evaluating the effects of multiple
treatments. The remainder of the examples we consider below require
stating these causal quantities to be contrasted from multiple
treatments. Single World Intervention Graphs, developed by James
Richardson and Jamie Robins and colleagues, allow investigators to
clearly state the counterfactual quantities to be contrasted under
different treatments and treatment regimes. Before discussing the
concept of interaction as a double-intervention, we introduce Richardson
and Robin's graphical tool.

\begin{table}

\caption{\label{tbl-swigtable}Single World Interventions Recover
separate caual diagrams for each treatment to be contrasted.}

\centering{

\swigtable

}

\end{table}%

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 1 is a causal directed acyclic
graph, where the associated factorisation of the joint distribution is
given:

\[
P(y, a, l) = P(l) P(a | l) P(y | a, l)
\]

Notice that the counterfactual outcomes to be contrasted do not appear
directly on the causal directed acyclic graph. However, the
corresponding counterfactual outcomes are given by Pearl's do-calculus
Pearl (\citeproc{ref-pearl2009a}{2009}), such tha the average treatment
effect for \(A\) on \(Y\) is identified by conditioning on \(L\):

\[
P(Y(a)|A,L) = P(Y = y|do(A =a), L=l) = P(Y=y|A=a L=l)
\]

In Single World Intervention Graphs we obtain counterfactual
factoriations directly from the graph.

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 2 is a Single World
Intervention Template, a graph valued function, that allows us to
generate separate causal diagrams for each intervention.
\(A = \Tilde{a}\) can take any value \(A \in \mathcal{A}\), where
\(\mathcal{A}\) is the set of all possible inteventions for \(A\).

The function takes inputs:

\[
P(A = \Tilde{a}, Y(A = \Tilde{a}, L))  = P(A = \Tilde{a})P(Y = \Tilde{y}|A = \Tilde{A}, L)
\]

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 3 is the graph value or Single
World Intevention Graph for the Single World Intervention Template
\(\mathcal{G} 2\) when is set to \(A =0\). This gives us the
factorisation:

\subsubsection{Node-Splitting in Single World Intervention Graphs
(SWIGs)}\label{node-splitting-in-single-world-intervention-graphs-swigs}

We represent the effects of hypothetical interventions by
node-splitting.

Consider a template graph \(\mathcal{G}\). Applying node-splitting to
\(A\) involves creating separate graphs for each value of \(A\) to be
contrasted.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{SWIG for \(A = 0\)}: Denoted as \(\mathcal{G}(A=0)\), this
  graph shows the hypothetical scenario where \(A\) is set to 0.
\item
  \textbf{SWIG for \(A = 1\)}: Denoted as \(\mathcal{G}(A=1)\), this
  graph shows the hypothetical scenario where \(A\) is set to 1.
\end{enumerate}

In these graphs, the node corresponding to the outcome \(Y\) is
relabelled to indicate it is now a potential outcome, such as \(Y(0)\)
or \(Y(1)\).

\subsubsection{d-Separation in SWIGs}\label{d-separation-in-swigs}

The rules of d-separation in the SWIGs allow us to read independence
relationships under each intervention to be compared. For example:

\begin{itemize}
\tightlist
\item
  In \(\mathcal{G}(A=0)\), \(A\) is set to 0, and \(L\) is the only edge
  into \(A\) and \(Y\). Thus, conditioning on \(L\) leads to
  \(A \coprod Y(0)\).
\item
  Similarly, in \(\mathcal{G}(A=1)\), \(A\) is set to 1, and \(L\) is
  the only edge into \(A\) and \(Y\). Thus, conditioning on \(L\) leads
  to \(A \coprod Y(1)\).
\end{itemize}

\subsubsection{Factorisation and
Modularity}\label{factorisation-and-modularity}

The factorisation of the joint distribution associated with these graphs
follows from the structure of the SWIGs. For the original DAG, the joint
distribution \(P(A, Y, L)\) can be factorised as \(P(L)P(A|L)P(Y|A,L)\).

For each Single World Intervention Graph, these factorisations are:

\[
P(A = \tilde{a}, Y(\tilde{a}=0) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=0) = y|A = \tilde{a}, L = l)P(L = l)
\] \[
P(A = \tilde{a}, Y(\tilde{a}=1) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=1) = y|A = \tilde{a}, L = l)P(L = l)
\]

These factorisations align with the standard causal directed acyclic
graph factorisations, where \(L\) is the only parent of \(A\),
\(Y(\tilde{a}=0)\), and \(Y(\tilde{a}=1)\) in their respective Single
World Intervention Graphs.

Identification holds if:

\[
P(Y(\tilde{a}) = y) = \sum_l P(Y = y|L = l, A = \tilde{a}) P(L = l)
\]

\subsubsection{Interaction as a
joint-intervention}\label{interaction-as-a-joint-intervention}

Consider two treatments, denoted as \(A\) and \(B\), and their outcome
as \(Y\). A joint intervention causal interaction implies that the
effect of \(A\) and \(B\) together on \(Y\) (denoted as \(Y(A,B)\)) is
not merely the sum of their individual effects.

\begin{table}

\caption{\label{tbl-interactionpuzzle}Causal Interaction}

\centering{

\interactionpuzzle

}

\end{table}%

For instance, consider the effect of beliefs in Big Gods (exposure
\(A\)) on social complexity (outcome \(Y\)), potentially influenced by a
culture's monumental architecture (exposure \(B\)). To assess the
individual and combined effects of \(A\) and \(B\), we look for evidence
of causal interaction on the difference scale. Evidence for interaction
would be present if the following inequality were to hold. Where,

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[Y(1,1)]\): Mean outcome for those jointly exposed to both
  treatments A and B.
\item
  \(\mathbb{E}[Y(1,0)]\): Mean outcome for those exposed to treatment A
  only.
\item
  \(\mathbb{E}[Y(0,1)]\): Mean outcome for those exposed to treatment B
  only.
\item
  \(\mathbb{E}[Y(0,1)]\): Mean outcome for those exposed to neither
  treatment A nor B.
\end{itemize}

We say there is evidence for interaction on the additive scale if

\[\bigg(\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) - \bigg[ \bigg(\underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) + \bigg(\underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \bigg)\bigg] \neq 0 \]

This equation simplifies to

\[ \underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} + \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \neq 0 \]

A positive value would indicate evidence for additive interaction. A
negative value would indicate evidence for sub-additive interaction. A
value near zero would imply no reliable evidence for interaction.

Table~\ref{tbl-interactionpuzzle} presents each counterfactual
interventions. We can read from the graphs, that identification in each
\(\mathcal{G}_{\Tilde{a}, \Tilde{b}}\) requires conditioning on all
confounders of \(A\), \(L_A\) and all confounders of B, \(L_B\).

As with effect-modification, evidence for causal interaction may differ
depending on the measurement scale one chooses to assess it VanderWeele
(\citeproc{ref-vanderweele2012}{2012}). Evidence for the strength of a
causal effect estimate for interaction in the presence of
effect-modification will differ depending on whether the effect is
measured on the ratio scale as opposed to the difference scale (see:
VanderWeele and Knol (\citeproc{ref-vanderweele2014}{2014}), who
recommends using the causal difference scale for most policy settings.)

Note that if \(A\) and \(B\) were to effect each other, we would need to
collect time series data, and estimate causal effects using causal
mediation analysis. The demands for causal mediation analysis are more
stringent than adjusting for confounder sets for both interventions. We
consider these challenges next.

\subsection{Causal Mediation Analysis}\label{causal-mediation-analysis}

\subsubsection{Statisical structural equation models lack
structure}\label{statisical-structural-equation-models-lack-structure}

In the human sciences, mediation analysis is often mired in confusion, a
situation exacerbated by the complex nature of causal relationships it
aims to reveal. However, confusion dissipates when we define our causal
question in relation to the counterfactuals we hope to estimate. Beyond
the intrinsic challenges of mediation analysis, much of the prevailing
confusion stems from the prevalent use of statisical structural equation
models (SEMs). These models generally lack a systematic way of modelling
the complex counterfactual contrasts that are relevant to evaluating
causality. The widespread disconnect between the dominant modelling
traditions and the demands of causal data science is a particularly
worrying feature of the causal crisis that pervades many human sciences
presently. We have no guarantees they that such models are
interpretable. However, we can do better by clearly defining our
estimands with respect to a clearly defined target population. Causal
diagrams are powerful compasses by which to clarify the conditions under
which these estimands may be identified from data.

\subsubsection{Defining a Mediaton
Estimand}\label{defining-a-mediaton-estimand}

To gain a clearer understanding of what causal mediation entails, it is
helpful to deconstruct the total effect into the natural direct and
indirect effects.

\begin{table}

\caption{\label{tbl-medationpuzzle}Causal Mediation}

\centering{

\mediationpuzzle

}

\end{table}%

The total effect of treatment \(A\) on outcome \(Y\) is defined as the
aggregate difference between the potential outcomes when the treatment
is applied versus when it is not. The estimand for the total effect (TE)
can be expressed as follows:

\[
TE = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
\]

The total effect can be further decomposed into direct and indirect
effects, which allow us to address questions of mediation. The potential
outcome \(Y(1)\) taking into account the mediator can be expanded:

\[ 
\mathbb{E}[Y(1)] = \mathbb{E}[Y(1, M(1))]
\]

Here, the effect of the exposure, set to \(A = 1\), is considered along
with the effect of the mediator at its natural value when \(A = 1\).

Similarly, the potential outcome \(\mathbb{E}[Y(0)]\) taking into
account the mediator can be expanded:

\[ 
\mathbb{E}[Y(0)] = \mathbb{E}[Y(0, M(0))]
\]

Here, we focus on the effect of the exposure, set to \(A = 0\), along
with the effect of the mediator at its natural value when \(A = 0\).

Next consider these quantities of interest as they relate to causal
mediation analysis. We can clarify our estimand by decomposing the Total
Effect (TE, which is equivalent to the average treatment effect, or
marginal effect) into the Natural Direct Effect (NDE) and the Natural
Indirect Effect (NIE).

\textbf{Natural Direct Effect (NDE)} is the effect of the treatment on
the outcome while maintaining the mediator at the level it would have
been if the treatment had \emph{not} been applied. The Natural Direct
Effect (NDE) is given:

\[
 NDE = \textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]
 \]

Here, the counterfactual quantities that are not directly realised in
the data are highlighted in blue:
\(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\). Noticethat we add this
term to the potential outcomes when \(A=0\), namely,
\(\mathbb{E}[Y(0)]\), recalling: \(\mathbb{E}[Y(0, M(0))] = Y(0)\)

\textbf{Natural Indirect Effect (NIE):} is the effect of the exposure on
the outcome that is mediated. To obtain these quantities we must compare
the potential outcome \(Y\) under treatment, where the mediator assumes
its natural level under treatment with the potential outcome when the
mediator assumes its natural value under no treatment is given:

\[
 NIE = \mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}
\]

Here, the counterfactual quantities that are not directly realised in
the data are again highlighted in blue:
\(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\). Notice that we subtract
the term from the potential outcomes when \(A=1\), namely,
\(\mathbb{E}[Y(1)]\), recalling:
\(\mathbb{E}[Y(1, M(1))] = \mathbb{E}[Y(1)]\).

Then, by rearranging this decomposition, we can demonstrate that the
total effect (TE) is the sum of the NDE and NIE. We do this by adding
and subtracting the term \(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\),
highlighted in blue to our equation is given:

\[
\text{Total Effect (TE)} = \underbrace{\bigg\{\mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\bigg\}}_{\text{Natural Indirect Effect (NIE)}} + \underbrace{\bigg\{\textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]\bigg\}}_{\text{Natural Direct Effect (NDE)}}
\]

The decomposition of the total effect into natural direct and indirect
effects greatly clarifies the targets of interest in causal mediation
analysis where the interest is in recovering natural indirect and direct
effects, see VanderWeele (\citeproc{ref-vanderweele2015}{2015}). These
are the quantities that causal mediation analysis often seeks
(\citeproc{ref-shi2021}{Shi \emph{et al.} 2021};
\citeproc{ref-steen2017}{Steen \emph{et al.} 2017};
\citeproc{ref-valeri2014}{Valeri \emph{et al.} 2014};
\citeproc{ref-vanderweele2014a}{VanderWeele and Vansteelandt 2014};
\citeproc{ref-vansteelandt2012}{Vansteelandt \emph{et al.} 2012}).
However, to express these quantities requires conceptualising them in
relation to counterfactuals. Lacking a counterfactual framework, it is
unclear what our statistical analysis would be estimating. Note that
VanderWeele (\citeproc{ref-vanderweele2015}{2015}) provides a full
decomposition that includes causal interaction in settings of causal
mediation.

Consider again the hypothesis that cultural beliefs in `big Gods'
influence social complexity, with political authority serving as a
mediator. We assume for present purposes we have well-defined
interventions and outcomes. What requirements are necessary to answer
our causal mediation question?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{No unmeasured exposure-outcome confounder}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod A | L\). After
accounting for the covariates in set \(L\), there must be no unmeasured
confounders influencing cultural beliefs in Big Gods, \(A\), and social
complexity \(Y\). For example, if our study examines the causal effect
of cultural beliefs in Big Gods (the exposure) on social complexity (the
outcome), and the covariates in \(L\) include factors such as geographic
location and historical context, we need to ensure that these covariates
effectively block any confounding paths between \(A\) and \(Y\).
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
brown.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{No unmeasured mediator-outcome confounder}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod M | V\). After
controlling for the covariate set \(V\), we must ensure that no other
unmeasured confounders affect the political authority \(M\) and social
complexity \(Y\). For instance, if trade networks affect political
authority and social complexity, to obstruct the unblocked path linking
our mediator and outcome we must account for trade networks.
Furthermore, we must be entitled to assume the absence of any other
confounders for the mediator-outcome path.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
blue.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{No unmeasured exposure-mediator confounder}
\end{enumerate}

This requirement is expressed: \(M(a) \coprod A | Q\). After controlling
for the covariate set \(Q\), we must ensure that no additional
unmeasured confounders affect cultural beliefs in big Gods \(A\) and
political authority \(M\). For example, the capability to construct
large ritual theatres may influence the belief in big Gods and the level
of political authority. If we have indicators for this technology
measured prior to the emergence of big Gods (these indicators being
\(Q\)), we must assume that accounting for \(Q\) closes the backdoor
path between the exposure and the mediator.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
green.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{No mediator-outcome confounder affected by the exposure}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod M(a^*) | V\). We must
ensure that no variables confounding the relationship between political
authority and social complexity in \(V\) are themselves influenced by
the cultural beliefs in big Gods (\(A\)). For example, when studying the
effect of cultural beliefs in big Gods (\(A\), the exposure) on social
complexity (\(Y\), the outcome) as mediated by political authority
(mediator), there can be no un-modelled factors, such as trade networks
(\(V\)), that influence both political authority and social complexity
and are themselves affected by the belief in big Gods.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path,
\(A\to \boxed{V}\rightarrowdotted M\).

Assumption 4, that there is no exposure-induced confounding in the
mediator-outcome relationship, is often a considerable obstacle for
causal mediation analysis. Where the exposure influences a confounder of
the mediator and outcome, we face a dilemma. Without adjusting for this
confounder, a backdoor path between the mediator and the outcome would
remain open. However, by adjusting for it, we partially obstruct the
path between the exposure and the mediator, leading to bias. In this
setting, we cannot recover the natural direct and indirect effects
directly from any observational data and may need to settle for
investigating controlled direct effects, which stipulate fixed values
for the mediator; see: VanderWeele
(\citeproc{ref-vanderweele2015}{2015}); Robins and Greenland
(\citeproc{ref-robins1992}{1992}).

Notice again that the requirements for counterfactual data analysis are
considerably stricter than has been appreciated in the structural
equation modelling traditions. Natural direct effect estimates and
natural indirect effects estimates require conceptualising a
counterfactual that is never directly observed from the data, namely:
\(\textcolor{blue}{Y(1, M(0))}\) see: VanderWeele
(\citeproc{ref-vanderweele2015}{2015}).

Unfortunately, a generation of researchers must unlearn the habit of
leaping from a description of a statistical process as embodied in a
structural equation diagram to the analysis of the data. It has been
over three decades since Robins and Greenland demonstrated that we
cannot understand the quantities we are estimating in mediation analysis
without first specifying the estimands of interest in terms of the
targeted counterfactuals of interest (\citeproc{ref-robins1992}{Robins
and Greenland 1992}).

\paragraph{3.2.4 Controlled direct effects (and other estimands for
mediation)}\label{controlled-direct-effects-and-other-estimands-for-mediation}

In the previous section, we focused on the assumptions necessary for
decomposing natural direct and indirect effects in causal mediation
analysis. It is crucial to note that consistent estimates for natural
direct and indirect effects are compromised if there exists a confounder
affected by the exposure, which also influences the mediator-outcome
relationship. Nonetheless, if all other assumptions hold, we can fix
this mediator at a specific level to estimate a `controlled direct
effect' of the exposure at different mediator levels.

Consider a scenario where estimating a controlled direct effect is of
interest. Suppose we aim to understand the effect of a stringent
pandemic lockdown, \(A\), on psychological distress, \(Y\), focusing on
trust in government, \(M\), as a mediator. Further, suppose that
pandemic lockdowns may plausibly influence attitudes towards the
government through pathways that also affect psychological distress. For
instance, people might trust the government more when it provides income
relief payments, which may also reduce psychological distress. Under the
rules of d-separation, conditioning on income relief payments, denoted
as \(V\), would attenuate the natural value of the mediator, trust in
the government, under exposure to the lockdowns. This blocking of the
exposure's effect is represented by the causal path
\(A \to \boxed{V} \rightarrowdotted Y\). Additionally, the exposure's
effect on the mediator is partially blocked by the causal path
\(A \to \boxed{V} \rightarrowdotted M\). However, if we do not condition
on \(V\), the path from trust in government, \(M\), to psychological
distress, \(Y\), would be confounded by the common cause \(V\), hence:
\(Y \leftarrowred V \rightarrowred M\).

In such a scenario, it would not be feasible to consistently decompose
the total effect of the exposure (pandemic lockdowns) on the outcome
(psychological distress) into natural indirect and direct effects.
Nevertheless, if all other assumptions hold, we could ascertain from
data the controlled direct effect of pandemic lockdowns on psychological
distress under fixed levels of trust in government.

For example, we could examine the effect of the pandemic lockdown if we
were able to intervene and set everyone's trust in government to, say,
one standard deviation above the baseline, compared with fixing trust in
government to the average level at baseline. We might use `shift
functions' that specify interventions as functions of the data. For
instance, we might investigate interventions that `shift only those
whose mistrust of government was below the mean level of trust at
baseline and compare these potential outcomes with those observed.'
Asking and answering precisely formulated causal questions such as this
might lead to clearer policy advice, especially in situations where
policymakers can influence public attitudes towards the government; see:
Williams and Daz (\citeproc{ref-williams2021}{2021}); Daz \emph{et
al.} (\citeproc{ref-duxedaz2021}{2021}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2022}{2022}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2023}{2023}).

In any case, I hope this brief discussion of causal mediation analysis
clarifies that it would be unwise to simply examine the coefficients
obtained from structural equation models and interpret them as
meaningful as in statistical mediation analysis. We have no guarantees
that these coefficients are interpretable. Rather, to answer any causal
question, we must first state it, with respect to clearly defined
counterfactual contrasts and a target population.

For those interested in estimands for causal mediation analysis, I
recommend visiting the CMAverse website
(\url{https://bs1125.github.io/CMAverse/articles/overview.html},
accessed 12 December 2023). This excellent resource provides
comprehensive documentation, software, and practical examples, including
sensitivity analyses. Next, we will consider more complex scenarios that
involve feedback between treatments and confounders across multiple time
points, settings in which traditional statistical methods also fail
provide valid causal inferences.

\newpage{}

\begin{table}

\caption{\label{tbl-medationassumptions}Assumptions of Causal Mediation}

\centering{

\mediationassumptionsswig

}

\end{table}%

\subsection{Time-fixed and Time-Varying Treatment
Regimes}\label{time-fixed-and-time-varying-treatment-regimes}

Our discussion of causal mediation analysis focused on how effects from
two sequential exposures may combine to influence an outcome. This
concept can be expanded to investigate the causal effects of multiple
sequential exposures -- referred to as `treatment regimes', or
`treatment strategies', or `modified treatment policies.' In many human
sciences where longitudinal data are collected, researchers will often
gravitate to longitudinal growth models and multi-level models. How
shall we interpret the coefficients of these models? To answer a causal
question we must first ask it -- that is, we must first state the
counterfactual contrast in which we are interested. Without stating the
the treatments to be contrasted, the scale on which the contrast will be
computed, and the population for whom inferences are valid, our
statistical models have no clear meaning. The inscrutibility of our
models remains even if there is no unmeasured confounding. However, we
learned from causal mediation analysis that even if investigators were
to randomise the treatment they could do not typically randomise the
mediator. This raises the prospect of intermediary confounding.
Moreover, we learned that even if investigators were to conduct a
sequentional trial such that the mediator was randomised, there would be
no arm of the trail that would yeld the cross-world quantity needed to
obtain a decomposition of the total effect into the natural indirect and
direct effects. The quantity -- \(\mathbb{E}[Y(1, M(0))\) -- is not
observed on any individual. Causal mediation anaysis is a special case
of causal inference under sequential treatments. We next clarify how
investigators may avoid the widespread confusions that pervade
longtitudinal data analysis by clearly stating their causal questions
and evaluating identification before reaching for any statistical model.

\subsubsection{Worked Example: Does Marriage Affect
Happiness?}\label{worked-example-does-marriage-affect-happiness}

Richard McElreath considers the question of whether marriage affects
happiness, and provides a simulation to clarify how age structure
complicates causal inferences McElreath
(\citeproc{ref-mcelreath2020}{2020}). Here, we develop this example. We
simply by considering the outcome, happiness, measured after two time
intervals. Assume this outcome to be well-defined and measured without
error. Assume further that positivity is satisfied, all outcomes are
observed within each level of confounding co-variate. Assume that
consistency is satisfied. Multiple versions of treatment are
conditionally independent of the outcomes.

\(A_t=1\) denotes the state of being married at time \(t\) and
\(A_t = 0\) where \(t \in \{0, 1, \tau\}\) where \(\tau\) is the end of
study and and \(Y_\tau\) denotes the outcome, Happiness

We see in Table~\ref{tbl-regimens-marriage} reveals that there are four
treatment strategies, and six causal contrasts we may estimate for the
four each treatment strategy combination.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1923}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3462}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4615}}@{}}
\caption{Table outlines four fixed treatment regimens and six causal
contrasts in time-series data where exposure varies. These labels apply
only to the two time
points.}\label{tbl-regimens-marriage}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Regime & Always married & \(Y(1,1)\) \\
Regime & Never married & \(Y(0,0)\) \\
Regime & Divorced & \(Y(1,0)\) \\
Regime & Gets married & \(Y(0,1)\) \\
Contrast & Always married vs.~Never married & \(E[Y(1,1) - Y(0,0)]\) \\
Contrast & Always married vs.~Divorced & \(E[Y(1,1) - Y(1,0)]\) \\
Contrast & Always married vs.~Gets married & \(E[Y(1,1) - Y(0,1)]\) \\
Contrast & Never married vs.~Divorced & \(E[Y(0,0) - Y(1,0)]\) \\
Contrast & Never married vs.~Gets married & \(E[Y(0,0) - Y(0,1)]\) \\
Contrast & Divorced vs.~Gets married & \(E[Y(1,0) - Y(0,1)]\) \\
\end{longtable}

The question ``Does marriage affect happiness?'' has no clear meaning
unless we state the contrast or set of contrasts for which we hope to
obtain valid causal inferences. To be scientifically meaningful, the
contrasts we state should be grounded in cleary communicated scientific
interests, and these interests should inform the target population for
which we take inferences to be valid. The question, for example, of
whether divorce makes one less happy one year later, will have different
answers depending on whether we compare divorce with remaining married,
with never having married, or with getting married. Notice the estimands
we state will imply different populations for whom results are meant to
generalise. The marginal effect estimate of Divorce vs Always married
generalises to the population who was always married. Clinicians and
relationship scientists might have reasons to focus on
effect-modification by gender, or sexual orientation, or birth cohort,
say. The marginal estimands will not automatically align with these
interests, and indeed risk erroneous policy inferences wherever the
target population differs from the sample population from which marginal
effects have been estimated -- even if our results obtain consistent
causal estimates of the targeted estimands.

We set further discussion about the need for clearly defined estimand
and target population to the side. Suppose investigators state and
clearly communicate the treatment regimes to be contrasted. Their next
task will be to evaluate sequential exchangeability: they must clarify
whether the potential outcomes are independent at each time point of the
outcome, obtained at the end of study.

\begin{table}

\caption{\label{tbl-swigtabledeveloped}Assumptions of Causal Mediation}

\centering{

\swigtabledeveloped

}

\end{table}%

Table~\ref{tbl-swigtabledeveloped} represents a two subsets of possible
confounding structures for a treatment regime conducted over two
intervals. Covariates in \(L_{t}\) denote measured confounders. \(U\)
denotes unmeasured confounders. \(A_t\) denotes the treatment,
``Marriage Status'' at time \(t\). \(Y\) denotes ``Happiness'' measured
at the end of study. We assume that conditioning on \(L_{t}\) is
sufficient to all backdoor paths for \(A_{t+1}\). We include indicators
of ``Happiness'' in \(L_{t}\), thus controlling for happiness as a
common cause of the marriage at time \(t+1\) and happiness at the end of
study \(\tau = \bar{A}-{\tau -1}\). Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}1\) and Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}2\)
are causal DAGs that the describe these structures. Recall when
constructing causal DAGs we do not generally draw a path from treaments
to outcome when our interest is in evalauating d-separation using
backdoor adjustment. Here we are not concerned that \(A_2\) is a
mediator of the path from \(A_1\) to \(Y\) because our estimand refers
to the combined effect of \(A_1\) and \(A_2\). Furthemrmore, we make no
attempt to separate these effects within any treatment regime; we assume
all nodes can be intervened upon.

Consider the structure of confounding presented in
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\). To close the
backdoor path from \(A_1\) to \(Y\) we must condition on \(L_0\). To
close the backdoor path from \(A_3\) to \(Y\) we must likewise condition
on \(L_2\). However, \(L_2\) is a collider of treatment \(A_1\) and
unmeasured confounders, such that conditioning on \(L_2\) opens a
backdoor path between \(A_1\) and \(Y\) This path is highlighted in red:
\(A_1 \association L_2 \association U \association Y\).

If Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\) faithfully
represents causality, it might seem that we cannot obtain valid
inference for any of the six causal contrasts we have defined. And
indeed were we to limit ourselves to standard methods we could not
obtain valid causal inferences. However, Robins
(\citeproc{ref-robins1986}{1986}) was the first to describe a consistent
estimation function that can be constructed where there is time-varying
confounding (refer to Robins \emph{et al.}
(\citeproc{ref-robins2004effects}{2004}), Hernn \emph{et al.}
(\citeproc{ref-hernan2004STRUCTURAL}{2004})).
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}3\) presents a Single
World Intervention Template that clarifies how identification may be
obtained in fixed treatment regimes where there is time-varying
confounding of the kind we observe in Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}1\), Recall that when constructing a Single World
Intervention Graph (or Template), we obtain factorisations for
counterfactual outcomes under a specific treatment regime by employing
`node-splitting' such that all nodes following an intervention are
relabelled as counterfactual states under preceeding intervention. After
a node-splitting, a fixed intervention is no longer a random variable.
Thus, under fixed treatment regimes, the counterfactul states that
follow an intervention are independent of the states that occur prior to
node splitting if there are no back-door paths into the random partition
of the node that has been split. If if all backdoor paths are closed
into the random partitions of the nodes on which interventions occur,
then we can graphically verify that the treatment is independent of the
counterfactual outcome for that intervention node. Where there are
multiple interventions, we insure sequential exchangeability at the
following node -- which we likewise split and relable -- by closing all
backdoor paths between the random portion of the following treatment
node. We have sequential independence if for each intervention node, all
backdoor paths are closed (refer to Robins and Richardson
(\citeproc{ref-robins2010alternative}{2010}); Richardson and Robins
(\citeproc{ref-richardson2013swigsprimer}{2013a}); Richardson and Robins
(\citeproc{ref-richardson2023potential}{2023})). The Single World
Intervention Template Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}3\) makes it clear that sequential identification may be
obtained. \(A_1\) is d-separated from \(Y\) by conditioning on \(L_0\);
\(A_3\) is d-separated from \(Y\) by conditioning on \(L_2\). Suppose
that the only confounder in \(L\) were happiness. By estimating the
effect of \(L_2\) on \(Y\), adjusting for \(A_1, L_2, L_0\), obtain
valid inference for \(Y\). By adjusting for \(L_0\) we obtain valid
inference for \(A_1\). We may \emph{not} estimate the combined effect of
a treatment strategy over \(A_1\) and \(A_2\) by employing regression,
multi-level regression, statisical structural equation models, or
propensity score matching. However, special estimators may be
constructed (refer to Robins (\citeproc{ref-robins1986}{1986}); Robins
\emph{et al.} (\citeproc{ref-robins2004effects}{2004}); Van Der Laan and
Rose (\citeproc{ref-vanderlaan2011}{2011}); Daz \emph{et al.}
(\citeproc{ref-diaz2021nonparametric}{2021})). Because our interest here
is in identification we shall review these estimators (for recent
reviews refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}); Chatton \emph{et al.}
(\citeproc{ref-chatton2020}{2020}); Van Der Laan and Rose
(\citeproc{ref-vanderlaan2018}{2018}); Chatton and Rohrer
(\citeproc{ref-chatton2024causal}{2024})).

\subsubsection{Time-varying confounding without treatment-confounder
feedback.}\label{time-varying-confounding-without-treatment-confounder-feedback.}

Consider how we may have time-varying confounding in the absence of
treatment-confounder \emph{feedback}. Again we are interested in
contrasts for a two treatment ``marriage'' treatment on ``happiness''
measured at the end of study. Again we assume that these variables are
well-defined, that the time intervals separating the measurements make
theoretical sense and that `marriage' can be intervened upon, that we
have specified a target population, and that our questions are
scientifically interesting. Our focus is on whether the estimands we
state can be obtained from observational data.
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\) presents a structure
in which there is time-varying confounding.

\(U_{AL}\) denotes ability over-confident personality, an unmeasured
variable, that is causally associated with associated with decisions to
marry early and with wealth. We do not suppose that \(U_{AL}\) affects
happiness. Therefore, on this assumption, investigators should make no
adjustment for \(U_{AL}\).

\(U_{AY}\) denotes a common cause of variables in \(L_2\) and happiness.
Suppose this this is ``job status'' which affects wealth, and happiness.
To sharpen the confounding problem, we can present it in its minimal
form, assuming that job status has no effect on baseline marriage rates
(whether it does make no difference to the structural features of the
problem). Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}2\) presents
the structure of confounding for this problem. (To declutter, we remove
baseline measurement of \(L_0\), which we assume to be conditioned on,
but not to block the hideen variable wealth --the ultra wealthy are
unemployed, Professor with status get paid peanuts \ldots{} nor does
status block the backdoor path through over-confidence). Note that there
is no treatment confounder feedback in this example. We will not imagine
that marriage affects stated wealth, but only that stated wealth affects
marriage (perhaps because wealth is a surrate of a latent cause of
stated wealth and happiness). To obtain valid inference for the effect
of \(A_2\) on \(Y\) we must adjust for \(L_2\). However \$L\_2 is a
collider of \(U_{AL}\) and \(U_{AY}\). We must therefore adjust for
\(L_2\). However \(L_2\) is also a collider of \(U_{AL}\) and
\(U_{LY}\); adjustment for \(L_2\) opens the path

\(A_1 \association U_{AL} \association L_2 \association U_{AY} Y\). We
have confounding.

Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\) clarifes that in the
in the fixed treatment regime sequential exchangeable can be obtained.
To estimate the effect of \(A_2\) we must condition on \(L_2\). When
estimating the effect of \(A_1\) on \(Y\) all backdoor paths are closed
because \(L_2\) is a collider, and \(A_0 \coprod Y\).

If \(L_2\) were not a collider, there would be unmeasured confounding.

\subsubsection{Dynamic Treatment Strategies (Modified Treatment
Policies)}\label{dynamic-treatment-strategies-modified-treatment-policies}

In a dynamic treatment strategy, or `modified treatment policy', the
value at which a treatment is fixed is a function of measured events
leading up to the treatment.

Suppose investigators were interested in the population average effect
of divorce on happiness if divorce were only permitted for those with
high social status.

This question is easy to ask but deceptively difficult to answer. For
example, we cannot fit an interaction of time \(\times\) social status
\(\times\) marriage status, because marital status might affect social
status. Yet even if marriage did not affect social status, as in
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\) and
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\) regression would not
produce valid estimates for the counterfactal question we asked.

To sharpen focus, imagine that investigators obtained indicators of
social status at baseline.

Suppose the investigators state the following fixed treatment strategy:

\(g_1(\cdot)\): remain married for at least two additional years:

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   a_{1} = 1 & \\ 
   a_{2} = 1 &   
    \end{cases}
\]

This regime is identified. The setting is identical to
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}3\) however with no
unmeasured variables and no arrow from \(A_1\) to \(L_2\).

However, for a causal contrast we require a second counterfactual
intervention. (A contrast requires at least two counterfactual
outcomes.)

\(g_2(\cdot)\): at each measurement interval, divorce only if one;s
social status is at least 50\% greater than average and the individual
would have divorced in the absence of intervention, otherwise enforce
marriage:

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   a_{1} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_1 = {0} \\ 
   a_{2} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_2 = {0} \\ 
   a_{t}(\mathbf{g}) = 1 & \text{otherwise} 
   \end{cases}
\]

Notice that in this estimand, treatment is computed as a function of
income at both of the natural value of \(A_t\) and the social status
\(L_t\), for \(t = \{1,2\}\)

Template Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}5\) presents
the confounding structure. To convey the dependence of the fixed node on
covariate history under treatment we use Richardson and Robins
(\citeproc{ref-richardson2013}{2013b})'s conventions and draw a dashed
line to convey new paths specified by the treatment regime:
\(\rightarrowdottedgreen\).

Robin's and Richardson's propose the extended dynamic g-formula for
identifying causality under dynamic treatment regimes:

First we define the set of counterfacutal variables in our dynamic
Single World Intervent Graph (or Template)

\begin{itemize}
\tightlist
\item
  \(\mathbb{A}^+(\mathbf{g})\) denotes the set of modified treatments
  variables under a dynamic regime \(\mathbf{g}\).
\item
  \(\mathbb{V}(\mathbf{g})\): denotes the set of counderfactual nodes
  following treatments.
\item
  \(\mathbb{W}(\mathbf{g})\): denotes the combined set of all
  counterfactual variables under dynamic regime corresponding to
  \(\mathcal{G}_\mathbf{g}\). In set notation, \[
  \mathbb{W}(\mathbf{g}) \equiv \mathbb{A}^+(\mathbf{g}) \cup \mathbb{V}(\mathbf{g}))
  \]
\end{itemize}

Next, at each intervention node \(t\), find all ancestors of
\(Y(\mathbf{g})\) in \(\mathbb{W}(\mathbf{g})\) that are not in the set
of current or past treatment covariates. In set notation,

\[
\mathbb{Z}_t(\mathbf{g}) \equiv \text{an}_{\mathcal{G}(\mathbf{g})}(Y(\mathbf{g})) \setminus (\mathbb{L}_k(\mathbf{g}) \cup \mathbb{A}_k(\mathbf{g}) \cup \mathbb{A}^+(\mathbf{g})).
\]

Third, we map \(\mathbb{Z}\) to a new Single World Intervention Graph
\(\mathcal{G}(\mathbf{a}^*)\), where the intervention \(\mathbf{a}^*\)
is specific value of \(A = a\) assigned under \(f^g(\cdot)\). This new
dSWIG \(\mathcal{G}(\mathbf{a}^*)\), is simply the original dSWIG
\(\mathcal{G}(\mathbf{g})\) in which the dashed arrows removed. As such
we may simply use dSWIG \(\mathcal{G}(\mathbf{g})\) ignoring the dashed
arrows -- as we do here.

Fourth, we ensure conditional independence of the treatment \(A_t = a*\)
with members of the set \(\mathbb{Z}_t\), if, for for all
\(\mathbf{a^*}\) (fixed nodes) and all time points \(t \in 1...\tau\),
where \(\tau\) is the end of the study.

\(\mathbb{Z}_t(\mathbf{a}^*) \coprod I(A_t(\mathbf{a}^*) = a^*_t) \mid \bar{\mathbb{L}}_t(\mathbf{a}^*), \bar{\mathbb{A}}_{t-1}(\mathbf{a}^*) = \bar{\mathbf{a}^*}_{t-1}\)

where, \(I\) denotes the indicator function:

\[
I(A_k(\mathbf{a}^*) = a^*_t) = 
\begin{cases} 
1 & \text{if } A_k(\mathbf{a}^*) = a^*_t, \\
0 & \text{otherwise}.
\end{cases}
\]

Effectively this algorithm amounts to:

\begin{verbatim}
1. Find the ancestors of $\mathbb{Z}_t(\mathbf{g})$ that are not in $\bar{\mathbb{L}}_t(\mathbf{g}) \cup \bar{\mathbb{A}}_t(\mathbf{g}) \cup \bar{\mathbb{A}}^+$
2. For each $A(\mathbold{a}^*_t)$ evalute whether $A(\mathbold{a}^*_t)$ is de-separated from members of $\mathbb{Z}_t(a)$  conditional on $\bar{\mathbb{L}}_t(\mathbf{a}) \cup \bar{\mathbb{A}}_{t-1}(\mathbf{a*}) \cup \mathbf{a*}$ in $\mathcal{G}(\mathbf{a}^*)$.
\end{verbatim}

Where:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{\(\mathbb{Z}_t(\mathbf{a}^*)\)}: denotes the subset of
  vertices in \(\mathcal{G}(\mathbf{a}^*)\) corresponding to
  \(\mathbb{Z}_t(\mathbf{g})\).
\item
  \textbf{\(A_t(\mathbf{a}^*) = a^*_t\)}: denotes the specific value of
  the treatment variable at time \(t\) under the intervention
  \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{L}}_t(\mathbf{a}^*)\)}: denotes the set of
  covariates up to time \(k\) under the intervention \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{A}}_{t-1}(\mathbf{a}^*)\)}: denotes the set of
  past treatment variables up to time \(t-1\) under the intervention
  \(\mathbf{a}^*\).
\end{enumerate}

In our example we can apply this formula as follows.

First we obtain \(\mathbb{Z}(\mathbf{g})_t\):

\[
\begin{aligned}
\mathbb{Z}(\mathbf{g}) &= \{A_1, L_1(\mathbf{g}), A_1(\mathbf{g}), A_2(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_1(\mathbf{g}) &= \{\mathbf{g}), L_1(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_2(\mathbf{g}) &= \{Y(\mathbf{g})\}
\end{aligned}
\]

Then we check conditional indepencies for each treatment. Although
\(\mathbf{a^*}) \coprod Y | L_2(\mathbf{a^*}), A_1\), we find that
\(A_1 \cancel \coprod L_1(\mathbf{a^*})\) and
\(A_1 \cancel \coprod A_2(\mathbf{a}^*)\); The counfounding paths are
\(A \association U_{AL} \association  L_2(\mathbf{a^*})\), and
\(A_1 \association U_{AL} \association  L_2(\mathbf{a^*}) \association  L_2(\mathbf{a^*})\).
Identification fails.

+++

If we convert template Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}5\) by the dynamic time-varying g-formula, we gave As shown
in Template Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\).
Alternatively we can test identification using template
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}5\) and ignoring the
dashed lines.

As shown in Template Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\)
dynamic treatment strategy is longer identified. A path open backdoor
path runs from
\(A_1 \association A^{+}_1(g) \association L_2(g) \association A^{+}_2(g)\)

As shown in Template Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}4\)
dynamic treatment strategy is longer identified. A path open backdoor
path runs from
\(A_1 \association A^{+}_1(g) \association L_2(g) \association A^{+}_2(g)\)
T

Readers should be awared that within the causal inference literatures
there are debates about identification under time-varying treatments
(refer to Richardson and Robins
(\citeproc{ref-richardson2023potential}{2023}); Richardson and Robins
(\citeproc{ref-richardson2013}{2013b}); Daz \emph{et al.}
(\citeproc{ref-Diaz2023}{2023}); Rudolph \emph{et al.}
(\citeproc{ref-rudolph2024mediation}{2024}); Shpitser \emph{et al.}
(\citeproc{ref-shpitser2022multivariate}{2022})). However, all agree
that it sufficient for identification, condition on covariate histories
at interventional, all treatments - whether fixed or modified - are
conditionally independent of future counterfactual outcomes.

\subsection{Conclusions}\label{conclusions}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or the
decision to publish it.

\subsection{Acknowledgements}\label{acknowledgements}

Errors are my own.

\subsection{Appendix A: Glossary}\label{appendix-a-glossary}

\begin{table}

\caption{\label{tbl-gloassary}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\subsection{Appendix B On the Clarity of Single World Intervention
Graphs}\label{appendix-b-on-the-clarity-of-single-world-intervention-graphs}

\newpage{}

\begin{table}

\caption{\label{tbl-pearltable}On the limitations of causal DAGs
compared to Single World Intervention Graphs.}

\centering{

\pearltable

}

\end{table}%

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-chatton2020}
Chatton, A, Le Borgne, F, Leyrat, C, \ldots{} Foucher, Y (2020)
G-computation, propensity score-based methods, and targeted maximum
likelihood estimator for causal inference with different covariates
sets: a comparative simulation study. \emph{Scientific Reports},
\textbf{10}(1), 9219.
doi:\href{https://doi.org/10.1038/s41598-020-65917-x}{10.1038/s41598-020-65917-x}.

\bibitem[\citeproctext]{ref-chatton2024causal}
Chatton, A, and Rohrer, JM (2024) The causal cookbook: Recipes for
propensity scores, g-computation, and doubly robust standardization.
\emph{Advances in Methods and Practices in Psychological Science},
\textbf{7}(1), 25152459241236149.

\bibitem[\citeproctext]{ref-duxedaz2021}
Daz, I, Williams, N, Hoffman, KL, and Schenck, EJ (2021) Non-parametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association}.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-diaz2021nonparametric}
Daz, I, Hejazi, NS, Rudolph, KE, and Der Laan, MJ van (2021)
Nonparametric efficient causal mediation with intermediate confounders.
\emph{Biometrika}, \textbf{108}(3), 627--641.

\bibitem[\citeproctext]{ref-Diaz2023}
Daz, I, Williams, N, and Rudolph, KE (2023) \emph{Journal of Causal
Inference}, \textbf{11}(1), 20220077.
doi:\href{https://doi.org/doi:10.1515/jci-2022-0077}{doi:10.1515/jci-2022-0077}.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernan2004STRUCTURAL}
Hernn, MA, Hernndez-Daz, S, and Robins, JM (2004) A structural
approach to selection bias. \emph{Epidemiology}, \textbf{15}(5),
615--625. Retrieved from \url{https://www.jstor.org/stable/20485961}

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and Daz, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoffman2022}
Hoffman, KL, Schenck, EJ, Satlin, MJ, \ldots{} Daz, I (2022) Comparison
of a target trial emulation framework vs cox regression to estimate the
association of corticosteroids with COVID-19 mortality. \emph{JAMA
Network Open}, \textbf{5}(10), e2234425.
doi:\href{https://doi.org/10.1001/jamanetworkopen.2022.34425}{10.1001/jamanetworkopen.2022.34425}.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in r and stan}, CRC press.

\bibitem[\citeproctext]{ref-neal2020introduction}
Neal, B (2020) Introduction to causal inference from a machine learning
perspective. \emph{Course Lecture Notes (Draft)}. Retrieved from
\url{https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf}

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013b) Single world intervention graphs:
A primer. In, Citeseer.

\bibitem[\citeproctext]{ref-richardson2013swigsprimer}
Richardson, TS, and Robins, JM (2013a) Single world intervention graphs:
A primer. In \emph{Second UAI workshop on causal structure learning,
{B}ellevue, {W}ashington}, Citeseer. Retrieved from
\url{https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=07bbcb458109d2663acc0d098e8913892389a2a7}

\bibitem[\citeproctext]{ref-richardson2023potential}
Richardson, TS, and Robins, JM (2023) Potential outcome and decision
theoretic foundations for statistical causality. \emph{Journal of Causal
Inference}, \textbf{11}(1), 20220012.

\bibitem[\citeproctext]{ref-robins1986}
Robins, J (1986) A new approach to causal inference in mortality studies
with a sustained exposure period---application to control of the healthy
worker survivor effect. \emph{Mathematical Modelling}, \textbf{7}(9-12),
1393--1512.

\bibitem[\citeproctext]{ref-robins1992}
Robins, JM, and Greenland, S (1992) Identifiability and exchangeability
for direct and indirect effects. \emph{Epidemiology}, \textbf{3}(2),
143--155.

\bibitem[\citeproctext]{ref-robins2004effects}
Robins, JM, Hernn, MA, and SiEBERT, U (2004) Effects of multiple
interventions. \emph{Comparative Quantification of Health Risks: Global
and Regional Burden of Disease Attributable to Selected Major Risk
Factors}, \textbf{1}, 2191--2230.

\bibitem[\citeproctext]{ref-robins2010alternative}
Robins, JM, and Richardson, TS (2010) Alternative graphical causal
models and the identification of direct effects. \emph{Causality and
Psychopathology: Finding the Determinants of Disorders and Their Cures},
\textbf{84}, 103--158.

\bibitem[\citeproctext]{ref-rudolph2024mediation}
Rudolph, KE, Williams, NT, and Diaz, I (2024) {Practical causal
mediation analysis: extending nonparametric estimators to accommodate
multiple mediators and multiple intermediate confounders}.
\emph{Biostatistics}, kxae012.
doi:\href{https://doi.org/10.1093/biostatistics/kxae012}{10.1093/biostatistics/kxae012}.

\bibitem[\citeproctext]{ref-shi2021}
Shi, B, Choirat, C, Coull, BA, VanderWeele, TJ, and Valeri, L (2021)
CMAverse: A suite of functions for reproducible causal mediation
analyses. \emph{Epidemiology}, \textbf{32}(5), e20--e22.

\bibitem[\citeproctext]{ref-shpitser2022multivariate}
Shpitser, I, Richardson, TS, and Robins, JM (2022) Multivariate
counterfactual systems and causal graphical models. In
\emph{Probabilistic and causal inference: The works of {J}udea {P}earl},
813--852.

\bibitem[\citeproctext]{ref-steen2017}
Steen, J, Loeys, T, Moerkerke, B, and Vansteelandt, S (2017) Medflex: An
{R} package for flexible mediation analysis using natural effect models.
\emph{Journal of Statistical Software}, \textbf{76}, 1--46.

\bibitem[\citeproctext]{ref-suzuki2013counterfactual}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2013) A
counterfactual approach to bias and effect modification in terms of
response types. \emph{BMC Medical Research Methodology}, \textbf{13}(1),
1--17.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-valeri2014}
Valeri, L, Lin, X, and VanderWeele, TJ (2014) Mediation analysis when a
continuous mediator is measured with error and the outcome follows a
generalized linear model. \emph{Statistics in Medicine},
\textbf{33}(28), 4875--4890.

\bibitem[\citeproctext]{ref-vanderlaan2011}
Van Der Laan, MJ, and Rose, S (2011) \emph{Targeted Learning: Causal
Inference for Observational and Experimental Data}, New York, NY:
Springer. Retrieved from
\url{https://link.springer.com/10.1007/978-1-4419-9782-1}

\bibitem[\citeproctext]{ref-vanderlaan2018}
Van Der Laan, MJ, and Rose, S (2018) \emph{Targeted Learning in Data
Science: Causal Inference for Complex Longitudinal Studies}, Cham:
Springer International Publishing. Retrieved from
\url{http://link.springer.com/10.1007/978-3-319-65304-4}

\bibitem[\citeproctext]{ref-vanderweele2012}
VanderWeele, TJ (2012) Confounding and Effect Modification: Distribution
and Measure. \emph{Epidemiologic Methods}, \textbf{1}(1), 55--82.
doi:\href{https://doi.org/10.1515/2161-962X.1004}{10.1515/2161-962X.1004}.

\bibitem[\citeproctext]{ref-vanderweele2015}
VanderWeele, TJ (2015) \emph{Explanation in causal inference: Methods
for mediation and interaction}, Oxford University Press.

\bibitem[\citeproctext]{ref-vanderweele2014}
VanderWeele, TJ, and Knol, MJ (2014) A tutorial on interaction.
\emph{Epidemiologic Methods}, \textbf{3}(1), 33--72.

\bibitem[\citeproctext]{ref-vanderweele2007}
VanderWeele, TJ, and Robins, JM (2007) Four types of effect
modification: a classification based on directed acyclic graphs.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{18}(5), 561--568.
doi:\href{https://doi.org/10.1097/EDE.0b013e318127181b}{10.1097/EDE.0b013e318127181b}.

\bibitem[\citeproctext]{ref-vanderweele2014a}
VanderWeele, T, and Vansteelandt, S (2014) Mediation analysis with
multiple mediators. \emph{Epidemiologic Methods}, \textbf{2}(1),
95--115.

\bibitem[\citeproctext]{ref-vansteelandt2012}
Vansteelandt, S, Bekaert, M, and Lange, T (2012) Imputation strategies
for the estimation of natural direct and indirect effects.
\emph{Epidemiologic Methods}, \textbf{1}(1), 131--158.

\bibitem[\citeproctext]{ref-williams2021}
Williams, NT, and Daz, I (2021) \emph{{l}mtp: Non-parametric causal
effects of feasible interventions based on modified treatment policies}.
doi:\href{https://doi.org/10.5281/zenodo.3874931}{10.5281/zenodo.3874931}.

\end{CSLReferences}



\end{document}
