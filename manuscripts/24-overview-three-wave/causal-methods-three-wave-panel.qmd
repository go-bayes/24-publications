---
title: "A Practical Guide to Causal Inference in Three-Wave Panel Studies"
abstract: |
  Causal inference from observational data poses considerable challenges. This guide explains an approach to estimating causal effects using panel data focussing on the three-wave panel design.

  **Part 1: Pre-specification of Causal Estimands for a Target Population** considers the first step: how to ask a causal question by clearly pre-specifying a causal contrast for a well-defined exposure on well-defined outcomes in the population of interest.

  **Part 2: Three-Wave Panel Design** discusses the methodology for obtaining causal effect estimates from three-wave panel studies and discusses issues of bias from sampling, attrition/missing responses, measurement error, and unmeasured confounding. Here we discuss methods for avoiding these biases, which should be considered in advance of data collection, but which is inevitable, even with the best-made plans. We describe strategies for handling these biases.

  **Part 3: Statistical Estimands and Estimators** describes the process of converting observational data into consistent causal effect estimates for the targeted causal estimands. Here we consider conventional parametric estimators, as well as more recently developed non-parametric and semi-parametric machine learning methods.

  **Part 4: Pre-registration, Data Analysis, and Reporting** describes the protocols for pre-registering analyses, conducting these data analyses, and clearly and accurately communicating scientific findings.

  **Part 5: Addressing Complex Causal Questions** discusses methods for addressing complex causal questions relating to treatment-effect heterogeneity, causal interactions, causal mediation, and longitudinal treatment strategies. We examine how the approaches discussed in Parts 1 - 4 may be cautiously adapted to handle these complex causal questions, and why social scientists should tread lightly before attempting to answer them.
  
  Overall, we hope to provide a clear, step-by-step guide that applied researchers may use to obtain robust causal inferences using three waves of longitudinal data.
author: 
  - name: Joseph A. Bulbulia
    affiliation: Victoria University of Wellington, New Zealand
    orcid_id: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: yes
keywords:
  - Causal Inference
  - Confounding
  - Counterfactuals
  - Missing data
  - Modified treatment policies
editor_options: 
  chunk_output_type: console
format:
  pdf:
    sanitize: true
    keep-tex: true
    link-citations: true
    colorlinks: true
    documentclass: article
    classoption: [singlecolumn]
    lof: false
    lot: false
    geometry:
      - top=30mm
      - left=20mm
      - heightrounded
    header-includes:
      - \input{/Users/joseph/GIT/templates/latex/custom-commands.tex}
      - \usepackage{draftwatermark}
date: last-modified
execute:
  echo: false
  warning: false
  include: true
  eval: true
fontfamily: libertinus
bibliography: /Users/joseph/GIT/templates/bib/references.bib
csl: /Users/joseph/GIT/templates/csl/camb-a.csl
---

```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: true

#tinytex::tlmgr_update()

# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
source("/Users/joseph/GIT/templates/functions/libs2.R")

# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
source("/Users/joseph/GIT/templates/functions/funs.R")

# ALERT: UNCOMMENT THIS AND DOWNLOAD THE FUNCTIONS FROM JB's GITHUB
source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)

source(
  "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
)


## WARNING SET THIS PATH TO YOUR DATA ON YOUR SECURE MACHINE. 
pull_path <-
  fs::path_expand(
    #"/Users/joseph/v-project\ Dropbox/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs_refactor/nzavs_data_23"
    "/Users/joseph/Library/CloudStorage/Dropbox-v-project/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs-current/r-data/nzavs_data"
  )

# read data: note that you need use the arrow package in R
### WARNING: THIS PATH WILL NOT WORK FOR YOU. PLEASE SET A PATH TO YOUR OWN COMPUTER!! ###
### WARNING: FOR EACH NEW STUDY SET UP A DIFFERENT PATH OTHERWISE YOU WILL WRITE OVER YOUR MODELS
push_mods <-  fs::path_expand(
  "/Users/joseph/Library/CloudStorage/Dropbox-v-project/data/nzvs_mods/24/jb-three-wave-guide"
)

# check path:is this correct?  check so you know you are not overwriting other directors
push_mods


# for latex graphs
# for making graphs
library("tinytex")
library("extrafont")
loadfonts(device = "all")

## Read in data from analysis 
# imports
#n_participants <-  here_read("n_participants")


# verify positivity 
#church
#transition_table <- here_read("transition_table")
#transition_table
# binary
#transition_table_2 <- here_read("transition_table_out_church_2")
#transition_table_2


# socialising
#transition_table_socialising <- here_read("transition_table_socialising")
#transition_table_socialising

# binary
#transition_table_socialising_shift<- here_read("transition_table_socialising_shift")
#transition_table_socialising_shift


# ordinary regressions
#fit_church_on_donate <-here_read("fit_church_on_donate")
#lm_coef_church_on_donate <- tbl_regression(fit_church_on_donate)
#b_cross_church_on_donate <-inline_text(lm_coef_church_on_donate, variable = religion_church_round, pattern = "b = {estimate}; (95% CI {conf.low}, {conf.high})")

# use
#b_cross_church_on_donate


#fit_church_on_volunteer <-here_read("fit_church_on_volunteer")
#lm_coef_fit_church_on_volunteer <- tbl_regression(fit_church_on_volunteer)
#b_cross_church_on_volunteer <-inline_text(lm_coef_fit_church_on_volunteer, variable = religion_church_round, pattern = "b = {estimate}; (95% CI {conf.low}, {conf.high})")

# use
#b_cross_church_on_volunteer


#fit_socialising_on_donate<-here_read("fit_socialising_on_donate")
#fit_socialising_on_donate <-here_read("fit_socialising_on_donate")
#lm_coef_fit_socialising_on_donate <- tbl_regression(fit_socialising_on_donate)
#b_cross_socialising_on_donate <-inline_text(lm_coef_fit_socialising_on_donate, variable = hours_community_sqrt_round, pattern = "b = {estimate}; (95% CI {conf.low}, {conf.high})")

# use
#b_cross_socialising_on_donate


#fit_socialising_on_volunteer <-here_read("fit_socialising_on_volunteer")
#fit_socialising_on_volunteer <-here_read("fit_socialising_on_volunteer")
#lm_coef_fit_socialising_on_volunteer <- tbl_regression(fit_socialising_on_volunteer)
#b_cross_socialising_on_volunteer <-inline_text(lm_coef_fit_socialising_on_volunteer, variable = hours_community_sqrt_round, pattern = "b = {estimate}; (95% CI {conf.low}, {conf.high})")

# use
#b_cross_socialising_on_volunteer
# 
# library(glue)
# # works but not used
# # testlm_coef_church_on_donate <- glue("b = {fit_church_on_donate_x[2, 1]}, SE = {fit_church_on_donate_x[2, 3]}")
# 
# # not this table is too long in most instance 
# # table_baseline<- here_read("table_baseline")
# 
# # personality
# table_baseline_personality <- here_read("table_baseline_personality")
# 
# # demographic vars
# table_demographic_vars <- here_read("table_demographic_vars")
# 
# # self reported behaviours 
# table_virtue_vars <- here_read("table_virtue_vars")
# 
# # prejudice 
# table_acceptance_vars<- here_read("table_acceptance_vars")
# 
# # help received 
# table_selected_sorted_names_help_received_vars <- here_read("table_selected_sorted_names_help_received_vars")
# 
# # density of the exposure 
# graph_density_of_exposure<- here_read("graph_density_of_exposure")
# graph_density_of_exposure_socialising<- here_read("graph_density_of_exposure_socialising")
# 
# # graphs
# # graph_density_of_exposure_socialising + ggtitle("Weekly hours socialing")
# #graph_density_of_exposure + ggtitle("Monthly religious service")
# 
# 
# # church outcomes
# 
# # self reported behaviour 
# tab_compare_church_prosocial_behaviour_z<- here_read("tab_compare_church_prosocial_behaviour_z")
# tab_compare_church_prosocial_behaviour_raw<- here_read("tab_compare_church_prosocial_behaviour_raw")
# tab_compare_church_LOSS_prosocial_behaviour_z<- here_read("tab_compare_church_LOSS_prosocial_behaviour_z")
# tab_compare_church_LOSS_prosocial_behaviour_raw<- here_read("tab_compare_church_LOSS_prosocial_behaviour_raw")
# 
# 
# group_tab_compare_church_prosocial_behaviour_raw<- here_read("group_tab_compare_church_prosocial_behaviour_raw")
# group_tab_compare_church_LOSS_prosocial_behaviour_z<- here_read("group_tab_compare_church_LOSS_prosocial_behaviour_z")
# group_tab_compare_church_prosocial_behaviour_z<- here_read("group_tab_compare_church_prosocial_behaviour_z")
# group_tab_compare_church_LOSS_prosocial_behaviour_raw<- here_read("group_tab_compare_church_LOSS_prosocial_behaviour_raw")
# 
# # RESULT OBJECTS 
# # group_tab_compare_church_prosocial_behaviour_z
# # group_tab_compare_church_prosocial_behaviour_raw
# # group_tab_compare_church_LOSS_prosocial_behaviour_z
# # group_tab_compare_church_LOSS_prosocial_behaviour_raw
# 
# 
# 
# plot_church_prosocial <- margot_plot(
#   group_tab_compare_church_prosocial_behaviour_z,
#   type = "RD",
#   title = "Religious service effect on reported donations and volunteering",
#   subtitle = ">= 1 x weekly service attendance",
#   xlab = "",
#   ylab = "",
#   estimate_scale = 1,
#   base_size = 8,
#   text_size = 2.5,
#   point_size = .5,
#   title_size = 12,
#   subtitle_size = 11,
#   legend_text_size = 8,
#   legend_title_size = 10,
#   x_offset = -1,
#   x_lim_lo = -1,
#   x_lim_hi =  .5
# )
# 
# plot_church_prosocial
# 
# 
# plot_church_LOSS_prosocial <- margot_plot(
#   group_tab_compare_church_LOSS_prosocial_behaviour_z,
#   type = "RD",
#   title = "Religious service loss on reported donations and volunteering",
#   subtitle = "loss of any service attendance",
#   xlab = "",
#   ylab = "",
#   estimate_scale = 1,
#   base_size = 8,
#   text_size = 2.5,
#   point_size = .5,
#   title_size = 12,
#   subtitle_size = 11,
#   legend_text_size = 8,
#   legend_title_size = 10,
#   x_offset = -1,
#   x_lim_lo = -1,
#   x_lim_hi =  .5
# )
# 
# plot_church_LOSS_prosocial
# 
# # prejudice
# # results
# group_tab_compare_church_prejudice_z <- here_read("group_tab_warm_church")
# tab_compare_church_prejudice_z  <- here_read("tab_warm_church")
# 
# 
# plot_church_prejudice  <- margot_plot(
#   group_tab_compare_church_prejudice_z,
#   type = "RD",
#   title = "Religious service effect on prejudice/acceptance",
#   subtitle = ">= 1 x weekly service attendance",
#   xlab = "",
#   ylab = "",
#   estimate_scale = 1,
#   base_size = 8,
#   text_size = 2.5,
#   point_size = .5,
#   title_size = 12,
#   subtitle_size = 11,
#   legend_text_size = 8,
#   legend_title_size = 10,
#   x_offset = -1,
#   x_lim_lo = -1,
#   x_lim_hi =  .5
# )
# 
# plot_church_prejudice
# # 
# # ggsave(
# #   plot_prejudice_church,
# #   path = here::here(here::here(push_mods, "figs")),
# #   width = 8,
# #   height = 6,
# #   units = "in",
# #   filename = "plot_prejudice_church.png",
# #   device = 'png',
# #   limitsize = FALSE,
# #   dpi = 600
# # )
# 
# 
# 
# 
# # HELP RECEIVED
# tab_church_help_received <- here_read('tab_church_help_received')
# group_tab_church_help_received <- here_read("group_tab_church_help_received")
# 
# # results
# # tab_church_help_received
# # group_tab_church_help_received
# 
# 
# 
# plot_church_help_received <- margot_plot(
#   group_tab_church_help_received,
#   type = "RR",
#   title = "Religious service effect on help received",
#   subtitle = ">= 1 x weekly service attendance",
#   xlab = "",
#   ylab = "",
#   estimate_scale = 1,
#   base_size = 8,
#   text_size = 2.5,
#   point_size = .5,
#   title_size = 12,
#   subtitle_size = 11,
#   legend_text_size = 8,
#   legend_title_size = 10,
#   x_offset = 0,
#   x_lim_lo = 0,
#   x_lim_hi =  2
# )
# 
# #plot_church_help_received

###################

#f <- function(data, trt){
#   ifelse( data[[trt]] <=4, 4,  data[[trt]] )
# }

#f <- function(data, trt){
#   ifelse( data[[trt]] <=4, 4,  data[[trt]] )
# }

# shift function for socialing: # simple shift,2 hours per week. 
# f_s <- function(data, trt){
#   ifelse( data[[trt]] <=2, 2,  data[[trt]] )
# }


# shift lose all religion
# > f_1
# function(data, trt){
#   ifelse( data[[trt]] > 0, 0,  data[[trt]] )
# }

## SD DATA
# dat_sd_tranform <- readRDS(here::here(push_mods_dogs_gain, "dat_sd_tranform"))


# comparative estimands
# compare_cats_sleep <- readRDS(here::here(push_mods_cats_gain , "compare_cats_sleep"))
# plot_group_tab_compare_cats_sleep <-readRDS(here::here(push_mods_cats_gain , "plot_group_tab_compare_cats_sleep"))
# plot_group_tab_compare_cats_sleep
# 
# compare_dogs_excercise <- readRDS(here::here(push_mods_dogs_gain , "compare_dogs_excercise"))
# plot_group_compare_dogs_excercise <-readRDS(here::here(push_mods_dogs_gain , "plot_group_compare_dogs_excercise"))
# 
# 
# plot_group_tab_compare_cats_sleep <-readRDS(here::here(push_mods_cats_gain , "plot_group_tab_compare_cats_sleep"))
# 
# 
# compare_dogs_excercise <- readRDS(here::here(push_mods_dogs_gain , "compare_dogs_excercise"))
# plot_group_compare_dogs_excercise <-readRDS(here::here(push_mods_dogs_gain , "plot_group_compare_dogs_excercise"))

```

## Introduction

## Part 1: Pre-specification of Causal Estimands for a Target Population

### What is causality?  

Consider an intervention, $A$, and its outcome, $Y$. We say that $A$ causes $Y$ if a change in $A$ would result in a change in $Y$ [@hume1902; @lewis1973]. Conversely, if altering $A$ does not affect $Y$, then we say that $A$ has no causal effect on $Y$.

In causal inference, our objective is to contrast potential outcomes of $Y$ under varying levels of a well-defined intervention or exposure. Critically, the aim is to use data to quantify this difference. This presents challenges because we cannot directly observe causal effects. We can only indirectly infer them, even in experiments.


### The fundamental problem of causal inference

For a binary treatment variable $A \in \{0,1\}$, and for each individual $i$ in a set $\{1, 2, \ldots, n\}$, let $A_i = 0$ and $A_i = 1$ denote that individuals exposure. Let $Y_i(0)$ and $Y_i(1)$, denote the potential outcomes to be contrasted. These terms embody 'potential outcomes', reflecting counterfactual states until they are realised.

Given that each individual $i$ receives either $A_i = 1$ or $A_i = 0$, the outcome observed corresponds to the treatment administered. However, for any given treatment state, the alternative outcome remains counterfactual and unobserved:

$$
Y_i|A_i = 1 \implies Y_i(0)|A_i = 1~ \text{is counterfactual}
$$
$$
Y_i|A_i = 0 \implies Y_i(1)|A_i = 0~ \text{is counterfactual}
$$

Defining $\text{Causal Effect}_i$ as the individual causal effect for unit $i$, we express it as:

$$
\text{Causal Effect}_i = Y_i(1) - Y_i(0)
$$

However, each unit $i$ can only experience one level of the exposure at any time, highlighting that $\text{Causal Effect}_i$ is fundamentally unobservable. Causality is never observed directly from data on individuals. This is called the *fundamental problem of causal inference* [@rubin1976; @holland1986].

#### Counterfactual recovery from randomised experiments

Although individual causal effects are elusive, we can estimate average treatment effects (ATE) by comparing groups subjected to different treatments. The ATE is the difference between the expected outcomes under each treatment condition for a binary variable $A \in \{0,1\}$:

$$
\text{Average Treatment Effect}  = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)].
$$

The challenge lies in calculating these averages when individual causal effects remain unobservable. In experiments, randomisation facilitates the estimation of treatment group averages by balancing confounding factors across groups, thus attributing differences in outcomes solely to the treatment.

This balance allows us to infer that:

$$
\widehat{\mathbb{E}}[Y(0) | A = 1] = \widehat{\mathbb{E}}[Y(0) | A = 0]
$$

and

$$
\widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y(1) | A = 0]
$$

Assuming causal consistency:

$$\widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y| A = 1]$$
$$\widehat{\mathbb{E}}[Y(0) | A = 0] = \widehat{\mathbb{E}}[Y| A = 0]$$

The estimated ATE in a randomised experiment is thus:

$$
\text{The Estimated Average Treatment Effect} = \widehat{\mathbb{E}}[Y | A = 1] - \widehat{\mathbb{E}}[Y | A = 0].
$$

Randomised experiments are pivotal for identifying causal effects by eliminating confounding variables through balanced randomisation. This approach reveals the inherently unobservable counterfactuals necessary for consistent average treatment effect estimation, thereby elucidating the pathway for causal inference in observational settings [@hernán2008a; @hernán2006; @hernán2022].


### Emulating a randomised controled experiment with observational data

Understanding these principles, and the assumptions underpinning identification is helps us to understand the central problem of causal inference in observational settings: **obtaining balance in the confounders across levels of the treatments to be compared**.  Put differently, causal inference requires emulating an idealised experiment, also called a 'target trial'.


#### Causal identification assumptions

##### Identification assumption 1: Causal consistency

Causal consistency assumes the observed outcome aligns with the potential outcome for a given exposure level:

$$Y^{observed} = AY(a=1) + (1-A)Y(a=0)$$

Observed outcomes can represent counterfactual outcomes under certain exposures, such that:

$$
Y^{observed}_i = 
\begin{cases} 
Y_i(~a^*) & \text{if } A_i = a* \\
Y_i(~a~) & \text{if } A_i = a
\end{cases}
$$

Causal consistency also assumes no interference between unit treatments, allowing potential outcomes to be set to the observed outcomes. For this assumption to hold, we require "treatment variation irrelevance"  [@vanderweele2009, @vanderweele2009; @vanderweele2013; @vanderweele2018]. If there are (1) well-defined outcomes for each treatment version, and (2) no confounding effects, the multiple versions of treatments can be used to estimate the causal effect:

$$K \coprod Y(k) | L$$ or equivalently $$Y(k) \coprod K | L$$

Here, the treatment $A$ is essentially a function of $K$ treatments, $A = f(k_1...k_v)$ versions

Limitations exist, however, when interventions are ill-defined, or the causal effect's interpretation is ambiguous. Put simply, given there are unknown ways of becoming religiously disaffiliated the interpretation of "disaffiliation" may be strained. It is strained in the sense that we would not know how to intervene to *make* a religiously affiliated person disaffiliate. We will return to this question in the discussion.

##### Identification assumption 2: Exchangability

Exchangeability assumes treatment assignment is independent of potential outcomes, given observed covariates. This is the "no-confounding" assumption that many psychologists have learned in association with experimental design. In the setting of observational data, we emulate randomisation by conditioning on indicators that may lead to an association of the exposure $A$ and the outcome $Y$ in the absence of causation.

$$Y(a)\coprod  A|L$$ or $$A \coprod  Y(a)|L$$

Where exchangability holds, we calculate the Average Treatment Effect (ATE)

$$
ATE = E[Y(a*)|L = l] - E[Y(a)|L = l] 
$$

Put differently, conditioning on confounders ensures *balance* in their distribution across exposures.

##### Identification assumption 3: Positivity

Positivity is satisfied if there is a positive probability of receiving or not receiving exposure at all covariate levels. Expressed as:

```{=tex}
\begin{equation}
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall a \in L
\end{equation}
```
There are two types of positivity violation.

-   **Random non-positivity**: Occurs when the causal effect of a missing observation is presumed to exist. This violation is the only one verifiable by data. Here, we check and report it.

-   **Deterministic non-positivity**: Occurs when the causal effect is inconceivable. For example, the causal effect of hysterectomy in biological males violates deterministic non-positivity.



### Other threats to Causal inference

#### 1. The threat of overly ambitious estimands

In causal inference, the Average Treatment Effect (ATE) conceived as a comparison between population-wide simulations at two levels of exposure, $E[Y(1)] - E[Y(0)]$, is often artificial. Artificiality is evident for continuous exposures, where such comparisons simplify the complexity of real-world phenomena into a low dimensional summary, such as a contrast of a one-standard-deviation difference in the mean, or a comparison of one quartile of exposure to another quartile of exposure. In practice, the requirements for targeting such contrasts impose a strong reliance on statistical models, which introduce further opportunities for bias. Such comparisons might also strain the positivity assumption because the relevant events occur infrequently or are absent within the strata of covariates required to satisfy conditional exchangeability. Moreover, treatment effects may not be monotonic. For this reason, comparing arbitrary points on a continuous scale, while relying on correct bmodelling specifications risks drawing erroneous conclusions [@calonico2022; @ogburn2021]. In short, the simplifications and models required for obtaining standard causal estimands often lack realism. The practical inferences that we draw from them may be misleading [@vansteelandt2022].

Furthermore, the 'average treatment effect' itself might not be our primary scientific interest. In many settings, we may want to understand heterogeneity in treatment effects without a clear understanding in advance of modelling where such heterogeneity may be found [@wager2018]. Presently, methods for valid causal inference in settings of heterogeneous treatment effects remain inchoate see @tchetgen2012; @wager2018; @cui2020; @foster2023; @foster2023; @kennedy2023; @nie2021.

Recently, causal data scientists have explored new classes of estimands and estimators, such as modified treatment policies or 'shift interventions' [@hoffman2023; @díaz2021; @vanderweele2018; @williams2021] and optimal treatment policies [@athey2021; @kitagawa2018]. Such estimands allow researchers to specify and examine a broader range of causal contrasts, such as treating only those likely to respond, or those who meet certain ethical criteria not determined by statisticians, or those who optimise a pre-specified [@wager2018; @cui2020; @díaz2021]. A review of these promising developments would take us beyond the scope of this discussion, however, readers should be aware that causal inference is not bound to standard $E[Y(1)] - E[Y(0)]$ estimands that require simulating often implausible or even unhelpful counterfactual outcomes for the entire population at two levels of a pre-specified intervention.

#### 2. The challenge of target validity

Investigators must recognise that a mismatch between the sample and target population can invalidate causal effect estimates even if the magnitudes are consistently estimated. If the mismatch affects effect-modifiers of the treatment effects there will be no guarantee that effect estimates for the sample will generalise to the target population -- that is, no guarantee that the effect estimates will achieve 'target validity' or equivalently 'external validity.' Worryingly such threats cannot be fully evaluated from responses in the restricted or censored sample (say more here)


#### 3. The challenge of satisfying data and conceptual assumptions

We must ensure that the measures in our data reflect the underlying realities of interest. 


{{< pagebreak >}}



## Part 2: A Three-Wave Panel Design

We describe methods for obtaining causal effect estimates from three-wave panel studies, and discusses issues of bias from attrition/missing responses, measurement error, and unmeasured confounding.

### Confounding bias

Causal diagrams are useful for evaluating the assumption of 'no unmeasured confounding' [@pearl1995; @pearl2009; @greenland1999]. 
We next use causal diagrams to clarify how confounding bias arises in three-wave panel studies. Our conventions are given in Table @tbl-01:

- **$A$** denotes the treatment or exposure variable. This is the intervention or condition whose effect we wish to investigate **This symbol represents the cause**.
- **$Y$** denotes the outcome variable. **This symbol represents the effect**.
- **$L$** denotes all measured confounders, variables that may affect both the treatment and the outcome.
- **$U$** denotes unmeasured confounders, variables not included in the analysis that could influence both the treatment and the outcome, potentially leading to biased conclusions.
- **$Z$** denotes an effect modifier, a variable within which levels of the treatment may vary. Effect modification is important when considering external validity, also known as target validity. When the distribution of effect modifiers in the sample differs from the distribution of the effect modifiers in the target population, the average treatment effects will generally differ. 
- **$M$** denotes a mediator, a variable factor through which the treatment affects the outcome. Our interest here is in identifying the total effect of treatment $A$ on an outcome $Y$. However, it is also important to understand how controlling for mediators can affect estimates of this total effect.

::: {#tbl-01}

```{=latex}
\terminologylocalconventions
```
Terminology that is used in this article for causal diagrams. (This table is adapted from [@bulbulia2023])

:::


::: {#tbl-02}

```{=latex}
\terminologygeneral
```
Basic conventions for causal diagrams. (This table is adapted from [@bulbulia2023])
:::


<!-- #### Elements of Causal Diagrams -->

<!-- ::: {#tbl-03} -->

<!-- ```{=latex} -->
<!-- \terminologydirectedgraph -->
<!-- ``` -->
<!-- This table is adapted from [@bulbulia2023] -->
<!-- ::: -->

<!-- Having established the meanings of our symbols, we now turn to the fundamental components of causal diagrams themselves. @tbl-02 describes the basic elements of causal diagrams themselves. Key features are: -->

<!-- 1. **Nodes**: representations of variables or events within a causal system. Each node stands for a distinct element that can influence or be influenced within the system. -->

<!-- 2. **Edges**: signify the relationships between the variables represented by nodes. In causal diagrams, edges are directed that define pathways of causal influence. Importantly, causal diagrams are non-parametric; thus, the representation of a relationship does not change with its nature—be it linear or non-linear, an arrow is used in both cases. -->

<!-- 3. **Parent and child**: a variable is termed a "child" if it receives an arrow from another variable, which is then referred to as its "parent." This terminology helps to describe the direction of causal influence within the diagram. -->

<!-- 4. **Acyclic**: causal diagrams must not contain cycles; that is, they cannot have feedback loops where a variable can be both a cause and effect of itself, directly or indirectly. This requirement ensures clarity in the direction of causal influence. In scenarios involving repeated measurements, nodes should be indexed by time to maintain acyclicity. -->

<!-- 5. **Conditioning**: a central aspect of causal analysis is determining how controlling for certain variables affects the unbiased estimation of the relationship between the treatment and the outcome. This process of "conditioning" or "adjustment" is visually represented by enclosing the variable in a box within the diagram. -->


<!-- #### The Rules of D-separation -->

<!-- Pearl demonstrated how d-separation rules can help us understand relationships between nodes in a causal diagram [@pearl1995]. -->

<!-- When we denote $X_1 \cancel\coprod X_2$, it signifies that the probability distributions of $X_1$ and $X_2$ are interconnected. This means occurrences in $X_1$ can provide insights into occurrences in $X_2$, showing a dependency or link between them. -->

<!-- Conversely, $X_1 \coprod X_2$ implies that $X_1$ and $X_2$ have independent probability distributions. Their outcomes do not influence each other; knowledge of $X_1$ offers no prediction about $X_2$. -->

<!-- A path is considered 'blocked' or 'd-separated' if a node along it obstructs the flow of influence. Two variables are d-separated, expressed as $X_1 \coprod X_2$, if all paths connecting them are blocked, indicating no influence or statistical association passes through. If any path remains unblocked, allowing influence to flow, the variables are d-connected, shown as $X_1 \cancel\coprod X_2$ [@pearl1995]. -->



<!-- ::: {#tbl-03} -->

<!-- ```{=latex} -->
<!-- \terminologydirectedgraph -->
<!-- ``` -->
<!-- This table is adapted from [@bulbulia2023] -->
<!-- ::: -->


<!-- ##### **Two Variables with No Arrows** -->

<!-- Graphing two variables, $X_0$ and $X_1$, without arrows between them implies no causal effect. If only these variables exist without a causal link, they are statistically independent, denoted as $X_0 \coprod X_1$. This independence means knowing one variable's value doesn't inform the other's value. -->

<!-- ##### **Two Variables with a Causal Arrow** -->

<!-- Adding a causal arrow from $X_0$ to $X_1$ ($X_0 \rightarrow X_1$) suggests $X_0$ causally influences $X_1$. This causal link indicates a statistical dependency between $X_0$ and $X_1$, represented as $X_0 \cancel\coprod X_1$. Knowledge about $X_0$ thus informs about $X_1$, reflecting their causal connection. -->

<!-- ##### **Three Variables: Fork, Chain, and Collider Structures** -->

<!-- We can introduce another causal relationship to the basic two-node structure in three fundamental ways: the fork, chain, and collider structures, each with specific rules for how conditioning on nodes affects the relationships: -->

<!-- **The Fork Structure**: In this structure ($X_0 \rightarrow X_1$ and $X_0 \rightarrow X_2$), $X_0$ is a common cause of $X_1$ and $X_2$. -->

<!-- **The Fork Structure Rule**: Here, $X_1$ and $X_2$ become conditionally independent given $X_0$ (if $\boxed{X_0}$, then $X_1 \coprod X_2 | X_0$). Conditioning on $X_0$ disconnects any statistical link between $X_1$ and $X_2$ through $X_0$. -->

<!-- **The Chain Structure**: This structure ($X_0 \rightarrow X_1 \rightarrow X_2$) depicts $X_0$ affecting $X_1$, which in turn affects $X_2$. -->

<!-- **The Chain Structure Rule**: $X_0$ and $X_2$ are conditionally independent given $X_1$ (if $\boxed{X_1}$, then $X_0 \coprod X_2 | X_1$). Conditioning on $X_1$ interrupts the indirect connection between $X_0$ and $X_2$. -->

<!-- **The Collider Structure**: This structure ($X_0 \rightarrow X_2 \leftarrow X_1$) positions $X_2$ as a common effect of $X_0$ and $X_1$. -->

<!-- **The Collider Structure Rule**: Initially, $X_0$ and $X_1$ are independent. However, conditioning on $X_2$ (or its descendant, $X_3$) induces an association between $X_0$ and $X_1$ ($X_0 \cancel\coprod X_1 | X_2$). This happens because conditioning on the shared effect (or its descendant) opens a pathway for $X_0$ and $X_1 -->


<!-- @tbl-03 outlines the basic rules governing how causal connections enable statistical associations among up to three related variables.[^notes] -->

<!-- [^notes]: To ensure confounder balance across treatments, we need $A\coprod Y(a)|L$ -- meaning potential outcomes are independent across treatment levels, given covariates $L$. Clearly, we cannot require that the treatment has no effect $A|Y,L$! -->


#### Causal diagrams must address a clearly stated pre-specified identification problem

Causal diagrams are tools designed to clarify the identification problem: in the simplest case, whether the causal effect of $A_t$ on $Y_{t + 1}$ can be accurately measured using data, separating actual causation from statistical association. These diagrams rely on 'structural assumptions' to map out the problem [@hernán2004a]. However, it is important to remember that data alone cannot validate these assumptions. Causal diagrams are only as good as the expert advice that informs them.

The identification problem breaks down into two main tasks:

**First task** determines whether $A$ and $Y$ are independent after accounting for common causes. This involves identifying and controlling for these causes and checking for any remaining pathways (backdoor paths) that might link $A$ and $Y$. The goal is to ascertain if $A$ and $Y$ are d-separated, implying no statistical association between them if considered independent.

**Second task**: assess the causal relationship between $A$ and $Y$, ensuring that the statistical association observed is a reliable indicator of causation, even after the conditioning strategy from the first task is applied. This step is necessary to ensure that the observed relationship between $A$ and $Y$ accurately reflects causality (conditional on assumptions encoded in the graph), mindful of potential biases introduced by over-conditioning.

#### Review of steps for constructing causal diagrams


1. **Incorporate all common causes of the exposure and outcome**: this includes both measured and unmeasured causes. Where possible, we combine similar causes under one variable, such as $L_0$ for demographic factors.

2. **Include all relevant ancestors of measured confounders**: any measured variable that is an ancestor of unmeasured confounders and is linked with either the exposure, the outcome, or both should be included. This helps in identifying and reducing bias from unmeasured causes.

3. **Clearly outline the timing of events**: we recommend using time subscripts (e.g., $L_0$, $A_1$, $Y_2$) to denote the sequence of events, clarifying the assumed causal order.

4. **Arrange the graph according to the causal order** we recommend structuring the diagram to reflect the chronological order of causality, enhancing understanding of the causal relationships.

5. **Mark conditioned variables**: typically, only variables conditioned upon are boxed, excluding the exposure and outcome unless measured inaccurately.

6. **Adopt clear conventions for identifying biases** because causal diagrams do not follow a universal standard, explicitly state the conventions used, such as colouring or describing pathways that could introduce bias.

7. **Focus on structural, not parametric, paths** avoid depicting non-linear relationships between nodes, as the aim is to assess confounding, not the specific nature of the relationships.

8. **Limit paths to those relevant to the identification problem**: Keep the diagram focused, including only pathways that contribute to solving the identification problem.

9. **Specify the research question addressed by the diagram**: again, we recommend making clear the particular question the causal diagram is intended to answer.

10. **State the contents of a graph for those with visual impairments**: not everyone has colour vision or vision. We recommend restating a causal graph in words.

#### Examples of confounding that three waves of panel data avoid


::: {#tbl-04}

```{=latex}
\terminologychronologicalhygeine
```
With three waves of data, we are able to avoid common confounding scenarios described in this graph. This table is adapted from [@bulbulia2023]
:::

In row 8 of @tbl-04, we encounter another scenario characterised by unmeasured confounding and a powerful response: by gathering data on both the treatment and the outcome at the initial assessment and adjusting for their baseline values any unmeasured link between treatment $A_1$ and outcome $Y_2$ must be *independent* of their baseline measurements. Therefore, incorporating baseline values of both treatment and outcome, alongside other measured covariates potentially representing descendants of unmeasured confounders, emerges as a powerful strategy for controlling confounding [@vanderweele2020].

Additionally, the causal diagram highlights a secondary advantage of this approach. Typically, a standard regression analysis yields what is termed a "prevalence exposure effect." This effect measures the relationship between the exposure or treatment status at time $t1$ and the subsequent outcome at time $t2$, following the pathway $A_{1} \to Y_{2}$. It is given as

$$
\text{Prevalence exposure effect:} \quad A_{1} \to Y_{2}
$$

Notably, this estimation does not account for the initial status of the exposure. It may only describe the effect of ongoing exposures on outcomes, which often diverge from the theoretically interesting effect.

Consider, for instance, a scenario where religious service makes people sceptical of surveys. The observed data on the link between religious service and trust in science would then be skewed towards those who are resilient to these effects. Consequently, it might erroneously seem that $A_{1} \to Y_{2}$ has a protective effect on trust whereas, initially, the treatment might be detrimental; see: @hernán2016; @danaei2012; @vanderweele2020; @bulbulia2022.

In contrast, controlling for the baseline exposure and outcome facilitates the identification of an incident exposure effect. This effect evaluates the causal link between the exposure or treatment status at time $t1$ and the observed outcome at time $t2$, conditional on the baseline exposure: $A_{0} \to A_{1} \to Y_{2}$.  Of course, this outcome would need to be weighted by the exposure at treatment because the sceptical might be more likely to drop out of the study.

Thus, by including the baseline exposure, we assess the *transition* in treatment or exposure status from $A_0$ to $A_1$, offering a more precise intervention point for estimating causal effects at $Y_2$ and more accurately by simulating an experimental setup. It is expressed:

$$
\text{Incident exposure effect:} \quad \boxed{A_{0}} \to A_{1} \to Y_{2}
$$

Revisiting our example, a model accounting for the baseline exposure implies that individuals undergo a change from the observed baseline level of $A_0$, allowing for an evaluation of causation of the treatment. This incident exposure effect more faithfully replicates a "target trial" or organises observational data into a hypothetical experiment with a "time-zero" for treatment initiation; see @hernán2016; @danaei2012; @vanderweele2020; @bulbulia2022.

Moreover, we achieve additional control over unmeasured confounding by also including the baseline exposure $A_0$ and the baseline outcome $Y_0$, leading to:

$$
\boxed{
\begin{aligned}
L_{0} \\
A_{0} \\
Y_{0}
\end{aligned}
}
\to A_{1} \to Y_{2}
$$


For any unobserved confounder to affect both the treatment and outcome it would need to do so independently of baseline measures of the treatment and outcome. Including baseline measures helps to address measured sources of confounding. 


{{< pagebreak >}}


### Worked example of a Three-Wave Panel Design for Obtaining a Marginal Incident-Exposure Effect

We sketch the outlines of a design for a three-wave panel study that intends to estimate an *incident exposure effect*. I do not intend this advice to be more than a sketch. However, I believe it is important to give readers a concrete example of how data collection for causal inference might occur.

#### Step 1. Ask a causal question

In a three-wave panel design, ensuring the relative timing of events is essential for valid causal inference [@vanderweele2020].

Here is a causal question:

What is the causal effect of attending weekly religious services compared to not attending services on charitable giving in the population of New Zealanders who identify as Christian?

To answer this question we must assess how changes in religious service attendance, measured from the beginning of the year (baseline) to mid-year (wave 1), affect levels of charitable giving at the end of the year (wave 2) In this design, the change in religious service attendance is captured between the first and second waves, while the outcome, charitable giving, is measured in the third wave. This establishes a sequential order that mirrors the cause-and-effect relationship. Ensuring such temporal ordering is crucial in any causal analysis. Note additionally that we must obtain comparisons from continuous data for binary data. Depending on the data, such a contrast might not be well supported. For example, change between these levels might occur only rarely, in which case our inference might rely too heavily on parametric model specifications. Focusing on the estimand:

##### Exposure:

-   A = 0: Attends less than once per month
-   A = 1: Attends weekly

##### Outcome:

-   Focus: One-year effect of shifting from A = 0 to A = 1.
-   Charitable giving as measured by self-reported giving

##### Scale of contrast:

-   ATE on the causal difference scale (per protocol).

##### Target population:

-   Individuals in New Zealand who might attend religious service and identify as Christian.

##### Source population:

-   National probability sample of New Zealanders (N = 34,000).

##### Baseline population:

-   Defined by eligibility criteria (including religious affiliation). If the baseline population differs from the target population, if sample weights for the distribution of covariates are available for the *target population*, these should be applied to the baseline population [although with caution, given the potential for model misspecification, see @stuart2015.]

Let $\widehat{ATE}_{target}$ denote the population average treatment effect for the target population. Let $\widehat{ATE}_{\text{restricted}}$ denote the average treatment effect at the end of treatment. Let $W$ denote a set of variables upon which the restricted and target populations structurally differ. We say that results *generalise* if we can guarantee that:

$$
\widehat{ATE}_{target} =  \widehat{ATE}_{restricted} 
$$

or if there is a known function such that:

$$
ATE_{target}\approx  f_W(ATE_{\text{restricted}}, W)
$$

In most cases, $f_W$ will be unknown, as it must account for potential heterogeneity of effects and unobserved sources of bias. For further discussion on this topic, see @imai2008misunderstandings; @cole2010generalizing; @stuart2018generalizability; @bulbulia2023c, and $\S 3.1.6$

#### Step 2. Ensure that the exposure is measured at wave 0 (baseline) and wave 1 (the exposure interval)

Measuring the exposure at both baseline (wave 0) and the exposure interval (wave 1) has the following benefits:

1.  **Enables estimation of incident exposure effect**: by including baseline observations, we can distinguish between incidence (new occurrences) and prevalence (existing states) exposure effects. For instance, in a study on religious service attendance, assessing the incident exposure effect allows us to differentiate the effect of starting to attend services regularly from the effect of ongoing attendance.

2.  **Confounding control**: measuring the exposure at baseline helps control for time-invariant confounders. These are factors that do not change over time and might affect both the exposure and outcome. In the context of religious service attendance, personal attributes like inherent religiosity could influence both attendance and related outcomes.

3.  **Sample adequacy**: for rare exposures, baseline measurements can assess sample size adequacy. If a change in exposure is infrequent (e.g., infrequent to weekly religious service attendance), a larger sample may be needed to satisfy the positivity assumption and detect causal effects. By measuring the exposure at baseline, we can better evaluate whether our sample is representative and large enough to detect such rare changes.

#### Step 3. Ensure that the outcome is measured at wave 0 (baseline) and wave 2 (post-exposure wave 1)

Measuring the outcome at both wave 0 (baseline) and the post-exposure outcome wave (wave 2) offers the following advantages:

1.  **Temporal ordering**: causes precede effects. We need this to avoid *causal incoherence*. For example, ensuring order protects us from inadvertently estimating $Y\rightarrowred A$.

2.  **Confounding control**: including the baseline measure of both the exposure and outcome allows for better control of confounding. This approach helps to isolate the effect of the exposure on the outcome from the exposure wave (wave 1) to the outcome wave (wave 2), independent of their baseline levels. It reduces the risk of confounding, where unmeasured factors might influence both the exposure and the outcome, as shown in @tbl-05.

#### Step 4. Measure observable common causes of the exposure and outcome

Next, we must identify and record at wave 0 (baseline) all potential confounders that could influence both the exposure (e.g., frequency of attending religious services) and the outcome (e.g., charitable giving). Proper identification and adjustment for these confounders are crucial for accurate causal inference. By obtaining measures of the confounders at baseline we:

a.  **Minimise mediation bias**: by measuring confounders at baseline, it will be difficult to produce the *causally incoherent* model: $A_1\to \boxed{L_2} \rightarrowdotted Y_3$

b.  **Minimise collider bias**: by measuring confounders at baseline, it will be difficult to produce the *causally incoherent* model: $A_1\rightarrowred L_3 \leftarrowred Y_2$.

The topic of measurement construction is vast. For now, it is worth noting that measures should be obtained in consultation with locals and domain experts [@vanderweele2022].

#### Step 5. Gather data for proxy variables of unmeasured common causes at the baseline wave

If any unmeasured confounders influence both the exposure and outcome, but we lack direct measurements, we should make efforts to include proxies for them at baseline. Even if this strategy cannot eliminate all bias from unmeasured confounding, it will generally reduce bias.

#### Step 6. Retain sample

Censoring leads to bias. Strategies for sample retention are essential.

a.  **Developing tracking protocols**: establish robust systems for tracking participants over the study period. This involves keeping updated records of contact information such as addresses, emails, phone numbers, and names and accounting for changes in name over time.

b.  **Motivate retention**: implement strategies to encourage ongoing participation. These incentives should ideally not lead to bias in the distribution of effect-modifiers that might affect the outcome of interest. For example, retention should not appeal to trust in science if trust in science is the outcome of interest.

c.  **Investigators should avoid acting in ways that lead to differential retention**: for example, stay out of the news.


::: {#tbl-05}

```{=latex}
\threeFF
```
Several sources of bias from attrition. In the first instance, an unmeasured common cause of the exposure also affects attrition. In the second instance, the exposure directly affects attrition. To address these sources of bias we use inverse probability of censoring weights.  (This table is adapted from [@bulbulia2023]), see Part 5 for additional examples. 
:::


{{< pagebreak >}}


## Part 3: Statistical Estimation and Estimators

We outline the process of converting observational data into consistent causal effect estimates for the targeted causal estimands. Here we describe the advantages and limitations of robust non-parametric and semi-parametric machine learning methods, arguing these should be used where sample size permits.

<!-- Example:  -->

<!-- **Objective**: we evaluate the causal effect of increased religious service attendance on pro-social behaviour. Previous studies suggest attending religious services more frequently may foster greater pro-social behaviour among individuals. To address causality, we investigate a hypothetical intervention that would increase the frequency of monthly religious service attendance to a minimum threshold of weekly service attendance, contrasted against the natural course of attendance patterns. -->

<!-- **Treatment ($A$)**: monthly religious service attendance, measured as the number of services attended per month. -->

<!-- **Outcome ($Y$)**: pro-social behaviour, quantitatively assessed through three domains: (1) self-reported behaviour: annual charitable donations, weekly volunteering; (2) prejudice/acceptance toward 12 minority groups; additionally evaluate self-reported religious prejudice; (3) help-received from others, a novel measure that minimises self-reporting bias; we evaluate help-received from family, from friends, and from the community. -->

<!-- **Covariates ($L$)**: baseline covariates include demographic characteristics, baseline religious service attendance, baseline measures of all outcomes, and variables that might affect the treatment and outcomes, such as work demands, number of children, number of siblings, and hours spent exercising and doing housework.  -->

### Causal estimation

Suppose we have defined our estimand. To obtain causal contrasts we recommend using doubly robust estimation methods. These combine inverse probability of treatment weights (propensity scores) with regression stratification. There are two models at work in a doubly robust estimator.



#### Parametric Doubly Robust Estimation

Combines the strengths of the IPTW and G-computation methods (see: [here](https://go-bayes.github.io/psych-434-2023/content/09-content.html#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study-e.g.-assessment-3-option-2).

The technique utilises both the propensity score and the outcome model, making it "doubly robust." This implies that if either of these models is correctly specified, the estimation will not be biased.

**Step 1** The first step is to estimate the propensity score. The propensity score, denoted as $e(L)$, is the conditional probability of the exposure $A = 1$ given the covariates $L$. The appropriate model to estimate this can be chosen based on the nature of the data and the exposure.

$$e = P(A = 1 | L) = f_A(L; \theta_A)$$

In this equation, $f_A(L; \theta_A)$ is a function that estimates the probability of the exposure $A = 1$ given covariates $L$.  We then calculate the weights for each individual, denoted as $v$, using the estimated propensity score:

$$
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
$$

Here, $v$ depends on $A$, and is calculated as the inverse of the propensity score for exposed individuals and as the inverse of $1-e$ for unexposed individuals.

**Step 2** The next step involves fitting a weighted outcome model. Using the weights computed from the estimated propensity scores, a model for the outcome $Y$, conditional on the exposure $A$, is fitted.

$$ \hat{E}(Y|A, L; V) = f_Y(A, L ; \theta_Y, V) $$

In this model, $f_Y$ is a function (in our case a weighted regression model) with parameters $θ_Y$. The weights $V$ are incorporated into the estimation process, affecting the contribution of each observation to the estimation of $θ_Y$, but they are not an additional variable in the model. Additionally, following @agnostic, we take the interaction of the exposure and baseline covariates when estimating our regression model. For binary outcomes, we model the rate ratio using Poisson regression. Although binomial regression is acceptable when the outcome is rare (less than 10%), non-collapsibility leads mean that we cannot interpret results as marginal causal effects. For consistency, we use the Poisson model with robust standard errors.

**Step 3** simulate the potential outcome for each individual under the hypothetical scenario where everyone is exposed to the intervention $A=a$, irrespective of their actual exposure level:

$$\hat{E}(a) = \hat{E}[Y_i|A=a; L,\hat{\theta}_Y, v_i]$$

This expectation is calculated for each individual $i$, with individual-specific weights $v_i$.

**Step 4** Estimate the causal effect as a contrast in averages of the population outcomes under each intervention:

$$\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]$$

The difference $\delta$ represents the average causal effect of changing the exposure from level $a'$ to level $a$.

For standard errors and confidence intervals, we use simulation-based inference methods [@greifer2023].

#### Semi-parametric and non-parametric estimator

#### Shift functions

Causider a causal question in which we apply the following contrasts:

-   The expected outcomes under each shift function defined above by the function $f(A)$, and
-   The expected outcomes under the actual observed attendance/socialising patterns.

Formally, each target is given:

$$ \Delta = E[Y(a*)|f(A),L] - E[Y(a)|A,L] $$

Where $\Delta$ is the average treatment effect of a modified treatment policy.

**Motivating example: shift function as a gain of weekly religious service**: the intervention of interest is defined by a shift function applied to the treatment variable, designed to assess the effect of shifting the treatment on all outcomes examined in the study. The focal estimand shift function is given

$$f(A) = \begin{cases} 4 & \text{if } A \leq 4  \text{ monthly religious service attendance} \\ A & \text{if } A > 4  \text{ monthly religious service attendance} \end{cases} $$

Here, we estimate outcomes in a hypothetical world in which all individuals were attend at least four religious services per month (weekly).

**Comparative intervention 1: shift function as loss of any religious service**:

Because the gain of religion might be different from the loss of religion, we additionally contrast the population average outcome were everyone to stop attending monthly religious service verse the expected outcome at the natural treatment values:

$$f(A) = 0 $$

Here, we estimate outcomes in a hypothetical world in which no individuals attended religious service.

<!-- ### Inclusion criteria and missing data -->

<!-- For example: -->

<!-- -   Participants who provided full information about both religious service attendance and hours of socialising at the baseline wave (NZAVS time 10, years 2018-10) and exposure wave (NZAVS wave 2019-20) were included. -->

<!-- -   Missing data for all variables at baseline were allowed. Missing data at baseline were imputed through the `mice` package [@vanbuuren2018]. -->

<!-- -   Inverse probability of censoring weights were calculated as part of estimation in `lmtp` to adjust for missing outcomes at NZAVS Time 12 (years 2020-2021, the outcome wave).  This allow for adjustment owing to attition and loss to follow up (see details of the `lmtp` package [@williams2021]) -->

<!-- #### Exclusion Criteria -->

<!-- -   Participants who did not respond to the religious service attendance question at baseline or the exposure wave.  -->

<!-- -   Participants who did not respond to the hours socialising question at baseline or the exposure wave.  -->

<!-- -   We allowed loss-to-follow-up in the outcome wave (NZAVS wave 2020); missing values owing to attrition and non-response were handled using censoring weights. -->

<!-- There were N = X  NZAVS participants who met these criteria. -->

<!-- ###  Method for confounding control -->

<!-- Effects should temporally succeed their causes. To circumvent reverse causation issues, outcomes were assessed in the year succeeding exposure, specifically the 2020 wave of the NZAVS. The causal diagram in @fig-outcomewide-dag outlines our approach to confounding control. We align with @vanderweele2020 in employing a *modified disjunctive cause criterion*, articulated as follows: -->

<!-- 1.  **Identify all relevant factors**: initially, enumerate all covariates affecting either the exposure or the outcomes across five domains, or both. These factors encompass variables influencing exposure or outcome and variables that could be consequences of such factors -->

<!-- 2.  **Remove instrumental variables**: subsequently, remove any factors identified as instrumental variables—factors influencing the exposure but not the outcome. The inclusion of instrumental variables diminishes efficiency. -->

<!-- 3.  **Include proxy variables for unmeasured common causes**: for unmeasured variables affecting both exposure and outcome, attempt to include a proxy variable. A proxy serves as a consequent of the unmeasured variable. -->

<!-- 4.  **Control for previous exposure**: accounting for prior exposure is imperative for assessing incident exposure as opposed to prevalent exposure. This step enhances confounding control and aids in sidestepping reverse causation and other unmeasured confounders. This ensures that any unmeasured confounder would need to affect both the outcome and the initial exposure, regardless of prior exposure levels, to account for an observed exposure-outcome association [@danaei2012; @hernan2023]. -->

<!-- 5.  **Control for baseline outcome**: controlling for the outcome at baseline is crucial for ruling out reverse causation. While this does not fully preclude reverse causation, it minimises its impact. Therefore, the baseline outcome, along with a comprehensive set of covariates, should be part of the model to render the confounding control assumption plausible. The baseline outcome often serves as the most potent confounder affecting both the exposure and subsequent outcome [@vanderweele2020]. -->

<!-- To mitigate bias from missing data due to non-response or panel attrition, we imputed missing values using the mice package in R [@vanbuuren2018]. To address non-response or missingness at follow-up, we employed censoring weights, integrated into our semi-parametric models. Valid inferences for the New Zealand population were secured by applying post-stratification census weights for age, European ethnicity, and gender. -->



**Treatment Model**: in the context of causal inference, a treatment model estimates the probability of receiving the treatment based on observed characteristics (covariates). In ordinary regression, this would be akin to the predictor variables in the model but modelling the treatment.

**Outcome Model**: this estimates the potential outcomes of interest, here, measures of well-being, conditional on treatment status and other covariates. In traditional regression settings, this model is what you typically fit to understand how predictors influence the outcome.

By using TMLE to combine both a treatment and outcome model, we can better identify the treatment effect. Here are the steps: 

1.  **Treatment model with propensity scores**: the initial phase of our analysis consists of generating propensity scores for the exposure for each participant. These scores quantify the probability of an individual having the treatment, conditional on their set of covariates.  **In plain terms,** we first calculate a score for each person that indicates how likely they are to experience the treatment based on various characteristics.This step is like determining each person's chances of having the treatment, given their particular life circumstances.

2.  **Weighting via propensity scores**: upon computing the propensity scores, we assign an inverse probability weight to each dataset entry. These weights serve to equilibrate the distribution of observed covariates between the treated and untreated cohorts, thus attenuating the bias in the causal estimates. **In plain terms,** we use propensity scores to make the contrast groups more comparable in a manner that emulates randomisation in experiments.

3.  **Outcome models**: a second targeted machine learning model focuses on the outcome variables, encompassing multiple measures of the outcome distributed across different domains of interest. This model incorporates both the individual treatment statuses and the previously calculated weights, enhancing our capacity for causal inference. **In plain terms** we create a model that tries to predict well-being levels based on whether experiences the treatment under consideration, while also considering conditional on covariates.

4.  **Doubly robust estimation**: Combines the treatment and outcome model to obtain robust results: only one of the two models needs to be correctly specified.

5.  **Counterfactual contrasts**: a core component of TMLE is the projection of counterfactual outcomes. By combining estimates from the treatment and outcome models, TMLE enables the computation of potential well-being levels for each individual under the treatment conditions that are contrasted. **In plain terms:** We use the models to estimate what someone's outcomes under two scenarios: treatment condition $A=a*$ versus treatment condition $A = a$. Note that our shift estimand, described below, helps to make the assumptions required for such contrasts more credible.

6.  **Effect estimation**: the final analytical stage involves determining the average treatment effect by contrasting the estimated counterfactual outcomes.

#### Survey weights

Where the distribution of variables related to a study is known, for example from national census data, it is generally advisable to employ survey weights in one's data.  Appendix 

#### Missing responses

See Part 5.

#### Inverse probability of censoring weights

See Part 5.

#### Example language for reporting the estimator

> We employ a semi-parametric estimator known as Targeted Minimum Loss-based Estimation (TMLE), which is adept at estimating the causal effect of modified treatment policies on outcomes over time. Estimatation was performed using `lmtp` package [@williams2021]. TMLE is a robust method that combines machine learning techniques with traditional statistical models to estimate causal effects while providing valid statistical uncertainty measures for these estimates.

> TMLE operates through a two-step process involving both outcome and treatment (exposure) models. Initially, it employes machine learning algorithms to flexibly model the relationship between treatments, covariates, and outcomes. This flexibility allows TMLE to account for complex, high-dimensional covariate spaces without imposing restrictive model assumptions. The outcome of this step is a set of initial estimates for these relationships.

> The second step of TMLE involves "targeting" these initial estimates by incorporating information about the observed data distribution to improve the accuracy of the causal effect estimate. This is achieved through an iterative updating process, which adjusts the initial estimates towards the true causal effect. This updating process is guided by the efficient influence function, ensuring that the final TMLE estimate is as close as possible to the true causal effect while still being robust to model misspecification in either the outcome or treatment model.

> A central feature of TMLE is its double-robustness property, meaning that if either the model for the treatment or the outcome is correctly specified, the TMLE estimator will still consistently estimate the causal effect. Additionally, TMLE uses cross-validation to avoid overfitting and ensure that the estimator performs well in finite samples. Each of these steps contributes to a robust methodology for examining the *causal* effects of interventions on outcomes. The integration of TMLE and machine learning technologies reduces the dependence on restrictive modelling assumptions and introduces an additional layer of robustness. For further details see [@hoffman2022; @hoffman2023; @díaz2021]

#### Example of a Sensitivity Analysis Using E-values

#### Definition of the E-value

> The minimum strength of association on the risk ratio scale that an unmeasured confounder would need to have with both the exposure and the outcome, conditional on the measured covariates, to fully explain away a specific exposure-outcome association

See: [@vanderweele2020; @mathur2018a]

For example, suppose that the lower bound of the the E-value was 1.3 with the lower bound of the confidence interval = 1.12, we might then write:

> With an observed risk ratio of RR=1.3, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 1.3-fold each (or 30%), above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 1.12-fold (or 12%) each could do so, but weaker joint confounder associations could not.

The equations are as follows (for risk ratios)

$$
E-value_{RR} = RR + \sqrt{RR \times (RR - 1)}
$$ $$
E-value_{LCL} = LCL + \sqrt{LCL \times (LCL - 1)}
$$

Here is an R function that will calculate E-values:

```{r}
calculate_e_value <- function(rr, lcl) {
  e_value_rr = rr + sqrt(rr*(rr - 1))
  e_value_lcl = lcl + sqrt(lcl*(lcl - 1))
  
  list(e_value_rr = e_value_rr, e_value_lcl = e_value_lcl)
}

# e.g. smoking causes cancer

# finding 	RR = 10.73 (95% CI: 8.02, 14.36)

calculate_e_value(10.73, 8.02)

```

Using VanderWeele's recommended reporting language, we may write:

> "With an observed risk ratio of RR=10.7, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 20.9-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 15.5-fold each could do so, but weaker joint confounder associations could not."

```{r}
#| label: evalue_ols
#| echo: true
compute_evalue_ols <- function(est, se, delta = 1, true = 0) {
  # rescale estimate and SE to reflect a contrast of size delta
  est <- est / delta
  se <- se / delta

  # compute transformed odds ratio and confidence intervals
  odds_ratio <- exp(0.91 * est)
  lo <- exp(0.91 * est - 1.78 * se)
  hi <- exp(0.91 * est + 1.78 * se)

  # compute E-Values based on the RR values
  evalue_point_estimate <- odds_ratio * sqrt(odds_ratio + 1)
  evalue_lower_ci <- lo * sqrt(lo + 1)

  # return E-values
  return(list(EValue_PointEstimate = evalue_point_estimate,
              EValue_LowerCI = evalue_lower_ci))
}

# e.g stimate of 0.5, a standard error of 0.1, and a standard deviation of 1.
results <- compute_evalue_ols(est = 0.5, se = 0.1, delta = 1)
print(results)
```

For one's report, Vanderweele suggests using the following language without modification:

> "With an observed risk ratio of RR=2.92, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 2.92-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 2.23-fold each could do so, but weaker joint confounder associations could not."

Note the E-values package will do the computational work for us. It returns a similar value as the E-Values function. 


```{r}
#| label: evalues
#| echo: true

# load package
library(EValue)

EValue::evalues.OLS( est = 0.5, se = 0.1, sd = 1, delta = 1, true = 0 )
```

## Part 4: Pre-registration, Data Analysis, and Reporting

We describe the protocols for pre-registration analysis, conducting these data analyses, and clearly and accurately communicating scientific findings.

### Recommended strategies for conveying results

- Report results of a cross-sectional model
- Explain the practical interest of causal effect estimates
- Contrast exposures: tread carefully


{{< pagebreak >}}


## Part 5: Addressing complex causal questions

We discuss methods for addressing more complex causal questions than average treatment-effect estimation, including investigating treatment-effect heterogeneity, causal interactions, causal mediation, and longitudinal treatment strategies.


::: {#tbl-time-varying-confounding}

```{=latex}
\terminologytimevaryingconfounding
```
Sources of time-varying confounding for more ambitious causal questions.  (This table is adapted from [@bulbulia2023])
:::

For further discussions of our approach, see: [@bulbulia2023a; @bulbulia2023; @bulbulia2022; @vanderweele2015; @hernan2023])


### Challenges from Measurement error bias


::: {#tbl-measurement-error}

```{=latex}
\terminologymeasurementerror
```
Measurement error bias may be undirected and uncorrelated, directed and uncorrelated, uncorrelated and directed, or correlated and undirected.  (This table is adapted from [@bulbulia2023])
:::



### Challenges for Censoring bias


::: {#tbl-censoring}

```{=latex}
\terminologycensoring
```
Examples of censoring bias.  (This table is adapted from [@bulbulia2023])
:::




### Challenges for External Validity

::: {#tbl-external-validity-confounding}

```{=latex}
\terminologyselectionrestrictionclassic
```
Examples of external validity threats from pre-exposure confounding.  (This table is adapted from [@bulbulia2023])
:::


::: {#tbl-external-validity-no-bias}

```{=latex}
\terminologyselectionrestrictionbaseline
```
Examples of external validity threats from restriction at baseline, or mismatch between the target and sample populuations.  (This table is adapted from [@bulbulia2023])
:::




## Conclusions: Summary of Advice




1.  **Clarify the causal question:** To answer a causal question we must first ask one [@hernan2023; @hernan2017per].
Prior to any analysis, it is crucial to explicitly define the causal question under examination. Within this: 

  - **Define your exposure.**
  - **Define your outcome(s)**
  - **Define causal estimand and its scale** 

2.  **Clearly define the target population**: for whom do we intend the results to generalise? For example, we might restrict our question to the population of people who identify as religious. Where relevant, survey weights should always be collected and used to obtain valid estimates for target population outcomes.

Suppose we wish to investigate the causal effect of religious service attendance on cooperation. As yet, there is no causal question. Within the umbrella term of "religious service attendance" multiple scenarios can be considered: attending religious service weekly service; attending some religious service from a baseline of no attendance, or losing religious service attendance.

A clearly defined question might contrast might be: "What is the expected causal effect of attending religious service at least weekly among those who do not attend weekly, contrasted with natural expectation were no intervention to occur?" (Note: this is a "shift intervention.")


3.  **Clearly state eligibility criteria.**: state inclusion/exclusion criteria to obtain valid causal estimates. Note that these criteria always relate to a target population.

4.  **Ensure correct temporal order in the variables in one’s data**: causality occurs in time. Confounders occur before exposures, which in turn must occur before the outcome.

5.  **Balance confounders**: once the temporal structure is set, we may adjust for confounders that could distort the causal link between exposure and outcome.

6.  **Include baseline measures of the treatment and outcome**: with at least three waves of data, we should include baseline measures for both the treatment and the outcomes. This strategy serves two objectives: first, it augments control for confounding variables, and second, it permits differentiation between "incidence" and "prevalence" effects. *Incidence effects* capture the emergence of new cases or conditions among individuals who acquire the treatment during the study. 

7.  **Adjust for missing data**: we generally recommend using inverse probability of censoring weights which may carry fewer assumptions that multiply imputing missing values.

8.  **Assess multiple dimensions of the outcome within the same study**: where scientifically relevant, we recommend using an outcomewide approach [@vanderweele2020] to assess multiple outcomes within a single study. This approach has several benefits.

First we obtain *contextualised effects*: each outcome is evaluated in context relative to the others. This facilitates a better understanding of the importance of each individual effect within the overarching construct of well-being.

Second, we *mitigate* spurious findings: by assessing multiple outcomes simultaneously, we minimise the risk of cherry-picking cases that confirm a preconceived hypothesis, thereby reducing the likelihood of chance findings.

Third, we *accelerate scientific understanding*: a comprehensive assessment can fast-track our scientific insights into the potential advantages and disadvantages of the treatment on multiple outcomes.

9.  **Where sample size permits, use machine learning with cross-validation**: Targeted Maximum Likelihood Estimation (TMLE) coupled with machine learning (the `SuperLearner` library in R [@polley2023]) has several advantages: first it reduces reliance on the assumption of a correctly specified model. The method is robust even if either the treatment model or the outcome model is incorrectly specified. Second, *machine Learning for confounder balancing improves precision* and further refines our ability to balance confounders, particularly when these are high-dimensional or interact in ways that cannot be known in advance [@díaz2021].

10. **Clearly state results using graphs**: it is often sensible to estimate effect using standardised outcomes which allows for ready graphical comparison. However, in some cases, effects on the data scale are more meaningful, in which case graphical comparisons may be misleading.

11. **Quantitatively assess robustness to unmeasured confounding**: report sensitivity analysis such as E-values.

12. **Measurement error**: note that all data, and in particular self-report data, may be subject to random measurement error. Given the limitations of self-report measures, the true effect sizes may differ from those estimated. Importantly, overly modest effects could arise, in part, from uncorrelated measurement inaccuracy in the treatment and outcomes.

13. **Generalisability and transportability**: findings should be interpreted within the context of the target population. Although the results may have broader relevance, direct extrapolation to different populations or sociocultural settings should only be undertaken cautiously

14 **Theoretical and practical relevance**: when describing the relevance of the data, it can be useful to state regression coefficients from cross-sectional data using models that do not adequately obtain casual effect estimates. In our experience, the results of "standard" models will be different, sometimes considerably so. Data simulations may also help to drive home the importance of adopting a careful causal inference approach.

{{< pagebreak >}}

<!-- ### Ethics -->

<!-- The NZAVS is reviewed every three years by the University of Auckland Human Participants Ethics Committee. Our most recent ethics approval statement is as follows: The New Zealand Attitudes and Values Study was approved by the University of Auckland Human Participants Ethics Committee on 26/05/2021 for six years until 26/05/2027, Reference Number UAHPEC22576. -->

## Acknowledgements

JB received support from TRT0418. JB received support from the Max Planck Institute for the Science of Human History. The funders had no role in preparing the manuscript or the decision to publish.


{{< pagebreak >}}

## Appendix A. Example of a transition table to verify positivity

### Example transition matrix

```{r}
#| label: verify-positivity-data-dogs
#| eval: false
#| echo: false

# transition_table_socialising
# transition_table_socialising_shift
```

@tbl-transition-socialising shows a transition matrix captures the movement between weekly hours socialising during the baseline (NZAVS time 10) wave and exposure wave (NZAVS time 11). Entries on the diagonal (in bold) indicate the number of individuals who stayed in their initial state. In contrast, the off-diagonal shows the transitions from the initial state (bold) to another state in the following wave (off diagonal). Again, a cell located at the intersection of row $i$ and column $j$, where $i \neq j$, shows the count of individuals moving from state $i$ to state $j$.

|  From   |  State 0  | State 1  | State 2 | State 3 | State 4 | State 5 | State 6 | State 7 | State 8 |
|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| State 0 | **20039** |   2243   |  1192   |   221   |   25    |   12    |    7    |    3    |    6    |
| State 1 |   2288    | **1389** |   731   |   103   |   11    |    4    |    3    |    0    |    0    |
| State 2 |   1328    |   660    | **806** |   161   |   29    |    6    |    2    |    1    |    2    |
| State 3 |    236    |   101    |   151   | **76**  |   17    |    5    |    1    |    0    |    0    |
| State 4 |    55     |    16    |   32    |   17    | **11**  |    3    |    1    |    2    |    0    |
| State 5 |    16     |    5     |    8    |    4    |    3    |  **0**  |    1    |    0    |    0    |
| State 6 |     8     |    1     |    0    |    0    |    1    |    0    |  **0**  |    0    |    1    |
| State 7 |     3     |    1     |    1    |    1    |    0    |    0    |    0    |  **0**  |    0    |
| State 8 |     3     |    1     |    1    |    1    |    1    |    0    |    0    |    0    |  **1**  |

: Transition matrix for change in the square of hours socialing with community each week {#tbl-transition-socialising}

@tbl-transition-socialising presents a summary of changes in socialising at the threshold that we compared. When shifting to socialising at least 1.4 hours per week, we imagine 'treating' 25,959 cases. Again this table is for illustration, as the the shift intervention allows us to flexibly contrast cases without projecting the entire population into one or another cell.

|         From         | \< 1.4 weekly hours | \>= 1.4 weekly hours |
|:--------------------:|:-------------------:|:--------------------:|
| \< 1.4 weekly hours  |      **25959**      |         2318         |
| \>= 1.4 weekly hours |        2434         |       **1347**       |

: Transition matrix for change in the square of hours socialing with community each week {#tbl-transition-socialising-shift}



## Appendix B. Example report of estimator




## Appendix C. Baseline in NZAVS

#### Age (waves: 1-15)

We asked participants' age in an open-ended question ("What is your age?" or "What is your date of birth").

#### Disability (waves: 5-15)

We assessed disability with a one-item indicator adapted from @verbrugge1997, that asks "Do you have a health condition or disability that limits you, and that has lasted for 6+ months?" (1 = Yes, 0 = No).

#### Education Attainment (waves: 1, 4-15)

Participants were asked "What is your highest level of qualification?". We coded participants highest finished degree according to the New Zealand Qualifications Authority. Ordinal-Rank 0-10 NZREG codes (with overseas school quals coded as Level 3, and all other ancillary categories coded as missing) See: https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf

#### Employment (waves: 1-3, 4-11)

We asked participants "Are you currently employed? (This includes self-employed or casual work)". \* note: This question disappeared in the updated NZAVS Technical documents (Data Dictionary).

#### European (waves: 1-15)

Participants were asked "Which ethnic group do you belong to (NZ census question)?" or "Which ethnic group(s) do you belong to? (Open-ended)" (wave: 3). Europeans were coded as 1, whereas other ethnicities were coded as 0.

#### Ethnicity (waves: 3)

Based on the New Zealand Census, we asked participants "Which ethnic group(s) do you belong to?". The responses were: (1) New Zealand European; (2) Māori; (3) Samoan; (4) Cook Island Māori; (5) Tongan; (6) Niuean; (7) Chinese; (8) Indian; (9) Other such as DUTCH, JAPANESE, TOKELAUAN. Please state:. We coded their answers into four groups: Maori, Pacific, Asian, and Euro (except for Time 3, which used an open-ended measure).

#### Gender (waves: 1-15)

We asked participants' gender in an open-ended question: "What is your gender?" or "Are you male or female?" (waves: 1-5). Female was coded as 0, Male was coded as 1, and gender diverse coded as 3 [@fraser_coding_2020]. (or 0.5 = neither female nor male)

#### Income (waves: 1-3, 4-15)

Participants were asked "Please estimate your total household income (before tax) for the year XXXX". To stabilise this indicator, we first took the natural log of the response + 1, and then centred and standardised the log-transformed indicator.

<!-- #### Job Security (waves: 1-3,4-7,9-15) -->

<!-- Participants indicated their feeling of job security by answering "How secure do you feel in your current job?" on a scale from 1 (not secure) to 7 (very secure). -->

<!-- #### Parent (waves: 5-15) -->

<!-- Participants were asked: "If you are a parent, what is the birth date of your eldest child?" or "If you are a parent, in which year was your eldest child born?" (waves: 10-15). Parents were coded as 1, while the others were coded as 0. -->

#### Number of Children (waves: 1-3, 4-15)

We measured the number of children using one item from @Bulbulia_2015. We asked participants "How many children have you given birth to, fathered, or adopted. How many children have you given birth to, fathered, or adopted?" or "How many children have you given birth to, fathered, or adopted. How many children have you given birth to, fathered, and/or parented?" (waves: 12-15).

#### Political Orientation

We measured participants' political orientation using a single item adapted from @jost_end_2006-1.

"Please rate how politically liberal versus conservative you see yourself as being."

(1 = Extremely Liberal to 7 = Extremely Conservative)

#### NZSEI-13 (waves: 8-15)

We assessed occupational prestige and status using the New Zealand Socio-economic Index 13 (NZSEI-13) [@fahy2017]. This index uses the income, age, and education of a reference group, in this case, the 2013 New Zealand census, to calculate a score for each occupational group. Scores range from 10 (Lowest) to 90 (Highest). This list of index scores for occupational groups was used to assign each participant an NZSEI-13 score based on their occupation.

Participants were asked, "If you are a parent, what is the birth date of your eldest child?".

#### Living with Partner

Participants were asekd "Do you live with your partner?" (1 = Yes, 0 = No).

#### Living in an Urban Area (waves: 1-15)

We coded whether they are living in an urban or rural area (1 = Urban, 0 = Rural) based on the addresses provided.

We coded whether they were living in an urban or rural area (1 = Urban, 0 = Rural) based on the addresses provided.

#### NZ Deprivation Index (waves: 1-15)

We used the NZ Deprivation Index to assign each participant a score based on where they live [@atkinson2019]. This score combines data such as income, home ownership, employment, qualifications, family structure, housing, and access to transport and communication for an area into one deprivation score.

#### NZ-Born (waves: 1-2,4-15)

We asked participants "Which country were you born in?" or "Where were you born? (please be specific, e.g., which town/city?)" (waves: 6-15).

#### Mini-IPIP 6 (waves: 1-3,4-15)

We measured participants personalities with the Mini International Personality Item Pool 6 (Mini-IPIP6) [@sibley2011] which consists of six dimensions and each dimension is measured with four items:

1.  agreeableness,

    i.  I sympathize with others' feelings.
    ii. I am not interested in other people's problems. (r)
    iii. I feel others' emotions.
    iv. I am not really interested in others. (r)

2.  conscientiousness,

    i.  I get chores done right away.
    ii. I like order.
    iii. I make a mess of things. (r)
    iv. I ften forget to put things back in their proper place. (r)

3.  extraversion,

    i.  I am the life of the party.
    ii. I don't talk a lot. (r)
    iii. I keep in the background. (r)
    iv. I talk to a lot of different people at parties.

4.  honesty-humility,

    i.  I feel entitled to more of everything. (r)
    ii. I deserve more things in life. (r)
    iii. I would like to be seen driving around in a very expensive car. (r)
    iv. I would get a lot of pleasure from owning expensive luxury goods. (r)

5.  neuroticism, and

    i.  I have frequent mood swings.
    ii. I am relaxed most of the time. (r)
    iii. I get upset easily.
    iv. I seldom feel blue. (r)

6.  openness to experience

    i.  I have a vivid imagination.
    ii. I have difficulty understanding abstract ideas. (r)
    iii. I do not have a good imagination. (r)
    iv. I am not interested in abstract ideas. (r)

Each dimension was assessed with four items and participants rated the accuracy of each item as it applies to them from 1 (Very Inaccurate) to 7 (Very Accurate). Items marked with (r) are reverse coded.

#### Honesty-Humility-Modesty Facet (waves: 10-14)

Participants indicated the extent to which they agree with the following four statements from @campbell2004 , and @sibley2011 (1 = Strongly Disagree to 7 = Strongly Agree)

```         
i.  I want people to know that I am an important person of high status, (Waves: 1, 10-14)
ii. I am an ordinary person who is no better than others.
iii. I wouldn't want people to treat me as though I were superior to them.
iv. I think that I am entitled to more respect than the average person is.
```

### Exposure variable

HERE

### Health well-being outcomes

### Appendix D. Why survey weights should be used when the target population is the national population.

Code to follow...



<!-- ### Appendix E. Population Average Treatment Effect {.appendix} -->

<!-- As indicated in the main manuscript, the Average Treatment Effects is obtained by contrasting the expected outcome when a population sampled is exposed to an exposure level, $E[Y(A = a)]$, with the expected outcome under a different exposure level, $E[Y(A=a')]$. -->

<!-- For a binary treatment with levels $A=0$ and $A=1$, the Average Treatment Effect (ATE), on the difference scale, is expressed: -->

<!-- $$ATE_{\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]$$ -->

<!-- On the risk ratio scale, the ATE is expressed: -->

<!-- $$ATE_{\text{risk ratio}} = \frac{E[Y(1)|L]}{E[Y(0)|L]}$$ -->

<!-- Other effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest. -->

<!-- Here we estimate the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the New Population if applied universally. This quantity can be expressed: -->

<!-- $$PATE_{\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)$$ -->

<!-- $$PATE_{\text{risk ratio}} = f\left(\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\right)$$ -->

<!-- where $f$ is a function that incorporates post-stratification weights $W$ into the estimation of the expected outcomes from which we obtain causal contrasts. Because the NZAVS is a national probability sample, i.e. inverse probability of being sampled 1. However, to incorporate gender, age, and ethnic differences we include post-stratification weight into our outcome-wide models. -->

{{< pagebreak >}}

## References {.appendix}


