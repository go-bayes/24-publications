% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Causal Directed Acyclic Graphs (DAGs) and Single World Intervention Graphs (SWIGs): A Practical Guide},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Causal Directed Acyclic Graphs (DAGs) and Single World
Intervention Graphs (SWIGs): A Practical Guide}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-05-11}
\begin{document}
\maketitle
\begin{abstract}
Causal inference requires contrasting counterfactual states of the world
under pre-specified interventions. Obtaining counterfactual contrasts
from data, in turn, relies on a framework of explicit assumptions and
careful, multi-step workflows. Causal diagrams are powerful tools for
clarifying whether and how the counterfactual contrasts we seek may be
identified from data. Here, I explain how to use two types of causal
diagram (1) causal directed acyclic graphs (DAGs), which are
user-friendly, and (2) single world intervention graphs (SWIGs), which
are complete. I use these tools to clarify frequently misunderstood
concepts of measurement error, interaction, mediation, longitudinal
feedback, and confounding in experiments. Along the way, I offer
practical tips and suggestions to avoid common pitfalls.

\textbf{KEYWORDS}: \emph{Causal Inference}; \emph{Culture};
\emph{DAGs};* \emph{Evolution}; \emph{Human Sciences};
\emph{Longitudinal}; Single World Intervention Graphs, Single World
Intervention Template, SWIGs; SWITs.
\end{abstract}

\subsection{Introduction}\label{introduction}

Human research begins with two questions:

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What do I want to know?
\item
  For which population does this knowledge generalise?
\end{enumerate}
\end{quote}

In the human sciences, questions are typically causal. We want to
understand what would happen if we were to intervene on the variables of
interest. However, many human scientists report non-causal associations.
Standard practice begins is to collect data, to apply regression models
of varying complexity, and to report the coefficients of these models,
describing these coefficients as ``predictions.'' Even when models
predict well it is typically unclear how to relate these coefficients
relate to the scientific questions that animated our interests. The
oracles are mysterious. The good news is that when assumptions are
satisfied, the associations we obtain from data may indicate causality.
For example, when interventions are controlled and randomised, often we
can be be confident that association implies causation. However careful
workflows are needed.

Within the careful workflows required for causal inference, causal
diagrams -- or causal graphs -- help investigators to understand whether
and how causal effects may be identified from data. We require
assumptions because This is a challenging because to quantitatively
address causal questions we must contrast different ways the world might
have been, using data we have obtain from the world as it is realised.
The world as it has been realised only tells us part of any causal
story.

After briefly reviewing the initial steps in a causal inference workflow
that precede deploying causal diagrams, I introduce \textbf{causal
directed acyclic graphs} -- or ``DAGs.'' I explain \textbf{the five
elementary graphical structures} from which all causal directed acyclic
graphs may be derived. The primary purpose a causal directed acyclic
graph encodes investigator assumptions about how variables other than a
treatment variable, or sequence of treatment variables of interest may
lead to non-causal associations with the outcome or outcomes of
interest. Our primary focus here will be on the application of causal
directed acyclic graphs to evaluating non-causal relations of
confounding bias. However we will also consider applications of causal
directed acyclic graphs to threats of measurement or information bias,
and to threats of sample-restriction bias, which some investigators also
call ``selection'' bias.

Next, I explain how the application of \textbf{the four elementary
rules} allows investigators to evaluate whether and how, conditional on
the structural assumptions encoded in a causal diagram, investigators
may identify causal effects from the relations they have assumed to hold
in the world. I then proceed with a series of illustrations that
demonstrate how applying the \textbf{the four elementary rules} to
different combinations of \textbf{the five elementary structures}
clarifies whether consistent estimates of magnitudes may be obtained
from observational data focussing on: (1) the imperative for temporal
order in data; (2) the insufficiency of temporal order for
identification; (3) measurement-error biases (4) sample-restriction
biases (5) confounding biases in experiments; (6) confounding and
sample-restriction biases in time-fixed and time-varying sequential
treatments.

Next, I introduce single world intervention graphs -- also known as
SWIGs, which are useful for evaluating structural sources of bias when
there are time-varying treatments. Another advantage of single world
intervention graphs is that they are fully general. They allow
investigators to encode assumptions about the conditional dependencies
for the counterfactuals data from which their causal contrasts are
derived.

At first, it might seem strange that relationships must be assumed when
learning about relationships. However, understanding this requirement is
essential for using causal diagrams responsibly

I provide a glossary at the end of this article to help readers wade
through what has evolved into a terminological quagmires. However
readers should keep in mind that the elementary concepts underpinning
causal inference are not complex.

Unfortunately a proliferation of terminology has muddled what are
essentially

Third, we apply the four elementary rules to problems, revealing that
collecting or aligning our data with the presumed order of causality, in
which causes precede effects, greatly reduces opportunities for
confounding

Fourth, we use to explain failure modes for caual inference, even when
temporal order in one's data is assured.

Fifth, we use causal diagrams to clarify confounding in randomised
experiments

Finally, we offer practical advice about how to construct causal
directed acyclic graphs, and suggest best practices

\subsection{Preliminaries}\label{preliminaries}

Causal diagrams, also called causal graph are graphical tools whose
primary purpose is to enable investigators to evaluate identifications
assumptions. Here, we will mostly focus on threats to identification
arising from confounding biases.

\textbf{Confounding bias}: there is no confounding bias if:

\begin{itemize}
\tightlist
\item
  the distribution of variables that might affect the outcome are
  imbalanced in the treatment groups to be compared
\end{itemize}

Causal graphs allow us to say:\\
- if there is no open back-door path between the treatment and the path
between the treatment and outcome is unblocked, there is no confounding
bais.

Before describing how causal diagrams work, we first define the meanings
of their symbols. Note there is no single convention for creating causal
graph, so it is important that we are clear when defining our meanings.

The concept of ``confounding bias'' helps to clarify what it is at stake
when evaluating the \emph{internal validity} of a study.

\newpage{}

\subsection{Variable naming
conventions}\label{variable-naming-conventions}

\begin{table}

\caption{\label{tbl-terminology}Variable naming conventions}

\centering{

\terminologylocalconventions

}

\end{table}%

For us:

\textbf{\(X\) denotes a random variable without reference to its role}

\textbf{\(A\) denotes the ``treatment'' or ``exposure'' variable.}

This is the variable for which we seek to understand the effect of
intervening on it. It is the ``cause;''

\textbf{\(Y\) denotes the outcome or response of an intervention.}

It is the ``effect.'' Last week we considered whether marriage \(A\)
causes happiness \(Y\).

\textbf{\(Y(a)\) denotes the counterfactual or potential state of \(Y\)
in response to setting the level of the exposure to a specific level,
\(A=a\).}

As we will consider in the second half of the course, to consistently
estimate causal effects we will need to evaluate counterfactual or
potential states of the world. Keeping to our example, we will need to
do more than evaluate marriage and happiness in people over time. We
will need to evaluate how happy the unmarried people would have been had
they been married and how happy the married people would have been had
they not been married. Of course, these events cannot be directly
observed. Thus to address fundamental questions in psychology, we need
to contrast counterfactual states of the world. This might seem like
science fiction; however, we are already familiar with methods for
obtaining such counterfactual contrasts -- namely, randomised controlled
experiments! We will return to this concept later, but for now, it will
be useful for you to understand the notation.

\textbf{\(L\) denotes a measured confounder or set of confounders}

\begin{itemize}
\tightlist
\item
  This set, if conditioned upon, closes an open back-door path between
  the treatment \(A\) and the outcome \(Y\).
\end{itemize}

Consider a scenario where happiness at time 0, \(L\), affects both the
probability of getting married at time 1, \(A\), and one's happiness at
time 2, \(Y\).

In this case, \(L\) serves as a confounder because it influences both
the treatment (marriage at time 1) and the outcome (happiness at time
2), potentially opening a back-door path that confounds the estimated
effect of marriage on happiness.

To accurately estimate the causal effect of marriage on happiness, then,
it is essential to control for \(L\). With cross-sectional data, such
control might be difficult.

\textbf{\(U\) denotes an unmeasured confounder}

\begin{itemize}
\tightlist
\item
  that is a variable that may affect both the treatment and the outcome,
  but for which we have no direct measurement. Suppose cultural
  upbringing affects both whether someone gets married and whether they
  are happy.
\end{itemize}

If this variable is not measured, we cannot accurately estimate a causal
effect of marriage on happiness.

\textbf{\(M\) denotes a mediator or a variable along the path from
exposure to outcome.}

For example, perhaps marriage causes wealth and wealth causes happiness.
As we shall see, conditioning on ``wealth'' when estimating the effect
of marriage on happiness will make it seem that marriage does not cause
happiness when it does, \emph{through} wealth.

**\(\bar{X}\) denotes a sequence of variables, for example, a sequence
of treatments.

Imagine we were interested in the causal effect of marriage and
remarriage on well-being. In this case, there are two treatments \(A_0\)
and \(A_1\) and four potential contrasts. For the scenario of marriage
and remarriage affecting well-being, we denote the potential outcomes as
\(Y(a_0, a_1)\), where \(a_0\) and \(a_1\) represent the specific values
taken by \(A_0\) and \(A_1\), respectively. Given two treatments,
\(A_0\) and \(A_1\), there are four primary contrasts of interest
correspond to the different combinations of these treatments. These
contrasts allow us to compare the causal effects of being married versus
not and of being remarried versus not on well-being. The potential
outcomes under these conditions can be specified as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(Y(0, 0)\): The potential outcome when there is no marriage.
\item
  \(Y(0, 1)\): The potential outcome when there is marriage.
\item
  \(Y(1, 0)\): The potential outcome when there is divorce.
\item
  \(Y(1, 1)\): The potential outcome from marriage prevalence.
\end{enumerate}

Each of these outcomes allows for a specific contrast. Which do we want
to contrast? We can see the question about `the causal effects of
marriage on happiness' is ambiguous. We must stated the causal contrast
we are interested in, given our substantive research interests.

\textbf{\(\mathcal{R}\) denotes a randomisation or a chance event.}

\subsubsection{Elements of our Causal
Graphs}\label{elements-of-our-causal-graphs}

The conventions that describe components of our causal graphs are given
in \textbf{?@fig-general}.

\begin{table}

\caption{\label{tbl-general}Nodes, Edges, Conditioning Conventions.}

\centering{

\terminologygeneral

}

\end{table}%

\paragraph{Time indexing}\label{time-indexing}

In our causal diagrams, we will implement two conventions to accurately
depict the temporal order of events.

First, the layout of a causal diagram will be structured from left to
right to reflect the sequence of causality as it unfolds in reality.
This orientation is crucial because causal diagrams must inherently be
acyclic and because causality itself is inherently temporal.

Second, we will enhance the representation of the event sequence within
our diagrams by systematically indexing our nodes according to the
relative timing of events. If an event represented by \(X_0\) precedes
another event represented by \(X_1\), the indexing will indicate this
chronological order.

\paragraph{Representing uncertainty in timing
explicitly}\label{representing-uncertainty-in-timing-explicitly}

In settings in which the sequence of events is ambiguous or cannot be
definitively known, particularly in the context of cross-sectional data
where all measurements are taken at a single point in time, we adopt a
specific convention to express causality under uncertainty:
\(X_{\phi t}\). This notation allows us to propose a temporal order
without clear, time-specific measurements, acknowledging our
speculation.

For instance, when the timing between events is unclear, we denote an
event that is presumed to occur first as \(X_{\phi 0}\) and a subsequent
event as \(X_{\phi 1}\), indicating a tentative ordering where
\(X_{\phi 0}\) is thought to precede \(X_{\phi 1}\). However, it is
essential to underscore that this notation signals our uncertainty
regarding the actual timing of events; our measurements do not give us
the confidence to assert this sequence definitively.

\paragraph{Terminology Arrows/ Directed
Paths}\label{terminology-arrows-directed-paths}

As indicated in \textbf{?@fig-general}, black arrows denote causality,
red arrows reveal an open backdoor path, dashed black arrows denote
attenuation, and red dashed arrows denote bias in a true causal
association between \(A\) and \(Y\). Finally, a blue arrow with a circle
point denotes effect-measure modification, also known as ``effect
modification.'' We might be interested in treatment effect heterogeneity
without evaluating the causality in the sources of this heterogeneity.
For example, we cannot typically imagine any intervention in which
people could be randomised into cultures. However, we may be interested
in whether the effects of an intervention that might be manipulable,
such as marriage, differ by culture. To clarify this interest, we
require a non-causal arrow.

\(\mathcal{R}\to A\) denotes a random treatment assignment.

\paragraph{Boxes}\label{boxes}

We use a black box to denote conditioning that reduces confounding or
that is inert.

We use a red box to describe settings in which conditioning on a
variable introduces confounding bias.

Occasionally we will use a dashed circle do denote a latent variable,
that is, a variable that is either not measured or not conditioned upon.

\paragraph{Terminology for Conditional
Independence}\label{terminology-for-conditional-independence}

The bottom panel of \textbf{?@fig-general} shows some mathematical
notation. Do not be alarmed, we are safe! Part 1 of the course will not
require more complicated math than this notation. And we shall see that
the notation is a compact way to describe intuitions that can be
expressed less compactly in words:

\begin{itemize}
\item
  \textbf{Statistical Independence (\(\coprod\)):} in the context of
  causal inference, statistical independence between the treatment and
  potential outcomes, denoted as \(A \coprod Y(a)\), means the treatment
  assignment is independent of the potential outcomes. This assumption
  is critical for estimating causal effects without bias.
\item
  \textbf{Statistical Dependence (\(\cancel\coprod\)):} conversely,
  \(\cancel\coprod\) denotes statistical dependence, indicating that the
  distribution of one variable is influenced by the other. For example,
  \(A \cancel\coprod Y(a)\) implies that the treatment assignment is
  related to the potential outcomes, potentially introducing bias into
  causal estimates.
\item
  \textbf{Conditioning (\(|\)):} conditioning, denoted by the vertical
  line \(|\), allows for specifying contexts or conditions under which
  independence or dependence holds.

  \begin{itemize}
  \item
    \textbf{Conditional Independence (\(A \coprod Y(a)|L\)):} This means
    that once we account for a set of variables \(L\), the treatment and
    potential outcomes are independent. This condition is often the
    basis for strategies aiming to control for confounding.
  \item
    \textbf{Conditional Dependence (\(A \cancel\coprod Y(a)|L\)):}
    States that potential outcomes and treatments are not independent
    after conditioning on \(L\), indicating a need for careful
    consideration in the analysis to avoid biased causal inferences.
  \end{itemize}
\end{itemize}

\subsection{The Five Elementary Structures of
Causality}\label{the-five-elementary-structures-of-causality}

Judea Pearl proved that all elementary structures of causality can be
represented graphically (\citeproc{ref-pearl2009a}{Pearl 2009}).
\textbf{?@fig-directedgraph} presents this five elementary structures.

\begin{table}

\caption{\label{tbl-fiveelementary}Elementary structures of causality}

\centering{

\terminologydirectedgraph

}

\end{table}%

The structures are as follows:

\begin{itemize}
\tightlist
\item
  \textbf{Two Variables:}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \textbf{Causality Absent:} There is no causal effect between
    variables \(A\) and \(B\). They do not influence each other, denoted
    as \(A \coprod B\), indicating they are statistically independent.
  \item
    \textbf{Causality:} Variable \(A\) causally affects variable \(B\).
    This relationship suggests an association between them, denoted as
    \(A \cancel\coprod B\), indicating they are statistically dependent.
  \end{enumerate}
\item
  \textbf{Three Variables:}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    \textbf{Fork:} Variable \(A\) causally affects both \(B\) and \(C\).
    Variables \(B\) and \(C\) are conditionally independent given \(A\),
    denoted as \(B \coprod C | A\). This structure implies that knowing
    \(A\) removes any association between \(B\) and \(C\) due to their
    common cause.
  \item
    \textbf{Chain:} A causal chain exists where \(C\) is affected by
    \(B\), which in turn is affected by \(A\). Variables \(A\) and \(C\)
    are conditionally independent given \(B\), denoted as
    \(A \coprod C | B\). This indicates that \(B\) mediates the effect
    of \(A\) on \(C\), and knowing \(B\) breaks the association between
    \(A\) and \(C\).
  \item
    \textbf{Collider:} Variable \(C\) is affected by both \(A\) and
    \(B\), which are independent. However, conditioning on \(C\) induces
    an association between \(A\) and \(B\), denoted as
    \(A \cancel\coprod B | C\). This structure is unique because it
    suggests that \(A\) and \(B\), while initially independent, become
    associated when we account for their common effect \(C\).
  \end{enumerate}
\end{itemize}

Once we understand the basic relationships between two variables, we can
build upon these to create more complex relationships. These structures
help us see how statistical independences and dependencies emerge from
the data, allowing us to clarify the causal relationships we presume
exist. Such clarity is crucial for ensuring that confounders are
balanced across treatment groups, given all measured confounders, so
that \(Y(a) \coprod A | L\).

\newpage{}

\subsection{The Four Rules of Confounding
Control}\label{the-four-rules-of-confounding-control}

Table~\ref{tbl-terminologyconfounders} describe the four elementary
rules of confounding control:

\begin{table}

\caption{\label{tbl-terminologyconfounders}Four rules of confounding
control}

\centering{

\terminologyelconfounders

}

\end{table}%

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Condition on Common Cause or its Proxy}: this rule applies to
  settings in which the treatment (\(A\)) and the outcome (\(Y\)) share
  common causes. By conditioning on these common causes, we block the
  open backdoor paths that could introduce bias into our causal
  estimates. Controlling for these common causes (or their proxies)
  helps tp isolate the specific effect of \(A\) on \(Y\). (We do not
  draw a path from \$ A \to Y\$ because we do not assume this path.)
\item
  \textbf{Do Not Condition on a Mediator}: this rule applies to settings
  in which the variable \(L\) is a mediator of \(A \to Y\). Here,
  conditioning on a mediator will bias the total causal effect estimate.
  Later in the course, we will discuss the assumptions required for
  causal mediation. For now, if we are interested in total effect
  estimates, we must not condition on a mediator. Here we draw the path
  from \(A \to Y\) to ensure that if such a path exists, it will not
  become biased from our conditioning strategy.
\item
  \textbf{Do Not Condition on a Collider}: this rule applies to settings
  in which we \(L\) is a common effect of \(A\) and \(Y\). Conditioning
  on a collider may invoke a spurious association. Last week we
  considered an example in which marriage caused wealth and happiness
  caused wealth. Conditioning on wealth in this setting will induce an
  association between happiness and marriage. Why? If we know the
  outcome, wealth, then we know there are at least two ways of wealth.
  Among those wealthy but low on happiness, we can predict that they are
  more likely to be married, for how else would they be wealthy?
  Similarly, among those who are wealthy and are not married, we can
  predict that they are happy, for how else would they be wealthy if not
  through marriage? These relationships are predictable entirely without
  a causal association between marriage and happiness!
\item
  \textbf{Proxy Rule: Conditioning on a Descendent Is Akin to
  Conditioning on Its Parent}: this rule applies to settings in which we
  \(L’\) is an effect from another variable \(L\). The graph considers
  when \(L’\) is downstream of a collider. For example, suppose we
  condition on home ownership, which is an effect of wealth. Such
  conditioning will open up a non-causal path without causation because
  home ownership is a proxy for wealth. Consider, if someone owns a
  house but is not married, they are more likely to be happy, for how
  else could they accumulate the wealth required for home ownership?
  Likewise, if someone is unhappy and owns a house, we can infer that
  they are more likely to be married because how else would they be
  wealthy? Conditioning on a proxy for a collider here is akin to
  conditioning on the collider itself.
\end{enumerate}

However, we can also use the proxy rule to reduce bias. Return to the
earlier example in which there is an unmeasured common cause of marriage
and happiness, which we called ``cultural upbringing'' Suppose we have
not measured this variable but have measured proxies for this variable,
such as country of birth, childhood religion, number of languages one
speaks, and others. By controlling for baseline values of these proxies,
we can exert more control over unmeasured confounding. Even if bias is
not eliminated, we should reduce bias wherever possible, which includes
not introducing new biases, such as mediator bias, along the way. Later
in the course, we will teach you how to perform sensitivity analyses to
verify the robustness of your results to unmeasured confounding.
Sensitivity analysis is critical because where the data are
observational, we cannot entirely rule out unmeasured confounding.

\newpage{}

\subsection{Direct Acyclic Graphs Reveal The Importance of
Timing}\label{direct-acyclic-graphs-reveal-the-importance-of-timing}

\begin{table}

\caption{\label{tbl-elementary-chronological-hyg}}

\centering{

\captionsetup{labelsep=none}

\terminologychronologicalhygeine

}

\end{table}%

The structural features of \textbf{seven} confounding problems. We shall
discuss examples of each, and how longitudinal data collection resolves
each problem.

\newpage{}

\subsection{Collecting Time Series Data is Insufficient for
Identification}\label{collecting-time-series-data-is-insufficient-for-identification}

\begin{table}

\caption{\label{tbl-chronology-notenough}Common confounding scenarios in
which chronology is not enough.}

\centering{

\terminologychronologicalhygeineNOTENOUGH

}

\end{table}%

\newpage{}

\subsection{Structures of Measurement Error
Biases}\label{structures-of-measurement-error-biases}

\begin{table}

\caption{\label{tbl-measurement-error}Measurement-error bias}

\centering{

\terminologymeasurementerror

}

\end{table}%

\newpage{}

\subsection{Structures of Selection-Restriction Biases from
Attrition}\label{structures-of-selection-restriction-biases-from-attrition}

\begin{table}

\caption{\label{tbl-censoring-bias}Censoring (attrition) bias}

\centering{

\terminologycensoring

}

\end{table}%

\newpage{}

\subsection{Confounding in Randomised Controlled
Experiments}\label{section-confounding-experiments}

\begin{table}

\caption{\label{tbl-experiments}Common confounding scenarios in
experiments}

\centering{

\terminologyelconfoundersexperiments

}

\end{table}%

\newpage{}

\subsection{Single World Intervention
Graphs}\label{single-world-intervention-graphs}

\begin{table}

\caption{\label{tbl-experiments}Common confounding scenarios in
experiments}

\centering{

\swigtable

}

\end{table}%

\newpage{}

\subsection{The Clarity of Single World Intervention Graph: Case
Study}\label{the-clarity-of-single-world-intervention-graph-case-study}

\begin{table}

\caption{\label{tbl-experiments}Common confounding scenarios in
experiments}

\centering{

\pearltable

}

\end{table}%

\newpage{}

\subsection{Advice}\label{advice}

\subsubsection{How to Create Causal Diagrams to Address Causal
Identification Problems
\{sec-how-to-create-causal-diagrams\}}\label{how-to-create-causal-diagrams-to-address-causal-identification-problems-sec-how-to-create-causal-diagrams}

The \textbf{identification problem} centres on whether we can derive the
true causal effect of a treatment (\(A\)) on an outcome (\(Y\)) from
observed data. Addressing the identification problem has two core
components:

\paragraph{First, evaluate bias in the absence of a treatment
effect}\label{first-evaluate-bias-in-the-absence-of-a-treatment-effect}

Before attributing any statistical association to causality, we must
eliminate non-causal sources of correlation. We do this by:

\begin{itemize}
\tightlist
\item
  Identifying factors that influence both treatment (\(A\)) and outcome
  (\(Y\)).
\item
  Developing adjustment strategies to control for confounders.
\item
  Blocking backdoor paths that create indirect, non-causal links between
  \(A\) and \(Y\). By adjusting for confounders, we aim to achieve
  d-separation between \(A\) and \(Y\).
\end{itemize}

\paragraph{Second, evaluate bias in the presence of a treatment
effect}\label{second-evaluate-bias-in-the-presence-of-a-treatment-effect}

After addressing potential confounders, we must ensure any remaining
association between \(A\) and \(Y\) reflects a true causal relationship.
We address \textbf{over-conditioning bias} by:

\begin{itemize}
\tightlist
\item
  Avoiding mediator bias
\item
  Avoiding collider bias
\item
  Verifying that any association between \(A\) and \(Y\) after in
  unbiased after all adjustments.
\end{itemize}

Thus, causal inference demands a delicate balance: identify and control
for confounders but avoid introducing new biases. Here is how
investigators should construct their causal diagrams.

\paragraph{Step 1. Clarify the research question evaluated by the
diagram}\label{step-1.-clarify-the-research-question-evaluated-by-the-diagram}

Before attempting to draw any causal diagram, state the problem your
diagram addresses and the population to whom the problem applies. Causal
identification strategies may vary by question. For example, the
confounding control strategy for evaluating the path \(L\to Y\) will
differ from that of assessing the path \(A\to Y\). For this reason,
reporting coefficients other than the association between \(A \to Y\) is
typically ill-advised; see Westreich and Greenland
(\citeproc{ref-westreich2013}{2013}); McElreath
(\citeproc{ref-mcelreath2020}{2020}); Bulbulia
(\citeproc{ref-bulbulia2023}{2023}).

\paragraph{Step 2. Include all common causes of the exposure and
outcome}\label{step-2.-include-all-common-causes-of-the-exposure-and-outcome}

Incorporate all common causes (confounders) of both the exposure and the
outcome into your diagram. This includes both measured and unmeasured
variables. Where possible, aggregate functionally similar common causes
into a single variable notation (e.g., \(L_0\) for demographic
variables).

\paragraph{Step 3. Include all ancestors of measured confounders linked
with the treatment, the outcome, or
both}\label{step-3.-include-all-ancestors-of-measured-confounders-linked-with-the-treatment-the-outcome-or-both}

Include any ancestors (precursors) of measured confounders that are
associated with either the treatment, the outcome, or both. This step is
crucial for addressing hidden biases arising from unmeasured
confounding. Simplify the diagram by grouping similar variables.

\paragraph{Step 4. Explicitly state assumptions about relative
timing}\label{step-4.-explicitly-state-assumptions-about-relative-timing}

Explicitly annotate the temporal sequence of events using subscripts
(e.g., \(L_0\), \(A_1\), \(Y_2\)). It is imperative that causal diagrams
are acyclic.

\paragraph{Step 5. Arrange temporal order of causality
visually}\label{step-5.-arrange-temporal-order-of-causality-visually}

Arrange your diagram to reflect the temporal progression of causality,
either left-to-right or top-to-bottom. This arrangement enhances the
comprehensibility of causal relations and is vital for dissecting
identification issues as discussed in \hyperref[sec-part3]{\textbf{Part
3}}, establishing temporal ordering is necessary for evaluating
identification problems.

\paragraph{Step 6. Box variables are those variables that we adjust for
to control
confounding}\label{step-6.-box-variables-are-those-variables-that-we-adjust-for-to-control-confounding}

Mark variables for adjustment (e.g., confounders) with boxes.

\paragraph{Step 7. Represent paths structurally, not
parametrically}\label{step-7.-represent-paths-structurally-not-parametrically}

Focus on whether paths exist, not their functional form (linear,
non-linear, etc.). Parametric descriptions are not relevant for bias
evaluation in a causal diagram. (For an explanation of causal
interaction and diagrams, see: Bulbulia
(\citeproc{ref-bulbulia2023}{2023}).)

\paragraph{Step 8. Minimise paths to those necessary for the
identification
problem}\label{step-8.-minimise-paths-to-those-necessary-for-the-identification-problem}

Reduce clutter; only include paths critical for a specific question
(e.g., backdoor paths, mediators).

\paragraph{Step 9. Consider Potential Unmeasured
Confounders}\label{step-9.-consider-potential-unmeasured-confounders}

Leverage domain expertise to clarify potential unmeasured confounders
and represent them in your diagram. This proactive step aids in
anticipating and addressing \emph{all} possible sources of confounding
bias.

\paragraph{\texorpdfstring{\textbf{Step 10. State Graphical
Conventions}}{Step 10. State Graphical Conventions}}\label{step-10.-state-graphical-conventions}

Establish and explain the graphical conventions used in your diagram
(e.g., using red to highlight open backdoor paths). Consistency in
symbol use enhances interpretability, while explicit descriptions
improve accessibility and understanding.

Practical Guide For Constructing Causal Diagrams and Reporting Results
When Causal Structure is Unclear \{\#section-part4\}

\subsubsection{Cross-sectional designs}\label{cross-sectional-designs}

In environmental psychology, researchers often grapple with whether
causal inferences can be drawn from cross-sectional data, especially
when longitudinal data are unavailable. The challenge is common to
cross-sectional designs. However, it is important to appreciate that
even longitudinal studies require careful assumption management. We next
discuss how causal diagrams can guide inference in both data types, with
examples relevant to environmental psychologists.

\paragraph{1. Graphically encode causal
assumptions}\label{graphically-encode-causal-assumptions}

Causal inference turns on assumptions. Although cross-sectional analyses
typically demand much stronger assumptions owing to the snapshot nature
of data, these assumptions, when transparently articulated, do not
permanently bar causal analysis. By stating different assumptions and
modelling the data following these assumptions, we might find that
certain causal conclusions are robust to these differences. Where the
implications of different assumptions disagree, we can better determine
the forms of data collection that would be required to settle such
differences. Below we consider an example where assumptions point to
different conclusions, revealing the benefits of collecting time-series
data to assess whether a variable is a confounder or a mediator.

\paragraph{2. Time-invariant
confounders}\label{time-invariant-confounders}

In cross-sectional studies, some confounders are inherently stable over
time, such as ethnicity, year and place of birth, and biological gender.
For environmental psychologists examining the relationship between
access to natural environments and psychological well-being, these
stable confounders can be adjusted for without concern for introducing
bias from mediators or colliders. For example, conditioning on one's
year of birth can help isolate recent urban development's effect on
mental health, independent of generational differences in attitudes
toward green spaces.

\paragraph{3. Stable confounders}\label{stable-confounders}

While not immutable, other confounders are less likely to be influenced
by the treatment. Variables such as sexual orientation, educational
attainment, and often income level fall into this category. For
instance, the effect of exposure to polluted environments on cognitive
outcomes can be analysed by conditioning on education level, assuming
that recent exposure to pollution is unlikely to change someone's
educational history retroactively.

\paragraph{4. Timing and reverse
causation}\label{timing-and-reverse-causation}

The sequence of treatment and outcome is crucial. Sometimes, the
temporal order is clear, reducing concerns about reverse causation.
Mortality is a definitive outcome where the timing issue is unambiguous.
If researching the effects of air quality on mortality, the causal
direction (poor air quality leading to higher mortality rates) is
straightforward. However, consider the relationship between
socio-economic status and health outcomes; the direction of causality is
complex because socioeconomic factors can influence health (through
access to resources), and poor health can affect socio-economic status
(through reduced earning capacity).

\paragraph{5. Create causal diagrams}\label{create-causal-diagrams}

Given the complexity of environmental influences on psychological
outcomes, it's prudent to construct multiple causal diagrams to cover
various hypothetical scenarios. For example, when studying the effect of
community green space on stress reduction, one diagram might assume the
direct benefits of green space on stress. At the same time, another
might include potential mediators like physical activity. By analysing
and reporting findings based on multiple diagrams, researchers can
examine the robustness of their conclusions across different theoretical
frameworks and sets of assumptions.

Table~\ref{tbl-cs} describes ambiguous confounding control arising from
cross-sectional data. Suppose again we are interested in the causal
effect of access to greenspace, denoted by \(A\) on ``happiness,''
denoted by \(Y\). We are uncertain whether exercise, denoted by \(L\),
is a common cause of \(A\) and \(Y\) and thus a confounder or whether
exercise is a mediator along the path from \(A\) to \(Y\). That is: (1)
those who exercise might seek access to green space, and (2) exercise
might increase happiness. Alternatively, the availability of green space
might encourage physical activity, which could subsequently affect
happiness. Causal diagrams can disentangle these relationships by
explicitly representing potential paths, thereby guiding appropriate
strategies for confounding control selection. We recommend using
multiple causal diagrams to investigate the consequences of different
plausible structural assumptions.

\textbf{Assumption 1: Exercise is a common cause of \(A\) and \(Y\)},
this scenario is presented in Table~\ref{tbl-cs} row 1. Here, our
strategy for confounding control is to estimate the effect of \(A\) on
\(Y\) conditioning on \(L\).

\textbf{Assumption 2: Exercise is a mediator of \(A\) and \(Y\)}, this
scenario is presented in Table~\ref{tbl-cs} row 2. Here, our strategy
for confounding control is simply estimating the effect of \(A\) on
\(Y\) without including \(L\) (assuming there are no other common causes
of the treatment and outcome).

\begin{table}

\caption{\label{tbl-cs}This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023})}

\centering{

\examplecrosssection

}

\end{table}%

We can simulate data and run separate regressions to clarify how answers
may differ, reflecting the different conditioning strategies embedded in
the different assumptions. The following simulation generates data from
a process in which exercise is a mediator (Scenario 2). (See Appendix C)

\begin{table}
\caption{Code for a simulation of a data generating process in which the effect
of exercise (L) fully mediates the effect of greenspace (A) on happiness
(Y).}\tabularnewline

\centering
\begin{tabular}{lcccccc}
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Model: Exercise assumed confounder} & \multicolumn{3}{c}{Model: Exercise assumed to be a mediator} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7}
\textbf{Characteristic} & \textbf{Beta} & \textbf{95\% CI} & \textbf{p-value} & \textbf{Beta} & \textbf{95\% CI} & \textbf{p-value}\\
\midrule
A & -0.27 & -0.53, -0.01 & 0.043 & 2.9 & 2.6, 3.2 & <0.001\\
L & 1.6 & 1.5, 1.7 & <0.001 &  &  & \\
\bottomrule
\multicolumn{7}{l}{\rule{0pt}{1em}\textsuperscript{1} CI = Confidence Interval}\\
\end{tabular}
\end{table}

This table presents the conditional treatment effect estimates. We
present code for obtaining marginal treatment effects in
\hyperref[appendix-c]{Appendix C}

On the assumptions outlined in Table~\ref{tbl-cs} row 1, in which we
\emph{assert} that exercise is a confounder, the average treatment
effect of access to green space on happiness is ATE = 2.92, CI =
{[}2.66, 3.21{]}.

On the assumptions outlined in Table~\ref{tbl-cs} row 2, in which we
\emph{assert} that exercise is a mediator, the average treatment effect
of access to green space on happiness is ATE = -0.27, CI = {[}-0.52,
-0.01{]}.

Note that although the mediator \(L\) is ``highly statistically
significant'', including it in the model is a mistake. We obtain a
negative effect estimate for the causal effect of green space access on
happiness.

With only cross-sectional data, we must infer the results are
inconclusive. Such understanding, although not the definitive answer we
sought, is progress. The result tells us we should not be overly
confident with our analysis (whatever p-values we recover!), and it
clarifies that longitudinal data are needed.

These findings illustrate the role that assumptions about the relative
timing of exercise as a confounder or as a mediator play.

\subsubsection{Recommendations for Conducting and Reporting Causal
Analyses with Cross-Sectional
Data}\label{recommendations-for-conducting-and-reporting-causal-analyses-with-cross-sectional-data}

When analysing and reporting analyses with cross-sectional data,
researchers face the challenge of making causal inferences without the
benefit of temporal information.

The following recommendations aim to guide researchers in navigating
these challenges effectively:

\textbf{Warning}: before proceeding with cross-sectional analysis,
examine whether panel data are available. Longitudinal data can provide
crucial temporal information that aids in establishing causality,
offering a more robust framework for causal inference. If longitudinal
data are unavailable, the recommendations above become even more
critical for using cross-sectional data best.

\paragraph{\texorpdfstring{1. \textbf{Draw multiple causal
diagrams}}{1. Draw multiple causal diagrams}}\label{draw-multiple-causal-diagrams}

Draw various causal diagrams to represent different theoretical
assumptions about the relationships and timing of variables relevant to
an identification problem. This approach comprehensively examines
possible causal pathways, clarifying variables' roles as confounders,
mediators, or colliders. For example, in studying the effect of urban
green spaces on mental health, consider diagrams that account for both
direct effects and pathways involving mediators like physical activity
or social interaction.

\paragraph{\texorpdfstring{2. \textbf{Perform and report analyses for
each
assumption}}{2. Perform and report analyses for each assumption}}\label{perform-and-report-analyses-for-each-assumption}

Conduct and transparently report separate analyses for each scenario
your causal diagrams depict. This practice ensures that your study is
theoretically grounded for each model. Presenting results from each
analytical approach and the underlying assumptions and statistical
methods promotes a balanced interpretation of findings. Although this
practice may be unfamiliar to some editors and reviewers, it is crucial
to address the inherent challenges of cross-sectional analysis by
expanding the scope of investigation beyond a single hypothesis.

\paragraph{\texorpdfstring{3. \textbf{Interpret findings with attention
to
ambiguities}}{3. Interpret findings with attention to ambiguities}}\label{interpret-findings-with-attention-to-ambiguities}

Interpret results carefully, highlighting any ambiguities or
inconsistencies across analyses. Discuss how varying assumptions about
structural relationships and the timing of events can lead to divergent
conclusions. For instance, exploring the theoretical and empirical
implications of access to green spaces appears to positively affect
mental health when considering exercise as a mediator but a negative
effect when considered a confounder.

\paragraph{\texorpdfstring{4. \textbf{Report divergent
findings}}{4. Report divergent findings}}\label{report-divergent-findings}

Approach conclusions with caution, especially when findings suggest
differing practical implications. Acknowledge the limitations of
cross-sectional data in establishing causality and the potential for
alternative explanations.

\paragraph{\texorpdfstring{5. \textbf{Identify avenues for future
research}}{5. Identify avenues for future research}}\label{identify-avenues-for-future-research}

Target future research that could clarify ambiguities. Consider the
design of longitudinal studies or experiments capable of clarifying
these ambiguities.

\paragraph{\texorpdfstring{6. \textbf{Supplement observational data with
simulated
data}}{6. Supplement observational data with simulated data}}\label{supplement-observational-data-with-simulated-data}

Leverage data simulation to understand the complexities of causal
inference. Simulating data based on various theoretical models allows
researchers to examine the effect of different assumptions on their
findings. This method tests analytical strategies under controlled
conditions, assessing the robustness of conclusions against assumption
violations or unobserved confounders.

\paragraph{\texorpdfstring{7. \textbf{Conduct sensitivity analyses to
assess
robustness}}{7. Conduct sensitivity analyses to assess robustness}}\label{conduct-sensitivity-analyses-to-assess-robustness}

implement sensitivity analyses to determine how dependent conclusions
are on specific assumptions or parameters within your causal model. Use
data simulation as a tool for these analyses, evaluating the sensitivity
of results to various theoretical and methodological choices.

Cross-sectional data are limiting; however, by appropriately bounding
uncertainties in your causal inferences, you may use them to advance
understanding. May your clarity and caution serve as an example for
others.

\subsubsection{Longitudinal Designs}\label{longitudinal-designs}

Causation occurs in time. Longitudinal designs offer a substantial
advantage over cross-sectional designs for causal inference because
sequential measurements allow us to capture causation and quantify its
magnitude. We typically do not need to assert timing as in
cross-sectional data settings. Because we know when variables have been
measured, we can reduce ambiguity about the directionality of causal
relationships. For instance, tracking changes in ``happiness'' following
changes in access to green spaces over time can more definitively
suggest causation than cross-sectional snapshots.

Despite this advantage, longitudinal researchers still face assumptions
regarding the absence of unmeasured confounders or the stability of
measured confounders over time. These assumptions must be explicitly
stated. As with cross-sectional designs, wherever assumptions differ,
researchers should draw different causal diagrams that reflect these
assumptions and subsequently conduct and report separate analyses.

In this section, we simulate a dataset to demonstrate the benefits of
incorporating both baseline exposure and baseline outcomes into
analysing the effect of access to open green spaces on happiness. This
approach allows us to control for initial levels of exposure and
outcomes, offering a clearer understanding of the causal relationship.
\hyperref[appendix-d-simulation-of-different-confounding-control-strategies]{Appendix
D} provides the code.
\hyperref[appendix-e-non-parametric-estimation-of-average-treatment-effects-using-causal-forests]{Appendix
E} provides an example of a non-parametric estimator for the causal
effect. As mentioned before, by conditioning on baseline levels of
access to green spaces and baseline mental health, researchers can more
accurately estimate the \emph{incident effect} of changes in green space
access on changes in mental health. Table~\ref{tbl-lg} offers an example
of how we may use multiple causal diagrams to clarify the problem and
our confounding control strategy.

\begin{table}

\caption{\label{tbl-lg}This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023})}

\centering{

\examplelongitudinal

}

\end{table}%

Our analysis assessed the average treatment effect (ATE) of access to
green spaces on happiness across three distinct models: uncontrolled,
standard controlled, and interaction controlled. These models were
constructed using a hypothetical cohort of 10,000 individuals,
incorporating baseline exposure to green spaces (\(A_0\)), baseline
happiness (\(Y_0\)), baseline confounders (\(L_0\)), and an unmeasured
confounder (\(U\)). The detailed simulation process and model
construction are given in
\hyperref[appendix-simulate-longitudinal-ate]{Appendix D}.

The ATE estimates from these models provide critical insights into the
effects of green space exposure on individual happiness while accounting
for various confounding factors. The model without control variables
estimated ATE = 1.55, CI = {[}1.47, 1.63{]}, significantly
overestimating the treatment effect. Incorporating standard covariate
control reduced this estimate to ATE = 0.86, CI = {[}0.8, 0.92{]},
aligning more closely with the expected effect but still overestimating.
Most notably, the model that included interactions among baseline
exposure, outcome, and confounders yielded ATE = 0.29, CI = {[}0.27,
0.31{]}, approximating the true effect of 0.3. This finding underscores
the importance of including baseline values of the exposure and outcome
wherever these data are available.

\subsubsection{Recommendations for Conducting and Reporting Causal
Analyses with Longitudinal
Data}\label{recommendations-for-conducting-and-reporting-causal-analyses-with-longitudinal-data}

Longitudinal data offer strong advantages for causal inference by
enabling researchers to establish the relative timing of confounders,
treatments, and outcomes. The temporal sequence of events is crucial for
establishing causality because causality occurs in time. The following
recommendations aim to guide researchers in leveraging longitudinal data
effectively to conduct and report causal analyses:

\paragraph{1. Draw multiple causal
diagrams}\label{draw-multiple-causal-diagrams-1}

\begin{itemize}
\tightlist
\item
  \textbf{Identification problem diagram}: begin by constructing a
  causal diagram that outlines your initial assumptions about the
  relationships among variables, identifying potential confounders and
  mediators. This diagram should illustrate the complexity of the
  identification problem.
\item
  \textbf{Solution diagram}: next, create a separate causal diagram that
  proposes solutions to the identified problems. This may involve
  highlighting variables for conditioning to isolate the causal effect
  of interest or suggesting novel pathways for investigation. Having
  distinct diagrams for the problem and its proposed solutions clarifies
  your study's analytic strategy and theoretical underpinning.
\end{itemize}

Table~\ref{tbl-lg} provides an example of a table with multiple causal
diagrams clarifying potential sources of confounding threats and reports
strategies for addressing them.

\paragraph{2. Attempt longitudinal designs with at least three waves of
data}\label{attempt-longitudinal-designs-with-at-least-three-waves-of-data}

Incorporating data from at least three intervals considerably enhances
your ability to infer causal relationships. This approach allows for the
examination of temporal precedence and lagged effects. For example, by
adjusting for physical activity measured before the treatment, we can
ensure that physical activity does not result from a new initiation to
green spaces, which we establish by measuring green space access at
baseline. Establishing chronological order in the temporal sequence of
events allows us to avoid confounding problems 1-4 in \textbf{?@tbl-04}.

\paragraph{3. Calculate Average Treatment Effects for a clearly
specified target
population}\label{calculate-average-treatment-effects-for-a-clearly-specified-target-population}

Estimating the average treatment effect (ATE) across the entire study
population provides a comprehensive measure of the intervention's
effects. This step is crucial for understanding the treatment's overall
effect and generalising findings to broader populations.

\paragraph{4. Where causality is unclear, report results for multiple
causal
graphs}\label{where-causality-is-unclear-report-results-for-multiple-causal-graphs}

Given that the true causal structure may be complex and partially
unknown, analysing and reporting results under each plausible causal
diagram is prudent. This practice acknowledges the uncertainty inherent
in causal modelling and demonstrates the robustness of findings across
different theoretical frameworks.

\paragraph{5. Conduct sensitivity
analyses}\label{conduct-sensitivity-analyses}

Sensitivity analyses are essential for assessing the robustness of your
findings to various assumptions within the causal model. These analyses
can include simulations, as illustrated in Appendices C and D, to
examine bias arising of unmeasured confounding, model misspecification,
and alternative causal pathways on the study conclusions. Sensitivity
analyses help to identify the conditions under which the findings hold,
enhancing the credibility of the causal inferences. (For more about
addressing missing data, see:
(\citeproc{ref-bulbulia2024PRACTICAL}{Bulbulia 2024}).)

\paragraph{6. Address missing data at baseline and study
attrition}\label{address-missing-data-at-baseline-and-study-attrition}

Longitudinal studies often need help with missing data and attrition,
which can introduce bias and affect the validity of causal inferences.
Implement and report strategies for handling missing data, such as
multiple imputation or sensitivity analyses that assess the bias arising
from missing responses at the study's conclusion. (For more about
addressing missing data, see:
(\citeproc{ref-bulbulia2024PRACTICAL}{Bulbulia 2024})).

By following these recommendations, you will more effectively navigate
the inherent limitations of observational longitudinal data, improving
the quality of your causal inferences.

\subsection{Summary}\label{summary}

Although powerful aides, causal directed acyclic graphs may encourage
false confidence wherever causal questions are ill-defined, the
structures of the world are uncertain, data-quality are poor,
statistical estimators are inadequate, or statistical models are
misspecified.

\subsubsection{On the priority of
assumptions.}\label{on-the-priority-of-assumptions.}

You might wonder, ``If not from the data, where do our assumptions about
causality come from?'' This question will come up repeatedly throughout
the course. The short answer is that our assumptions are based on
existing knowledge. This reliance on current knowledge might seem
counterintuitive for buiding scientific knowledge-\/--- shouldn't we use
data to build knowledge, not the other way around? Yes, but it is not
that straightforward. Data often hold the answers we're looking for but
can be ambiguous. When the causal structure is unclear, it is important
to sketch out different causal diagrams, explore their implications,
and, if necessary, conduct separate analyses based on these diagrams.

Otto Neurath, an Austrian philosopher and a member of the Vienna Circle,
famously used the metaphor of a ship that must be rebuilt at sea to
describe the process of scientific theory and knowledge development.

\begin{quote}
Duhem has shown \ldots{} that every statement about any happening is
saturated with hypotheses of all sorts and that these in the end are
derived from our whole world-view. We are like sailors who on the open
sea must reconstruct their ship but are never able to start afresh from
the bottom. Where a beam is taken away a new one must at once be put
there, and for this the rest of the ship is used as support. In this
way, by using the old beams and driftwood, the ship can be shaped
entirely anew, but only by gradual reconstruction.
(\citeproc{ref-neurath1973}{Neurath 1973 p. 199})
\end{quote}

This quotation emphasises the iterative process that accumulates
scientific knowledge; new insights are cast from the foundation of
existing knowledge. Causal diagrams are at home in Neurath's boat. The
tradition of science that believes that knowledge develops from the
results of statistical tests applied to data should be resisted. The
data alone typically do not contain the answers we seek.

\newpage{}

\subsection{Appendix A: Glossary}\label{appendix-a-glossary}

\begin{table}

\caption{\label{tbl-experiments}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\subsection{Appendix B:}\label{appendix-b}

\subsection{Examples of common causal
questions}\label{examples-of-common-causal-questions}

\begin{table}

\caption{\label{tbl-common-interests}Common causal questions}

\centering{

\terminologycommoncausalinterests

}

\end{table}%

\subsection{Effect Modification}\label{effect-modification}

\begin{table}

\caption{\label{tbl-common-interests}representing effect modification}

\centering{

\terminologyeffectmodification

}

\end{table}%

\begin{table}

\caption{\label{tbl-common-interests}Common causal questions}

\centering{

\terminologyeffectmodificationtypes

}

\end{table}%

\newpage{}

\subsection{Appedix C:}\label{appedix-c}

\subsection{Time-varying Confounding: Causal
Mediation}\label{time-varying-confounding-causal-mediation}

\begin{table}

\caption{\label{tbl-mediation}Anatomy of bias in mediation analysis:
statistical SEM fails.}

\centering{

\mediationfull

}

\end{table}%

\newpage{}

\subsection{Appedix D}\label{appedix-d}

\subsubsection{Time-varying Confounding: Treatment Confounder
Feedback}\label{time-varying-confounding-treatment-confounder-feedback}

\begin{figure}

\centering{

\feedbackA

}

\caption{\label{fig-timevarying-amplification}Treatment-confounder
feedback: statistical SEM fails.}

\end{figure}%

\newpage{}

\subsubsection{Time-varying Confounding in the Absence of
Treatment-confounder
feedback}\label{time-varying-confounding-in-the-absence-of-treatment-confounder-feedback}

\begin{figure}

\centering{

\feedbackB

}

\caption{\label{fig-timevarying-nofeedback}Anatomy of bias in
treatment-confounder feedback}

\end{figure}%

\newpage{}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-bulbulia2024PRACTICAL}
Bulbulia, J (2024) A practical guide to causal inference in three-wave
panel studies. \emph{PsyArXiv Preprints}.
doi:\href{https://doi.org/10.31234/osf.io/uyg3d}{10.31234/osf.io/uyg3d}.

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in r and stan}, CRC press.

\bibitem[\citeproctext]{ref-neurath1973}
Neurath, O (1973) Anti-spengler. In M. Neurath and R. S. Cohen, eds.,
\emph{Empiricism and sociology}, Dordrecht: Springer Netherlands,
158--213.
doi:\href{https://doi.org/10.1007/978-94-010-2525-6_6}{10.1007/978-94-010-2525-6\_6}.

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-westreich2013}
Westreich, D, and Greenland, S (2013) The table 2 fallacy: Presenting
and interpreting confounder and modifier coefficients. \emph{American
Journal of Epidemiology}, \textbf{177}(4), 292--298.

\end{CSLReferences}



\end{document}
