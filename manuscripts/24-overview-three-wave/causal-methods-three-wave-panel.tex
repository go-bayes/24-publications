% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  singlecolumn]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=20mm,heightrounded]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/templates/latex/custom-commands.tex}
\usepackage{draftwatermark}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={A Practical Guide to Causal Inference in Three-Wave Panel Studies},
  pdfauthor={Joseph A. Bulbulia},
  pdfkeywords={Causal Inference, Confounding, Counterfactuals, Missing
data, Modified treatment policies},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{A Practical Guide to Causal Inference in Three-Wave Panel
Studies}
\author{Joseph A. Bulbulia}
\date{2024-02-07}

\begin{document}
\maketitle
\begin{abstract}
Causal inference from observational data poses considerable challenges.
This guide explains an approach to estimating causal effects using panel
data focussing on the three-wave panel design.

\textbf{Part 1: Pre-specification of Causal Estimands for a Target
Population} considers the first step: how to ask a causal question by
clearly pre-specifying a causal contrast for a well-defined exposure on
well-defined outcomes in the population of interest.

\textbf{Part 2: Three-Wave Panel Design} discusses the methodology for
obtaining causal effect estimates from three-wave panel studies and
discusses issues of bias from sampling, attrition/missing responses,
measurement error, and unmeasured confounding. Here we discuss methods
for avoiding these biases, which should be considered in advance of data
collection, but which is inevitable, even with the best-made plans. We
describe strategies for handling these biases.

\textbf{Part 3: Statistical Estimands and Estimators} describes the
process of converting observational data into consistent causal effect
estimates for the targeted causal estimands. Here we consider
conventional parametric estimators, as well as more recently developed
non-parametric and semi-parametric machine learning methods.

\textbf{Part 4: Pre-registration, Data Analysis, and Reporting}
describes the protocols for pre-registering analyses, conducting these
data analyses, and clearly and accurately communicating scientific
findings.

\textbf{Part 5: Addressing Complex Causal Questions} discusses methods
for addressing complex causal questions relating to treatment-effect
heterogeneity, causal interactions, causal mediation, and longitudinal
treatment strategies. We examine how the approaches discussed in Parts 1
- 4 may be cautiously adapted to handle these complex causal questions,
and why social scientists should tread lightly before attempting to
answer them.

Overall, we hope to provide a clear, step-by-step guide that applied
researchers may use to obtain robust causal inferences using three waves
of longitudinal data.
\end{abstract}

\subsection{Introduction}\label{introduction}

\subsection{Part 1: Pre-specification of Causal Estimands for a Target
Population}\label{part-1-pre-specification-of-causal-estimands-for-a-target-population}

\subsubsection{What is causality?}\label{what-is-causality}

Consider an intervention, \(A\), and its outcome, \(Y\). We say that
\(A\) causes \(Y\) if a change in \(A\) would result in a change in
\(Y\) (\citeproc{ref-hume1902}{Hume 1902};
\citeproc{ref-lewis1973}{Lewis 1973}). Conversely, if altering \(A\)
does not affect \(Y\), then we say that \(A\) has no causal effect on
\(Y\).

In causal inference, our objective is to contrast potential outcomes of
\(Y\) under varying levels of a well-defined intervention or exposure.
Critically, the aim is to use data to quantify this difference. This
presents challenges because we cannot directly observe causal effects.
We can only indirectly infer them, even in experiments.

\subsubsection{The fundamental problem of causal
inference}\label{the-fundamental-problem-of-causal-inference}

For a binary treatment variable \(A \in \{0,1\}\), and for each
individual \(i\) in a set \(\{1, 2, \ldots, n\}\), let \(A_i = 0\) and
\(A_i = 1\) denote that individuals exposure. Let \(Y_i(0)\) and
\(Y_i(1)\), denote the potential outcomes to be contrasted. These terms
embody `potential outcomes', reflecting counterfactual states until they
are realised.

Given that each individual \(i\) receives either \(A_i = 1\) or
\(A_i = 0\), the outcome observed corresponds to the treatment
administered. However, for any given treatment state, the alternative
outcome remains counterfactual and unobserved:

\[
Y_i|A_i = 1 \implies Y_i(0)|A_i = 1~ \text{is counterfactual}
\] \[
Y_i|A_i = 0 \implies Y_i(1)|A_i = 0~ \text{is counterfactual}
\]

Defining \(\text{Causal Effect}_i\) as the individual causal effect for
unit \(i\), we express it as:

\[
\text{Causal Effect}_i = Y_i(1) - Y_i(0)
\]

However, each unit \(i\) can only experience one level of the exposure
at any time, highlighting that \(\text{Causal Effect}_i\) is
fundamentally unobservable. Causality is never observed directly from
data on individuals. This is called the \emph{fundamental problem of
causal inference} (\citeproc{ref-holland1986}{Holland 1986};
\citeproc{ref-rubin1976}{Rubin 1976}).

\paragraph{Counterfactual recovery from randomised
experiments}\label{counterfactual-recovery-from-randomised-experiments}

Although individual causal effects are elusive, we can estimate average
treatment effects (ATE) by comparing groups subjected to different
treatments. The ATE is the difference between the expected outcomes
under each treatment condition for a binary variable \(A \in \{0,1\}\):

\[
\text{Average Treatment Effect}  = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)].
\]

The challenge lies in calculating these averages when individual causal
effects remain unobservable. In experiments, randomisation facilitates
the estimation of treatment group averages by balancing confounding
factors across groups, thus attributing differences in outcomes solely
to the treatment.

This balance allows us to infer that:

\[
\widehat{\mathbb{E}}[Y(0) | A = 1] = \widehat{\mathbb{E}}[Y(0) | A = 0]
\]

and

\[
\widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y(1) | A = 0]
\]

Assuming causal consistency:

\[\widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y| A = 1]\]
\[\widehat{\mathbb{E}}[Y(0) | A = 0] = \widehat{\mathbb{E}}[Y| A = 0]\]

The estimated ATE in a randomised experiment is thus:

\[
\text{The Estimated Average Treatment Effect} = \widehat{\mathbb{E}}[Y | A = 1] - \widehat{\mathbb{E}}[Y | A = 0].
\]

Randomised experiments are pivotal for identifying causal effects by
eliminating confounding variables through balanced randomisation. This
approach reveals the inherently unobservable counterfactuals necessary
for consistent average treatment effect estimation, thereby elucidating
the pathway for causal inference in observational settings
(\citeproc{ref-hernuxe1n2008a}{Hernán \emph{et al.} 2008};
\citeproc{ref-hernuxe1n2022}{Hernán \emph{et al.} 2022};
\citeproc{ref-hernuxe1n2006}{Hernán and Robins 2006}).

\subsubsection{Emulating a randomised controled experiment with
observational
data}\label{emulating-a-randomised-controled-experiment-with-observational-data}

Understanding these principles, and the assumptions underpinning
identification is helps us to understand the central problem of causal
inference in observational settings: \textbf{obtaining balance in the
confounders across levels of the treatments to be compared}. Put
differently, causal inference requires emulating an idealised
experiment, also called a `target trial'.

\paragraph{Causal identification
assumptions}\label{causal-identification-assumptions}

\subparagraph{Identification assumption 1: Causal
consistency}\label{identification-assumption-1-causal-consistency}

Causal consistency assumes the observed outcome aligns with the
potential outcome for a given exposure level:

\[Y^{observed} = AY(a=1) + (1-A)Y(a=0)\]

Observed outcomes can represent counterfactual outcomes under certain
exposures, such that:

\[
Y^{observed}_i = 
\begin{cases} 
Y_i(~a^*) & \text{if } A_i = a* \\
Y_i(~a~) & \text{if } A_i = a
\end{cases}
\]

Causal consistency also assumes no interference between unit treatments,
allowing potential outcomes to be set to the observed outcomes. For this
assumption to hold, we require ``treatment variation irrelevance''
VanderWeele (\citeproc{ref-vanderweele2009}{2009}). If there are (1)
well-defined outcomes for each treatment version, and (2) no confounding
effects, the multiple versions of treatments can be used to estimate the
causal effect:

\[K \coprod Y(k) | L\] or equivalently \[Y(k) \coprod K | L\]

Here, the treatment \(A\) is essentially a function of \(K\) treatments,
\(A = f(k_1...k_v)\) versions

Limitations exist, however, when interventions are ill-defined, or the
causal effect's interpretation is ambiguous. Put simply, given there are
unknown ways of becoming religiously disaffiliated the interpretation of
``disaffiliation'' may be strained. It is strained in the sense that we
would not know how to intervene to \emph{make} a religiously affiliated
person disaffiliate. We will return to this question in the discussion.

\subparagraph{Identification assumption 2:
Exchangability}\label{identification-assumption-2-exchangability}

Exchangeability assumes treatment assignment is independent of potential
outcomes, given observed covariates. This is the ``no-confounding''
assumption that many psychologists have learned in association with
experimental design. In the setting of observational data, we emulate
randomisation by conditioning on indicators that may lead to an
association of the exposure \(A\) and the outcome \(Y\) in the absence
of causation.

\[Y(a)\coprod  A|L\] or \[A \coprod  Y(a)|L\]

Where exchangability holds, we calculate the Average Treatment Effect
(ATE)

\[
ATE = E[Y(a*)|L = l] - E[Y(a)|L = l] 
\]

Put differently, conditioning on confounders ensures \emph{balance} in
their distribution across exposures.

\subparagraph{Identification assumption 3:
Positivity}\label{identification-assumption-3-positivity}

Positivity is satisfied if there is a positive probability of receiving
or not receiving exposure at all covariate levels. Expressed as:

\begin{equation}
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall a \in L
\end{equation}

There are two types of positivity violation.

\begin{itemize}
\item
  \textbf{Random non-positivity}: Occurs when the causal effect of a
  missing observation is presumed to exist. This violation is the only
  one verifiable by data. Here, we check and report it.
\item
  \textbf{Deterministic non-positivity}: Occurs when the causal effect
  is inconceivable. For example, the causal effect of hysterectomy in
  biological males violates deterministic non-positivity.
\end{itemize}

\subsubsection{Other threats to Causal
inference}\label{other-threats-to-causal-inference}

\paragraph{1. The threat of overly ambitious
estimands}\label{the-threat-of-overly-ambitious-estimands}

In causal inference, the Average Treatment Effect (ATE) conceived as a
comparison between population-wide simulations at two levels of
exposure, \(E[Y(1)] - E[Y(0)]\), is often artificial. Artificiality is
evident for continuous exposures, where such comparisons simplify the
complexity of real-world phenomena into a low dimensional summary, such
as a contrast of a one-standard-deviation difference in the mean, or a
comparison of one quartile of exposure to another quartile of exposure.
In practice, the requirements for targeting such contrasts impose a
strong reliance on statistical models, which introduce further
opportunities for bias. Such comparisons might also strain the
positivity assumption because the relevant events occur infrequently or
are absent within the strata of covariates required to satisfy
conditional exchangeability. Moreover, treatment effects may not be
monotonic. For this reason, comparing arbitrary points on a continuous
scale, while relying on correct bmodelling specifications risks drawing
erroneous conclusions (\citeproc{ref-calonico2022}{Calonico \emph{et
al.} 2022}; \citeproc{ref-ogburn2021}{Ogburn and Shpitser 2021}). In
short, the simplifications and models required for obtaining standard
causal estimands often lack realism. The practical inferences that we
draw from them may be misleading
(\citeproc{ref-vansteelandt2022}{Vansteelandt and Dukes 2022}).

Furthermore, the `average treatment effect' itself might not be our
primary scientific interest. In many settings, we may want to understand
heterogeneity in treatment effects without a clear understanding in
advance of modelling where such heterogeneity may be found
(\citeproc{ref-wager2018}{Wager and Athey 2018}). Presently, methods for
valid causal inference in settings of heterogeneous treatment effects
remain inchoate see Tchetgen and VanderWeele
(\citeproc{ref-tchetgen2012}{2012}); Wager and Athey
(\citeproc{ref-wager2018}{2018}); Cui \emph{et al.}
(\citeproc{ref-cui2020}{2020}); Foster and Syrgkanis
(\citeproc{ref-foster2023}{2023}); Foster and Syrgkanis
(\citeproc{ref-foster2023}{2023}); Kennedy
(\citeproc{ref-kennedy2023}{2023}); Nie and Wager
(\citeproc{ref-nie2021}{2021}).

Recently, causal data scientists have explored new classes of estimands
and estimators, such as modified treatment policies or `shift
interventions' (\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-hoffman2023}{Hoffman \emph{et al.} 2023};
\citeproc{ref-vanderweele2018}{VanderWeele 2018};
\citeproc{ref-williams2021}{Williams and Díaz 2021}) and optimal
treatment policies (\citeproc{ref-athey2021}{Athey and Wager 2021};
\citeproc{ref-kitagawa2018}{Kitagawa and Tetenov 2018}). Such estimands
allow researchers to specify and examine a broader range of causal
contrasts, such as treating only those likely to respond, or those who
meet certain ethical criteria not determined by statisticians, or those
who optimise a pre-specified (\citeproc{ref-cui2020}{Cui \emph{et al.}
2020}; \citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-wager2018}{Wager and Athey 2018}). A review of these
promising developments would take us beyond the scope of this
discussion, however, readers should be aware that causal inference is
not bound to standard \(E[Y(1)] - E[Y(0)]\) estimands that require
simulating often implausible or even unhelpful counterfactual outcomes
for the entire population at two levels of a pre-specified intervention.

\paragraph{2. The challenge of target
validity}\label{the-challenge-of-target-validity}

Investigators must recognise that a mismatch between the sample and
target population can invalidate causal effect estimates even if the
magnitudes are consistently estimated. If the mismatch affects
effect-modifiers of the treatment effects there will be no guarantee
that effect estimates for the sample will generalise to the target
population -- that is, no guarantee that the effect estimates will
achieve `target validity' or equivalently `external validity.'
Worryingly such threats cannot be fully evaluated from responses in the
restricted or censored sample (say more here)

\paragraph{3. The challenge of satisfying data and conceptual
assumptions}\label{the-challenge-of-satisfying-data-and-conceptual-assumptions}

We must ensure that the measures in our data reflect the underlying
realities of interest.

\newpage{}

\subsection{Part 2: A Three-Wave Panel
Design}\label{part-2-a-three-wave-panel-design}

We describe methods for obtaining causal effect estimates from
three-wave panel studies, and discusses issues of bias from
attrition/missing responses, measurement error, and unmeasured
confounding.

\subsubsection{Confounding bias}\label{confounding-bias}

Causal diagrams are useful for evaluating the assumption of `no
unmeasured confounding' (\citeproc{ref-greenland1999}{Greenland \emph{et
al.} 1999}; \citeproc{ref-pearl1995}{Pearl 1995},
\citeproc{ref-pearl2009}{2009}). We next use causal diagrams to clarify
how confounding bias arises in three-wave panel studies. Our conventions
are given in Table Table~\ref{tbl-01}:

\begin{itemize}
\tightlist
\item
  \textbf{\(A\)} denotes the treatment or exposure variable. This is the
  intervention or condition whose effect we wish to investigate
  \textbf{This symbol represents the cause}.
\item
  \textbf{\(Y\)} denotes the outcome variable. \textbf{This symbol
  represents the effect}.
\item
  \textbf{\(L\)} denotes all measured confounders, variables that may
  affect both the treatment and the outcome.
\item
  \textbf{\(U\)} denotes unmeasured confounders, variables not included
  in the analysis that could influence both the treatment and the
  outcome, potentially leading to biased conclusions.
\item
  \textbf{\(Z\)} denotes an effect modifier, a variable within which
  levels of the treatment may vary. Effect modification is important
  when considering external validity, also known as target validity.
  When the distribution of effect modifiers in the sample differs from
  the distribution of the effect modifiers in the target population, the
  average treatment effects will generally differ.
\item
  \textbf{\(M\)} denotes a mediator, a variable factor through which the
  treatment affects the outcome. Our interest here is in identifying the
  total effect of treatment \(A\) on an outcome \(Y\). However, it is
  also important to understand how controlling for mediators can affect
  estimates of this total effect.
\end{itemize}

\begin{table}

\caption{\label{tbl-01}Terminology that is used in this article for
causal diagrams. (This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologylocalconventions

}

\end{table}%

\begin{table}

\caption{\label{tbl-02}Basic conventions for causal diagrams. (This
table is adapted from (\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologygeneral

}

\end{table}%

\paragraph{Causal diagrams must address a clearly stated pre-specified
identification
problem}\label{causal-diagrams-must-address-a-clearly-stated-pre-specified-identification-problem}

Causal diagrams are tools designed to clarify the identification
problem: in the simplest case, whether the causal effect of \(A_t\) on
\(Y_{t + 1}\) can be accurately measured using data, separating actual
causation from statistical association. These diagrams rely on
`structural assumptions' to map out the problem
(\citeproc{ref-hernuxe1n2004a}{Hernán \emph{et al.} 2004}). However, it
is important to remember that data alone cannot validate these
assumptions. Causal diagrams are only as good as the expert advice that
informs them.

The identification problem breaks down into two main tasks:

\textbf{First task} determines whether \(A\) and \(Y\) are independent
after accounting for common causes. This involves identifying and
controlling for these causes and checking for any remaining pathways
(backdoor paths) that might link \(A\) and \(Y\). The goal is to
ascertain if \(A\) and \(Y\) are d-separated, implying no statistical
association between them if considered independent.

\textbf{Second task}: assess the causal relationship between \(A\) and
\(Y\), ensuring that the statistical association observed is a reliable
indicator of causation, even after the conditioning strategy from the
first task is applied. This step is necessary to ensure that the
observed relationship between \(A\) and \(Y\) accurately reflects
causality (conditional on assumptions encoded in the graph), mindful of
potential biases introduced by over-conditioning.

\paragraph{Review of steps for constructing causal
diagrams}\label{review-of-steps-for-constructing-causal-diagrams}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Incorporate all common causes of the exposure and outcome}:
  this includes both measured and unmeasured causes. Where possible, we
  combine similar causes under one variable, such as \(L_0\) for
  demographic factors.
\item
  \textbf{Include all relevant ancestors of measured confounders}: any
  measured variable that is an ancestor of unmeasured confounders and is
  linked with either the exposure, the outcome, or both should be
  included. This helps in identifying and reducing bias from unmeasured
  causes.
\item
  \textbf{Clearly outline the timing of events}: we recommend using time
  subscripts (e.g., \(L_0\), \(A_1\), \(Y_2\)) to denote the sequence of
  events, clarifying the assumed causal order.
\item
  \textbf{Arrange the graph according to the causal order} we recommend
  structuring the diagram to reflect the chronological order of
  causality, enhancing understanding of the causal relationships.
\item
  \textbf{Mark conditioned variables}: typically, only variables
  conditioned upon are boxed, excluding the exposure and outcome unless
  measured inaccurately.
\item
  \textbf{Adopt clear conventions for identifying biases} because causal
  diagrams do not follow a universal standard, explicitly state the
  conventions used, such as colouring or describing pathways that could
  introduce bias.
\item
  \textbf{Focus on structural, not parametric, paths} avoid depicting
  non-linear relationships between nodes, as the aim is to assess
  confounding, not the specific nature of the relationships.
\item
  \textbf{Limit paths to those relevant to the identification problem}:
  Keep the diagram focused, including only pathways that contribute to
  solving the identification problem.
\item
  \textbf{Specify the research question addressed by the diagram}:
  again, we recommend making clear the particular question the causal
  diagram is intended to answer.
\item
  \textbf{State the contents of a graph for those with visual
  impairments}: not everyone has colour vision or vision. We recommend
  restating a causal graph in words.
\end{enumerate}

\paragraph{Examples of confounding that three waves of panel data
avoid}\label{examples-of-confounding-that-three-waves-of-panel-data-avoid}

\begin{table}

\caption{\label{tbl-04}With three waves of data, we are able to avoid
common confounding scenarios described in this graph. This table is
adapted from (\citeproc{ref-bulbulia2023}{Bulbulia 2023a})}

\centering{

\terminologychronologicalhygeine

}

\end{table}%

In row 8 of Table~\ref{tbl-04}, we encounter another scenario
characterised by unmeasured confounding and a powerful response: by
gathering data on both the treatment and the outcome at the initial
assessment and adjusting for their baseline values any unmeasured link
between treatment \(A_1\) and outcome \(Y_2\) must be \emph{independent}
of their baseline measurements. Therefore, incorporating baseline values
of both treatment and outcome, alongside other measured covariates
potentially representing descendants of unmeasured confounders, emerges
as a powerful strategy for controlling confounding
(\citeproc{ref-vanderweele2020}{VanderWeele \emph{et al.} 2020}).

Additionally, the causal diagram highlights a secondary advantage of
this approach. Typically, a standard regression analysis yields what is
termed a ``prevalence exposure effect.'' This effect measures the
relationship between the exposure or treatment status at time \(t1\) and
the subsequent outcome at time \(t2\), following the pathway
\(A_{1} \to Y_{2}\). It is given as

\[
\text{Prevalence exposure effect:} \quad A_{1} \to Y_{2}
\]

Notably, this estimation does not account for the initial status of the
exposure. It may only describe the effect of ongoing exposures on
outcomes, which often diverge from the theoretically interesting effect.

Consider, for instance, a scenario where religious service makes people
sceptical of surveys. The observed data on the link between religious
service and trust in science would then be skewed towards those who are
resilient to these effects. Consequently, it might erroneously seem that
\(A_{1} \to Y_{2}\) has a protective effect on trust whereas, initially,
the treatment might be detrimental; see: Hernán \emph{et al.}
(\citeproc{ref-hernuxe1n2016}{2016}); Danaei \emph{et al.}
(\citeproc{ref-danaei2012}{2012}); VanderWeele \emph{et al.}
(\citeproc{ref-vanderweele2020}{2020}); Bulbulia
(\citeproc{ref-bulbulia2022}{2022}).

In contrast, controlling for the baseline exposure and outcome
facilitates the identification of an incident exposure effect. This
effect evaluates the causal link between the exposure or treatment
status at time \(t1\) and the observed outcome at time \(t2\),
conditional on the baseline exposure: \(A_{0} \to A_{1} \to Y_{2}\). Of
course, this outcome would need to be weighted by the exposure at
treatment because the sceptical might be more likely to drop out of the
study.

Thus, by including the baseline exposure, we assess the
\emph{transition} in treatment or exposure status from \(A_0\) to
\(A_1\), offering a more precise intervention point for estimating
causal effects at \(Y_2\) and more accurately by simulating an
experimental setup. It is expressed:

\[
\text{Incident exposure effect:} \quad \boxed{A_{0}} \to A_{1} \to Y_{2}
\]

Revisiting our example, a model accounting for the baseline exposure
implies that individuals undergo a change from the observed baseline
level of \(A_0\), allowing for an evaluation of causation of the
treatment. This incident exposure effect more faithfully replicates a
``target trial'' or organises observational data into a hypothetical
experiment with a ``time-zero'' for treatment initiation; see Hernán
\emph{et al.} (\citeproc{ref-hernuxe1n2016}{2016}); Danaei \emph{et al.}
(\citeproc{ref-danaei2012}{2012}); VanderWeele \emph{et al.}
(\citeproc{ref-vanderweele2020}{2020}); Bulbulia
(\citeproc{ref-bulbulia2022}{2022}).

Moreover, we achieve additional control over unmeasured confounding by
also including the baseline exposure \(A_0\) and the baseline outcome
\(Y_0\), leading to:

\[
\boxed{
\begin{aligned}
L_{0} \\
A_{0} \\
Y_{0}
\end{aligned}
}
\to A_{1} \to Y_{2}
\]

For any unobserved confounder to affect both the treatment and outcome
it would need to do so independently of baseline measures of the
treatment and outcome. Including baseline measures helps to address
measured sources of confounding.

\newpage{}

\subsubsection{Worked example of a Three-Wave Panel Design for Obtaining
a Marginal Incident-Exposure
Effect}\label{worked-example-of-a-three-wave-panel-design-for-obtaining-a-marginal-incident-exposure-effect}

We sketch the outlines of a design for a three-wave panel study that
intends to estimate an \emph{incident exposure effect}. I do not intend
this advice to be more than a sketch. However, I believe it is important
to give readers a concrete example of how data collection for causal
inference might occur.

\paragraph{Step 1. Ask a causal
question}\label{step-1.-ask-a-causal-question}

In a three-wave panel design, ensuring the relative timing of events is
essential for valid causal inference
(\citeproc{ref-vanderweele2020}{VanderWeele \emph{et al.} 2020}).

Here is a causal question:

What is the causal effect of attending weekly religious services
compared to not attending services on charitable giving in the
population of New Zealanders who identify as Christian?

To answer this question we must assess how changes in religious service
attendance, measured from the beginning of the year (baseline) to
mid-year (wave 1), affect levels of charitable giving at the end of the
year (wave 2) In this design, the change in religious service attendance
is captured between the first and second waves, while the outcome,
charitable giving, is measured in the third wave. This establishes a
sequential order that mirrors the cause-and-effect relationship.
Ensuring such temporal ordering is crucial in any causal analysis. Note
additionally that we must obtain comparisons from continuous data for
binary data. Depending on the data, such a contrast might not be well
supported. For example, change between these levels might occur only
rarely, in which case our inference might rely too heavily on parametric
model specifications. Focusing on the estimand:

\subparagraph{Exposure:}\label{exposure}

\begin{itemize}
\tightlist
\item
  A = 0: Attends less than once per month
\item
  A = 1: Attends weekly
\end{itemize}

\subparagraph{Outcome:}\label{outcome}

\begin{itemize}
\tightlist
\item
  Focus: One-year effect of shifting from A = 0 to A = 1.
\item
  Charitable giving as measured by self-reported giving
\end{itemize}

\subparagraph{Scale of contrast:}\label{scale-of-contrast}

\begin{itemize}
\tightlist
\item
  ATE on the causal difference scale (per protocol).
\end{itemize}

\subparagraph{Target population:}\label{target-population}

\begin{itemize}
\tightlist
\item
  Individuals in New Zealand who might attend religious service and
  identify as Christian.
\end{itemize}

\subparagraph{Source population:}\label{source-population}

\begin{itemize}
\tightlist
\item
  National probability sample of New Zealanders (N = 34,000).
\end{itemize}

\subparagraph{Baseline population:}\label{baseline-population}

\begin{itemize}
\tightlist
\item
  Defined by eligibility criteria (including religious affiliation). If
  the baseline population differs from the target population, if sample
  weights for the distribution of covariates are available for the
  \emph{target population}, these should be applied to the baseline
  population (although with caution, given the potential for model
  misspecification, see \citeproc{ref-stuart2015}{Stuart \emph{et al.}
  2015}.)
\end{itemize}

Let \(\widehat{ATE}_{target}\) denote the population average treatment
effect for the target population. Let
\(\widehat{ATE}_{\text{restricted}}\) denote the average treatment
effect at the end of treatment. Let \(W\) denote a set of variables upon
which the restricted and target populations structurally differ. We say
that results \emph{generalise} if we can guarantee that:

\[
\widehat{ATE}_{target} =  \widehat{ATE}_{restricted} 
\]

or if there is a known function such that:

\[
ATE_{target}\approx  f_W(ATE_{\text{restricted}}, W)
\]

In most cases, \(f_W\) will be unknown, as it must account for potential
heterogeneity of effects and unobserved sources of bias. For further
discussion on this topic, see Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018}); Bulbulia
(\citeproc{ref-bulbulia2023c}{2023b}), and \(\S 3.1.6\)

\paragraph{Step 2. Ensure that the exposure is measured at wave 0
(baseline) and wave 1 (the exposure
interval)}\label{step-2.-ensure-that-the-exposure-is-measured-at-wave-0-baseline-and-wave-1-the-exposure-interval}

Measuring the exposure at both baseline (wave 0) and the exposure
interval (wave 1) has the following benefits:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Enables estimation of incident exposure effect}: by including
  baseline observations, we can distinguish between incidence (new
  occurrences) and prevalence (existing states) exposure effects. For
  instance, in a study on religious service attendance, assessing the
  incident exposure effect allows us to differentiate the effect of
  starting to attend services regularly from the effect of ongoing
  attendance.
\item
  \textbf{Confounding control}: measuring the exposure at baseline helps
  control for time-invariant confounders. These are factors that do not
  change over time and might affect both the exposure and outcome. In
  the context of religious service attendance, personal attributes like
  inherent religiosity could influence both attendance and related
  outcomes.
\item
  \textbf{Sample adequacy}: for rare exposures, baseline measurements
  can assess sample size adequacy. If a change in exposure is infrequent
  (e.g., infrequent to weekly religious service attendance), a larger
  sample may be needed to satisfy the positivity assumption and detect
  causal effects. By measuring the exposure at baseline, we can better
  evaluate whether our sample is representative and large enough to
  detect such rare changes.
\end{enumerate}

\paragraph{Step 3. Ensure that the outcome is measured at wave 0
(baseline) and wave 2 (post-exposure wave
1)}\label{step-3.-ensure-that-the-outcome-is-measured-at-wave-0-baseline-and-wave-2-post-exposure-wave-1}

Measuring the outcome at both wave 0 (baseline) and the post-exposure
outcome wave (wave 2) offers the following advantages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Temporal ordering}: causes precede effects. We need this to
  avoid \emph{causal incoherence}. For example, ensuring order protects
  us from inadvertently estimating \(Y\rightarrowred A\).
\item
  \textbf{Confounding control}: including the baseline measure of both
  the exposure and outcome allows for better control of confounding.
  This approach helps to isolate the effect of the exposure on the
  outcome from the exposure wave (wave 1) to the outcome wave (wave 2),
  independent of their baseline levels. It reduces the risk of
  confounding, where unmeasured factors might influence both the
  exposure and the outcome, as shown in Table~\ref{tbl-05}.
\end{enumerate}

\paragraph{Step 4. Measure observable common causes of the exposure and
outcome}\label{step-4.-measure-observable-common-causes-of-the-exposure-and-outcome}

Next, we must identify and record at wave 0 (baseline) all potential
confounders that could influence both the exposure (e.g., frequency of
attending religious services) and the outcome (e.g., charitable giving).
Proper identification and adjustment for these confounders are crucial
for accurate causal inference. By obtaining measures of the confounders
at baseline we:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \textbf{Minimise mediation bias}: by measuring confounders at
  baseline, it will be difficult to produce the \emph{causally
  incoherent} model: \(A_1\to \boxed{L_2} \rightarrowdotted Y_3\)
\item
  \textbf{Minimise collider bias}: by measuring confounders at baseline,
  it will be difficult to produce the \emph{causally incoherent} model:
  \(A_1\rightarrowred L_3 \leftarrowred Y_2\).
\end{enumerate}

The topic of measurement construction is vast. For now, it is worth
noting that measures should be obtained in consultation with locals and
domain experts (\citeproc{ref-vanderweele2022}{VanderWeele 2022}).

\paragraph{Step 5. Gather data for proxy variables of unmeasured common
causes at the baseline
wave}\label{step-5.-gather-data-for-proxy-variables-of-unmeasured-common-causes-at-the-baseline-wave}

If any unmeasured confounders influence both the exposure and outcome,
but we lack direct measurements, we should make efforts to include
proxies for them at baseline. Even if this strategy cannot eliminate all
bias from unmeasured confounding, it will generally reduce bias.

\paragraph{Step 6. Retain sample}\label{step-6.-retain-sample}

Censoring leads to bias. Strategies for sample retention are essential.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \textbf{Developing tracking protocols}: establish robust systems for
  tracking participants over the study period. This involves keeping
  updated records of contact information such as addresses, emails,
  phone numbers, and names and accounting for changes in name over time.
\item
  \textbf{Motivate retention}: implement strategies to encourage ongoing
  participation. These incentives should ideally not lead to bias in the
  distribution of effect-modifiers that might affect the outcome of
  interest. For example, retention should not appeal to trust in science
  if trust in science is the outcome of interest.
\item
  \textbf{Investigators should avoid acting in ways that lead to
  differential retention}: for example, stay out of the news.
\end{enumerate}

\begin{table}

\caption{\label{tbl-05}Several sources of bias from attrition. In the
first instance, an unmeasured common cause of the exposure also affects
attrition. In the second instance, the exposure directly affects
attrition. To address these sources of bias we use inverse probability
of censoring weights. (This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023a})), see Part 5 for
additional examples.}

\centering{

\threeFF

}

\end{table}%

\newpage{}

\subsection{Part 3: Statistical Estimation and
Estimators}\label{part-3-statistical-estimation-and-estimators}

We outline the process of converting observational data into consistent
causal effect estimates for the targeted causal estimands. Here we
describe the advantages and limitations of robust non-parametric and
semi-parametric machine learning methods, arguing these should be used
where sample size permits.

\subsubsection{Causal estimation}\label{causal-estimation}

Suppose we have defined our estimand. To obtain causal contrasts we
recommend using doubly robust estimation methods. These combine inverse
probability of treatment weights (propensity scores) with regression
stratification. There are two models at work in a doubly robust
estimator.

\paragraph{Parametric Doubly Robust
Estimation}\label{parametric-doubly-robust-estimation}

Combines the strengths of the IPTW and G-computation methods (see:
\href{https://go-bayes.github.io/psych-434-2023/content/09-content.html\#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study-e.g.-assessment-3-option-2}{here}.

The technique utilises both the propensity score and the outcome model,
making it ``doubly robust.'' This implies that if either of these models
is correctly specified, the estimation will not be biased.

\textbf{Step 1} The first step is to estimate the propensity score. The
propensity score, denoted as \(e(L)\), is the conditional probability of
the exposure \(A = 1\) given the covariates \(L\). The appropriate model
to estimate this can be chosen based on the nature of the data and the
exposure.

\[e = P(A = 1 | L) = f_A(L; \theta_A)\]

In this equation, \(f_A(L; \theta_A)\) is a function that estimates the
probability of the exposure \(A = 1\) given covariates \(L\). We then
calculate the weights for each individual, denoted as \(v\), using the
estimated propensity score:

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

Here, \(v\) depends on \(A\), and is calculated as the inverse of the
propensity score for exposed individuals and as the inverse of \(1-e\)
for unexposed individuals.

\textbf{Step 2} The next step involves fitting a weighted outcome model.
Using the weights computed from the estimated propensity scores, a model
for the outcome \(Y\), conditional on the exposure \(A\), is fitted.

\[ \hat{E}(Y|A, L; V) = f_Y(A, L ; \theta_Y, V) \]

In this model, \(f_Y\) is a function (in our case a weighted regression
model) with parameters \(θ_Y\). The weights \(V\) are incorporated into
the estimation process, affecting the contribution of each observation
to the estimation of \(θ_Y\), but they are not an additional variable in
the model. Additionally, following {``Agnostic notes on regression
adjustments to experimental data''} (\citeproc{ref-agnostic}{n.d.}), we
take the interaction of the exposure and baseline covariates when
estimating our regression model. For binary outcomes, we model the rate
ratio using Poisson regression. Although binomial regression is
acceptable when the outcome is rare (less than 10\%), non-collapsibility
leads mean that we cannot interpret results as marginal causal effects.
For consistency, we use the Poisson model with robust standard errors.

\textbf{Step 3} simulate the potential outcome for each individual under
the hypothetical scenario where everyone is exposed to the intervention
\(A=a\), irrespective of their actual exposure level:

\[\hat{E}(a) = \hat{E}[Y_i|A=a; L,\hat{\theta}_Y, v_i]\]

This expectation is calculated for each individual \(i\), with
individual-specific weights \(v_i\).

\textbf{Step 4} Estimate the causal effect as a contrast in averages of
the population outcomes under each intervention:

\[\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]\]

The difference \(\delta\) represents the average causal effect of
changing the exposure from level \(a'\) to level \(a\).

For standard errors and confidence intervals, we use simulation-based
inference methods (\citeproc{ref-greifer2023}{Greifer \emph{et al.}
2023}).

\paragraph{Semi-parametric and non-parametric
estimator}\label{semi-parametric-and-non-parametric-estimator}

\paragraph{Shift functions}\label{shift-functions}

Causider a causal question in which we apply the following contrasts:

\begin{itemize}
\tightlist
\item
  The expected outcomes under each shift function defined above by the
  function \(f(A)\), and
\item
  The expected outcomes under the actual observed attendance/socialising
  patterns.
\end{itemize}

Formally, each target is given:

\[ \Delta = E[Y(a*)|f(A),L] - E[Y(a)|A,L] \]

Where \(\Delta\) is the average treatment effect of a modified treatment
policy.

\textbf{Motivating example: shift function as a gain of weekly religious
service}: the intervention of interest is defined by a shift function
applied to the treatment variable, designed to assess the effect of
shifting the treatment on all outcomes examined in the study. The focal
estimand shift function is given

\[f(A) = \begin{cases} 4 & \text{if } A \leq 4  \text{ monthly religious service attendance} \\ A & \text{if } A > 4  \text{ monthly religious service attendance} \end{cases} \]

Here, we estimate outcomes in a hypothetical world in which all
individuals were attend at least four religious services per month
(weekly).

\textbf{Comparative intervention 1: shift function as loss of any
religious service}:

Because the gain of religion might be different from the loss of
religion, we additionally contrast the population average outcome were
everyone to stop attending monthly religious service verse the expected
outcome at the natural treatment values:

\[f(A) = 0 \]

Here, we estimate outcomes in a hypothetical world in which no
individuals attended religious service.

\textbf{Treatment Model}: in the context of causal inference, a
treatment model estimates the probability of receiving the treatment
based on observed characteristics (covariates). In ordinary regression,
this would be akin to the predictor variables in the model but modelling
the treatment.

\textbf{Outcome Model}: this estimates the potential outcomes of
interest, here, measures of well-being, conditional on treatment status
and other covariates. In traditional regression settings, this model is
what you typically fit to understand how predictors influence the
outcome.

By using TMLE to combine both a treatment and outcome model, we can
better identify the treatment effect. Here are the steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Treatment model with propensity scores}: the initial phase of
  our analysis consists of generating propensity scores for the exposure
  for each participant. These scores quantify the probability of an
  individual having the treatment, conditional on their set of
  covariates. \textbf{In plain terms,} we first calculate a score for
  each person that indicates how likely they are to experience the
  treatment based on various characteristics.This step is like
  determining each person's chances of having the treatment, given their
  particular life circumstances.
\item
  \textbf{Weighting via propensity scores}: upon computing the
  propensity scores, we assign an inverse probability weight to each
  dataset entry. These weights serve to equilibrate the distribution of
  observed covariates between the treated and untreated cohorts, thus
  attenuating the bias in the causal estimates. \textbf{In plain terms,}
  we use propensity scores to make the contrast groups more comparable
  in a manner that emulates randomisation in experiments.
\item
  \textbf{Outcome models}: a second targeted machine learning model
  focuses on the outcome variables, encompassing multiple measures of
  the outcome distributed across different domains of interest. This
  model incorporates both the individual treatment statuses and the
  previously calculated weights, enhancing our capacity for causal
  inference. \textbf{In plain terms} we create a model that tries to
  predict well-being levels based on whether experiences the treatment
  under consideration, while also considering conditional on covariates.
\item
  \textbf{Doubly robust estimation}: Combines the treatment and outcome
  model to obtain robust results: only one of the two models needs to be
  correctly specified.
\item
  \textbf{Counterfactual contrasts}: a core component of TMLE is the
  projection of counterfactual outcomes. By combining estimates from the
  treatment and outcome models, TMLE enables the computation of
  potential well-being levels for each individual under the treatment
  conditions that are contrasted. \textbf{In plain terms:} We use the
  models to estimate what someone's outcomes under two scenarios:
  treatment condition \(A=a*\) versus treatment condition \(A = a\).
  Note that our shift estimand, described below, helps to make the
  assumptions required for such contrasts more credible.
\item
  \textbf{Effect estimation}: the final analytical stage involves
  determining the average treatment effect by contrasting the estimated
  counterfactual outcomes.
\end{enumerate}

\paragraph{Survey weights}\label{survey-weights}

Where the distribution of variables related to a study is known, for
example from national census data, it is generally advisable to employ
survey weights in one's data. Appendix

\paragraph{Missing responses}\label{missing-responses}

See Part 5.

\paragraph{Inverse probability of censoring
weights}\label{inverse-probability-of-censoring-weights}

See Part 5.

\paragraph{Example language for reporting the
estimator}\label{example-language-for-reporting-the-estimator}

\begin{quote}
We employ a semi-parametric estimator known as Targeted Minimum
Loss-based Estimation (TMLE), which is adept at estimating the causal
effect of modified treatment policies on outcomes over time.
Estimatation was performed using \texttt{lmtp} package
(\citeproc{ref-williams2021}{Williams and Díaz 2021}). TMLE is a robust
method that combines machine learning techniques with traditional
statistical models to estimate causal effects while providing valid
statistical uncertainty measures for these estimates.
\end{quote}

\begin{quote}
TMLE operates through a two-step process involving both outcome and
treatment (exposure) models. Initially, it employes machine learning
algorithms to flexibly model the relationship between treatments,
covariates, and outcomes. This flexibility allows TMLE to account for
complex, high-dimensional covariate spaces without imposing restrictive
model assumptions. The outcome of this step is a set of initial
estimates for these relationships.
\end{quote}

\begin{quote}
The second step of TMLE involves ``targeting'' these initial estimates
by incorporating information about the observed data distribution to
improve the accuracy of the causal effect estimate. This is achieved
through an iterative updating process, which adjusts the initial
estimates towards the true causal effect. This updating process is
guided by the efficient influence function, ensuring that the final TMLE
estimate is as close as possible to the true causal effect while still
being robust to model misspecification in either the outcome or
treatment model.
\end{quote}

\begin{quote}
A central feature of TMLE is its double-robustness property, meaning
that if either the model for the treatment or the outcome is correctly
specified, the TMLE estimator will still consistently estimate the
causal effect. Additionally, TMLE uses cross-validation to avoid
overfitting and ensure that the estimator performs well in finite
samples. Each of these steps contributes to a robust methodology for
examining the \emph{causal} effects of interventions on outcomes. The
integration of TMLE and machine learning technologies reduces the
dependence on restrictive modelling assumptions and introduces an
additional layer of robustness. For further details see
(\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-hoffman2022}{Hoffman \emph{et al.} 2022},
\citeproc{ref-hoffman2023}{2023})
\end{quote}

\paragraph{Example of a Sensitivity Analysis Using
E-values}\label{example-of-a-sensitivity-analysis-using-e-values}

\paragraph{Definition of the E-value}\label{definition-of-the-e-value}

\begin{quote}
The minimum strength of association on the risk ratio scale that an
unmeasured confounder would need to have with both the exposure and the
outcome, conditional on the measured covariates, to fully explain away a
specific exposure-outcome association
\end{quote}

See: (\citeproc{ref-vanderweele2020}{VanderWeele \emph{et al.} 2020};
\citeproc{ref-mathur2018a}{\textbf{mathur2018a?}})

For example, suppose that the lower bound of the the E-value was 1.3
with the lower bound of the confidence interval = 1.12, we might then
write:

\begin{quote}
With an observed risk ratio of RR=1.3, an unmeasured confounder that was
associated with both the outcome and the exposure by a risk ratio of
1.3-fold each (or 30\%), above and beyond the measured confounders,
could explain away the estimate, but weaker joint confounder
associations could not; to move the confidence interval to include the
null, an unmeasured confounder that was associated with the outcome and
the exposure by a risk ratio of 1.12-fold (or 12\%) each could do so,
but weaker joint confounder associations could not.
\end{quote}

The equations are as follows (for risk ratios)

\[
E-value_{RR} = RR + \sqrt{RR \times (RR - 1)}
\] \[
E-value_{LCL} = LCL + \sqrt{LCL \times (LCL - 1)}
\]

Here is an R function that will calculate E-values:

\begin{verbatim}
$e_value_rr
[1] 20.94777

$e_value_lcl
[1] 15.52336
\end{verbatim}

Using VanderWeele's recommended reporting language, we may write:

\begin{quote}
``With an observed risk ratio of RR=10.7, an unmeasured confounder that
was associated with both the outcome and the exposure by a risk ratio of
20.9-fold each, above and beyond the measured confounders, could explain
away the estimate, but weaker joint confounder associations could not;
to move the confidence interval to include the null, an unmeasured
confounder that was associated with the outcome and the exposure by a
risk ratio of 15.5-fold each could do so, but weaker joint confounder
associations could not.''
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compute\_evalue\_ols }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(est, se, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{, }\AttributeTok{true =} \DecValTok{0}\NormalTok{) \{}
  \CommentTok{\# rescale estimate and SE to reflect a contrast of size delta}
\NormalTok{  est }\OtherTok{\textless{}{-}}\NormalTok{ est }\SpecialCharTok{/}\NormalTok{ delta}
\NormalTok{  se }\OtherTok{\textless{}{-}}\NormalTok{ se }\SpecialCharTok{/}\NormalTok{ delta}

  \CommentTok{\# compute transformed odds ratio and confidence intervals}
\NormalTok{  odds\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est)}
\NormalTok{  lo }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est }\SpecialCharTok{{-}} \FloatTok{1.78} \SpecialCharTok{*}\NormalTok{ se)}
\NormalTok{  hi }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est }\SpecialCharTok{+} \FloatTok{1.78} \SpecialCharTok{*}\NormalTok{ se)}

  \CommentTok{\# compute E{-}Values based on the RR values}
\NormalTok{  evalue\_point\_estimate }\OtherTok{\textless{}{-}}\NormalTok{ odds\_ratio }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(odds\_ratio }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{  evalue\_lower\_ci }\OtherTok{\textless{}{-}}\NormalTok{ lo }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(lo }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

  \CommentTok{\# return E{-}values}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{EValue\_PointEstimate =}\NormalTok{ evalue\_point\_estimate,}
              \AttributeTok{EValue\_LowerCI =}\NormalTok{ evalue\_lower\_ci))}
\NormalTok{\}}

\CommentTok{\# e.g stimate of 0.5, a standard error of 0.1, and a standard deviation of 1.}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{compute\_evalue\_ols}\NormalTok{(}\AttributeTok{est =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{se =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{)}
\FunctionTok{print}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$EValue_PointEstimate
[1] 2.529831

$EValue_LowerCI
[1] 2.008933
\end{verbatim}

For one's report, Vanderweele suggests using the following language
without modification:

\begin{quote}
``With an observed risk ratio of RR=2.92, an unmeasured confounder that
was associated with both the outcome and the exposure by a risk ratio of
2.92-fold each, above and beyond the measured confounders, could explain
away the estimate, but weaker joint confounder associations could not;
to move the confidence interval to include the null, an unmeasured
confounder that was associated with the outcome and the exposure by a
risk ratio of 2.23-fold each could do so, but weaker joint confounder
associations could not.''
\end{quote}

Note the E-values package will do the computational work for us. It
returns a similar value as the E-Values function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load package}
\FunctionTok{library}\NormalTok{(EValue)}

\NormalTok{EValue}\SpecialCharTok{::}\FunctionTok{evalues.OLS}\NormalTok{( }\AttributeTok{est =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{se =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{, }\AttributeTok{true =} \DecValTok{0}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            point    lower    upper
RR       1.576173 1.319166 1.883252
E-values 2.529142 1.968037       NA
\end{verbatim}

\subsection{Part 4: Pre-registration, Data Analysis, and
Reporting}\label{part-4-pre-registration-data-analysis-and-reporting}

We describe the protocols for pre-registration analysis, conducting
these data analyses, and clearly and accurately communicating scientific
findings.

\subsubsection{Recommended strategies for conveying
results}\label{recommended-strategies-for-conveying-results}

\begin{itemize}
\tightlist
\item
  Report results of a cross-sectional model
\item
  Explain the practical interest of causal effect estimates
\item
  Contrast exposures: tread carefully
\end{itemize}

\newpage{}

\subsection{Part 5: Addressing complex causal
questions}\label{part-5-addressing-complex-causal-questions}

We discuss methods for addressing more complex causal questions than
average treatment-effect estimation, including investigating
treatment-effect heterogeneity, causal interactions, causal mediation,
and longitudinal treatment strategies.

\begin{table}

\caption{\label{tbl-time-varying-confounding}Sources of time-varying
confounding for more ambitious causal questions. (This table is adapted
from (\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologytimevaryingconfounding

}

\end{table}%

For further discussions of our approach, see:
(\citeproc{ref-bulbulia2022}{Bulbulia 2022};
\citeproc{ref-bulbulia2023a}{Bulbulia \emph{et al.} 2023};
\citeproc{ref-bulbulia2023}{Bulbulia 2023a};
\citeproc{ref-hernan2023}{Hernan and Robins 2023};
\citeproc{ref-vanderweele2015}{VanderWeele 2015}))

\subsubsection{Challenges from Measurement error
bias}\label{challenges-from-measurement-error-bias}

\begin{table}

\caption{\label{tbl-measurement-error}Measurement error bias may be
undirected and uncorrelated, directed and uncorrelated, uncorrelated and
directed, or correlated and undirected. (This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologymeasurementerror

}

\end{table}%

\subsubsection{Challenges for Censoring
bias}\label{challenges-for-censoring-bias}

\begin{table}

\caption{\label{tbl-censoring}Examples of censoring bias. (This table is
adapted from (\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologycensoring

}

\end{table}%

\subsubsection{Challenges for External
Validity}\label{challenges-for-external-validity}

\begin{table}

\caption{\label{tbl-external-validity-confounding}Examples of external
validity threats from pre-exposure confounding. (This table is adapted
from (\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologyselectionrestrictionclassic

}

\end{table}%

\begin{table}

\caption{\label{tbl-external-validity-no-bias}Examples of external
validity threats from restriction at baseline, or mismatch between the
target and sample populuations. (This table is adapted from
(\citeproc{ref-bulbulia2023}{Bulbulia 2023a}))}

\centering{

\terminologyselectionrestrictionbaseline

}

\end{table}%

\subsection{Conclusions: Summary of
Advice}\label{conclusions-summary-of-advice}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Clarify the causal question:} To answer a causal question we
  must first ask one (\citeproc{ref-hernan2023}{Hernan and Robins 2023};
  \citeproc{ref-hernan2017per}{Hernán \emph{et al.} 2017}). Prior to any
  analysis, it is crucial to explicitly define the causal question under
  examination. Within this:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \textbf{Define your exposure.}
\item
  \textbf{Define your outcome(s)}
\item
  \textbf{Define causal estimand and its scale}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Clearly define the target population}: for whom do we intend
  the results to generalise? For example, we might restrict our question
  to the population of people who identify as religious. Where relevant,
  survey weights should always be collected and used to obtain valid
  estimates for target population outcomes.
\end{enumerate}

Suppose we wish to investigate the causal effect of religious service
attendance on cooperation. As yet, there is no causal question. Within
the umbrella term of ``religious service attendance'' multiple scenarios
can be considered: attending religious service weekly service; attending
some religious service from a baseline of no attendance, or losing
religious service attendance.

A clearly defined question might contrast might be: ``What is the
expected causal effect of attending religious service at least weekly
among those who do not attend weekly, contrasted with natural
expectation were no intervention to occur?'' (Note: this is a ``shift
intervention.'')

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  \textbf{Clearly state eligibility criteria.}: state
  inclusion/exclusion criteria to obtain valid causal estimates. Note
  that these criteria always relate to a target population.
\item
  \textbf{Ensure correct temporal order in the variables in one's data}:
  causality occurs in time. Confounders occur before exposures, which in
  turn must occur before the outcome.
\item
  \textbf{Balance confounders}: once the temporal structure is set, we
  may adjust for confounders that could distort the causal link between
  exposure and outcome.
\item
  \textbf{Include baseline measures of the treatment and outcome}: with
  at least three waves of data, we should include baseline measures for
  both the treatment and the outcomes. This strategy serves two
  objectives: first, it augments control for confounding variables, and
  second, it permits differentiation between ``incidence'' and
  ``prevalence'' effects. \emph{Incidence effects} capture the emergence
  of new cases or conditions among individuals who acquire the treatment
  during the study.
\item
  \textbf{Adjust for missing data}: we generally recommend using inverse
  probability of censoring weights which may carry fewer assumptions
  that multiply imputing missing values.
\item
  \textbf{Assess multiple dimensions of the outcome within the same
  study}: where scientifically relevant, we recommend using an
  outcomewide approach (\citeproc{ref-vanderweele2020}{VanderWeele
  \emph{et al.} 2020}) to assess multiple outcomes within a single
  study. This approach has several benefits.
\end{enumerate}

First we obtain \emph{contextualised effects}: each outcome is evaluated
in context relative to the others. This facilitates a better
understanding of the importance of each individual effect within the
overarching construct of well-being.

Second, we \emph{mitigate} spurious findings: by assessing multiple
outcomes simultaneously, we minimise the risk of cherry-picking cases
that confirm a preconceived hypothesis, thereby reducing the likelihood
of chance findings.

Third, we \emph{accelerate scientific understanding}: a comprehensive
assessment can fast-track our scientific insights into the potential
advantages and disadvantages of the treatment on multiple outcomes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\item
  \textbf{Where sample size permits, use machine learning with
  cross-validation}: Targeted Maximum Likelihood Estimation (TMLE)
  coupled with machine learning (the \texttt{SuperLearner} library in R
  (\citeproc{ref-polley2023}{Polley \emph{et al.} 2023})) has several
  advantages: first it reduces reliance on the assumption of a correctly
  specified model. The method is robust even if either the treatment
  model or the outcome model is incorrectly specified. Second,
  \emph{machine Learning for confounder balancing improves precision}
  and further refines our ability to balance confounders, particularly
  when these are high-dimensional or interact in ways that cannot be
  known in advance (\citeproc{ref-duxedaz2021}{Díaz \emph{et al.}
  2021}).
\item
  \textbf{Clearly state results using graphs}: it is often sensible to
  estimate effect using standardised outcomes which allows for ready
  graphical comparison. However, in some cases, effects on the data
  scale are more meaningful, in which case graphical comparisons may be
  misleading.
\item
  \textbf{Quantitatively assess robustness to unmeasured confounding}:
  report sensitivity analysis such as E-values.
\item
  \textbf{Measurement error}: note that all data, and in particular
  self-report data, may be subject to random measurement error. Given
  the limitations of self-report measures, the true effect sizes may
  differ from those estimated. Importantly, overly modest effects could
  arise, in part, from uncorrelated measurement inaccuracy in the
  treatment and outcomes.
\item
  \textbf{Generalisability and transportability}: findings should be
  interpreted within the context of the target population. Although the
  results may have broader relevance, direct extrapolation to different
  populations or sociocultural settings should only be undertaken
  cautiously
\end{enumerate}

14 \textbf{Theoretical and practical relevance}: when describing the
relevance of the data, it can be useful to state regression coefficients
from cross-sectional data using models that do not adequately obtain
casual effect estimates. In our experience, the results of ``standard''
models will be different, sometimes considerably so. Data simulations
may also help to drive home the importance of adopting a careful causal
inference approach.

\newpage{}

\subsection{Acknowledgements}\label{acknowledgements}

JB received support from TRT0418. JB received support from the Max
Planck Institute for the Science of Human History. The funders had no
role in preparing the manuscript or the decision to publish.

\newpage{}

\subsection{Appendix A. Example of a transition table to verify
positivity}\label{appendix-a.-example-of-a-transition-table-to-verify-positivity}

\subsubsection{Example transition
matrix}\label{example-transition-matrix}

Table~\ref{tbl-transition-socialising} shows a transition matrix
captures the movement between weekly hours socialising during the
baseline (NZAVS time 10) wave and exposure wave (NZAVS time 11). Entries
on the diagonal (in bold) indicate the number of individuals who stayed
in their initial state. In contrast, the off-diagonal shows the
transitions from the initial state (bold) to another state in the
following wave (off diagonal). Again, a cell located at the intersection
of row \(i\) and column \(j\), where \(i \neq j\), shows the count of
individuals moving from state \(i\) to state \(j\).

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}@{}}
\caption{Transition matrix for change in the square of hours socialing
with community each
week}\label{tbl-transition-socialising}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
From
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 0
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 6
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 7
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 8
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
From
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 0
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 6
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 7
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 8
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
State 0 & \textbf{20039} & 2243 & 1192 & 221 & 25 & 12 & 7 & 3 & 6 \\
State 1 & 2288 & \textbf{1389} & 731 & 103 & 11 & 4 & 3 & 0 & 0 \\
State 2 & 1328 & 660 & \textbf{806} & 161 & 29 & 6 & 2 & 1 & 2 \\
State 3 & 236 & 101 & 151 & \textbf{76} & 17 & 5 & 1 & 0 & 0 \\
State 4 & 55 & 16 & 32 & 17 & \textbf{11} & 3 & 1 & 2 & 0 \\
State 5 & 16 & 5 & 8 & 4 & 3 & \textbf{0} & 1 & 0 & 0 \\
State 6 & 8 & 1 & 0 & 0 & 1 & 0 & \textbf{0} & 0 & 1 \\
State 7 & 3 & 1 & 1 & 1 & 0 & 0 & 0 & \textbf{0} & 0 \\
State 8 & 3 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & \textbf{1} \\
\end{longtable}

Table~\ref{tbl-transition-socialising} presents a summary of changes in
socialising at the threshold that we compared. When shifting to
socialising at least 1.4 hours per week, we imagine `treating' 25,959
cases. Again this table is for illustration, as the the shift
intervention allows us to flexibly contrast cases without projecting the
entire population into one or another cell.

\begin{longtable}[]{@{}ccc@{}}
\caption{Transition matrix for change in the square of hours socialing
with community each
week}\label{tbl-transition-socialising-shift}\tabularnewline
\toprule\noalign{}
From & \textless{} 1.4 weekly hours & \textgreater= 1.4 weekly hours \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
From & \textless{} 1.4 weekly hours & \textgreater= 1.4 weekly hours \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textless{} 1.4 weekly hours & \textbf{25959} & 2318 \\
\textgreater= 1.4 weekly hours & 2434 & \textbf{1347} \\
\end{longtable}

\subsection{Appendix B. Example report of
estimator}\label{appendix-b.-example-report-of-estimator}

\subsection{Appendix C. Baseline in
NZAVS}\label{appendix-c.-baseline-in-nzavs}

\paragraph{Age (waves: 1-15)}\label{age-waves-1-15}

We asked participants' age in an open-ended question (``What is your
age?'' or ``What is your date of birth'').

\paragraph{Disability (waves: 5-15)}\label{disability-waves-5-15}

We assessed disability with a one-item indicator adapted from Verbrugge
(\citeproc{ref-verbrugge1997}{1997}), that asks ``Do you have a health
condition or disability that limits you, and that has lasted for 6+
months?'' (1 = Yes, 0 = No).

\paragraph{Education Attainment (waves: 1,
4-15)}\label{education-attainment-waves-1-4-15}

Participants were asked ``What is your highest level of
qualification?''. We coded participants highest finished degree
according to the New Zealand Qualifications Authority. Ordinal-Rank 0-10
NZREG codes (with overseas school quals coded as Level 3, and all other
ancillary categories coded as missing) See:
https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf

\paragraph{Employment (waves: 1-3,
4-11)}\label{employment-waves-1-3-4-11}

We asked participants ``Are you currently employed? (This includes
self-employed or casual work)''. * note: This question disappeared in
the updated NZAVS Technical documents (Data Dictionary).

\paragraph{European (waves: 1-15)}\label{european-waves-1-15}

Participants were asked ``Which ethnic group do you belong to (NZ census
question)?'' or ``Which ethnic group(s) do you belong to? (Open-ended)''
(wave: 3). Europeans were coded as 1, whereas other ethnicities were
coded as 0.

\paragraph{Ethnicity (waves: 3)}\label{ethnicity-waves-3}

Based on the New Zealand Census, we asked participants ``Which ethnic
group(s) do you belong to?''. The responses were: (1) New Zealand
European; (2) Māori; (3) Samoan; (4) Cook Island Māori; (5) Tongan; (6)
Niuean; (7) Chinese; (8) Indian; (9) Other such as DUTCH, JAPANESE,
TOKELAUAN. Please state:. We coded their answers into four groups:
Maori, Pacific, Asian, and Euro (except for Time 3, which used an
open-ended measure).

\paragraph{Gender (waves: 1-15)}\label{gender-waves-1-15}

We asked participants' gender in an open-ended question: ``What is your
gender?'' or ``Are you male or female?'' (waves: 1-5). Female was coded
as 0, Male was coded as 1, and gender diverse coded as 3
(\citeproc{ref-fraser_coding_2020}{Fraser \emph{et al.} 2020}). (or 0.5
= neither female nor male)

\paragraph{Income (waves: 1-3, 4-15)}\label{income-waves-1-3-4-15}

Participants were asked ``Please estimate your total household income
(before tax) for the year XXXX''. To stabilise this indicator, we first
took the natural log of the response + 1, and then centred and
standardised the log-transformed indicator.

\paragraph{Number of Children (waves: 1-3,
4-15)}\label{number-of-children-waves-1-3-4-15}

We measured the number of children using one item from Bulbulia
(\citeproc{ref-Bulbulia_2015}{2015}). We asked participants ``How many
children have you given birth to, fathered, or adopted. How many
children have you given birth to, fathered, or adopted?'' or ``How many
children have you given birth to, fathered, or adopted. How many
children have you given birth to, fathered, and/or parented?'' (waves:
12-15).

\paragraph{Political Orientation}\label{political-orientation}

We measured participants' political orientation using a single item
adapted from Jost (\citeproc{ref-jost_end_2006-1}{2006}).

``Please rate how politically liberal versus conservative you see
yourself as being.''

(1 = Extremely Liberal to 7 = Extremely Conservative)

\paragraph{NZSEI-13 (waves: 8-15)}\label{nzsei-13-waves-8-15}

We assessed occupational prestige and status using the New Zealand
Socio-economic Index 13 (NZSEI-13) (\citeproc{ref-fahy2017}{Fahy
\emph{et al.} 2017}). This index uses the income, age, and education of
a reference group, in this case, the 2013 New Zealand census, to
calculate a score for each occupational group. Scores range from 10
(Lowest) to 90 (Highest). This list of index scores for occupational
groups was used to assign each participant an NZSEI-13 score based on
their occupation.

Participants were asked, ``If you are a parent, what is the birth date
of your eldest child?''.

\paragraph{Living with Partner}\label{living-with-partner}

Participants were asekd ``Do you live with your partner?'' (1 = Yes, 0 =
No).

\paragraph{Living in an Urban Area (waves:
1-15)}\label{living-in-an-urban-area-waves-1-15}

We coded whether they are living in an urban or rural area (1 = Urban, 0
= Rural) based on the addresses provided.

We coded whether they were living in an urban or rural area (1 = Urban,
0 = Rural) based on the addresses provided.

\paragraph{NZ Deprivation Index (waves:
1-15)}\label{nz-deprivation-index-waves-1-15}

We used the NZ Deprivation Index to assign each participant a score
based on where they live (\citeproc{ref-atkinson2019}{Atkinson \emph{et
al.} 2019}). This score combines data such as income, home ownership,
employment, qualifications, family structure, housing, and access to
transport and communication for an area into one deprivation score.

\paragraph{NZ-Born (waves: 1-2,4-15)}\label{nz-born-waves-1-24-15}

We asked participants ``Which country were you born in?'' or ``Where
were you born? (please be specific, e.g., which town/city?)'' (waves:
6-15).

\paragraph{Mini-IPIP 6 (waves:
1-3,4-15)}\label{mini-ipip-6-waves-1-34-15}

We measured participants personalities with the Mini International
Personality Item Pool 6 (Mini-IPIP6) (\citeproc{ref-sibley2011}{Sibley
\emph{et al.} 2011}) which consists of six dimensions and each dimension
is measured with four items:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  agreeableness,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I sympathize with others' feelings.
  \item
    I am not interested in other people's problems. (r)
  \item
    I feel others' emotions.
  \item
    I am not really interested in others. (r)
  \end{enumerate}
\item
  conscientiousness,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I get chores done right away.
  \item
    I like order.
  \item
    I make a mess of things. (r)
  \item
    I ften forget to put things back in their proper place. (r)
  \end{enumerate}
\item
  extraversion,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I am the life of the party.
  \item
    I don't talk a lot. (r)
  \item
    I keep in the background. (r)
  \item
    I talk to a lot of different people at parties.
  \end{enumerate}
\item
  honesty-humility,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I feel entitled to more of everything. (r)
  \item
    I deserve more things in life. (r)
  \item
    I would like to be seen driving around in a very expensive car. (r)
  \item
    I would get a lot of pleasure from owning expensive luxury goods.
    (r)
  \end{enumerate}
\item
  neuroticism, and

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I have frequent mood swings.
  \item
    I am relaxed most of the time. (r)
  \item
    I get upset easily.
  \item
    I seldom feel blue. (r)
  \end{enumerate}
\item
  openness to experience

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I have a vivid imagination.
  \item
    I have difficulty understanding abstract ideas. (r)
  \item
    I do not have a good imagination. (r)
  \item
    I am not interested in abstract ideas. (r)
  \end{enumerate}
\end{enumerate}

Each dimension was assessed with four items and participants rated the
accuracy of each item as it applies to them from 1 (Very Inaccurate) to
7 (Very Accurate). Items marked with (r) are reverse coded.

\paragraph{Honesty-Humility-Modesty Facet (waves:
10-14)}\label{honesty-humility-modesty-facet-waves-10-14}

Participants indicated the extent to which they agree with the following
four statements from Campbell \emph{et al.}
(\citeproc{ref-campbell2004}{2004}) , and Sibley \emph{et al.}
(\citeproc{ref-sibley2011}{2011}) (1 = Strongly Disagree to 7 = Strongly
Agree)

\begin{verbatim}
i.  I want people to know that I am an important person of high status, (Waves: 1, 10-14)
ii. I am an ordinary person who is no better than others.
iii. I wouldn't want people to treat me as though I were superior to them.
iv. I think that I am entitled to more respect than the average person is.
\end{verbatim}

\subsubsection{Exposure variable}\label{exposure-variable}

HERE

\subsubsection{Health well-being
outcomes}\label{health-well-being-outcomes}

\subsubsection{Appendix D. Why survey weights should be used when the
target population is the national
population.}\label{appendix-d.-why-survey-weights-should-be-used-when-the-target-population-is-the-national-population.}

Code to follow\ldots{}

\newpage{}

\subsection*{References}\label{references}
\addcontentsline{toc}{subsection}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-agnostic}
Agnostic notes on regression adjustments to experimental data:
Reexamining freedman{'}s critique (n.d.). Retrieved from
\url{https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-1/Agnostic-notes-on-regression-adjustments-to-experimental-data--Reexamining/10.1214/12-AOAS583.full}

\bibitem[\citeproctext]{ref-athey2021}
Athey, S, and Wager, S (2021) Policy Learning With Observational Data.
\emph{Econometrica}, \textbf{89}(1), 133--161.
doi:\href{https://doi.org/10.3982/ECTA15732}{10.3982/ECTA15732}.

\bibitem[\citeproctext]{ref-atkinson2019}
Atkinson, J, Salmond, C, and Crampton, P (2019) \emph{NZDep2018 index of
deprivation, user{'}s manual.}, Wellington.

\bibitem[\citeproctext]{ref-bulbulia2022}
Bulbulia, JA (2022) A workflow for causal inference in cross-cultural
psychology. \emph{Religion, Brain \& Behavior}, \textbf{0}(0), 1--16.
doi:\href{https://doi.org/10.1080/2153599X.2022.2070245}{10.1080/2153599X.2022.2070245}.

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023a) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-bulbulia2023c}
Bulbulia, JA (2023b) Selection bias (with and without confounding)
explained with sequential causal diagrams. Retrieved from
\url{https://osf.io/cjgey}

\bibitem[\citeproctext]{ref-bulbulia2023a}
Bulbulia, JA, Afzali, MU, Yogeeswaran, K, and Sibley, CG (2023)
Long-term causal effects of far-right terrorism in {N}ew {Z}ealand.
\emph{PNAS Nexus}, \textbf{2}(8), pgad242.

\bibitem[\citeproctext]{ref-Bulbulia_2015}
Bulbulia, S, J. A. (2015) Religion and parental cooperation: An
empirical test of slone's sexual signaling model. In \&. V. S. J. Slone
D., ed., \emph{The attraction of religion: A sexual selectionist
account}, Bloomsbury Press, 29--62.

\bibitem[\citeproctext]{ref-calonico2022}
Calonico, S, Cattaneo, MD, Farrell, MH, and Titiunik, R (2022)
\emph{Rdrobust: Robust data-driven statistical inference in
regression-discontinuity designs}. Retrieved from
\url{https://CRAN.R-project.org/package=rdrobust}

\bibitem[\citeproctext]{ref-campbell2004}
Campbell, WK, Bonacci, AM, Shelton, J, Exline, JJ, and Bushman, BJ
(2004) Psychological entitlement: interpersonal consequences and
validation of a self-report measure. \emph{Journal of Personality
Assessment}, \textbf{83}(1), 29--45.
doi:\href{https://doi.org/10.1207/s15327752jpa8301_04}{10.1207/s15327752jpa8301\_04}.

\bibitem[\citeproctext]{ref-cole2010generalizing}
Cole, SR, and Stuart, EA (2010) Generalizing evidence from randomized
clinical trials to target populations: The ACTG 320 trial.
\emph{American Journal of Epidemiology}, \textbf{172}(1), 107--115.

\bibitem[\citeproctext]{ref-cui2020}
Cui, Y, Kosorok, MR, Sverdrup, E, Wager, S, and Zhu, R (2020) Estimating
heterogeneous treatment effects with right-censored data via causal
survival forests. Retrieved from
\url{https://arxiv.org/abs/2001.09887v5}

\bibitem[\citeproctext]{ref-danaei2012}
Danaei, G, Tavakkoli, M, and Hernán, MA (2012) Bias in observational
studies of prevalent users: lessons for comparative effectiveness
research from a meta-analysis of statins. \emph{American Journal of
Epidemiology}, \textbf{175}(4), 250--262.
doi:\href{https://doi.org/10.1093/aje/kwr301}{10.1093/aje/kwr301}.

\bibitem[\citeproctext]{ref-duxedaz2021}
Díaz, I, Williams, N, Hoffman, KL, and Schenck, EJ (2021) Non-parametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association}.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-fahy2017}
Fahy, KM, Lee, A, and Milne, BJ (2017) \emph{New Zealand socio-economic
index 2013}, Wellington, New Zealand: Statistics New Zealand-Tatauranga
Aotearoa.

\bibitem[\citeproctext]{ref-foster2023}
Foster, DJ, and Syrgkanis, V (2023) Orthogonal statistical learning.
\emph{The Annals of Statistics}, \textbf{51}(3), 879--908.
doi:\href{https://doi.org/10.1214/23-AOS2258}{10.1214/23-AOS2258}.

\bibitem[\citeproctext]{ref-fraser_coding_2020}
Fraser, G, Bulbulia, J, Greaves, LM, Wilson, MS, and Sibley, CG (2020)
Coding responses to an open-ended gender measure in a new zealand
national sample. \emph{The Journal of Sex Research}, \textbf{57}(8),
979--986.
doi:\href{https://doi.org/10.1080/00224499.2019.1687640}{10.1080/00224499.2019.1687640}.

\bibitem[\citeproctext]{ref-greenland1999}
Greenland, S, Pearl, J, and Robins, JM (1999) Causal diagrams for
epidemiologic research. \emph{Epidemiology (Cambridge, Mass.)},
\textbf{10}(1), 37--48.

\bibitem[\citeproctext]{ref-greifer2023}
Greifer, N, Worthington, S, Iacus, S, and King, G (2023) \emph{Clarify:
Simulation-based inference for regression models}. Retrieved from
\url{https://iqss.github.io/clarify/}

\bibitem[\citeproctext]{ref-hernan2023}
Hernan, MA, and Robins, JM (2023) \emph{Causal inference}, Taylor \&
Francis. Retrieved from
\url{https://books.google.co.nz/books?id=/_KnHIAAACAAJ}

\bibitem[\citeproctext]{ref-hernuxe1n2008a}
Hernán, MA, Alonso, A, Logan, R, \ldots{} Robins, JM (2008)
Observational studies analyzed like randomized experiments: An
application to postmenopausal hormone therapy and coronary heart
disease. \emph{Epidemiology}, \textbf{19}(6), 766.
doi:\href{https://doi.org/10.1097/EDE.0b013e3181875e61}{10.1097/EDE.0b013e3181875e61}.

\bibitem[\citeproctext]{ref-hernuxe1n2004a}
Hernán, MA, Hernández-Díaz, S, and Robins, JM (2004) A structural
approach to selection bias. \emph{Epidemiology}, \textbf{15}(5),
615--625. Retrieved from \url{https://www.jstor.org/stable/20485961}

\bibitem[\citeproctext]{ref-hernuxe1n2006}
Hernán, MA, and Robins, JM (2006) Estimating causal effects from
epidemiological data. \emph{Journal of Epidemiology \& Community
Health}, \textbf{60}(7), 578--586.
doi:\href{https://doi.org/10.1136/jech.2004.029496}{10.1136/jech.2004.029496}.

\bibitem[\citeproctext]{ref-hernan2017per}
Hernán, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-hernuxe1n2016}
Hernán, MA, Sauer, BC, Hernández-Díaz, S, Platt, R, and Shrier, I (2016)
Specifying a target trial prevents immortal time bias and other
self-inflicted injuries in observational analyses. \emph{Journal of
Clinical Epidemiology}, \textbf{79}, 7075.

\bibitem[\citeproctext]{ref-hernuxe1n2022}
Hernán, MA, Wang, W, and Leaf, DE (2022) Target trial emulation: A
framework for causal inference from observational data. \emph{JAMA},
\textbf{328}(24), 2446--2447.
doi:\href{https://doi.org/10.1001/jama.2022.21383}{10.1001/jama.2022.21383}.

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and Díaz, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoffman2022}
Hoffman, KL, Schenck, EJ, Satlin, MJ, \ldots{} Díaz, I (2022) Comparison
of a target trial emulation framework vs cox regression to estimate the
association of corticosteroids with COVID-19 mortality. \emph{JAMA
Network Open}, \textbf{5}(10), e2234425.
doi:\href{https://doi.org/10.1001/jamanetworkopen.2022.34425}{10.1001/jamanetworkopen.2022.34425}.

\bibitem[\citeproctext]{ref-holland1986}
Holland, PW (1986) Statistics and causal inference. \emph{Journal of the
American Statistical Association}, \textbf{81}(396), 945960.

\bibitem[\citeproctext]{ref-hume1902}
Hume, D (1902) \emph{Enquiries Concerning the Human Understanding: And
Concerning the Principles of Morals}, Clarendon Press.

\bibitem[\citeproctext]{ref-imai2008misunderstandings}
Imai, K, King, G, and Stuart, EA (2008) Misunderstandings between
experimentalists and observationalists about causal inference.
\emph{Journal of the Royal Statistical Society Series A: Statistics in
Society}, \textbf{171}(2), 481--502.

\bibitem[\citeproctext]{ref-jost_end_2006-1}
Jost, JT (2006) The end of the end of ideology. \emph{American
Psychologist}, \textbf{61}(7), 651--670.
doi:\href{https://doi.org/10.1037/0003-066X.61.7.651}{10.1037/0003-066X.61.7.651}.

\bibitem[\citeproctext]{ref-kennedy2023}
Kennedy, EH (2023) Towards optimal doubly robust estimation of
heterogeneous causal effects. \emph{Electronic Journal of Statistics},
\textbf{17}(2), 3008--3049.
doi:\href{https://doi.org/10.1214/23-EJS2157}{10.1214/23-EJS2157}.

\bibitem[\citeproctext]{ref-kitagawa2018}
Kitagawa, T, and Tetenov, A (2018) Who should be treated? Empirical
welfare maximization methods for treatment choice. \emph{Econometrica},
\textbf{86}(2), 591--616. Retrieved from
\url{https://www.jstor.org/stable/44955978}

\bibitem[\citeproctext]{ref-lewis1973}
Lewis, D (1973) Causation. \emph{The Journal of Philosophy},
\textbf{70}(17), 556--567.
doi:\href{https://doi.org/10.2307/2025310}{10.2307/2025310}.

\bibitem[\citeproctext]{ref-nie2021}
Nie, X, and Wager, S (2021) Quasi-oracle estimation of heterogeneous
treatment effects. \emph{Biometrika}, \textbf{108}(2), 299--319.
doi:\href{https://doi.org/10.1093/biomet/asaa076}{10.1093/biomet/asaa076}.

\bibitem[\citeproctext]{ref-ogburn2021}
Ogburn, EL, and Shpitser, I (2021) Causal modelling: The two cultures.
\emph{Observational Studies}, \textbf{7}(1), 179--183.
doi:\href{https://doi.org/10.1353/obs.2021.0006}{10.1353/obs.2021.0006}.

\bibitem[\citeproctext]{ref-pearl1995}
Pearl, J (1995) Causal diagrams for empirical research.
\emph{Biometrika}, \textbf{82}(4), 669--688.

\bibitem[\citeproctext]{ref-pearl2009}
Pearl, J (2009) \emph{\href{https://doi.org/10.1214/09-SS057}{Causal
inference in statistics: An overview}}.

\bibitem[\citeproctext]{ref-polley2023}
Polley, E, LeDell, E, Kennedy, C, and Laan, M van der (2023)
\emph{SuperLearner: Super learner prediction}. Retrieved from
\url{https://CRAN.R-project.org/package=SuperLearner}

\bibitem[\citeproctext]{ref-rubin1976}
Rubin, DB (1976) Inference and missing data. \emph{Biometrika},
\textbf{63}(3), 581--592.
doi:\href{https://doi.org/10.1093/biomet/63.3.581}{10.1093/biomet/63.3.581}.

\bibitem[\citeproctext]{ref-sibley2011}
Sibley, CG, Luyten, N, Purnomo, M, \ldots{} Robertson, A (2011) The
Mini-IPIP6: Validation and extension of a short measure of the Big-Six
factors of personality in New Zealand. \emph{New Zealand Journal of
Psychology}, \textbf{40}(3), 142--159.

\bibitem[\citeproctext]{ref-stuart2018generalizability}
Stuart, EA, Ackerman, B, and Westreich, D (2018) Generalizability of
randomized trial results to target populations: Design and analysis
possibilities. \emph{Research on Social Work Practice}, \textbf{28}(5),
532--537.

\bibitem[\citeproctext]{ref-stuart2015}
Stuart, EA, Bradshaw, CP, and Leaf, PJ (2015) Assessing the
Generalizability of Randomized Trial Results to Target Populations.
\emph{Prevention Science}, \textbf{16}(3), 475--485.
doi:\href{https://doi.org/10.1007/s11121-014-0513-z}{10.1007/s11121-014-0513-z}.

\bibitem[\citeproctext]{ref-tchetgen2012}
Tchetgen, EJT, and VanderWeele, TJ (2012) On causal inference in the
presence of interference. \emph{Statistical Methods in Medical
Research}, \textbf{21}(1), 5575.

\bibitem[\citeproctext]{ref-vanderweele2009}
VanderWeele, TJ (2009) Concerning the consistency assumption in causal
inference. \emph{Epidemiology}, \textbf{20}(6), 880.
doi:\href{https://doi.org/10.1097/EDE.0b013e3181bd5638}{10.1097/EDE.0b013e3181bd5638}.

\bibitem[\citeproctext]{ref-vanderweele2015}
VanderWeele, TJ (2015) \emph{Explanation in causal inference: Methods
for mediation and interaction}, Oxford University Press.

\bibitem[\citeproctext]{ref-vanderweele2018}
VanderWeele, TJ (2018) On well-defined hypothetical interventions in the
potential outcomes framework. \emph{Epidemiology}, \textbf{29}(4), e24.
doi:\href{https://doi.org/10.1097/EDE.0000000000000823}{10.1097/EDE.0000000000000823}.

\bibitem[\citeproctext]{ref-vanderweele2022}
VanderWeele, TJ (2022) Constructed measures and causal inference:
Towards a new model of measurement for psychosocial constructs.
\emph{Epidemiology}, \textbf{33}(1), 141.
doi:\href{https://doi.org/10.1097/EDE.0000000000001434}{10.1097/EDE.0000000000001434}.

\bibitem[\citeproctext]{ref-vanderweele2013}
VanderWeele, TJ, and Hernan, MA (2013) Causal inference under multiple
versions of treatment. \emph{Journal of Causal Inference},
\textbf{1}(1), 120.

\bibitem[\citeproctext]{ref-vanderweele2020}
VanderWeele, TJ, Mathur, MB, and Chen, Y (2020) Outcome-wide
longitudinal designs for causal inference: A new template for empirical
studies. \emph{Statistical Science}, \textbf{35}(3), 437466.

\bibitem[\citeproctext]{ref-vansteelandt2022}
Vansteelandt, S, and Dukes, O (2022) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657685.

\bibitem[\citeproctext]{ref-verbrugge1997}
Verbrugge, LM (1997) A global disability indicator. \emph{Journal of
Aging Studies}, \textbf{11}(4), 337--362.
doi:\href{https://doi.org/10.1016/S0890-4065(97)90026-8}{10.1016/S0890-4065(97)90026-8}.

\bibitem[\citeproctext]{ref-wager2018}
Wager, S, and Athey, S (2018) Estimation and inference of heterogeneous
treatment effects using random forests. \emph{Journal of the American
Statistical Association}, \textbf{113}(523), 1228--1242.
doi:\href{https://doi.org/10.1080/01621459.2017.1319839}{10.1080/01621459.2017.1319839}.

\bibitem[\citeproctext]{ref-williams2021}
Williams, NT, and Díaz, I (2021) \emph{Lmtp: Non-parametric causal
effects of feasible interventions based on modified treatment policies}.
doi:\href{https://doi.org/10.5281/zenodo.3874931}{10.5281/zenodo.3874931}.

\end{CSLReferences}



\end{document}
