% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={The Weirdest Causal Inferences in the World},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{The Weirdest Causal Inferences in the World}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-05-25}
\begin{document}
\maketitle
\begin{abstract}
Human scientists ask and answer questions about humans. Many of these
questions are causal. This study clarifies two failure modes in causal
inference. (1) Measurement error bias occurs when there is a discrepancy
between a variable's true value and its observed value. (2)
Sample-restriction bias arises when the association between cause and
effect in a study population does not reflect the causal association in
the target population. We use causal directed acyclic graphs (causal
DAGs) to show how these threats to valid inference relate to each other.
Our discussion addresses concerns that psycho-social datasets often draw
entirely from `Western, Educated, Industrialized, Rich, and Democratic
(WEIRD)' populations. We provide simple graphical tools to help
investigators evaluate when sample restriction is a feature and when it
is a bug.

\textbf{KEYWORDS}: \emph{Causal Inference}; \emph{Comparative};
\emph{Cross-Cultural}; \emph{DAGs};* \emph{Evolution},
\emph{Experiments}; *Measurement Error**; \emph{Selection Bias};
\end{abstract}

\subsection{Introduction}\label{introduction}

Human scientists ask and answer questions. To anchor answers in facts,
we collect data.

Most human scientists work in what Joseph Henrich, Steven Heine, and Ara
Norenzayan have termed `WEIRD' societies: `Western, Educated,
Industrialized, Rich, and Democratic Societies'
(\citeproc{ref-henrich2010weirdest}{Henrich \emph{et al.} 2010}).
Unsurprisingly, WEIRD samples are over-represented in human science
datasets (\citeproc{ref-arnett2008neglected}{Arnett 2008};
\citeproc{ref-sears1986college}{Sears 1986}). Henrich \emph{et al.}
(\citeproc{ref-henrich2010weirdest}{2010}) illustrate how WEIRD samples
differ from non-WEIRD samples in areas such as spatial cognition and
perceptions of fairness, while showing continuities in basic emotions
recognition, positive self-views, and motivation to punish anti-social
behaviour. Because science seeks generalisation wherever it can, Henrich
\emph{et al.} (\citeproc{ref-henrich2010weirdest}{2010}) urge that
sampling from non-WEIRD populations is desirable.

Recently, a host of institutional diversity and inclusion initiatives
have been developed that commend researchers to obtain data from global
samples. In my view, the motivation for these mission statements is
ethically laudable. The injunction for a broader science of humanity
also accords with institutional missions. For example, the scientific
mission of the American Psychological Association (APA) is `to promote
the advancement, communication, and application of psychological science
and knowledge to benefit society and improve lives.' The APA does not
state that it wants to understand and benefit only North Atlantic
Societies.\footnote{https://www.apa.org/pubs/authors/equity-diversity-inclusion}.
It is therefore tempting to use such a mission statement as an ideal by
which to evaluate the samples used in human scientific research.

Suppose we agree that promoting a globally diverse science makes ethical
sense. Does the sampling of globally diverse populations always advance
this ideal? It is easy find examples in which restricting our source
population makes better scientific sense. Suppose we are interested in
the psychological effects of restorative justice among victims of
violent crime. Here, it would make little scientific sense to sample
from a population that has not experienced violent crime. Nor would it
make ethical sense. The scientific question, which my have important
ethical importance, is not served by casting a wider net. Suppose our
the interest were to investigate the health effects of calorie
restriction. It might be unethical to include children or the elderly.
It make little sense to investigate the psychological impact of
vasectomy in biological female or historectomy in biological males

In the cases we just considered, the scientific questions pertained to a
sub-sample of the human population and so could be sensibly restricted.
However even for questions that relate to all of humanity, sampling from
all of humanity might be undesirable. For example, if we were interested
in the effects of a vaccine on disease, sampling from one population
might be as good as sampling from all. Sampling from one population
might spare time and expense, which come with opportunity costs. We
might conclude that sampling universally, where unnecessary, is wasteful
and unethical. It would be worse than weird to do so.

We might agree with our mission statements in judging that ethical
aspirations must guide research at every phase. More fundamental, we
cannot assess the bandwidth of human diversity from the armchair,
without emprical study, and this is a motivation to investigate. Yet,
mistaking our aspirations for sampling directives risks wasteful
science. Because waste carries opportunity costs, wasteful science is
unethical science.

I present this examples to remind ourselves of the importance of
addressing questions of sampling in relation to its context.

During the past twenty years, the causal data science, also known as
`causal inference' or `CI', has enabled tremendous clarity for questions
of research design and analysis
(\citeproc{ref-richardson2014causal}{Richardson and Rotnitzky 2014}).
Here, we will examine how workflows developed from causal inference
clarify threats and opportunities for comparative human research. Put
differently causal inference helps us to clarify the assumptions under
which restriction desirable and when it not. Not all questions are
causal, of course. However, because manifest associations a dataset may
not be evidence of \emph{association} in the world, even those who seek
descriptive understanding benefit benefit from causal inferential
workflows (\citeproc{ref-vansteelandt2022a}{Vansteelandt and Dukes
2022a}).

In the remainder of the introduction I review causal directed acyclic
graphs (causal DAGs). Readers familiar with causal diagrams may skip
this section. Because causal diagrams encode causal assumptions, we use
will use the terms `structural' and `causal' synoymously. I encourage
readers unfamiliar with causal directed acyclic graphs to develop
familiarity before proceeding: (\citeproc{ref-barrett2021}{Barrett
2021}; \citeproc{ref-bulbulia2023}{Bulbulia 2023};
\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024 Chapter 6};
\citeproc{ref-mcelreath2020}{McElreath 2020} chapater 5,6;
\citeproc{ref-neal2020introduction}{Neal 2020};
\citeproc{ref-pearl2009a}{Pearl 2009}).

\textbf{Part 1} uses causal diagrams to clarify five structural features
of measurement-error bias. Understanding measurement error bias is
essential in all research. In comparative human scientific research,
measurement error casts a long dark shadow.

\textbf{Part 2} examines structural sources of biase arising from
attrition and non-response, also known as `right-censoring bias', or
simply `censoring bias'. This term denotes a form of sample restriction
that occurs after the start of study. It may lead to bias in the absence
of confounding wherever sample population at the end of study differs
from sample population at the start of study. For simplicity we assume
that the sample poulation at the start of study is equivalent to the
source population which is in turn equivalent to the target population
of interest.

\textbf{Part 3} considers threats to target validity at the start of
study, when there is a mismatch between the sample population at the
start of study and the target population. To simplify, in this section
we suppose that the sample population is equivalent to the source
population, and consider threats to `target validity' when the source
population and the target population do not match. We clarify `match'
and `mismatch' by focusing on structural threats to inference when the
sample population is (1) too restrictive (for example too WEIRD) (2)
Insufficiently restrictive (WEIRD is too weird).

Throughout, we shall consider that although the concepts of measurement
bias, right-censoring bias, and source bias (left-censoring bias) are
distinct, common structural motifs are shared by each. Causal directed
acyclic graphs clarify these recurring structural motives, greatly
clarifying the tasks of comparative research design.

We begin with a brief overview of causal inference and causal diagrams
and our terminology.

\subsubsection{What is causality?}\label{what-is-causality}

To quantify a causal effect we must contrast the world as it has been
realised -- which is, in principle, observable -- with the world as it
might have been otherwise -- which is, in principle, not observable.

Consider a binary treatment variable \(A \in \{0,1\}\) representing the
randomised administration of a vaccine for individuals \(i\) in the set
\(\{1, 2, \ldots, n\}\). \(A_i = 1\) denotes administration in the
vaccine condition and \(A_i = 0\) denotes administration in the control
condition. The potential outcomes for each individual are denoted as
\(Y_i(0)\) and \(Y_i(1)\). These are the outcomes that are yet to be
realised before administration. For this reason they are called
`potential' or `counterfactual' outcomes. For an individual \(i\) we can
define a causal effect as a contrast between the outcome as it would
have been observed in response to one level of an intervention and the
outcome as it would have been observed in response to another level of
the intervention. Such a contrast for the \(i^{th}\) individual can be
expressed on the difference scale as:

\[
\text{Individual Treatment Effect} = Y_i(1) - Y_i(0)
\]

where the `Individual Treatment Effect' defines the difference in
respect of some predefined measure \(Y\) in a scenario in which the
treatment is received compared with a scenario in which the treatment is
not received, and \(Y_i(1) - Y_i(0) \neq 0\) denotes a causal effect of
\(A\) on \(Y\) for unit \(i\) on the difference scale. Similarly
\(\frac{Y_i(1)}{Y_i(0)}\neq 1\) denotes a causal effect of treatment
\(A\) for unit \(i\) on the risk-ratio scale. For any unit \(i\) these
quantities cannot be computed from observational data.

Suppose Alice is given vaccine: \(A_{\text{Alice}} = 1\). If we assume
the realised outcome \(Y_{Alice}| A = 1\) is equal to the counterfactual
outcome \(Y_{Alice}(1)\) then for Alice \(Y_{Alice}(1)\) is observed but
\(Y_{Alice}(0)\) remains counterfactual, and missing. Similarly, if Bob
is not given vaccine, for Bob \(Y_{Bob}(0)\) is observed but
\(Y_{Bob}(1)\) is not. That we cannot observe individual level causal
effects is called the \emph{Fundamental Problem of Causal Inference}
(\citeproc{ref-holland1986}{Holland 1986};
\citeproc{ref-rubin1976}{Rubin 1976}). This problem has long puzzled
philosophers(\citeproc{ref-hume1902}{Hume 1902};
\citeproc{ref-lewis1973}{Lewis 1973}), However, although individual
causal effects are generally unobservable, we may sometimes recover
average causal effects by treatment group.

\subsubsection{How we obtain average causal effect estimates from
ideally conducted randomised
experiments?}\label{how-we-obtain-average-causal-effect-estimates-from-ideally-conducted-randomised-experiments}

The Average Treatment Effect measures the difference in outcomes between
treated and control groups such that,

\[
\text{Average Treatement Effect} = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
\]

where \(\mathbb{E}[Y(1)]\) and \(\mathbb{E}[Y(0)]\) are the average
outcome for the the target population in a study were \emph{everyone} in
the target population subject to treatment contrasted with the average
were \emph{everyone} in the target population subject to the control
condition.

In a randomised experiment, we estimate these averages under the
assumption that the sample population matches the target population and
by considering average observed and unobserved outcomes under the
treatments to be contrasted:

\[
\text{ATE} = \left(\mathbb{E}[Y(1)|A = 1] + \mathbb{E}[Y(1)|A = 0]\right) - \left(\mathbb{E}[Y(0)|A = 0] + \mathbb{E}[Y(0)|A = 1]\right)
\]

Effective randomisation ensures that potential outcomes are similarly
distributed across both groups such that any differences in the averages
of the treatment groups may be attributed to treatment. Therefore, in
the ideally conducted randomised experiment, the average outcomes can be
expected to be equal across different treatment conditions for the
population from which the sample is drawn:

\[
\widehat{\mathbb{E}}[Y(0) | A = 1] = \widehat{\mathbb{E}}[Y(0) | A = 0], \quad \widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y(1) | A = 0]
\]

This provides an unbiased estimate of the Average Treatment Effect
\(\widehat{\text{ATE}}\),

\[
\widehat{\text{ATE}} = \widehat{\mathbb{E}}[Y | A = 1] - \widehat{\mathbb{E}}[Y | A = 0]
\]

Randomised controlled experiments are powerful because they evenly
distribute potential explanatory factors across treatment groups. We
cannot observe Alice or Bob's individual causal effects. However, for
the groups to which they have been randomised, we recover average causal
effects by a Sherlock-Holmes process of inference by elimination:
randomisation rules out alternative explanations.

Note that in the context of our imagined experiment
\(\widehat{\text{ATE}}\) applies to the population from which the
experimental participants were drawn as calculated on the difference
scale. An more explict notation would define this effect estimate by
referencing it's scale and population:
\(\widehat{\text{ATE}}^{a'-a}_{\text{S}}\), where \(a'-a\) denotes the
difference scale, and \(S\) denotes source population. We will return to
this point in Part 2, but it is important to build intuition early that
in causal inference we must specifying: (1) the causal effect of
interest; (2) a scale of contrast; and (3) a target population for whom
a causal effect estimate is meant to generalise.

\subsubsection{To obtain average causal effect estimates from
observational studies requires three fundamental
assumptions}\label{to-obtain-average-causal-effect-estimates-from-observational-studies-requires-three-fundamental-assumptions}

An observational study aims to estimate the average treatment effects in
a setting where researchers do not control treatments or randomise the
treatment assignments. We may only consistently obtain and estimate the
counterfactual contrasts under strict assumptions. There are three
fundamental assumptions for obtaining from observational data the
counterfactual quantities required to compute causal contrasts.

\paragraph{Assumption 1. Causal
Consistency}\label{assumption-1.-causal-consistency}

Causal consistency states that the observed outcome for each individual
under the treatment they actually received is equal to their potential
outcome under that treatment. This means if an individual \(i\) received
treatment \(A_i = 1\), then their observed outcome \(Y_i\) is the same
as their potential outcome under treatment, denoted as \(Y_i(1)\).
Similarly, if they did not receive the treatment (\(A_i = 0\)), their
observed outcome is the same as their potential outcome without
treatment, denoted as \(Y_i(0)\), such that:

\[
Y_i = A_i \cdot Y_i(1) + (1 - A_i) \cdot Y_i(0)
\]

where:

\begin{itemize}
\tightlist
\item
  \(Y_i\) is the observed outcome for individual \(i\);
\item
  \(A_i\) is the treatment status for individual \(i\), with
  \(A_i = 1\); indicating treatment received and \(A_i = 0\) indicating
  no treatment;
\item
  \(Y_i(1)\) and \(Y_i(0)\) are the potential outcomes for individual
  \(i\) under treatment and no treatment, respectively.
\end{itemize}

The causal consistency assumption necessary to linking the theoretical
concept of potential outcomes -- the target quantities of interest --
with observable data (see Bulbulia \emph{et al.}
(\citeproc{ref-bulbulia2023a}{2023})).

\paragraph{Assumption 2. Conditional exchangeability (or
ignorability):}\label{assumption-2.-conditional-exchangeability-or-ignorability}

Conditional exchangeability states that given a set of measured
covariates \(L\), the potential outcomes are independent of the
treatment assignment. That is, once we control for \(L\), the treatment
assignment \(A\) is as good as random with respect to the potential
outcomes:

\[
Y(a) \coprod A | L
\]

where:

\begin{itemize}
\tightlist
\item
  \(Y(a)\) represents the potential outcomes for a particular treatment
  level \(a\).
\item
  \(\coprod\) denotes conditional independence.
\item
  \(A\) represents the treatment levels to be contrasted.
\item
  \(L\) represents the measured covariates.
\end{itemize}

Under the conditional exchangeability assumption, any differences in
outcomes between treatment groups can be attributed to the treatment.
Note that the conditional exchangeability assumption requires that all
confounding variables that affect both the treatment assignment \(A\)
and the potential outcomes \(Y(a)\) are measured and included in \(L\)
(For further clarification, see Appendix A).

\paragraph{Assumption 3. Positivity}\label{assumption-3.-positivity}

The positivity assumption requires that every individual in the
population has a non-zero probability of receiving each treatment level,
given their covariates. More formally,

\[
0 < Pr(A = a | L = l) < 1, \quad \forall a \in A, \, \forall l \in L \, \text{ such that } \, Pr(L = l) > 0
\]

where:

\begin{itemize}
\tightlist
\item
  \(A\) is the treatment or exposure variable.
\item
  \(L\) is a vector of covariates.
\item
  \(a\) and \(l\) represent specific values of treatment and covariates,
  respectively.
\end{itemize}

The positivity assumption in causal inference, essential for ensuring
valid estimates of treatment effects, requires that every individual has
a non-zero chance of receiving each treatment across all covariates in
\(L\).\footnote{In practice, verifying this assumption faces two main
  challenges: a. \textbf{Data sparsity}: certain covariate combinations
  are rare or unobserved in the data, making it difficult to empirically
  confirm positivity for these groups. b. \textbf{Model dependence}: as
  a result of data sparsity researchers rely on statistical models to
  estimate treatment probabilities for all covariate patterns, but these
  assessments are only as reliable as the models used, which may be
  subject to misspecification or inaccuracies.}

\paragraph{Additional assumptions}\label{additional-assumptions}

There are additional practical and data assumptions for valid causal
inference (see Bulbulia \emph{et al.}
(\citeproc{ref-bulbulia2023a}{2023})). It is important to note that
these assumptions are theoretical and often challenging to verify in
practice. For example, the assumption of no unmeasured confounders
(implicit in conditional exchangeability) is particularly challenging
because it involves variables that are not observed. Note that even in
ideally conducted randomised experiments, the fundamental assumptions of
causal inference must be satisfied (see Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008})).

\subsubsection{Terminology}\label{terminology}

To better avoid terminology confusion we define the meanings of our
terms:

\begin{itemize}
\item
  \textbf{Unit/individual}: an entity, such as an object, person, or
  culture. We will use the term `individual' in place of the more
  general term `unit'. Think, `row' in one's dataset.
\item
  \textbf{Variable}: a feature of an individual, transient or permenant.
  `John was sleepy but is no longer.'`Alice was born in December.'
\item
  \textbf{Treatment}: equivalent to `exposure', an event that might
  change a variable. `John was sleepy, we intervened with coffee, he's
  wide awake.' `Alice was born in December; there's nothing to change
  that.' The `cause'.
\item
  \textbf{Outcome}: the response variable or `effect'. In causal
  inference, we contrast `potential' or `counterfacutal outcomes'; in
  observational or `real world' studies in which treatments are not
  randomised, the assumptions under which we obtain contrasts of
  counterfactual outcomes are typically much stronger than in randomised
  controlled experiments.
\item
  \textbf{Confounding}: a state in which the the treatment and outcome
  share a common cause and no adjustment is made to remove the
  non-causal association, or in which the the treatment and outcome
  share a common effect, and adjustment is made for this common effect,
  or when the effect of the treatment and the outcome is mediated by a
  variable which is conditioned upon. In each case, observed assocition
  will not reflect a causal association. Causal directed acyclic graphs
  clarify strategies for confounding control.
\item
  \textbf{Measurement}: a recorded trace of a variable, such as a column
  in one's dataset.
\item
  \textbf{Measurement error}: a misalignment between the true state of a
  variable and its recorded state. `Alice was born 30/Nov, records were
  lost, and her birthday was recorded 29/Nov.'
\item
  \textbf{Population}: abstraction from statistics, denotes the set of
  all indivuals defined by certain features. John belongs to the set of
  all individuals who ignore instructions.
\item
  \textbf{Super-population}: abstraction, the population of all possible
  individuals of a given kind, another abstract but useful concept. John
  and Alice belong to a super-population of hominins.
\item
  \textbf{Restricted population}: we say population \(p\) is restricted
  relative to another population \(P\), if the individuals \(p\in P\)
  share some but not all features of \(P\). `The living' are a
  restriction of hominins.
\item
  \textbf{Target population}: a restriction of the super-population
  whose features interests investigators. An investigator who defines
  their interests is a member of the population of `good investators.'
\item
  \textbf{Source population}: the population from which the study's
  sample is drawn. Investigators wanted to recruit from a general
  population but recruited from the pool of first-year university
  psychology students conscripts.
\item
  \textbf{Baseline sample population}: the abstract set of individuals
  from which the units in one's study at treatment assigned belong,
  e.g.~`the set of all first-year university psychology students
  conscript might end up in this study'. To simplify, we will think of
  the baseline population as the \emph{source population.}
\item
  \textbf{Selection into the sample}: the process by which individuals
  are included in a population or sample. Selection occurs, and is under
  investigator control, when a target population is defined from a
  super-population, or when investigators apply eligibility criteria for
  inclusion in the analytic sample. Selection into the sample is often
  out of investigator control. Investigators might aspire to answering
  questions about all of humanity but find themselves limited to
  undergraduate samples. Investigators might sample from a source
  population, but recover an analytic sample that differs from it in
  ways they cannot measure, such as mistrust of scientists. There is
  typically attrition of an analytic sample over time, and this is not
  typically fully within investigator control. Because term `selection'
  has different meanings in different areas of human science, we will
  speak of `sample restriction.'
\item
  \textbf{Censored sample population}: the population from which the
  censored units are drawn. Censoring is uninformative if, for everyone
  in the baseline population, there is no effect of treatment (the sharp
  causal null hypothesis). Censoring is informative if there is an
  effect of the treatment, and this effect varies in at least one
  stratum of the baseline population. Note that uninformative censoring
  does not ensure valid inference for the target population even when
  valid inference is ensured for the baseline population. If the
  baseline population differs in the distribution of those features that
  modify the effect of the treatment, and no correction is applied,
  unbiased effect estimates for the baseline population will
  nevertheless be biased for the target population in at least one
  measure of effect (\citeproc{ref-greenland2009commentary}{Greenland
  2009}; \citeproc{ref-lash2020}{Lash \emph{et al.} 2020}). This is why
  it is important for investigators to state a causal effect of interest
  with respect to \emph{the full data} that includes the counterfactual
  quantities for the treatments to be compared in a clearly defined
  target population were all memembers of the target population exposed
  to each level of treatment to be constrasted
  (\citeproc{ref-westreich2017}{Westreich \emph{et al.} 2017a}).
\item
  \textbf{Generalisability}: we say a study's findings generalise to a
  target population if the effects observed in the study group are also
  valid for the target group for structurally valid reasons
  (i.e.~non-accidentally). Clearly, the similarity of the source
  population to the target population in study-relevant characteristics
  enhances the applicability of the findings to the target population.
\end{itemize}

Suppose we sample randomly from the target population where,

\begin{itemize}
\tightlist
\item
  \(n_S\) denotes the size of the study sample \(S\).
\item
  \(N_T\) denotes the total size of the target population \(T\).
\item
  \(\hat{ATE}_{S}\) denotes the estimated average treatment effect in
  the study sample.
\item
  \(\hat{ATE}_{T}\) denotes the estimated average treatment effect in
  the target population.
\end{itemize}

Assuming the rest of a causal inference workflow goes to plan
(randomisation succeeds, there is no measurement error, no model
misspecification, etc), as the random sample size \(n_S\) increases over
the target population \(N_T\), the estimated treatment effect in \(S\)
converges to that in \(T\):

\[
\lim_{n_S \to N_T} \hat{ATE}_{S} = \hat{ATE}_{T}
\]

\begin{itemize}
\tightlist
\item
  \textbf{Transportability}: sometimes the target population is the
  general population of interest from which researchers have sampled.
  Where results are valid, they will generalise to this general
  population. Often the population of interest is a `trial eligible'
  population, not a general population. For example, suppose our
  scientific question pertains to a restricted population, such as first
  year North American university students. If we were to successful
  sample from globally diverse population, the sample treatment effect
  might not transport to the trail eligible population of North American
  university students. In this setting, researchers should be
  discouraged from sampling from a global populatio because doing so
  will lead to bias if the target and sample populations differ in the
  distribution of variables that modify the effect of the treatment on
  the outcome. If there is no treatment in effect in any stratums, there
  will (generally) not be bias (the NULL will hold.) Although the
  concept of a `target population' is critical for interpreting our
  results, this concept cannot be expressed absolutely. Rather, it is
  relative to the scientific interests and purposes at hand. The closer
  we sample from the target population the less results will rely on
  methods for adjustment, which carry the burdens of model
  misspecification bias.
\end{itemize}

Suppose we have not randomly sampled from the target population such
that \(S\) is not a subset of \(T\).

Define,

\begin{itemize}
\tightlist
\item
  \(\hat{ATE}_{S}\) as the estimated average treatment effect in the
  study sample \(S\).
\item
  \(\hat{ATE}_{T}\) as the estimated average treatment effect in the
  target population \(T\).
\item
  \(f(S, R)\) as the mapping function over \(S\) using a measured set of
  variables \(R\) that permits valid projection of the source ATE to the
  population ATE.
\end{itemize}

\[
\hat{ATE}_{S} \xrightarrow{f(S, R)} \hat{ATE}_{T}
\]

All problems in adjusting for sampling bias are problems of obtaining a
satisfactory function for such transportation.

\begin{itemize}
\item
  \textbf{Marginal effect}: synonym for the average treatment effect --
  always relative to some population investigators specify.
\item
  \textbf{Intention-to-treat effect}: the marginal effect of random
  treatment assignment.
\item
  \textbf{Per-protocol effect}: the effect of adherence to a randomly
  assigned treatment assignment if adherence were perfect
  (\citeproc{ref-hernan2017per}{Hernán \emph{et al.} 2017}). We have no
  guarantee that the intention-to-treat effect will be the same as the
  per-protocol effect. A safe assumption is that:
  \(\widehat{ATE}_{\text{target}}^{\text{Per-Protocol}} \ne \widehat{ATE}_{\text{target}}^{\text{Intention-to-Treat}}\).
\end{itemize}

When evaluating evidence for causality, in addition to specifying their
causal contrast, effect measure, and target population, investigators
should specify whether they are estimating an intention-to-treat or
per-protocol effect (\citeproc{ref-hernuxe1n2004}{Hernán 2004};
\citeproc{ref-tripepi2007}{Tripepi \emph{et al.} 2007}).

Note that our terminology differs in causal inference for the concepts
we have defined here: (refer to Dahabreh \emph{et al.}
(\citeproc{ref-dahabreh2021study}{2021}); Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Westreich \emph{et al.}
(\citeproc{ref-westreich2017transportability}{2017b})). A clear
decomposition of key concepts need to assess generalisability -- or what
we call `target validity' - is given in Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}). For a less technical,
pragmatically useful discussion refer to Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018}).

\subsubsection{Graphical Conventions}\label{graphical-conventions}

\begin{itemize}
\item
  \textbf{\(A\)}: denotes the `treatment' or `exposure' - a random
  variable, `the cause.'
\item
  \textbf{\(Y\)}: denotes the outcome or response, measured at the end
  of study. \(Y\) is the `effect'.
\item
  \textbf{\(L\)}: denotes a measured confounder or set of confounders.
\item
  \textbf{\(U\)}: denotes an unmeasured confounder or confounders.
\end{itemize}

\begin{itemize}
\item
  \textbf{Node}: a node or vertex represents characteristics or features
  of units within a population on a causal diagram -- that is a
  `variable.' In causal directed acyclic graphs, we draw nodes with
  respect to the \emph{target population}, which is the population for
  whom investigators seek causal inferences
  (\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020}). Time-indexed
  node: \(X_t\) denotes relative chronology
\item
  \textbf{Arrow} (\(\rightarrowNEW\)): denotes causal relationship from
  the node at the base of the arrow (a `parent') to the node at the tip
  of the arrow (a `child'). In causal DAGS it is conventional to refrain
  from drawing an arrow from treatment to outcome to avoid asserting a
  causal path from \(A\) to \(Y\) because iyr purpose is to ascertain
  whether causality can be identified for this path. All other nodes and
  paths -- including the absence of nodes and paths -- is typically
  assumed.
\item
  \textbf{Red Arrow} (\(\rightarrowred\)): path of non-causal
  association between the treatment and outcome. Despite the arrows,
  this path is associational and may flow against time.
\end{itemize}

\begin{itemize}
\item
  \textbf{Open Blue Arrow} (\(\rightarrowblue\)): denots effect
  modification, which occurs when the levels of the effect of treatment
  vary within levels of a covariate. We do not assess the causal effect
  of the effect-modifier on the outcome, recognising that it may be
  incoherent to consider intervening on the effect-modifier. However, as
  we noted above: if the distribution of effect modifiers in the sample
  population differs from the distribution of effect modifiers in the
  target population then at least one measure of causal effect will
  differ (as we considered above.)
\item
  \textbf{Boxed Variable} \(\big(\boxed{X}\big)\): conditioning or
  adjustment for \(X\).
\item
  \textbf{Red-Boxed Variable} \(\big(\boxedred{X}\big)\): highlights the
  source of confounding bias from adjustment.
\item
  \textbf{Dashed Circle} \(\big( \circledotted{X}\big)\): no adjustment
  is made for a variable (implied for unmeasured confounders).
\end{itemize}

\begin{itemize}
\tightlist
\item
  \textbf{\(\mathcal{G}\)} names a causal directed acyclic graph.
\end{itemize}

\subsubsection{Causal Directed Acyclic Graphs (causal
DAGs)}\label{causal-directed-acyclic-graphs-causal-dags}

In the 1990s, Judea Pearl showed that we can evaluate causal
dependencies using observable probability distributions
(\citeproc{ref-pearl1995}{Pearl 1995}, \citeproc{ref-pearl2009a}{2009}).
He also demonstrated that causal directed acyclic graphs (causal DAGs)
clarify the conditional dependencies among variables
(\citeproc{ref-pearl1995}{Pearl 1995}). Based on assumptions about
causal structure, researchers can identify causal effects from joint
distributions of observed data.

Pearl developed graphical rules known as d-separation
(\citeproc{ref-pearl1995}{Pearl 1995}):

\begin{itemize}
\tightlist
\item
  \textbf{Fork rule} (\(B \leftarrowNEW \boxed{A} \rightarrowNEW C\)):
  \(B\) and \(C\) are independent when conditioned on \(A\)
  (\(B \coprod C \mid A\)).
\item
  \textbf{Chain rule} (\(A \rightarrowNEW \boxed{B} \rightarrowNEW C\)):
  Conditioning on \(B\) blocks the path between \(A\) and \(C\)
  (\(A \coprod C \mid B\)).
\item
  \textbf{Collider rule}
  (\(A \rightarrowNEW \boxed{C} \leftarrowNEW B\)): \(A\) and \(B\) are
  independent until conditioned on \(C\), which introduces dependence
  (\(A \cancel{\coprod} B \mid C\)).
\end{itemize}

These rules lead to the backdoor criterion and `backdoor adjustment'
theorem, which provide algorithms for identifying causal effects based
on the structural assumptions encoded in a causal DAG
(\citeproc{ref-pearl1995}{Pearl 1995}).

Consider the following graphs from Table~\ref{tbl-terminologygeneral}:

\begin{itemize}
\tightlist
\item
  \textbf{\(\mathcal{G}_1\)}: If \(A\) and \(B\) are not causally
  related and share no common causes, \(A\) and \(B\) will not be
  statistically related.
\item
  \textbf{\(\mathcal{G}_2\)}: If \(A\) causes \(B\), and they share no
  common causes or their common causes are accounted for, \(A\) and
  \(B\) will be statistically related.
\item
  \textbf{\(\mathcal{G}_3\)}: If \(A\) causes \(B\) and \(A\) causes
  \(C\), then conditioning on \(A\) allows us to estimate the effect of
  \(B\) on \(C\).
\item
  \textbf{\(\mathcal{G}_4\)}: If \(A\) causes \(B\) and \(B\) causes
  \(C\), conditioning on \(B\) obscures the true causal effect of \(A\)
  on \(C\), making \(A\) independent of \(C\).
\item
  \textbf{\(\mathcal{G}_5\)}: If \(A\) causes \(C\) and \(B\) causes
  \(C\), conditioning on \(C\) associates \(A\) and \(B\), despite no
  direct causal effect.
\end{itemize}

If we assume that the variables in the graph correspond to Structural
Causal Models, all causal relationships can be defined by the elementary
structures presented above.

\subsubsection{Review of d-separation for Causal Identification on a
Graph}\label{review-of-d-separation-for-causal-identification-on-a-graph}

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologydirectedgraph

}

\end{table}%

\subsubsection{Effect-modification on Causal Directed Acyclic Graph:
`off-label'
convention.}\label{effect-modification-on-causal-directed-acyclic-graph-off-label-convention.}

The primary function of a causal directed acyclic graph is clarify
relations of conditional independence Table~\ref{tbl-terminologygeneral}
for the purposes of casual identification. We have just noted that the
the modification of a causal effect within one or more stratums of the
target population opens the possibility for biased average treatment
effects estimates wherever the distribution of these effect modifiers
differs in the sample population. We do not generally represent
non-linearities in causal directed acyclic graphs, which are tools for
obtaining relationships of conditional and unconditional independence
from assumed structural relationships, encoded in a causal diagramme,
that may lead to a non-causal treatment/outcome association.

Table~\ref{tbl-terminologygeneral} presents our convention for
highlighting a relationship of effect modification in settings where (1)
we assume no confounding of treatment and outcome and (2) there is
effect modification such that the effect of A and Y differs in at least
one stratum of the target population.

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologyeffectmodification

}

\end{table}%

To focus on effect modification, we do not draw a causal arrow from the
direct effect modifier \(F\) to the outcome \(Y\). This convention is
specific to this article (refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), pp.~126-127, for a discussion
of `noncausal' arrows).

\subsection{Part 1 Measurement Error
Bias}\label{part-1-measurement-error-bias}

\begin{table}

\caption{\label{tbl-terminologymeasurementerror}Six Structural Sources
of Measurement Error Bias}

\centering{

\terminologymeasurementerror

}

\end{table}%

\subsubsection{Example 1: Uncorrelated errors under sharp null: no
treatment
effect}\label{example-1-uncorrelated-errors-under-sharp-null-no-treatment-effect}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_1\)
illustrates uncorrelated non-differential measurement error under the
`sharp-null,'\,' which arises when the error terms in the exposure and
outcome are independent. In this setting the structure of measurement
error is not expected to produce bias.

For example, consider a study investigating a causal effect of beliefs
in big Gods on social complexity in ancient societies. Imagine that
societies either randomly omitted or inaccurately recorded details about
their beliefs in big Gods and their social complexities. This might
happen from the varying preservation of records across cultures,
unrelated to the actual beliefs or social complexities. In this
scenario, the errors in historical record for beliefs in big Gods and
for social complexity will be independent. Such errors may generally not
introduce bias -- suggesting an effect --when there is no true effect
(although see Richardson and Robins
(\citeproc{ref-richardson2013}{2013}) for edge cases).

\subsubsection{Example 2: Uncorrelated errors under treatment effect
biases true effects toward the
null.}\label{example-2-uncorrelated-errors-under-treatment-effect-biases-true-effects-toward-the-null.}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_2\)
illustrates uncorrelated non-differential measurement error, that is
bias that arises when the error terms in the exposure and outcome are
independent (information bias). In this setting, bias will typically
attenuate a true treatment effect.

Consider again the example of a study investigating a causal effect of
beliefs in big Gods on social complexity in ancient societies, were
there are uncorrelated errors in the treatment and outcome. In this
case, measurement error will typically make it seem that the true causal
effects of beliefs in big Gods is smaller that it is, or perhaps even
that such an effect is absent.

\subsubsection{Example 3: Correlated errors Non-Differential
(Undirected) Measurement
Errors}\label{example-3-correlated-errors-non-differential-undirected-measurement-errors}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_3\)
illustrates the structure of correlated non-differential (un-directed)
measurement error bias, which arises when the error terms of the
treatment and outcome share a common cause.

Consider an example: imagine that societies with more sophisticated
record-keeping systems tend to offer more precise and comprehensive
records both of beliefs in big Gods and of social complexity. In this
setting, it is the record-keeping systems that give an illusion of a
relationship between big Gods and social complexity. This might occur
without any effect of big-God beliefs on the measurement of social
complexity or vice versa. Nevertheless, the correlated sources of error
for both the exposure and outcome may suggest causation in its absence.

\subsubsection{Example 4: Uncorrelated Directed Measurement Error:
Exposure affects error of
outcome}\label{example-4-uncorrelated-directed-measurement-error-exposure-affects-error-of-outcome}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_4\)
illustrates the structure of uncorrelated differential (or directed)
measurement error, in the when a non-causal path is opened linking the
treatment, the outcome, or a common cause of the treatment an outcome.

Keeping with our previous example, imagine that beliefs in big Gods lead
to inflated records of social complexity in a culture's record keeping.
This might happen because the record keepers in societies that believe
in big Gods prefer societies to reflect the grandeur of their big Gods.
Suppose further that cultures lacking beliefs in big Gods prefer
Bacchanalian-style feasting to record keeping. In this scenario,
societies with record keepers who believe in big Gods would appear to
have more social complexity than equally complex societies without such
record keepers

\subsubsection{Example 5: Uncorrelated Directed error: Outcome affects
error of
exposure}\label{example-5-uncorrelated-directed-error-outcome-affects-error-of-exposure}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_5\)
illustrates the structure of uncorrelated differential (or directed)
measurement error, this time when the outcome affects the recording ot
the treatment that preceeded the outcome.

Consider if `history is written by the victors' how might this affect
measurement error bias? Suppose that social complexity causes beliefs in
big Gods. Perhaps kings make big Gods after the image of kings. If the
kings prefer a history in which big Gods were historically present, this
might bias the historical record, opening a path of association that
reverses the order of causation.

\subsubsection{Example 6: Directed error: outcome affects error of
exposure}\label{example-6-directed-error-outcome-affects-error-of-exposure}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_6\)
illustrates the structure of correlated differential (directed)
measurement error, which occurs when the exposure affects levels of
already correlated error terms.

Suppose social complexity produces a flattering class of religious
elites who tend to produce vainglorious depictions of kings and their
dominions, and also of the extend and scope of their societies beliefs
in big Gods. For example, such elites might tend to downplay widespread
cultural practices of worshiping lesser gods, inflate population
estimates, and overstate their the range of their economies. In this
scenario the errors of the exposure and of the outcome are both
correlated and differential.

We limit the biases of measurement error by reducing error in our
measures. Often, specialist knowledge can guide the expected direction
of measurement error associations, positive or negative (see: Suzuki
\emph{et al.} (\citeproc{ref-suzuki2020}{2020}), VanderWeele and Robins
(\citeproc{ref-vanderweele2010}{2010}), and VanderWeele and Robins
(\citeproc{ref-vanderweele2007a}{2007})). In some situations,
researchers might use causal diagrams with signed paths to refine causal
inferences, as suggested by VanderWeele
(\citeproc{ref-vanderweele2012}{2012}). These techniques extend beyond
the scope of this study. The point of these examples is to demonstrate
how causal diagrams can clarify sources of confounding from measurement
bias.

\subsection{Part 2: Selection-Restriction Bias From Right-Censoring
(Attrition)}\label{part-2-selection-restriction-bias-from-right-censoring-attrition}

There is much confusion about the topic of `selection bias', however,
there need not be. Some of this confusion is terminological. So we being
by avoiding the term `selection bias', and clarify our meanings.

**In Part 2 we will assume that the baseline sample population is the
target population, and focus on biases arising from the
(right)-censoring of the sample population.

\begin{table}

\caption{\label{tbl-terminologycensoring}Five Structural Sources of
Right-Censoring Bias}

\centering{

\terminologycensoring

}

\end{table}%

\subsubsection{Example 1: Confounding by common cause of treatment and
attrition}\label{example-1-confounding-by-common-cause-of-treatment-and-attrition}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_1\) illustrates
confounding by common cause of treatment and outcome in the censored
such that the potential outcomes of the population at baseline \(Y(a)\)
may differ from those of the censored population at the end of study
\(Y'(a)\) such that \(Y'(a) \neq Y(a)\).

Suppose investigators are interested in whether religious service
attendance affects volunteering. Suppose that an unmeasured variable,
loyality, affects religious service attendance, attrition, and
volunteering. The structure of this bias reveals an open backdoor path
from from the treatment to the outcome.

Recall our measurement error causal diagrams. The structure we observe
here is one of correlated measurement errors
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_3\)). In this
example, attrition may exacerbate measurement error bias.

\subsubsection{Example 2: Treatment affects
censoring}\label{example-2-treatment-affects-censoring}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_2\) illustrates
confounding bias in which the treatment affects the censoring process.

Consider a study investigating the effects of mediation on volunteering.
Suppose there is no treatment effect of meditation on volunteering, but
that meditation affects social desirability, and that social
desirability affects both attrition and reported volunteering.

Recall our measurement error causal diagrams. The structure we observe
here is one of directed uncorrelated measurement error
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_4\)).
Randomisation ensures no backdoor paths. However, if the intervention
affects both attrition and bias in the outcome, this may exacerbate
measurement error bias.

Consider a study investigating the effects of mediation on well-being.
Suppose there is no treatment effect but that Buddha-like detachment
increases attrition. If \(\mathcal{G}_4\) faithfully represents reality,
there will be no bias in the treatment effect estimate. That is, there
will be no risk that attrition will induce the appearance of a causa
effect in its absence.

\subsubsection{Example 3: No treatment effect when outcome causing
censoring}\label{example-3-no-treatment-effect-when-outcome-causing-censoring}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_3\) illustrates the
structure of bias when there is no treatment effect yet the outcome
affects censoring.

If \(\mathcal{G}_3\) faithfully represents reality, there will be no
bias in the treatment effect estimate from attrition, even if there is
measurement error in the outcome. Recall again our measurement error
causal diagrams. The structure we observe here is one of undirected
uncorrelated measurement error
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_1\)). Here,
we would not expect attrition to induce or exaggerate the appearance of
a causal effect in its absence, for the same reason that uncorrelated
treatment errors. However \(\mathcal{G}_3\) assumes a sharp null (no
arrow from \(A\to Y\) for any individual). If we believed in the sharp
null we would not be motivated to conduct the experiment.

\subsubsection{Example 4: Treatment effect when outcome causes censoring
and there is a true treatment
effect}\label{example-4-treatment-effect-when-outcome-causes-censoring-and-there-is-a-true-treatment-effect}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_4\) illustrates the
structure of bias when the outcome affects censoring in the presence of
a treatment effect. In contrast to the previous example, here there is
scope for confounding bias.

Consider again a study investigating the effects of mediation on
well-being. This time suppose that Buddha-like detachment affects
attrition. As such, the investigators will observe a restricted range of
effect in the sample at the end of study compared to the sample at the
start of the study. The structure of bias in this example is not one of
measurement error. Rather, there is confounding of the per-protocal
effect of the meditation on well-being. Note that if the randomisation
were successful, the `intent-to-treat' effect would be unbiased.

\subsubsection{Example 5: Treatment effect and effect-modifiers differ
in censored (restriction bias without
confounding)}\label{example-5-treatment-effect-and-effect-modifiers-differ-in-censored-restriction-bias-without-confounding}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) represents a
setting in which there is a true treatment effect, but the distribution
of effect-modifiers -- variables that interact with the treatment --
differ among the sample at baseline and the sample at the end of study.
Knowing nothing else, we might expect this setting to be standard. Where
measured variables are sufficient to predict attrition, that is, where
missingness is at random, we can obtain valid estimates for a treatment
effect by inverse probability of treatment weighting
(\citeproc{ref-cole2008}{Cole and Hernán 2008};
\citeproc{ref-leyrat2021}{Leyrat \emph{et al.} 2021}). In this approach,
the sample gives more weight to under-represented individuals owing to
drop-out. As with missing data imputation, IPW with censoring weights
also assumes that we can correctly model the missingness from the
observed data (\citeproc{ref-shiba2021}{Shiba and Kawahara
2021}).However, if missingness is not completely at random, then
identification may be compromised
(\citeproc{ref-malinsky2022semiparametric}{Malinsky \emph{et al.} 2022};
\citeproc{ref-tchetgen2017general}{Tchetgen Tchetgen and Wirth 2017}).

\newpage{}

\subsection{Part 3: Selection-Restriction Bias at Baseline
(Left-Censoring)}\label{part-3-selection-restriction-bias-at-baseline-left-censoring}

\subsubsection{Sample-Restriction Bias Considered as
Collider-Restriction
Bias}\label{sample-restriction-bias-considered-as-collider-restriction-bias}

\begin{table}

\caption{\label{tbl-terminologyselectionrestrictionclassic}Collider-Stratification
bias at start of study (`M-bias')}

\centering{

\terminologyselectionrestrictionclassic

}

\end{table}%

Table~\ref{tbl-terminologyselectionrestrictionclassic} \(\mathcal{G}_1\)
illustrates an example of sample restriction bias at baseline in which
there is collider-restriction bias

Suppose investigators what to estimate the causal effects of regular
physical activity, \(A\), and heart health \(Y\), in adults. Their
design:

\textbf{Target population}: all adults in a given city.

\textbf{Source population}: adults visiting a network of community
health centers for routine check-ups.

\textbf{Selection for Study (\(T = 1\))}: participants are selected
based on their willingness to participate in a health survey conducted
at these centers. Suppose the analytic sample is representative of this
source population, and the source and target poulation converge, such
\(Pr(D = 1) = Pr(S = 1) = Pr(T)\)

Suppose there are two unmeasured variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Health Awareness, \(U1\), an unmeasured variable that influences both
  the probability of participating in the study,\(\boxed{S = 1}\) and
  being physically active, \(A\). We assume that people with higher
  health awareness are both more likely to engage in physical activity
  and to participate in health-related studies.
\item
  Socioeconomic Status (SES), \(U2\), an unmeasured variable that
  influences both the probability of participating in the study,
  \(\boxed{S = 1}\) and heart health, \(Y\). We assume that individuals
  with higher SES have better access to healthcare and are more likely
  to participate in health surveys; they also tend to have better heart
  health from healthy lifestyles: joining expensive gyms, juicing, long
  vacations, and the like.
\end{enumerate}

As presented in Table~\ref{tbl-terminologyselectionrestrictionclassic}
\(\mathcal{G}_1\), there is collider restriction bias from conditioning
on \(T=1\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\(U1\)}: because individuals with higher health awareness are
  more likely to be both physically active and participate in the study,
  the subsample over-represents physically active individuals. This
  overestimates the prevalence of physical activity, setting up a bias
  in overstating the potential benefits of physical activity on heart
  health in the general population.
\item
  \textbf{\(U2\)}: because individuals with higher health awareness may
  have better heart health from SES-related factors, this opens a
  confounding path from physical activity and heart health through the
  selected sample, setting up the investigators for the potentially
  erroneous inference that physical activity has a greater positive
  impact on heart health than it actually does in the general
  population. The actual effect of physical activity on heart health in
  the general population might be less pronounced than observed.
\end{enumerate}

It might seem as though researchers need to sample from the target
population, the sub-sample will not work. However, by adjusting for
health awareness or SES, or a proxy of either, researchers may block the
open path between.
Table~\ref{tbl-terminologyselectionrestrictionclassic} \(\mathcal{G}_2\)
presents this sollution. This strategy will only provide an unbiased
effect estimate for the population if either there is no causal effect
for all strata of the selected sample (the sharp null hypothesis) or
there are no interactions between the distribution of effect modifiers
in the sample population and the target population. The next series of
examples illustrates challenges to obtaining valid causal effect
estimates in the presence of interactions.

\subsubsection{Sample-Restriction Bias Without Collider-Restriction
Bias}\label{sample-restriction-bias-without-collider-restriction-bias}

\textbf{Source bias or 'Sample-Restriction-at-Baseline Bias} occurs when
the sample populationg (source population) does not accurately represent
the group of interest (target population) in the distribution of
variables that modify treatments effects. Such bias occurs because the
selection into the study occurs on an effect modifier for the effect of
the exposure on the outcome. Note that although the causal effect of
\(A\to Y\) is unbiased for the exposed and unexposed in the source
population, the effect estimate does not generalise to the exposed and
unexposed in the target population. Although there is no confounding,
causal inferences in this scenario do not generalise as we might hope
(\citeproc{ref-suzuki2016}{Suzuki \emph{et al.} 2016};
\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020};
\citeproc{ref-suzuki2014}{Suzuki and Yamamoto 2014}).

\textbf{Appendix B} provides a simulation that illustrates the bias.
\textbf{Appendix C} provides a mathmatical explanation.

\begin{table}

\caption{\label{tbl-terminologyselectionrestrictionbaseline}The
association in the population of selected individuals differs from the
causal association for the target population. Hernán calls this scenario
`selection bias off the null' (\citeproc{ref-hernuxe1n2017}{Hernán
2017}). Lu et al.~call this scenario `Type 2 selection bias'
(\citeproc{ref-lu2022}{Lu \emph{et al.} 2022}). We call this bias
`Sample-Restriction Bias at Baseline.'}

\centering{

\terminologyselectionrestrictionbaseline

}

\end{table}%

\subsubsection{Problem 1: Target population is not WEIRD; sample
population is
WEIRD}\label{problem-1-target-population-is-not-weird-sample-population-is-weird}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{1.1}\) presents a scenario in which there is source bias
for the population parameter. When that sample we obtain at baseline
differs from the target population, and where the distributions of
variables that modify treatment differ between the sample and target
populations, effect-estimates may be biased, even in the absence of
confounding bias.

Example: we want to take `the difficult steps to building a broader,
richer, and better-grounded understanding of our species' but have
sampled from a pool of undergraduate students. For many questions,
causal effect estimates in this sample population will not generalise to
the target popultion.

We might decide to adjust expectations, and not attempt species-level
generalisations.

Or we might decide to sample more widely from our local population, and,
where possible, weight the sample to better recover the population
parameters of interest for our target sample. To obtain weighted
estimates for the target population, we must first defined by
eligibility criteria. If the baseline population differs from the target
population, where sample weights for the distribution of covariates are
available for the \emph{target population}, these should be applied to
the baseline population (with caution, given potential for model
mis-specification, see \citeproc{ref-stuart2015}{Stuart \emph{et al.}
2015}.)

Let \(\widehat{ATE}_{target}\) denote the population average treatment
effect for the target population. Let
\(\widehat{ATE}_{\text{restricted}}\) denote the average treatment
effect at the end of treatment. Let \(W\) denote a set of variables upon
which the restricted and target populations structurally differ. We say
that results \emph{generalise} if we can guarantee that:

\[
\widehat{ATE}_{target} =  \widehat{ATE}_{restricted} 
\]

or if there is a known function such that:

\[
ATE_{target}\approx  f_W(ATE_{\text{restricted}}, W)
\]

In most cases, \(f_W\) will be unknown, as it must account for potential
heterogeneity of effects and unobserved sources of bias. For further
discussion on this topic, see: Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018})

Suppose we take the bold option and sample from the species.
Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{1.2}\) projects this scenario. What would this recover?
If there is considerable heterogeneity, then we might not know how to
interpret the average treatment effect that we recover. Put differently,
we might not be able to interpret how the quantity we obtain relates to
WEIRD population, or any specific culture for that matter. To obtain
such effects we would need to model treatment heterogeneity. If we seek
explicity comparative models we will need to ensure validity for every
sample that we compare.

\subsubsection{Example 2: Target population is WEIRD; sample population
is not
WEIRD}\label{example-2-target-population-is-weird-sample-population-is-not-weird}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.1}\) presents a scenario in which there the source
population does not meet eligibility criteria. Consider again the
question of whether vascectomy affects a sense of meaning and purpose in
life. Suppose further we want to evaluate effects in New Zealand among
men over the age of 40 who have no prior history of vasectomy, who are
in relationships with heterosexual partners. The target population is
weirder than WEIRD, in the sense it must be narrower. We should not
sample from young children, the elderly, and any who do not qualify. For
many scientific questions, a narrow population us desirable.

Note that Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.1}\) is identical to
Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) --
right-censoring bias with effect modifiers in an otherwise unconfounded
study. The problem is formally the same: source-target population
mismatch. However, whereas in the right-censoring setting, we imagined
no source bias at baseline -- mismatch arose from attrition -- here
there is a mismatch at baseline.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.2}\) presents a solution. Ensure eligibility criteria
are scientifically relevant and feasible. Sample from this eligible
population. With caution, apply survey or other weights where these
weights enable a closer approximate to the distributions of
effect-modifiers in the target population.

\subsubsection{Example 3: Correlated measurement error of covariates and
outcome in the absence of a treatment
effect}\label{example-3-correlated-measurement-error-of-covariates-and-outcome-in-the-absence-of-a-treatment-effect}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.1}\) considers the threats to target validity from
correlated measurement errors in the target population arising from
structured errors. Even if the treatment is measured with out error,
there may be multiple sources of error leading to association without
causation.

Suppose the structures of correlated error correspond to features of
cultural units. Suppose further that investigators develop a plan for a
cross-cultural investigation to clarify the relationship between
interventions on religious service attendance (\(A\)) and an outcome
\(Y\) charitable giving. The investigators plan to obtain measures of
covariates \(L\) sufficient to control for confounding. Suppose the
investigators observe religious attendance so that it is not measured
with error (as did \citeproc{ref-shaver2021comparison}{Shaver \emph{et
al.} 2021}), yet there is heterogeneity in the measurement of covariates
\(L\) and the outcome \(Y\). For example, if charitable giving measures
are included as baseline covariates in \(L\), measurement errors at
baseline will be correlated with outcome measures. Perhaps in certain
cultures, religious serive is under-reported (associated with
witchcraft), in other cultures, it is over reported. Suppose further
that true covariates affect the treatment and outcome. As shown in
Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.1}\), multiple paths of bias are opened.

Moreover, because measurements are causally related to the phenomena
they record, investigators cannot apply statistical tests to verify
whether measures are recorded with error
(\citeproc{ref-vanderweele2022}{VanderWeele 2022};
\citeproc{ref-vansteelandt2022}{Vansteelandt and Dukes 2022b}). Whether
the phenomena that investigtors hope measure are functionally equivalent
across cultural settings remains unknown. Of course, we all want to
understand the species, however, asking coherent omparative questions in
the human sciences is not as easy as lying. Including multiple cultures
into a single analysis imposes considerable burdens on investigators.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.2}\) provides sensible solution: restrict one's study
to those cultures where causality can be identified. Democritus wrote,
`I would rather discover one cause than gain the kingdom of Persia'
(\citeproc{ref-freeman1948ancilla}{Freeman 1948}).' Paraphrasing
Democritus we might say, `I should rather discover one WIERD cause than
the kingdom of associational comparative research'.

\subsubsection{Example 4: Correlated measurement error of
effect-modifiers for an overly ambitious target
population}\label{example-4-correlated-measurement-error-of-effect-modifiers-for-an-overly-ambitious-target-population}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{4.1}\) considers the threats to target validity from
correlated measurement errors in the target population arising from
structured errors linking measurements for the effect modifiers. Even if
the treatment is randomised so that there are no open backdoor paths,
and even if the treatment and outcome are measured without error,
investigators will not be able to obtain valid estimates for
treatment-effect heterogeneity from their data, nor will they be able to
apply target-sample weights (such as census weights) to obtain valid
estimates for the populations in which the measurement errros of effect
modifiers are manifest.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{4.2}\) suggest that where measures of effect-modification
are uncertain, best to consider settings in which the measurements are
reliable -- whether or note the settings are WEIRD.

\subsection{Conclusions}\label{conclusions}

\begin{itemize}
\tightlist
\item
  Measurement first The trail of the serpant of measurement error bias
  runs across every study. Challenges for managing this serpant are
  greatly augmented where structures of measurement error may open
  pathways of bias linking treatments and outcomes in absence of
  causality.
\end{itemize}

\subsubsection{Building intuition for why definitions are insufficient
for understanding selection and source
biases}\label{building-intuition-for-why-definitions-are-insufficient-for-understanding-selection-and-source-biases}

When considering how source/target population mismatch imperiles
science, it is tempting to seek general definitions, typologies, and
identification criteria by which to spot the snakes.

\newpage{}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or the
decision to publish it.

\subsection{Acknowledgements}\label{acknowledgements}

Errors are my own.

\newpage{}

\subsection{Appendix A: Glossary}\label{appendix-a-glossary}

\begin{table}

\caption{\label{tbl-experiments}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\newpage{}

\subsection{Appendix B: R Simulation to Clarify Why The Distribution of
Effect Modifiers Matter For Estimating Treatment Effects For A Target
Population}\label{appendix-b-r-simulation-to-clarify-why-the-distribution-of-effect-modifiers-matter-for-estimating-treatment-effects-for-a-target-population}

First, we load the \texttt{stdReg} library, which obtains marginal
effect estimates by simulating counterfactuals under different levels of
treatment (\citeproc{ref-sjuxf6lander2016}{Sjölander 2016}). If a
treatment is continuous, the levels can be specified.

We also load the \texttt{parameters} library, which creates nice tables
(\citeproc{ref-parameters2020}{\textbf{parameters2020?}}).

Next, we write a function to simulate data for the sample and and target
populations.

We assume the treatment effect is the same in the sample and target
population. We will assume that the coefficient for the effect-modifier
and the coefficient for interaction are the same. We assume no
unmeasured confounding throughout the study. We assume only selective
attrition of one effect modifier such that the baseline population
differs from the sample population at the end of the study.

That is: \textbf{the distribution of effect modifiers is the only
respect in which the sample will differ from the target population.}

This function will generate data under a range of scenarios.\footnote{See
  documentation in the \texttt{margot} package: Bulbulia
  (\citeproc{ref-margot2024}{2024})}

\begin{longtable}[]{@{}ll@{}}
\caption{Data summary}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
Name & data \\
Number of rows & 100000 \\
Number of columns & 7 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Column type frequency: & \\
numeric & 7 \\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ & \\
Group variables & None \\
\end{longtable}

\textbf{Variable type: numeric}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.3053}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1053}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.1474}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0632}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0526}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 20\tabcolsep) * \real{0.0632}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
skim\_variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_missing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
complete\_rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
mean
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
sd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p25
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p50
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p75
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
p100
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
hist
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
sample\_data.y\_sample & 0 & 1 & 0.74 & 1.08 & -1.71 & 0.01 & 0.59 &
1.21 & 5.21 & ▂▇▃▁▁ \\
sample\_data.a\_sample & 0 & 1 & 0.49 & 0.50 & 0.00 & 0.00 & 0.00 & 1.00
& 1.00 & ▇▁▁▁▇ \\
sample\_data.z\_sample & 0 & 1 & 0.09 & 0.29 & 0.00 & 0.00 & 0.00 & 0.00
& 1.00 & ▇▁▁▁▁ \\
sample\_data.weights & 0 & 1 & 0.98 & 1.30 & 0.56 & 0.56 & 0.56 & 0.56 &
5.00 & ▇▁▁▁▁ \\
population\_data.y\_population & 0 & 1 & 1.88 & 1.60 & -2.09 & 0.51 &
1.76 & 3.26 & 6.01 & ▁▇▆▆▁ \\
population\_data.a\_population & 0 & 1 & 0.50 & 0.50 & 0.00 & 0.00 &
1.00 & 1.00 & 1.00 & ▇▁▁▁▇ \\
population\_data.z\_population & 0 & 1 & 0.50 & 0.50 & 0.00 & 0.00 &
1.00 & 1.00 & 1.00 & ▇▁▁▁▇ \\
\end{longtable}

We have generated both sample and population data.

Next, we verify that the distributions of effect modifiers differ in the
sample and in the target population:

\begin{verbatim}

   0    1 
9055  945 
\end{verbatim}

\begin{verbatim}

    0     1 
49916 50084 
\end{verbatim}

The sample and population distributions differ.

Next, consider the question: `What are the differences in the
coefficients that we obtain from the study population at the end of
study, as compared with the those we would obtain for target
population?'

First, we obtain the regression coefficients for the sample. They are as
follows:

\begin{verbatim}
Parameter           | Coefficient |       SE |        95% CI | t(9996) |      p
-------------------------------------------------------------------------------
(Intercept)         |   -6.89e-03 | 7.38e-03 | [-0.02, 0.01] |   -0.93 | 0.350 
a sample            |        1.01 |     0.01 | [ 0.99, 1.03] |   95.84 | < .001
z sample            |        2.47 |     0.02 | [ 2.43, 2.52] |  104.09 | < .001
a sample × z sample |        0.51 |     0.03 | [ 0.44, 0.57] |   14.82 | < .001
\end{verbatim}

We next obtain the regression coefficients for the weighted regression
of the sample. Notice that the coefficients are virtually the same:

\begin{verbatim}
Parameter           | Coefficient |        95% CI |      p
----------------------------------------------------------
(Intercept)         |   -6.89e-03 | [-0.03, 0.01] | 0.480 
a sample            |        1.01 | [ 0.98, 1.04] | < .001
z sample            |        2.47 | [ 2.45, 2.50] | < .001
a sample × z sample |        0.51 | [ 0.47, 0.55] | < .001

Model: y_sample ~ a_sample * z_sample (10000 Observations)
Residual standard deviation: 0.494 (df = 9996)
\end{verbatim}

We might be tempted to infer that weighting wasn't relevant to the
analysis. However, we'll see that such an interpretation would be a
mistake.

Next, we obtain model coefficients for the population. Note again there
is no difference -- only narrower errors owing to the large sample size.

\begin{verbatim}
Parameter                   | Coefficient |       SE |        95% CI | t(99996) |      p
----------------------------------------------------------------------------------------
(Intercept)                 |    2.49e-03 | 3.18e-03 | [ 0.00, 0.01] |     0.78 | 0.434 
a population                |        1.00 | 4.49e-03 | [ 0.99, 1.01] |   222.35 | < .001
z population                |        2.50 | 4.49e-03 | [ 2.49, 2.51] |   556.80 | < .001
a population × z population |        0.50 | 6.35e-03 | [ 0.49, 0.51] |    78.80 | < .001
\end{verbatim}

Again, there is no difference. That is, we find that all model
coefficients are practically equivalent. The different distribution of
effect modifiers does not result in different coefficient values for the
treatment effect, the effect-modifier `effect,' or the interaction of
effect modifier and treatment.

Consider why this is the case: in a large sample where the causal
effects are invariant -- as we have simulated them to be -- we will have
good replication in the effect modifiers within the sample, so our
statistical model can recover the \emph{coefficients} for the population
without challenge.

However, \emph{in causal inference, we are interested in the marginal
effect of the treatment. That is, we seek an estimate for the
counterfactual }contrast* in which everyone in a pre-specified
population was subject to one level of treatment compared with a
counterfactual condition in which everyone in a population was subject
to another level of the same treatment.

\textbf{When the sample population differs in the distribution of effect
modifiers from the target population effect, the marginal effect
estimates will typically differ.}

To see this, we use the \texttt{stdReg} package to recover marginal
effect estimates, comparing (1) the sample ATE, (2) the true oracle ATE
for the population, and (3) the weighted sample ATE. We will use the
outputs of the same models above. The only difference is that we will
calculate marginal effects from these outputs. We will contrast a
difference from an intervention in which everyone receives treatment = 0
with one in which everyone receives treatment = 1, however, this choice
is arbitrary, and the general lessons apply irrespective of the
estimand.

First, consider this Average Treatment Effect for the sample population.

\begin{verbatim}

Formula: y_sample ~ a_sample * z_sample
Family: gaussian 
Link function: identity 
Exposure:  a_sample 
Reference level:  a_sample = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00     0.0000       0.00       0.00
1     1.06     0.0101       1.04       1.08
\end{verbatim}

The treatment effect is given as a 1.06 unit change in the outcome
across the sample population, with a confidence interval from 1.04 to
1.08.

Next, we obtain the true (oracle) treatment effect for the population
under the same intervention.

\begin{verbatim}

Formula: y_population ~ a_population * z_population
Family: gaussian 
Link function: identity 
Exposure:  a_population 
Reference level:  a_population = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00    0.00000       0.00       0.00
1     1.25    0.00327       1.24       1.26
\end{verbatim}

Note, the true treatment effect is a 1.25 unit change in the population,
with a confidence bound between 1.24 and 1.26. This is well outside the
ATE that we obtain from the sample population!

Next, consider the ATE in the weighted regression, where the sample was
weighted to the target population's true distribution of effect
modifiers.

\begin{verbatim}

Formula: y_sample ~ a_sample * z_sample
Family: gaussian 
Link function: identity 
Exposure:  a_sample 
Reference level:  a_sample = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00     0.0000       0.00       0.00
1     1.25     0.0172       1.22       1.29
\end{verbatim}

We find that we obtain the population-level causal effect estimate with
accurate coverage by weighting the sample to the target population. So
with appropriate weights, our results generalise from the sample to the
target population.

\subsection{Lessons}\label{lessons}

\begin{itemize}
\tightlist
\item
  Regression coefficients do not clarify the problem of sample/target
  population mismatch -- or selection bias as discussed in this
  manuscript.
\item
  The correct advice to investigators is that they should not rely on
  regression coefficients when evaluating the biases that arise from
  sample attrition. This advice applies to both methods that the authors
  use to investigate threats of bias. That is, to implement this advice,
  the authors must first take it.
\item
  Generally, observed data are insufficient for assessing threats.
  Observed data do not clarify structural sources of bias, nor do they
  clarify effect-modification in the full counterfactual data condition
  in which all receive the treatment and all do not receive the
  treatment (at the same level).
\item
  To properly assess bias, one would need access to the counterfactual
  outcome---what would have happened to the missing participants had
  they not been lost to follow-up or had they responded. Again, the join
  distributions over `full data' are inherently unobservable
  (\citeproc{ref-vanderlaan2011}{Van Der Laan and Rose 2011}).
\item
  In simple settings like the one we just simulated, we may address the
  gap between the sample and target population using methods such as
  modelling the censoring (e.g., censoring weighting). However, we never
  know what setting we are in or whether it is simple---such modelling
  must be handled with care. There is a large and growing epidemiology
  literature on this topic (see, for example, Li \emph{et al.}
  (\citeproc{ref-li2023non}{2023})).
\end{itemize}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-arnett2008neglected}
Arnett, JJ (2008) The neglected 95\%: Why american psychology needs to
become less american. \emph{American Psychologist}, \textbf{63}(7),
602--614.
doi:\href{https://doi.org/10.1037/0003-066X.63.7.602}{10.1037/0003-066X.63.7.602}.

\bibitem[\citeproctext]{ref-barrett2021}
Barrett, M (2021) \emph{Ggdag: Analyze and create elegant directed
acyclic graphs}. Retrieved from
\url{https://CRAN.R-project.org/package=ggdag}

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-margot2024}
Bulbulia, JA (2024) \emph{Margot: MARGinal observational
treatment-effects}.
doi:\href{https://doi.org/10.5281/zenodo.10907724}{10.5281/zenodo.10907724}.

\bibitem[\citeproctext]{ref-bulbulia2023a}
Bulbulia, JA, Afzali, MU, Yogeeswaran, K, and Sibley, CG (2023)
Long-term causal effects of far-right terrorism in {N}ew {Z}ealand.
\emph{PNAS Nexus}, \textbf{2}(8), pgad242.

\bibitem[\citeproctext]{ref-cole2008}
Cole, SR, and Hernán, MA (2008) Constructing inverse probability weights
for marginal structural models. \emph{American Journal of Epidemiology},
\textbf{168}(6), 656--664.

\bibitem[\citeproctext]{ref-cole2010generalizing}
Cole, SR, and Stuart, EA (2010) Generalizing evidence from randomized
clinical trials to target populations: The ACTG 320 trial.
\emph{American Journal of Epidemiology}, \textbf{172}(1), 107--115.

\bibitem[\citeproctext]{ref-dahabreh2021study}
Dahabreh, IJ, Haneuse, SJA, Robins, JM, \ldots{} Hernán, MA (2021) Study
designs for extending causal inferences from a randomized trial to a
target population. \emph{American Journal of Epidemiology},
\textbf{190}(8), 1632--1642.

\bibitem[\citeproctext]{ref-freeman1948ancilla}
Freeman, K (1948) \emph{Ancilla to the pre-socratic philosophers},
Reprint edition, Cambridge, MA: Harvard University Press.

\bibitem[\citeproctext]{ref-greenland2009commentary}
Greenland, S (2009) Commentary: Interactions in epidemiology: Relevance,
identification, and estimation. \emph{Epidemiology}, \textbf{20}(1),
14--17.

\bibitem[\citeproctext]{ref-henrich2010weirdest}
Henrich, J, Heine, SJ, and Norenzayan, A (2010) The weirdest people in
the world? \emph{Behavioral and Brain Sciences}, \textbf{33}(2-3),
61--83.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernuxe1n2004}
Hernán, MA (2004) A definition of causal effect for epidemiological
research. \emph{Journal of Epidemiology \& Community Health},
\textbf{58}(4), 265--271.
doi:\href{https://doi.org/10.1136/jech.2002.006361}{10.1136/jech.2002.006361}.

\bibitem[\citeproctext]{ref-hernuxe1n2017}
Hernán, MA (2017) Invited commentary: Selection bias without colliders
\textbar{} american journal of epidemiology \textbar{} oxford academic.
\emph{American Journal of Epidemiology}, \textbf{185}(11), 1048--1050.
Retrieved from \url{https://doi.org/10.1093/aje/kwx077}

\bibitem[\citeproctext]{ref-hernan2017per}
Hernán, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-holland1986}
Holland, PW (1986) Statistics and causal inference. \emph{Journal of the
American Statistical Association}, \textbf{81}(396), 945--960.

\bibitem[\citeproctext]{ref-hume1902}
Hume, D (1902) \emph{Enquiries Concerning the Human Understanding: And
Concerning the Principles of Morals}, Clarendon Press.

\bibitem[\citeproctext]{ref-imai2008misunderstandings}
Imai, K, King, G, and Stuart, EA (2008) Misunderstandings between
experimentalists and observationalists about causal inference.
\emph{Journal of the Royal Statistical Society Series A: Statistics in
Society}, \textbf{171}(2), 481--502.

\bibitem[\citeproctext]{ref-lash2020}
Lash, TL, Rothman, KJ, VanderWeele, TJ, and Haneuse, S (2020)
\emph{Modern epidemiology}, Wolters Kluwer. Retrieved from
\url{https://books.google.co.nz/books?id=SiTSnQEACAAJ}

\bibitem[\citeproctext]{ref-lewis1973}
Lewis, D (1973) Causation. \emph{The Journal of Philosophy},
\textbf{70}(17), 556--567.
doi:\href{https://doi.org/10.2307/2025310}{10.2307/2025310}.

\bibitem[\citeproctext]{ref-leyrat2021}
Leyrat, C, Carpenter, JR, Bailly, S, and Williamson, EJ (2021) Common
methods for handling missing data in marginal structural models: What
works and why. \emph{American Journal of Epidemiology}, \textbf{190}(4),
663--672.

\bibitem[\citeproctext]{ref-li2023non}
Li, W, Miao, W, and Tchetgen Tchetgen, E (2023) Non-parametric inference
about mean functionals of non-ignorable non-response data without
identifying the joint distribution. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{85}(3),
913--935.

\bibitem[\citeproctext]{ref-lu2022}
Lu, H, Cole, SR, Howe, CJ, and Westreich, D (2022) Toward a Clearer
Definition of Selection Bias When Estimating Causal Effects.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{33}(5), 699--706.
doi:\href{https://doi.org/10.1097/EDE.0000000000001516}{10.1097/EDE.0000000000001516}.

\bibitem[\citeproctext]{ref-malinsky2022semiparametric}
Malinsky, D, Shpitser, I, and Tchetgen Tchetgen, EJ (2022)
Semiparametric inference for nonmonotone missing-not-at-random data: The
no self-censoring model. \emph{Journal of the American Statistical
Association}, \textbf{117}(539), 1415--1423.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in r and stan}, CRC press.

\bibitem[\citeproctext]{ref-neal2020introduction}
Neal, B (2020) Introduction to causal inference from a machine learning
perspective. \emph{Course Lecture Notes (Draft)}. Retrieved from
\url{https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf}

\bibitem[\citeproctext]{ref-pearl1995}
Pearl, J (1995) Causal diagrams for empirical research.
\emph{Biometrika}, \textbf{82}(4), 669--688.

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013) Single world intervention graphs:
A primer. In, Citeseer.

\bibitem[\citeproctext]{ref-richardson2014causal}
Richardson, TS, and Rotnitzky, A (2014) Causal etiology of the research
of james m. robins. \emph{Statistical Science}, \textbf{29}(4),
459--484.

\bibitem[\citeproctext]{ref-rubin1976}
Rubin, DB (1976) Inference and missing data. \emph{Biometrika},
\textbf{63}(3), 581--592.
doi:\href{https://doi.org/10.1093/biomet/63.3.581}{10.1093/biomet/63.3.581}.

\bibitem[\citeproctext]{ref-sears1986college}
Sears, DO (1986) College sophomores in the laboratory: Influences of a
narrow data base on social psychology's view of human nature.
\emph{Journal of Personality and Social Psychology}, \textbf{51}(3),
515.

\bibitem[\citeproctext]{ref-shaver2021comparison}
Shaver, JH, White, TA, Vakaoti, P, and Lang, M (2021) A comparison of
self-report, systematic observation and third-party judgments of church
attendance in a rural fijian village. \emph{Plos One}, \textbf{16}(10),
e0257160.

\bibitem[\citeproctext]{ref-shiba2021}
Shiba, K, and Kawahara, T (2021) Using propensity scores for causal
inference: Pitfalls and tips. \emph{Journal of Epidemiology},
\textbf{31}(8), 457--463.

\bibitem[\citeproctext]{ref-sjuxf6lander2016}
Sjölander, A (2016) Regression standardization with the R package
stdReg. \emph{European Journal of Epidemiology}, \textbf{31}(6),
563--574.
doi:\href{https://doi.org/10.1007/s10654-016-0157-3}{10.1007/s10654-016-0157-3}.

\bibitem[\citeproctext]{ref-stuart2018generalizability}
Stuart, EA, Ackerman, B, and Westreich, D (2018) Generalizability of
randomized trial results to target populations: Design and analysis
possibilities. \emph{Research on Social Work Practice}, \textbf{28}(5),
532--537.

\bibitem[\citeproctext]{ref-stuart2015}
Stuart, EA, Bradshaw, CP, and Leaf, PJ (2015) Assessing the
Generalizability of Randomized Trial Results to Target Populations.
\emph{Prevention Science}, \textbf{16}(3), 475--485.
doi:\href{https://doi.org/10.1007/s11121-014-0513-z}{10.1007/s11121-014-0513-z}.

\bibitem[\citeproctext]{ref-suzuki2016}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2016) A typology of
four notions of confounding in epidemiology. \emph{Journal of
Epidemiology}, \textbf{27}(2), 49--55.
doi:\href{https://doi.org/10.1016/j.je.2016.09.003}{10.1016/j.je.2016.09.003}.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-suzuki2014}
Suzuki, E, and Yamamoto, E (2014) Further refinements to the
organizational schema for causal effects. \emph{Epidemiology},
\textbf{25}(4), 618.
doi:\href{https://doi.org/10.1097/EDE.0000000000000114}{10.1097/EDE.0000000000000114}.

\bibitem[\citeproctext]{ref-tchetgen2017general}
Tchetgen Tchetgen, EJ, and Wirth, KE (2017) A general instrumental
variable framework for regression analysis with outcome missing not at
random. \emph{Biometrics}, \textbf{73}(4), 1123--1131.

\bibitem[\citeproctext]{ref-tripepi2007}
Tripepi, G, Jager, KJ, Dekker, FW, Wanner, C, and Zoccali, C (2007)
Measures of effect: Relative risks, odds ratios, risk difference, and
{`}number needed to treat{'}. \emph{Kidney International},
\textbf{72}(7), 789--791.
doi:\href{https://doi.org/10.1038/sj.ki.5002432}{10.1038/sj.ki.5002432}.

\bibitem[\citeproctext]{ref-vanderlaan2011}
Van Der Laan, MJ, and Rose, S (2011) \emph{Targeted Learning: Causal
Inference for Observational and Experimental Data}, New York, NY:
Springer. Retrieved from
\url{https://link.springer.com/10.1007/978-1-4419-9782-1}

\bibitem[\citeproctext]{ref-vanderweele2012}
VanderWeele, TJ (2012) Confounding and Effect Modification: Distribution
and Measure. \emph{Epidemiologic Methods}, \textbf{1}(1), 55--82.
doi:\href{https://doi.org/10.1515/2161-962X.1004}{10.1515/2161-962X.1004}.

\bibitem[\citeproctext]{ref-vanderweele2022}
VanderWeele, TJ (2022) Constructed measures and causal inference:
Towards a new model of measurement for psychosocial constructs.
\emph{Epidemiology}, \textbf{33}(1), 141.
doi:\href{https://doi.org/10.1097/EDE.0000000000001434}{10.1097/EDE.0000000000001434}.

\bibitem[\citeproctext]{ref-vanderweele2007a}
VanderWeele, TJ, and Robins, JM (2007) Directed acyclic graphs,
sufficient causes, and the properties of conditioning on a common
effect. \emph{American Journal of Epidemiology}, \textbf{166}(9),
1096--1104.
doi:\href{https://doi.org/10.1093/aje/kwm179}{10.1093/aje/kwm179}.

\bibitem[\citeproctext]{ref-vanderweele2010}
VanderWeele, TJ, and Robins, JM (2010) Signed directed acyclic graphs
for causal inference. \emph{Journal of the Royal Statistical Society
Series B: Statistical Methodology}, \textbf{72}(1), 111--127.
doi:\href{https://doi.org/10.1111/j.1467-9868.2009.00728.x}{10.1111/j.1467-9868.2009.00728.x}.

\bibitem[\citeproctext]{ref-vansteelandt2022}
Vansteelandt, S, and Dukes, O (2022b) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657--685.

\bibitem[\citeproctext]{ref-vansteelandt2022a}
Vansteelandt, S, and Dukes, O (2022a) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657--685.

\bibitem[\citeproctext]{ref-westreich2017}
Westreich, D, Edwards, JK, Lesko, CR, Stuart, E, and Cole, SR (2017a)
Transportability of trial results using inverse odds of sampling
weights. \emph{American Journal of Epidemiology}, \textbf{186}(8),
1010--1014.
doi:\href{https://doi.org/10.1093/aje/kwx164}{10.1093/aje/kwx164}.

\bibitem[\citeproctext]{ref-westreich2017transportability}
Westreich, D, Edwards, JK, Lesko, CR, Stuart, E, and Cole, SR (2017b)
Transportability of trial results using inverse odds of sampling
weights. \emph{American Journal of Epidemiology}, \textbf{186}(8),
1010--1014.

\end{CSLReferences}



\end{document}
