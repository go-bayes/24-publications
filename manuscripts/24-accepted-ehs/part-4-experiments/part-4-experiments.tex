% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Methods in Causal Inference Part 4: Confounding in Experiments},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Methods in Causal Inference Part 4: Confounding in Experiments}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-06-13}
\begin{document}
\maketitle
\begin{abstract}
Confounding bias arises when a treatment and outcome share a common
cause. In randomised controlled experiments (trials), treatment
assignment is random, ostensibly eliminating confounding bias. Here, we
use causal directed acyclic graphs (causal DAGs) to unveil eight
structural sources of bias that nevertheless persist in these trials.
This analysis highlights the crucial role of causal inference methods in
the design and analysis of experiments, ensuring the validity of
conclusions drawn from experimental data.

\textbf{Keywords:} \emph{Causal Inference}; \emph{Experiments};
\emph{DAGs}; \emph{Evolution}; \emph{Per Protocol Effect};
\emph{Intention to Treat Effect}; \emph{RCT}.
\end{abstract}

\subsection{Introduction}\label{introduction}

``Does not randomisation, by its very nature, eliminate all systematic
causes of treatment assignment and outcome?''

Yes.

``Does this mean that confounding bias is ruled out?''

No.

Assume large sample sizes to minimise random differences in variable
distribution. Assume that the experimental trials are double-blind, with
consistent treatment conditions across all arms, applied by meticulous
investigators. Assume no chance event, other than randomisation.
Finally, assume that the target population is not restricted in the
sample population, ensuring that the experiments, if internally valid,
will generalise. Assume no measurement error in the measures.

Nevertheless, confounding biases can arise. Here, I use eight examples
to illustrate common risks. Whereas some risks arise from common flaws
in experimental designs, such as post-randomisation selection criteria
and post-randomisation covariate adjustment, hazards in estimating the
`per-protocol effect' of treatments do not arise from design errors.
These typically require the use of methods for causal inference in `real
world' observational studies. The eight examples demonstrate the utility
of causal directed acyclic graphs (causal DAGs) for easing the cognitive
demand in diagnosing confounding bias in experimental designs. Overall,
understanding how confounding occurs is crucial for experimental design,
data analysis, and inference, demonstrating the utility of causal
inference methods for diagnosing and addressing vulnerabilities in
randomised experimental designs.

We begin by defining our terms. Supplementary materials \textbf{S1}
provides a glossary of general terms used in causal inference.

\subsubsection{Terminology}\label{terminology}

\begin{itemize}
\item
  \textbf{Confounding bias}: Treatment and outcome are associated
  independently of causality or are disassociated in the presence of
  causality relative to the causal question at hand.
\item
  \textbf{Intention-to-Treat Effect (or `intent-to-treat effect')}: The
  effect of treatment assignment, analysed based on initial treatment
  assignment, reflecting real-world effectiveness but possibly obscuring
  mechanisms.
\item
  \textbf{Per-protocol effect}: The effect of adherence to a randomly
  assigned treatment if adherence were perfect
  (\citeproc{ref-hernan2017per}{Hern√°n \emph{et al.} 2017}). We have no
  guarantee that the intention-to-treat effect will be the same as the
  per-protocol effect. A safe assumption is that:
\end{itemize}

\[
\widehat{ATE}_{\text{target}}^{\text{Per-Protocol}} \ne \widehat{ATE}_{\text{target}}^{\text{Intention-to-Treat}}
\]

When evaluating evidence for causality, investigators should specify
whether they are estimating an intention-to-treat or per-protocol
effect. They should do this in addition to stating a causal contrast,
effect measure, and target population,
(\citeproc{ref-hernuxe1n2004}{Hern√°n 2004};
\citeproc{ref-tripepi2007}{Tripepi \emph{et al.} 2007}) and to
evaluating sources of measurement error bias
(\citeproc{ref-bulbulia2024wierd}{Bulbulia 2024 (in press)b}).

\subsubsection{Meaning of Symbols}\label{meaning-of-symbols}

We use the following conventions in our directed acyclic graphs:

\begin{itemize}
\item
  \textbf{Node}: A node or vertex represents characteristics or features
  of units within a population on a causal diagram -- that is, a
  `variable.' In causal directed acyclic graphs, we draw nodes with
  respect to the \emph{target population}, which is the population for
  whom investigators seek causal inferences
  (\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020}). A time-indexed
  node \(X_t\) denotes relative chronology; \(X_{\phi t}\) indicates
  assumed timing, possibly erroneous.
\item
  \textbf{Edge without an Arrow} (\(\association\)): Path of
  association, causality not asserted.
\item
  \textbf{Red Edge without an Arrow} (\(\associationred\)): Confounding
  path: ignores arrows to clarify statistical dependencies.
\item
  \textbf{Arrow} (\(\rightarrowNEW\)): Denotes a causal relationship
  from the node at the base of the arrow (a parent) to the node at the
  tip of the arrow (a child). We typically refrain from drawing an arrow
  from treatment to outcome to avoid asserting a causal path from \(A\)
  to \(Y\) because the function of a causal directed acyclic graph is to
  evaluate whether causality can be identified for this path.
\item
  \textbf{Red Arrow} (\(\rightarrowred\)): Path of non-causal
  association between the treatment and outcome. The path is
  associational and may run against arrows.
\item
  \textbf{Dashed Arrow} (\(\rightarrowdotted\)): Denotes a true
  association between the treatment and outcome that becomes partially
  obscured when conditioning on a mediator, assuming \(A\) causes \(Y\).
\item
  \textbf{Dashed Red Arrow} (\(\rightarrowdottedred\)): Highlights
  over-conditioning bias from conditioning on a mediator.
\item
  \textbf{Boxed Variable} \(\boxed{X}\): Conditioning or adjustment for
  \(X\).
\item
  \textbf{Red-Boxed Variable} \(\boxedred{X}\): Highlights the source of
  confounding bias from adjustment.
\item
  \textbf{Dashed Circle} \(\circledotted{X}\): Indicates no adjustment
  is made for a variable (implied for unmeasured confounders).
\item
  \textbf{\(\mathcal{R} \rightarrow A\)}: Randomisation into a treatment
  condition.
\end{itemize}

\subsubsection{Review of d-separation for Causal Identification on a
Graph}\label{review-of-d-separation-for-causal-identification-on-a-graph}

\begin{table}

\caption{\label{tbl-fiveelementary}The five elementary structures of
causality from which all causal directed acyclic graphs can be built.}

\centering{

\terminologydirectedgraph

}

\end{table}%

Pearl demonstrated that causal dependencies could be evaluated by
linking observable probability distributions to directed acyclic graphs
(\citeproc{ref-pearl1995}{Pearl 1995}, \citeproc{ref-pearl2009a}{2009}).
This means that, based on assumptions about causal structure,
investigators could investigate strategies for identifying causal
effects from the joint distributions of observed data. The graphical
rules that Pearl developed and proved are known as the rules of
d-separation (\citeproc{ref-pearl1995}{Pearl 1995}), and are presented
in Table~\ref{tbl-fiveelementary}.

The rules of d-separation are as follows:

\begin{enumerate}[a)]
     \item {\bf Fork rule} ($B \leftarrowNEW \boxed{A} \rightarrowNEW C$): $B$ and $C$ are independent when conditioning on $A$: ($B \coprod C \mid A$).
     \item {\bf Chain rule} ($A \rightarrowNEW \boxed{B} \rightarrowNEW C$): Conditioning on $B$ blocks the path between $A$ and $C$: ($A \coprod C \mid B$).
     \item {\bf Collider rule} ($A \rightarrowNEW \boxed{C} \leftarrowNEW B$): $A$ and $B$ are independent until conditioning on $C$, which introduces dependence: ($A \cancel{\coprod} B \mid C$). 
\end{enumerate}

The rules of d-separation give rise to the backdoor criterion which
provides an identification algorithm conditional on the structural
assumptions encoded in a causal directed acyclic graph
(\citeproc{ref-pearl1995}{Pearl 1995}).

\textbf{Backdoor Adjustment}: In a causal directed acyclic graph, we say
that a set of variables \(L\) satisfies the backdoor adjustment theorem
relative to the treatment \(A\) and the outcome \(Y\) if \(L\) blocks
every path between \(A\) and \(Y\) that contains an arrow pointing into
\(A\) (a backdoor path). Formally, \(L\) must satisfy two conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{No Path Condition}: No element of \(L\) is a descendant of
  \(A\).
\item
  \textbf{Blocking Condition}: \(L\) blocks all backdoor paths from
  \(A\) to \(Y\).
\end{enumerate}

If \(L\) satisfies these conditions, we say the causal effect of \(A\)
on \(Y\) is identified conditional on \(\boxed{L}\)
(\citeproc{ref-pearl2009a}{Pearl 2009}).

\subsection{Eight Examples of Confounding Bias in
Experiments}\label{eight-examples-of-confounding-bias-in-experiments}

\begin{table}

\caption{\label{tbl-terminologyelconfoundersexperiments}Eight
confounding biases in Randomised Controlled Trials.}

\centering{

\terminologyelconfoundersexperiments

}

\end{table}%

We use causal directed acyclic graphs to describe eight types of
confounding bias in randomised controlled trials (`experiments'). We use
the symbol \(\mathcal{G}\) to denote a causal directed acyclic graph in
the table. The first digit in the graph subscript indexes the example.
The second digit in the graph subscript indexes the problem or the
response to the problem. Specifically, if the subscript `1' is used, it
refers to the graph associated with the problem; if `2' is used, it
refers to the graph associated with the response.

\subsubsection{Example 1: Post-treatment Adjustment Blocks Treatment
Effect}\label{example-1-post-treatment-adjustment-blocks-treatment-effect}

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{1.1}\) illustrates the threat of confounding bias by
conditioning on a post-treatment mediator McElreath
(\citeproc{ref-mcelreath2020}{2020}). Imagine investigators are
interested in whether the framing of an authority as religious or
secular -- `source framing' -- affects subjective ratings of confidence
in the authority -- `source credibility.' There are two conditions. A
claim is presented from an authority. The content of the claim does not
vary by condition. Participants are asked to rate the claim on a
credibility scale. Next, imagine that the investigators decide they
should control for religiosity. Furthermore, imagine there is a true
effect of source framing. Finally, assume that the source framing not
only affects source credibility but also affects religiosity. Perhaps
viewing a religious authority makes religious people more religious. In
this scenario, measuring religiosity following the experimental
intervention will partially block the effect of the treatment on the
outcome. It might make it appear that the treatment does not work for
religious people, when in reality it works because it amplifies
religiosity. (Note that in this graph we assume that \(L_1\) occurs
before \(Y_2\), however, investigators may have measured \(L_1\) after
\(Y_2\). Our time index pertains to the occurrence of the event, not to
its measurement. This statement applies to all examples that follow.)

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{1.2}\) clarifies a response: do not control
post-treatment variables, here the intermediary effects of
`religiosity'. If effect-modification by religiosity is scientifically
interesting, measure religiosity before randomisation. Randomisation did
not prevent confounding.

\subsubsection{Example 2: Post-treatment Adjustment Induces Collider
Stratification
Bias}\label{example-2-post-treatment-adjustment-induces-collider-stratification-bias}

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{2.1}\) illustrates the threat of confounding bias by
conditioning on a post-treatment collider (\citeproc{ref-cole2010}{Cole
\emph{et al.} 2010}). Imagine the same experiment as in Example 1 and
the same conditioning strategy, where religiosity is measured following
the treatment. We assume the treatment affects religiosity. However, in
this example, religiosity has no causal effect on the outcome, source
credibility. Finally, imagine an unmeasured variable affects both the
mediator, religiosity (\(L_1\)), and the outcome, source credibility
(\(Y_2\)). This unmeasured confounder might be religious education in
childhood. In this scenario, conditioning on the post-treatment variable
religiosity will open a backdoor path between the treatment and outcome,
leading to an association in the absence of causation. Randomisation did
not prevent confounding.

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{2.2}\) clarifies a response: do not control
post-treatment variables.

The point that investigators should not condition on post-treatment
variables can be illustrated with a common flaw in experimental designs:
exclusion based on `attention checks'. Consider that if an experimental
condition affects attention and an unmeasured variable is a common cause
of attention and the outcome, then selection on attention will induce
confounding bias in a randomised experiment. For example, imagine that
people are more attentive to the scientific authority design because
science is interesting -- whether or not one is religious, yet religion
is not interesting whether or not one is religious. Suppose further that
an unmeasured `altruistic disposition' affects both attention and
ratings of source credibility. By selecting on attention, investigators
may unwittingly destroy randomisation. If attention is a scientifically
interesting effect modifier, it should be measured before random
assignment to treatment.

\subsubsection{Example 3: Demographic Measures at End of Study Induce
Collider Stratification
Bias}\label{example-3-demographic-measures-at-end-of-study-induce-collider-stratification-bias}

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{3.1}\) illustrates the threat of confounding bias from
adjusting for post-treatment variables, here, one affected by the
treatment and outcome absent any unmeasured confounder. In our example,
imagine both the treatment, source framing, and the outcome, source
credibility, affect religiosity measured at the end of the study.
Investigators measure religiosity at the end of the study and include
this measure as a covariate. However, doing so induces collider bias
such that if both the treatment and outcome are positively associated
with religiosity, the collider, they will be negatively associated with
each other. Conditioning on the collider risks the illusion of a
negative experimental effect without causality.

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{3.2}\) clarifies a response: again, do not control
post-treatment variables. Here, `religiosity' is measured after the end
of the study. If the scientific interest is in effect modification or
obtaining statistical precision, measure covariates before
randomisation.

\subsubsection{Example 4: Demographic Measures at End of Study Condition
on a Collider That Opens a Backdoor
Path}\label{example-4-demographic-measures-at-end-of-study-condition-on-a-collider-that-opens-a-backdoor-path}

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{4.1}\) illustrates the threat of confounding bias by
adjusting for post-treatment variables, here affected only by the
treatment and an unmeasured cause of the outcome. Suppose source
credibility affects religiosity (religious people are reminded of their
faith), but there is no experimental effect of framing on credibility.
Imagine further that there is an unmeasured common cause of the
covariate religiosity and the outcome source credibility. This
unmeasured confounder might be religious education in childhood. In this
scenario, conditioning on the post-treatment variable religiosity will
open a backdoor path between the treatment and outcome, leading to an
association without causation. Again, we find that randomisation did not
prevent confounding.

Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{4.2}\) clarifies a response. Again, unless investigators
can rule out an effect of treatment, they should not condition on a
post-treatment covariate. The covariates of interest should be measured
before randomisation.

\subsubsection{Example 5: Treatment Affects Attrition Biasing Measure of
Outcome}\label{example-5-treatment-affects-attrition-biasing-measure-of-outcome}

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{5}\)
Suppose that the experimental condition affects measurement error in
self-reported source credibility \(U_{\Delta Y}\). For example, suppose
that source framing has no effect on credibility. However, those in the
scientific authority condition are more likely to express credibility
for science due to self-presentation bias. Likewise, perceiving the
investigators to be irreligious, participants in the religious source
framing condition might report less credibility for religious
authorities than they secretly harbour. Directed measurement error from
the treatment to the measurement error of the outcomes creates an
association without true causality, which we denote by removing any
arrow between the treatment \(A\) and the true outcome \(Y\).

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{5}\)
suggests there is no easy solution to directed measurement error bias in
this setting. If the magnitude of the bias were known, investigators
could apply adjustments (\citeproc{ref-lash2009applying}{Lash \emph{et
al.} 2009}). Additional experiments might be devised that are
insensitive to directed measurement error bias. Investigators might
compute sensitivity analyses to examine how much measurement error bias
would be required to explain away a result (refer to Linden \emph{et
al.} (\citeproc{ref-linden2020EVALUE}{2020}) for a relatively
easy-to-implement sensitivity analysis). The point we make here is that
randomisation does not prevent confounding by directed measurement error
bias. Investigators must be vigilant.

\subsubsection{Example 6: Per Protocol Effect Lost in Sustained
Treatments Where Treatment Adherence Is Affected by a Measured
Confounder}\label{example-6-per-protocol-effect-lost-in-sustained-treatments-where-treatment-adherence-is-affected-by-a-measured-confounder}

Setting aside self-inflicted injuries of post-treatment conditioning and
directed measurement error, \textbf{randomisation recovers unbiased
causal effect estimates for randomisation into treatment.}. Under
perfect adherence, such estimates correspond to the causal effects of
the treatments themselves. However, adherence is seldom perfect. The
following examples reveal challenges for recovering per-protocol effects
in settings where there is imperfect adherence.
Table~\ref{tbl-terminologyelconfoundersexperiments}
\(\mathcal{G}_{6-8}\) are adapted from Hern√°n \emph{et al.}
(\citeproc{ref-hernan2017per}{2017}).

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{6}\)
illustrates the threat for identifying the per-protocol effect in
sustained treatments where treatment adherence is affected by a measured
confounder. Consider a sequential experiment that investigates the
effects of sustained adherence to yoga on psychological distress,
measured at the end of the study. Suppose that inflexible people are
less likely to adhere to the protocols set out in the experiment and
therefore do not. Suppose that flexibility is measured by indicator
\(L\). If we do not condition on \(L\), there is an open path from
\(A_1 \associationred L_0 \associationred U \associationred Y_2\).
Although investigators may recover the effect of randomisation into
treatment, the per-protocol effect is confounded.

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{6}\)
also clarifies a response. Conditioning on \(L_0\) and \(L_1\) will
block the backdoor path, leading to an unbiased per-protocol effect
estimate.

\subsubsection{Example 7: Per protocol effect lost in sustained
treatments where past treatments affect measured confounder of future
treatment
adherence}\label{example-7-per-protocol-effect-lost-in-sustained-treatments-where-past-treatments-affect-measured-confounder-of-future-treatment-adherence}

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{7}\)
illustrates the threat for identifying the per-protocol effect in
sustained treatments where past treatments affect measured confounder of
future treatment adherence. Suppose that yoga affects flexibility. We
should condition on pre-treatment measures of flexibility to identify
the per-protocol effect. However, conditioning on the post-treatment
measure of flexibility, \(\boxed{L_1}\) induces collider stratification
bias. This path runs from
\(A_1 \associationred L_1 \associationred U \associationred Y_3\).
However, if we do not condition on \(L_1\) there is an open backdoor
path from \(A_1 \associationred U \associationred Y_3\). We cannot
estimate a per-protocol effect by conditioning strategies.

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{7}\)
does not clarify the response. However, in a sequential treatment with
fixed strategies, in which there is sequential exchangeability -- or no
unmeasured confounding at each time point -- valid estimators for the
sequential treatments may be constructed (refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}); Dƒ±ÃÅaz \emph{et al.}
(\citeproc{ref-diaz2021nonparametric}{2021}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2023}{2023})). Although we may naively obtain an
intention-to-treat effect estimate without special methods, inferring an
effect of doing yoga on well-being -- the per-protocol effect, requires
special methods. These methods are not routinely used in the human
sciences.

\subsubsection{Example 8: Per Protocol Effect Lost in Sustained
Treatments Because Both Measured and Unmeasured Confounders Affect
Treatment
Adherence}\label{example-8-per-protocol-effect-lost-in-sustained-treatments-because-both-measured-and-unmeasured-confounders-affect-treatment-adherence}

Table~\ref{tbl-terminologyelconfoundersexperiments} \(\mathcal{G}_{8}\)
illustrates the threat for identifying the per-protocol effect in
sustained treatments with measured and unmeasured confounders. Suppose
flexibility affects adherence, yoga affects flexibility, and an
unmeasured variable, such as prejudice toward Eastern spiritual
practices, affects adherence. We have no measures for this variable.
There is unmeasured confounding.

If there were no effect of yoga on well-being except through
flexibility, and furthermore if flexibility were not affected by the
unmeasured antipathy toward Eastern spiritual practices, and further, if
the effect of flexibility on yoga at each time point were conditionally
independent of all future counterfactual data, both for the treatments
and the outcomes, then it might be possible to construct special
estimators that identify the per-protocol effect of yoga on well-being
in the presence of unmeasured confounding that affects adherence (refer
to Hern√°n \emph{et al.} (\citeproc{ref-hernan2017per}{2017})). These
special estimators are quite different from the ANOVAs, regressions
models, and multi-level regression models routinely deployed in
experimental studies. However, if we seek to understand the effect of
yoga on well-being and not the effect of random assignment to yoga on
well-being the routine estimators will not work: we require special
estimators (\citeproc{ref-diaz2023lmtp}{D√≠az \emph{et al.} 2023};
\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024};
\citeproc{ref-hoffman2023}{Hoffman \emph{et al.} 2023}).

\subsection{Conclusions}\label{conclusions}

The examples considered here do not exhaust all threats to causal
inference in experiments. For example, I have not covered biases arising
from sample attrition (refer to Bulbulia
(\citeproc{ref-bulbulia2024wierd}{2024 (in press)b})). However, I hope
the eight examples presented persuade experimental investigators of the
following:

First, there is no need to adjust for baseline confounders in a
non-sequential randomised experiment. Although an unadjusted difference
of means should be reported, Lin has shown that if a study is
sufficiently powered, regression adjustment where the full set of
treatments are interacted with baseline covariates may improve (and will
not diminish) asymptotic precision
(\citeproc{ref-lin2012regressexperiments}{Lin 2013}). In some settings,
investigators will want to evaluate effect modification with strata of
covariates at baseline. However, in sufficiently large samples,
randomisation ensures balance.

Second, confounding biases can occur in randomised experiments even when
randomisation succeeds. To evaluate such bias, we must first state
whether our causal estimand is the intention-to-treat effect or the
per-protocol effect. Randomisation recovers an unbiased estimate of the
intention-to-treat effect---that is, the effect of treatment assignment.
Randomisation will only recover the per-protocol effect, the effect of
following treatment, when those assigned to treatment adhere to their
assignments.

Third, causal directed acyclic graphs are useful for clarifying sources
of bias for both the intention-to-treat effect and the per-protocol
effect. For the intention-to-treat effect, biases arise in two main
ways: when investigators impose selection criteria on participants after
randomisation (e.g., assessing treatment effects only in those who have
followed protocols) or when investigators estimate treatment effects
using covariates collected after randomisation. Both post-treatment
selection and post-treatment conditioning are self-inflicted sources of
confounding bias. The remedy is to not allow your design to compromise
randomisation. For the per-protocol effect, randomisation cannot
guarantee unbiased estimates. Obtaining consistent estimates for the
per-protocol effect requires the same assumptions and methods that are
required when estimating causal effects in observational studies.

Fourth, in a sequential randomised experiment, standard methods such as
regression adjustment, statistical structural equation models, and
multi-level models will often fail to yield unbiased estimands
(\citeproc{ref-bulbulia2024swigstime}{Bulbulia 2024 (in press)a};
\citeproc{ref-richardson2013}{Richardson and Robins 2013};
\citeproc{ref-young2014identification}{Young \emph{et al.} 2014}).
Special estimators such as `g-methods'
(\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024}) or targeted
learning (\citeproc{ref-vanderlaan2018}{Van Der Laan and Rose 2018}) may
be necessary to recover per-protocol effects in sequential designs. The
requirements for estimating per-protocol effects in experiments cannot
be stated in isolation from the details of each study
(\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024};
\citeproc{ref-robins1986}{Robins 1986}).

From these observations, we offer the following practical advice:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ensure covariate data are collected before randomisation into
  treatments.
\item
  If attention is a relevant covariate, measure it before randomisation.
  Do not use `attention checks' to select participants after
  randomisation into treatments.
\item
  If adjustment is used in a single-point treatment with baseline
  covariates, interact every level of treatment with the baseline
  covariates, following Lin
  (\citeproc{ref-lin2012regressexperiments}{2013}).
\item
  For sequential treatments, collect data for adherence (where
  possible).
\item
  For sequential treatments, at each measurement interval, ensure
  covariate data collection for any variable that might affect adherence
  or that might be proxies for such variables, particularly if these
  variables, or proxies for these variables, might affect outcomes at
  the end of the study.
\item
  Do not infer per-protocol effects from the portion of the sample that
  followed experimental protocols. Such selection can lead to
  differences between the study population at the start and end,
  compromising external validity.
\item
  Where possible, report both the per-protocol effect and the
  intention-to-treat effect.
\end{enumerate}

In a separate work, I considered bias arising from attrition in the
absence of confounding when treatment assignment is randomised
(\citeproc{ref-bulbulia2024wierd}{Bulbulia 2024 (in press)b}).
Describing the special methods for estimating per-protocol effects with
multiple sequential treatments is beyond the scope of this commentary
(\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024}). My aim has
been to demonstrate that satisfying the assumptions for valid causal
inferences in experiments is often more challenging than many
experimental human scientists currently realize (refer to
\citeproc{ref-montgomery2018}{Montgomery \emph{et al.} 2018}).

For example, I was part of an international team that administered
questionnaires about religious identification following randomisation in
a cross-cultural study investigating the source-credibility of religious
and scientific authority (\citeproc{ref-hoogeveen2022einstein}{Hoogeveen
\emph{et al.} 2022}). This approach might have attenuated effect
modification by religiosity. Causal inference methods have significant
potential to enhance the design, analysis, and interpretation of
experimental research, including my own work.

\newpage{}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or the
decision to publish it.

\newpage{}

\subsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-bulbulia2024swigstime}
Bulbulia, JosephA (2024 (in press)a) Methods in causal inference part 2:
Interaction, mediation, and time-varying treatments. \emph{Evolutionary
Human Sciences}, \textbf{6}.

\bibitem[\citeproctext]{ref-bulbulia2024wierd}
Bulbulia, JosephA (2024 (in press)b) Methods in causal inference part 3:
Measurement error and external validity threats. \emph{Evolutionary
Human Sciences}, \textbf{6}.

\bibitem[\citeproctext]{ref-cole2010}
Cole, SR, Platt, RW, Schisterman, EF, \ldots{} Poole, C (2010)
Illustrating bias due to conditioning on a collider. \emph{International
Journal of Epidemiology}, \textbf{39}(2), 417--420.
doi:\href{https://doi.org/10.1093/ije/dyp334}{10.1093/ije/dyp334}.

\bibitem[\citeproctext]{ref-diaz2023lmtp}
D√≠az, I, Williams, N, Hoffman, KL, and Schenck, EJ (2023) Nonparametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association},
\textbf{118}(542), 846--857.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-diaz2021nonparametric}
Dƒ±ÃÅaz, I, Hejazi, NS, Rudolph, KE, and Der Laan, MJ van (2021)
Nonparametric efficient causal mediation with intermediate confounders.
\emph{Biometrika}, \textbf{108}(3), 627--641.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernuxe1n2004}
Hern√°n, MA (2004) A definition of causal effect for epidemiological
research. \emph{Journal of Epidemiology \& Community Health},
\textbf{58}(4), 265--271.
doi:\href{https://doi.org/10.1136/jech.2002.006361}{10.1136/jech.2002.006361}.

\bibitem[\citeproctext]{ref-hernan2017per}
Hern√°n, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and D√≠az, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoogeveen2022einstein}
Hoogeveen, S, Haaf, JM, Bulbulia, JA, et al.others (2022) The einstein
effect provides global evidence for scientific source credibility
effects and the influence of religiosity. \emph{Nature Human Behaviour},
\textbf{6}(4), 523--535.

\bibitem[\citeproctext]{ref-lash2009applying}
Lash, TL, Fox, MP, and Fink, AK (2009) \emph{Applying quantitative bias
analysis to epidemiologic data}, Springer.

\bibitem[\citeproctext]{ref-lin2012regressexperiments}
Lin, W (2013) {Agnostic notes on regression adjustments to experimental
data: Reexamining Freedman's critique}. \emph{The Annals of Applied
Statistics}, \textbf{7}(1), 295--318.
doi:\href{https://doi.org/10.1214/12-AOAS583}{10.1214/12-AOAS583}.

\bibitem[\citeproctext]{ref-linden2020EVALUE}
Linden, A, Mathur, MB, and VanderWeele, TJ (2020) Conducting sensitivity
analysis for unmeasured confounding in observational studies using
e-values: The evalue package. \emph{The Stata Journal}, \textbf{20}(1),
162--175.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in {R} and {S}tan}, CRC press.

\bibitem[\citeproctext]{ref-montgomery2018}
Montgomery, JM, Nyhan, B, and Torres, M (2018) How conditioning on
posttreatment variables can ruin your experiment and what to do about
It. \emph{American Journal of Political Science}, \textbf{62}(3),
760--775.
doi:\href{https://doi.org/10.1111/ajps.12357}{10.1111/ajps.12357}.

\bibitem[\citeproctext]{ref-pearl1995}
Pearl, J (1995) Causal diagrams for empirical research.
\emph{Biometrika}, \textbf{82}(4), 669--688.

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013) Single world intervention graphs:
A primer. In, Citeseer. Retrieved from
\url{https://core.ac.uk/display/102673558}

\bibitem[\citeproctext]{ref-robins1986}
Robins, J (1986) A new approach to causal inference in mortality studies
with a sustained exposure period---application to control of the healthy
worker survivor effect. \emph{Mathematical Modelling}, \textbf{7}(9-12),
1393--1512.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-tripepi2007}
Tripepi, G, Jager, KJ, Dekker, FW, Wanner, C, and Zoccali, C (2007)
Measures of effect: Relative risks, odds ratios, risk difference, and
{`}number needed to treat{'}. \emph{Kidney International},
\textbf{72}(7), 789--791.
doi:\href{https://doi.org/10.1038/sj.ki.5002432}{10.1038/sj.ki.5002432}.

\bibitem[\citeproctext]{ref-vanderlaan2018}
Van Der Laan, MJ, and Rose, S (2018) \emph{Targeted Learning in Data
Science: Causal Inference for Complex Longitudinal Studies}, Cham:
Springer International Publishing. Retrieved from
\url{http://link.springer.com/10.1007/978-3-319-65304-4}

\bibitem[\citeproctext]{ref-young2014identification}
Young, JG, Hern√°n, MA, and Robins, JM (2014) Identification, estimation
and approximation of risk under interventions that depend on the natural
value of treatment using observational data. \emph{Epidemiologic
Methods}, \textbf{3}(1), 1--19.

\end{CSLReferences}



\end{document}
