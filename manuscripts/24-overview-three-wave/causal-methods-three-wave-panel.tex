% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  singlecolumn]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=20mm,heightrounded]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/templates/latex/custom-commands.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={A Practical Guide to Causal Analysis in Three-Wave Panel Studies},
  pdfauthor={Joseph A. Bulbulia},
  pdfkeywords={Causal Inference, Confounding, Counterfactuals, Missing
data, Modified treatment policies},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{A Practical Guide to Causal Analysis in Three-Wave Panel Studies}
\author{Joseph A. Bulbulia}
\date{2024-02-07}

\begin{document}
\maketitle
\begin{abstract}
Causal inference from observational data poses considerable challenges.
This guide explains an approach to estimating causal effects using panel
data.

\textbf{Part 1: Pre-specification of Causal Estimands for a Target
Population} considers the first step: how to ask a causal question by
clearly pre-specifying a causal contrast for a well-defined exposure on
well-defined outcomes in the population of interest.

\textbf{Part 2: Three-Wave Panel Design} discusses the methodology for
obtaining causal effect estimates from three-wave panel studies and
discusses issues of bias from sampling, attrition/missing responses,
measurement error, and unmeasured confounding. Here we discuss methods
for avoiding these biases, which should be considered in advance of data
collection and may nevertheless be inevitable even with the best-made
plans.

\textbf{Part 3: Statistical Estimands and Estimators} describes the
process of converting observational data into consistent causal effect
estimates for the targeted causal estimands. Here we consider
conventional parametric estimators, as well as more recently developed
non-parametric and semi-parametric machine learning methods.

\textbf{Part 4: Pre-registration, Data Analysis, and Reporting}
describes the protocols for pre-registering analyses, conducting these
data analyses, and clearly and accurately communicating scientific
findings.

\textbf{Part 5: Addressing Complex Causal Questions} discusses methods
for addressing complex causal questions relating to treatment-effect
heterogeneity, causal interactions, causal mediation, and longitudinal
treatment strategies. We examine how the approaches discussed in Parts 1
- 4 may be cautiously adapted to handle these complex causal questions,
and why social scientists should tread lightly before attempting to
answer them. Overall, we hope to provide a clear, step-by-step guide
that applied researchers may use to obtain robust causal inferences
using three waves of longitudinal data.
\end{abstract}

\subsection{Introduction}\label{introduction}

\subsection{Part 1: Pre-specification of Causal Estimands for a Target
Population}\label{part-1-pre-specification-of-causal-estimands-for-a-target-population}

To answer a causal question we must first ask one
(\citeproc{ref-hernan2023}{Hernan and Robins 2023};
\citeproc{ref-hernan2017per}{Hernán \emph{et al.} 2017}).

\subsubsection{Causal identification
assumptions}\label{causal-identification-assumptions}

\subsubsection{Identification assumption 1: Causal
consistency}\label{identification-assumption-1-causal-consistency}

Causal consistency assumes the observed outcome aligns with the
potential outcome for a given exposure level:

\[Y^{observed} = AY(a=1) + (1-A)Y(a=0)\]

Observed outcomes can represent counterfactual outcomes under certain
exposures, such that:

\[
Y^{observed}_i = 
\begin{cases} 
Y_i(~a^*) & \text{if } A_i = a* \\
Y_i(~a~) & \text{if } A_i = a
\end{cases}
\]

Causal consistency also assumes no interference between unit treatments,
allowing potential outcomes to be set to the observed outcomes. For this
assumption to hold, we require ``treatment variation irrelevance.'' If
there are (1) well-defined outcomes for each treatment version, and (2)
no confounding effects, the multiple versions of treatments can be used
to estimate the causal effect:

\[K \coprod Y(k) | L\] or equivalently \[Y(k) \coprod K | L\]

Here, the treatment \(A\) is essentially a function of \(K\) treatments,
\(A = f(k_1...k_v)\) versions

Limitations exist, however, when interventions are ill-defined, or the
causal effect's interpretation is ambiguous. Put simply, given there are
unknown ways of becoming religiously disaffiliated the interpretation of
``disaffiliation'' may be strained. It is strained in the sense that we
would not know how to intervene to \emph{make} a religiously affiliated
person disaffiliate. We will return to this question in the discussion.

\paragraph{Identification assumption 2:
Exchangability}\label{identification-assumption-2-exchangability}

Exchangeability assumes treatment assignment is independent of potential
outcomes, given observed covariates. This is the ``no-confounding''
assumption that many psychologists have learned in association with
experimental design. In the setting of observational data, we emulate
randomisation by conditioning on indicators that may lead to an
association of the exposure \(A\) and the outcome \(Y\) in the absence
of causation.

\[Y(a)\coprod  A|L\] or \[A \coprod  Y(a)|L\]

Where exchangability holds, we calculate the Average Treatment Effect
(ATE)

\[
ATE = E[Y(a*)|L = l] - E[Y(a)|L = l] 
\]

Put differently, conditioning on confounders ensures \emph{balance} in
their distribution across exposures.

\paragraph{Identification assumption 3:
Positivity}\label{identification-assumption-3-positivity}

Positivity is satisfied if there is a positive probability of receiving
or not receiving exposure at all covariate levels. Expressed as:

\begin{equation}
0 < \Pr(A=a|L)<1, ~ \forall a \in A, ~ \forall a \in L
\end{equation}

There are two types of positivity violation.

\begin{itemize}
\item
  \textbf{Random non-positivity}: Occurs when the causal effect of a
  missing observation is presumed to exist. This violation is the only
  one verifiable by data. Here, we check and report it.
\item
  \textbf{Deterministic non-positivity}: Occurs when the causal effect
  is inconceivable. For example, the causal effect of hysterectomy in
  biological males violates deterministic non-positivity.
\end{itemize}

\subsubsection{Conceptual, data, and modelling
assumptions}\label{conceptual-data-and-modelling-assumptions}

We have reviewed the three fundamental assumptions of causal inference.
However, we must also consider further conceptual, data, and modelling
assumptions that, in addition to the foundational assumptions we just
reviewed, must also be satisfied to obtain valid causal inferences. We
next consider a subset of these assumptions.

\paragraph{Overly ambitious estimands}\label{overly-ambitious-estimands}

In causal inference, the Average Treatment Effect (ATE) conceived as
comparison between population-wide simulations at two levels of
exposure, \(E[Y(1)] - E[Y(0)]\), is often artificial. Artificiality is
evident for continuous exposures, where such comparisons simplify the
complexity of real-world phenomena into a low dimensional summary, such
as a contrast of a one-standard-deviation difference in the mean, or a
comparison of one quartile of exposure to another quartile of exposure.
In practice, the requirements for targeting such contrasts impose a
strong reliance on statistical models, which introduce further
opportunities for bias. Such comparisons might also strain the
positivity assumption because the relevant events occur infrequently or
are absent within the strata of covariates required to satisfy
conditional exchangeability. Moreover, because treatment effects
arebrarely linear and may not be monotonic. For this reason,
comparingbarbitrary points on a continuous scale, while relying on
correctbmodelling specifications, risks drawing erroneous
conclusionsb(\citeproc{ref-calonico2022}{Calonico \emph{et al.} 2022};
\citeproc{ref-ogburn2021}{Ogburn and Shpitser 2021}). In short, the
simplifications and modelsbrequired for obtaining standard causal
estimands often lack realism. The practical inferences that we draw from
them may be misleading (\citeproc{ref-vansteelandt2022}{Vansteelandt and
Dukes 2022}).

Furthermore, the `average treatment effect' itself might not be our
primary scientific interest. In many setting we may want to understand
heterogeneity in treatment effects without a clear understanding in
advance of modelling where such heterogeneity may be found
(\citeproc{ref-wager2018}{Wager and Athey 2018}). Presently, methods for
valid causal inference in settings of heterogeneous treatment effects
remain inchoate see: Tchetgen and VanderWeele
(\citeproc{ref-tchetgen2012}{2012}); Wager and Athey
(\citeproc{ref-wager2018}{2018}); Cui \emph{et al.}
(\citeproc{ref-cui2020}{2020}); Foster and Syrgkanis
(\citeproc{ref-foster2023}{2023}); Foster and Syrgkanis
(\citeproc{ref-foster2023}{2023}); Kennedy
(\citeproc{ref-kennedy2023}{2023}); Nie and Wager
(\citeproc{ref-nie2021}{2021}).

Recently, causal data scientists have explored new classes of estimands
and estimators, such as modified treatment policies or `shift
interventions' (\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-hoffman2023}{Hoffman \emph{et al.} 2023};
\citeproc{ref-vanderweele2018}{VanderWeele 2018};
\citeproc{ref-williams2021}{Williams and Díaz 2021}) and optimal
treatment policies (\citeproc{ref-athey2021}{Athey and Wager 2021};
\citeproc{ref-kitagawa2018}{Kitagawa and Tetenov 2018}). Such estimands
allow researchers to specify and examine a broader range of causal
contrasts, such as treating those as treating only those likely to
respond, or those who meet certain ethical criteria not determined by
statisticians, or those who optimise a pre-specified
(\citeproc{ref-cui2020}{Cui \emph{et al.} 2020};
\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-wager2018}{Wager and Athey 2018}). A review of these
promising developments would take us beyond the scope of this
discussion, however, readers should be aware that causal inference is
not bound to standard \(E[Y(1)] - E[Y(0)]\) estimands that require
simulating often implausible or even unhelpful counterfactual outcomes
for the entire population at two levels of a pre-specified intervention.

\paragraph{Target validity}\label{target-validity}

Investigators must recognise that a mismatch between the sample and
target population can invalidate causal effect estimates even if the
magnitudes are consistently estimated. If the mismatch affects
effect-modifiers of the treatment-effects there will be no guarantee
that effect-estimates for the sample will generalise to the target
population -- that is, no guarantee that the effect estimates will
achieve `target validity,' or equivalently `external validity.'
Worringly such threats cannot be fully evaluated from responses in the
restricted or censored sample (say more here)

\subsection{Part 2: A Three-Wave Panel
Design}\label{part-2-a-three-wave-panel-design}

We describe a methods for obtaining causal effect estimates from
three-wave panel studies, and discusses issues of bias from
attrition/missing responses, measurement error, unmeasured confounding.

\subsubsection{Confounding bias}\label{confounding-bias}

Say more

\subsubsection{Measurement bias}\label{measurement-bias}

Say more

\subsubsection{Restriction Bias}\label{restriction-bias}

Say more

\subsubsection{Example of a Three-Wave Panel Design for Obtaining a
Marginal Incident-Exposure
Effect}\label{example-of-a-three-wave-panel-design-for-obtaining-a-marginal-incident-exposure-effect}

Causal diagrams point the need for obtaining clearly defined time-series
data. How might we do it? Here, I sketch the outlines of a design for a
three-wave panel study that intends to estimate an \emph{incident
exposure effect}. I do not intend this advice to be more than a sketch.
However, I believe it is important to give readers a concrete example
for how data collection for causal inference might occur.

\paragraph{Step 1. Ask a causal
question}\label{step-1.-ask-a-causal-question}

In a three-wave panel design, ensuring the relative timing of events
essential for valid causal inference
(\citeproc{ref-vanderweele2020}{VanderWeele \emph{et al.} 2020}).

Here is a causal question:

What is the causal effect of attending weekly religious services
compared to not attending services on charitable giving in the
population of New Zealanders who identify as Christian?

To answer this question we must assess how changes in religious service
attendance, measured from the beginning of the year (baseline) to
mid-year (wave 1), affect levels of charitable giving at the end of the
year (wave 2) In this design, the change in religious service attendance
is captured between the first and second waves, while the outcome,
charitable giving, is measured in the third wave. This establishes a
sequential order that mirrors the cause-and-effect relationship.
Ensuring such temporal ordering is crucial in any causal analysis. Note
additionally that we must obtain comparisons from continuous data for a
binary data. Depending on the data, such a contrast might not be well
supported. For example, change between these levels might occur only
rarely, in which case our inference might rely too heavily on parametric
model specifications. Focusing on the estimand:

\subparagraph{Exposure:}\label{exposure}

\begin{itemize}
\tightlist
\item
  A = 0: Attends less than once per month
\item
  A = 1: Attends weekly
\end{itemize}

\subparagraph{Outcome:}\label{outcome}

\begin{itemize}
\tightlist
\item
  Focus: One-year effect of shifting from A = 0 to A = 1.
\item
  Charitable giving as measured by self-reported giving
\end{itemize}

\subparagraph{Scale of contrast:}\label{scale-of-contrast}

\begin{itemize}
\tightlist
\item
  ATE on the causal difference scale (per protocol).
\end{itemize}

\subparagraph{Target population:}\label{target-population}

\begin{itemize}
\tightlist
\item
  Individuals in New Zealand who might attend religious service and
  identify as Christian.
\end{itemize}

\subparagraph{Source population:}\label{source-population}

\begin{itemize}
\tightlist
\item
  National probability sample of New Zealanders (N = 34,000).
\end{itemize}

\subparagraph{Baseline population:}\label{baseline-population}

\begin{itemize}
\tightlist
\item
  Defined by eligibility criteria (including religious affiliation). If
  the baseline population differs from the target population, if sample
  weights for the distribution of covariates are available for the
  \emph{target population}, these should be applied to the baseline
  population (although with caution, given potential for model
  mis-specification, see \citeproc{ref-stuart2015}{Stuart \emph{et al.}
  2015}.)
\end{itemize}

Let \(\widehat{ATE}_{target}\) denote the population average treatment
effect for the target population. Let
\(\widehat{ATE}_{\text{restricted}}\) denote the average treatment
effect at the end of treatment. Let \(W\) denote a set of variables upon
which the restricted and target populations structurally differ. We say
that results \emph{generalise} if we can guarantee that:

\[
\widehat{ATE}_{target} =  \widehat{ATE}_{restricted} 
\]

or if there is a known function such that:

\[
ATE_{target}\approx  f_W(ATE_{\text{restricted}}, W)
\]

In most cases, \(f_W\) will be unknown, as it must account for potential
heterogeneity of effects and unobserved sources of bias. For further
discussion on this topic, see: Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018}); Bulbulia
(\citeproc{ref-bulbulia2023c}{2023b}), and \(\S 3.1.6\)

\paragraph{Step 2. Ensure that the exposure is measured at wave 0
(baseline) and wave 1 (the exposure
interval)}\label{step-2.-ensure-that-the-exposure-is-measured-at-wave-0-baseline-and-wave-1-the-exposure-interval}

Measuring the exposure at both baseline (wave 0) and the exposure
interval (wave 1) has the following benefits:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Enables estimation of incident exposure effect}: by including
  baseline observations, we can distinguish between incidence (new
  occurrences) and prevalence (existing states) exposure effects. For
  instance, in a study on religious service attendance, assessing the
  incident exposure effect allows us to differentiate the effect of
  starting to attend services regularly from the effect of ongoing
  attendance.
\item
  \textbf{Confounding control}: measuring the exposure at baseline helps
  control for time-invariant confounders. These are factors that do not
  change over time and might affect both the exposure and outcome. In
  the context of religious service attendance, personal attributes like
  inherent religiosity could influence both attendance and related
  outcomes.
\item
  \textbf{Sample adequacy}: for rare exposures, baseline measurements
  can assess sample size adequacy. If a change in exposure is infrequent
  (e.g., infrequent to weekly religious service attendance), a larger
  sample may be needed to satisfy the positivity assumption and detect
  causal effects. By measuring the exposure at baseline, we can better
  evaluate whether our sample is representative and large enough to
  detect such rare changes.
\end{enumerate}

\paragraph{Step 3. Ensure that the outcome is measured at wave 0
(baseline) and wave 2 (post-exposure wave
1)}\label{step-3.-ensure-that-the-outcome-is-measured-at-wave-0-baseline-and-wave-2-post-exposure-wave-1}

Measuring the outcome at both wave 0 (baseline) and the post-exposure
outcome wave (wave 2) offers the following advantages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Temporal ordering}: causes precede effects. We need this to
  avoid \emph{causal incoherence}. For example, ensuring order protects
  us from inadvertently estimating \(Y\rightarrowred A\).
\item
  \textbf{Confounding control}: including the baseline measure of both
  the exposure and outcome allows for better control of confounding.
  This approach helps to isolate the effect of the exposure on the
  outcome from the exposure wave (wave 1) to the outcome wave (wave 2),
  independent of their baseline levels. It reduces the risk of
  confounding, where unmeasured factors might influence both the
  exposure and the outcome, as shown in Figure~\ref{fig-dag-1}.
\end{enumerate}

\paragraph{Step 4. Measure observable common causes of the exposure and
outcome}\label{step-4.-measure-observable-common-causes-of-the-exposure-and-outcome}

Next, we must identify and record at wave 0 (baseline) all potential
confounders that could influence both the exposure (e.g., frequency of
attending religious services) and the outcome (e.g., charitable giving).
Proper identification and adjustment for these confounders are crucial
for accurate causal inference. By obtaining measures of the confounders
at baseline we:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \textbf{Minimise mediation bias}: by measuring confounders at
  baseline, it will be difficult to produce the \emph{causally
  incoherent} model: \(A_1\to \boxed{L_2} \rightarrowdotted Y_3\)
\item
  \textbf{Minimise collider bias}: by measuring confounders at baseline,
  it will be difficult to produce the \emph{causally incoherent} model:
  \(A_1\rightarrowred L_3 \leftarrowred Y_2\).
\end{enumerate}

The topic of measurement construction is vast. For now, it is worth
noting that measures should be obtained in consultation with locals and
domain experts (\citeproc{ref-vanderweele2022}{VanderWeele 2022}).

\paragraph{Step 5. Gather data for proxy variables of unmeasured common
causes at the baseline
wave}\label{step-5.-gather-data-for-proxy-variables-of-unmeasured-common-causes-at-the-baseline-wave}

If any unmeasured confounders influence both the exposure and outcome,
but we lack direct measurements, we should make efforts to include
proxies for them at baseline. Even if this strategy cannot eliminate all
bias from unmeasured confounding, it will generally reduce bias.

\paragraph{Step 6. Retain sample}\label{step-6.-retain-sample}

Censoring leads to bias. Strategies for sample retention are essential.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \textbf{Developing tracking protocols}: establish robust systems for
  tracking participants over the study period. This involves keeping
  updated records of contact information such as addresses, emails,
  phone numbers, and names, and accounting for changes in name over
  time.
\item
  \textbf{Motivate retention}: implement strategies to encourage ongoing
  participation. These incentives should ideally not lead to bias in the
  distribution of effect-modifiers that might affect the outcome of
  interest. For example, retention should not appeal to trust in science
  if trust in science is the outcome of interest.
\item
  \textbf{Investigators should avoid acting in ways that lead to
  differential retention}: for example, stay out of the news.
\end{enumerate}

\begin{figure}

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{causal-methods-three-wave-panel_files/figure-pdf/fig-dag-1-1.pdf}

}

\caption{\label{fig-dag-1}Three-wave panel design with
selection-restriction bias. Where the exposure affects attrition, and an
unmeasured confounder (U\_C=1) may affect both attrition and the
outcome, there is scope for restriction bias from censoring. Even if the
exposure does not affect censoring, if U\_C=1 leads to informative
censoring, the marginal effect in the censored may differ from the
marginal effect in the uncensored (Section 3.1.6). Note we seek
inference on the distribution of Y over C=0,1 (the target population.)
Post-treatment selection bias cannot be corrected by conditioning on
baseline co-variates. The best strategy is to minimise attrition and
non-response. However, because attrition is nearly inevitable, we apply
correction methods such as censoring weighting or multiple imputation.
These methods introduce scope for bias from model mis-specification.}

\end{figure}%

\subsection{Part 3: Statistical Estimation and
Estimators}\label{part-3-statistical-estimation-and-estimators}

We outline the process of converting observational data into consistent
causal effect estimates for the targeted causal estimands. Here we
describe the advantages and limitations of robust non-parametric and
semi-parametric machine learning methods, arguing these should be used
where sample size permits.

\subsubsection{Causal estimation}\label{causal-estimation}

Suppose we have defined our estimand. To obtain causal contrasts we
recommend using doubly robust estimation methods. These combine inverse
probability of treatment weights (propensity scores) with regression
stratification. There are two models at work in a doubly robust
estimator.

\paragraph{Parametric Doubly Robust
Estimation}\label{parametric-doubly-robust-estimation}

Combines the strengths of the IPTW and G-computation methods (see:
\href{https://go-bayes.github.io/psych-434-2023/content/09-content.html\#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study-e.g.-assessment-3-option-2}{here}.

The technique utilises both the propensity score and the outcome model,
making it ``doubly robust.'' This implies that if either of these models
is correctly specified, the estimation will not be biased.

\textbf{Step 1} The first step is to estimate the propensity score. The
propensity score, denoted as \(e(L)\), is the conditional probability of
the exposure \(A = 1\) given the covariates \(L\). The appropriate model
to estimate this can be chosen based on the nature of the data and the
exposure.

\[e = P(A = 1 | L) = f_A(L; \theta_A)\]

In this equation, \(f_A(L; \theta_A)\) is a function that estimates the
probability of the exposure \(A = 1\) given covariates \(L\). Here, we
use the \texttt{ebalance} method from the \texttt{clarify} package,
which we have found to ensure good balance on the confounders (see fig
below). We then calculate the weights for each individual, denoted as
\(v\), using the estimated propensity score:

\[
v = 
\begin{cases} 
\frac{1}{e} & \text{if } A = 1 \\
\frac{1}{1-e} & \text{if } A = 0 
\end{cases}
\]

Here, \(v\) depends on \(A\), and is calculated as the inverse of the
propensity score for exposed individuals and as the inverse of \(1-e\)
for unexposed individuals.

\textbf{Step 2} The next step involves fitting a weighted outcome model.
Using the weights computed from the estimated propensity scores, a model
for the outcome \(Y\), conditional on the exposure \(A\), is fitted.

\[ \hat{E}(Y|A, L; V) = f_Y(A, L ; \theta_Y, V) \]

In this model, \(f_Y\) is a function (in our case a weighted regression
model) with parameters \(θ_Y\). The weights \(V\) are incorporated into
the estimation process, affecting the contribution of each observation
to the estimation of \(θ_Y\), but they are not an additional variable in
the model. Additionally, following {``Agnostic notes on regression
adjustments to experimental data''} (\citeproc{ref-agnostic}{n.d.}), we
take the interaction of the exposure and baseline covariates when
estimating our regression model. For binary outcomes we model the rate
ratio using Poisson regression. Although binomial regression is
acceptable when the outcome is rare (less than 10\%), non-collapsability
leads means that we cannot interpret results as marginal causal effects.
For consistency we use the Poisson model with robust standard errors.

\textbf{Step 3} simulate the potential outcome for each individual under
the hypothetical scenario where everyone is exposed to the intervention
\(A=a\), irrespective of their actual exposure level:

\[\hat{E}(a) = \hat{E}[Y_i|A=a; L,\hat{\theta}_Y, v_i]\]

This expectation is calculated for each individual \(i\), with
individual-specific weights \(v_i\).

\textbf{Step 4} Estimate the causal effect as a contrast in averages of
the population outcomes under each intervention:

\[\hat{\delta} = \hat{E}[Y(a)] - \hat{E}[Y(a')]\]

The difference \(\delta\) represents the average causal effect of
changing the exposure from level \(a'\) to level \(a\).

For standard errors and confidence intervals, we use simulation-based
inference methods (\citeproc{ref-greifer2023}{Greifer \emph{et al.}
2023}).

\paragraph{Semi-parametric and non-parametric
estimator}\label{semi-parametric-and-non-parametric-estimator}

\paragraph{Shift functions}\label{shift-functions}

Causider a causal question in which we applying the following contrasts:

\begin{itemize}
\tightlist
\item
  The expected outcomes under each shift function defined above by the
  function \(f(A)\), and
\item
  The expected outcomes under the actual observed attendance/socalising
  patterns.
\end{itemize}

Formally, the each target is given:

\[ \Delta = E[Y(a*)|f(A),L] - E[Y(a)|A,L] \]

Where \(\Delta\) is the average treatment effect of a modified treatment
policy.

\textbf{Motiviting example: shift function as gain of weekly religious
service}: the intervention of interest is defined by a shift function
applied to the treatment variable, designed to assess the effect of
shifting the treatment on all outcomes examined in the study. The focal
estimand shift function may be formally specified as:

\[f(A) = \begin{cases} 4 & \text{if } A \leq 4  \text{ monthly religious service attendance} \\ A & \text{if } A > 4  \text{ monthly religious service attendance} \end{cases} \]

Here, we estimate outcomes in a hypothetical world in which all
individuals were attend at least four religious services per month
(weekly).

\textbf{Comparative intervention 1: shift function as loss of any
religious service}:

Because the gain of religion might be different from the loss of
religion, we additionally contrast the population average outcome were
everyone to stop attending monthly religious service verse the expected
outcome at the natural treatment values:

\[f(A) = 0 \]

Here, we estimate outcomes in a hypothetical world in which no
individuals attended religious service.

\paragraph{Survey weights}\label{survey-weights}

TBA

\paragraph{Missing responses}\label{missing-responses}

TBA

\paragraph{Inverse probabilty of censoring
weights}\label{inverse-probabilty-of-censoring-weights}

TBA

\paragraph{Example report estimator}\label{example-report-estimator}

\begin{quote}
We employ a semi-parametric estimator known as Targeted Minimum
Loss-based Estimation (TMLE), which is adept at estimating the causal
effect of modified treatment policies on outcomes over time.
Estimatation was performed using \texttt{lmtp} package
(\citeproc{ref-williams2021}{Williams and Díaz 2021}). TMLE is a robust
method that combines machine learning techniques with traditional
statistical models to estimate causal effects while providing valid
statistical uncertainty measures for these estimates.
\end{quote}

\begin{quote}
TMLE operates through a two-step process involving both outcome and
treatment (exposure) models. Initially, it employes machine learning
algorithms to flexibly model the relationship between treatments,
covariates, and outcomes. This flexibility allows TMLE to account for
complex, high-dimensional covariate spaces without imposing restrictive
model assumptions. The outcome of this step is a set of initial
estimates for these relationships.
\end{quote}

\begin{quote}
The second step of TMLE involves ``targeting'' these initial estimates
by incorporating information about the observed data distribution to
improve the accuracy of the causal effect estimate. This is achieved
through an iterative updating process, which adjusts the initial
estimates towards the true causal effect. This updating process is
guided by the efficient influence function, ensuring that the final TMLE
estimate is as close as possible to the true causal effect while still
being robust to model misspecification in either the outcome or
treatment model.
\end{quote}

\begin{quote}
A central feature of TMLE is its double-robustness property, meaning
that if either the model for the treatment or the outcome is correctly
specified, the TMLE estimator will still consistently estimate the
causal effect. Additionally, TMLE uses cross-validation to avoid
overfitting and ensure that the estimator performs well in finite
samples. Each of these steps contributes to a robust methodology for
examining the \emph{causal} effects on of interventions on outcomes. The
marriage of TMLE and machine learning technologies reduces the
dependence on restrictive modelling assumptions and introduces an
additional layer of robustness. For further details see
(\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021};
\citeproc{ref-hoffman2022}{Hoffman \emph{et al.} 2022},
\citeproc{ref-hoffman2023}{2023})
\end{quote}

\subsubsection{Example Sensitivity Analysis Using
E-values}\label{example-sensitivity-analysis-using-e-values}

\subsubsection{E-value}\label{e-value}

\begin{quote}
The minimum strength of association on the risk ratio scale that an
unmeasured confounder would need to have with both the exposure and the
outcome, conditional on the measured covariates, to fully explain away a
specific exposure-outcome association
\end{quote}

See: {[}VanderWeele \emph{et al.}
(\citeproc{ref-vanderweele2020}{2020}){]}(\citeproc{ref-mathur2018a}{\textbf{mathur2018a?}})

For example, suppose that the lower bound of the the E-value was 1.3
with the lower bound of the confidence interval = 1.12, we might then
write:

\begin{quote}
With an observed risk ratio of RR=1.3, an unmeasured confounder that was
associated with both the outcome and the exposure by a risk ratio of
1.3-fold each (or 30\%), above and beyond the measured confounders,
could explain away the estimate, but weaker joint confounder
associations could not; to move the confidence interval to include the
null, an unmeasured confounder that was associated with the outcome and
the exposure by a risk ratio of 1.12-fold (or 12\%) each could do so,
but weaker joint confounder associations could not.
\end{quote}

The equations are as follows (for risk ratios)

\[
E-value_{RR} = RR + \sqrt{RR \times (RR - 1)}
\] \[
E-value_{LCL} = LCL + \sqrt{LCL \times (LCL - 1)}
\]

Here is an R function that will calculate E-values

\begin{verbatim}
$e_value_rr
[1] 20.94777

$e_value_lcl
[1] 15.52336
\end{verbatim}

Using VanderWeele's recommended reporting language, we may write:

\begin{quote}
``With an observed risk ratio of RR=10.7, an unmeasured confounder that
was associated with both the outcome and the exposure by a risk ratio of
20.9-fold each, above and beyond the measured confounders, could explain
away the estimate, but weaker joint confounder associations could not;
to move the confidence interval to include the null, an unmeasured
confounder that was associated with the outcome and the exposure by a
risk ratio of 15.5-fold each could do so, but weaker joint confounder
associations could not.''
\end{quote}

Note that in this class, most of the outcomes will be (standardised)
continuous outcomes. Here's a function and LaTeX code to describe the
approximation.

This function takes a linear regression coefficient estimate
(\texttt{est}), its standard error (\texttt{se}), the standard deviation
of the outcome (\texttt{sd}), a contrast of interest in the exposure
(\texttt{delta}, which defaults to 1), and a ``true'' standardized mean
difference (true, which defaults to 0). It calculates the odds ratio
using the formula from (\citeproc{ref-vanderweele2017}{VanderWeele and
Ding 2017}) and Chinn (2000) and then uses this to calculate the
E-value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compute\_evalue\_ols }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(est, se, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{, }\AttributeTok{true =} \DecValTok{0}\NormalTok{) \{}
  \CommentTok{\# rescale estimate and SE to reflect a contrast of size delta}
\NormalTok{  est }\OtherTok{\textless{}{-}}\NormalTok{ est }\SpecialCharTok{/}\NormalTok{ delta}
\NormalTok{  se }\OtherTok{\textless{}{-}}\NormalTok{ se }\SpecialCharTok{/}\NormalTok{ delta}

  \CommentTok{\# compute transformed odds ratio and confidence intervals}
\NormalTok{  odds\_ratio }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est)}
\NormalTok{  lo }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est }\SpecialCharTok{{-}} \FloatTok{1.78} \SpecialCharTok{*}\NormalTok{ se)}
\NormalTok{  hi }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FloatTok{0.91} \SpecialCharTok{*}\NormalTok{ est }\SpecialCharTok{+} \FloatTok{1.78} \SpecialCharTok{*}\NormalTok{ se)}

  \CommentTok{\# compute E{-}Values based on the RR values}
\NormalTok{  evalue\_point\_estimate }\OtherTok{\textless{}{-}}\NormalTok{ odds\_ratio }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(odds\_ratio }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{  evalue\_lower\_ci }\OtherTok{\textless{}{-}}\NormalTok{ lo }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(lo }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}

  \CommentTok{\# return E{-}values}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{EValue\_PointEstimate =}\NormalTok{ evalue\_point\_estimate,}
              \AttributeTok{EValue\_LowerCI =}\NormalTok{ evalue\_lower\_ci))}
\NormalTok{\}}

\CommentTok{\# e.g stimate of 0.5, a standard error of 0.1, and a standard deviation of 1.}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{compute\_evalue\_ols}\NormalTok{(}\AttributeTok{est =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{se =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{)}
\FunctionTok{print}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$EValue_PointEstimate
[1] 2.529831

$EValue_LowerCI
[1] 2.008933
\end{verbatim}

For one's report, Vanderweele suggest using the following language
without modification:

\begin{quote}
``With an observed risk ratio of RR=2.92, an unmeasured confounder that
was associated with both the outcome and the exposure by a risk ratio of
2.92-fold each, above and beyond the measured confounders, could explain
away the estimate, but weaker joint confounder associations could not;
to move the confidence interval to include the null, an unmeasured
confounder that was associated with the outcome and the exposure by a
risk ratio of 2.23-fold each could do so, but weaker joint confounder
associations could not.''
\end{quote}

Note the E-values package will do the computational work for us. It
returns very similar values as the explicit function. We recommend using
the E-value package

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load package}
\FunctionTok{library}\NormalTok{(EValue)}

\NormalTok{EValue}\SpecialCharTok{::}\FunctionTok{evalues.OLS}\NormalTok{( }\AttributeTok{est =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{se =} \FloatTok{0.1}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{, }\AttributeTok{delta =} \DecValTok{1}\NormalTok{, }\AttributeTok{true =} \DecValTok{0}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            point    lower    upper
RR       1.576173 1.319166 1.883252
E-values 2.529142 1.968037       NA
\end{verbatim}

\subsubsection{Part 4: Pre-registration, Data Analysis, and
Reporting}\label{part-4-pre-registration-data-analysis-and-reporting}

We describe the protocols for pre-registrating analysis, conducting
these data analyses, and clearly and accurately communicating scientific
findings.

\subsubsection{Optional strategies for conveying
results}\label{optional-strategies-for-conveying-results}

\paragraph{Report results of a cross-sectional
model}\label{report-results-of-a-cross-sectional-model}

Explain causal effect estimates

\paragraph{Contrast condition}\label{contrast-condition}

Tread carefully

\subsubsection{Part 5: Addressing complex causal
questions}\label{part-5-addressing-complex-causal-questions}

We discuss methods for addressing more complex causal questions than
average treatment effect estimation, including investigating
treatment-effect heterogeneity, causal interactions, causal mediation,
and longitudinal treatment strategies.

For further discussions of our approach, see:
(\citeproc{ref-bulbulia2022}{Bulbulia 2022};
\citeproc{ref-bulbulia2023a}{Bulbulia \emph{et al.} 2023};
\citeproc{ref-bulbulia2023}{Bulbulia 2023a};
\citeproc{ref-hernan2023}{Hernan and Robins 2023};
\citeproc{ref-vanderweele2015}{VanderWeele 2015}))

\subsubsection{Example transition
matrix}\label{example-transition-matrix}

Table~\ref{tbl-transition-socialising} shows a transition matrix
captures the movement between weekly hours socialising during the
baseline (NZAVS time 10) wave and exposure wave (NZAVS time 11). Entries
on the diagonal (in bold) indicate the number of individuals who stayed
in their initial state. In contrast, the off-diagonal shows the
transitions from the initial state (bold) to another state the following
wave (off diagnal). Again, a cell located at the intersection of row
\(i\) and column \(j\), where \(i \neq j\), shows the count of
individuals moving from state \(i\) to state \(j\).

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}
  >{\centering\arraybackslash}p{(\columnwidth - 18\tabcolsep) * \real{0.1000}}@{}}
\caption{Transition matrix for change in the square of hours socialing
with community each
week}\label{tbl-transition-socialising}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
From
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 0
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 6
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 7
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 8
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
From
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 0
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 6
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 7
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
State 8
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
State 0 & \textbf{20039} & 2243 & 1192 & 221 & 25 & 12 & 7 & 3 & 6 \\
State 1 & 2288 & \textbf{1389} & 731 & 103 & 11 & 4 & 3 & 0 & 0 \\
State 2 & 1328 & 660 & \textbf{806} & 161 & 29 & 6 & 2 & 1 & 2 \\
State 3 & 236 & 101 & 151 & \textbf{76} & 17 & 5 & 1 & 0 & 0 \\
State 4 & 55 & 16 & 32 & 17 & \textbf{11} & 3 & 1 & 2 & 0 \\
State 5 & 16 & 5 & 8 & 4 & 3 & \textbf{0} & 1 & 0 & 0 \\
State 6 & 8 & 1 & 0 & 0 & 1 & 0 & \textbf{0} & 0 & 1 \\
State 7 & 3 & 1 & 1 & 1 & 0 & 0 & 0 & \textbf{0} & 0 \\
State 8 & 3 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & \textbf{1} \\
\end{longtable}

Table~\ref{tbl-transition-socialising} presents a summary of changes in
socialising at the threshold that we compared. When shifting to
socialising at least 1.4 hours per week, we imagine `treating' 25,959
cases. Again this table is for illustration, as the the shift
intervention allows us to flexibly contrast cases without projecting the
entire population in to one or another cell.

\begin{longtable}[]{@{}ccc@{}}
\caption{Transition matrix for change in the square of hours socialing
with community each
week}\label{tbl-transition-socialising-shift}\tabularnewline
\toprule\noalign{}
From & \textless{} 1.4 weekly hours & \textgreater= 1.4 weekly hours \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
From & \textless{} 1.4 weekly hours & \textgreater= 1.4 weekly hours \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textless{} 1.4 weekly hours & \textbf{25959} & 2318 \\
\textgreater= 1.4 weekly hours & 2434 & \textbf{1347} \\
\end{longtable}

\subsubsection{Example report of
estimator}\label{example-report-of-estimator}

\textbf{Treatment Model}: in the context of causal inference, a
treatment model estimates the likelihood of receiving the
treatment---here, pet ownership---based on observed characteristics
(covariates). In ordinary regression, this would be akin to the
predictor variables in the model, but modelling the treatment, in this
case pet ownership.

\textbf{Outcome Model}: this estimates the potential outcomes of
interest, here, measures of well-being, conditional on treatment status
and other covariates. In traditional regression settings, this model is
what you typically fit to understand how predictors influence the
outcome.

By using TMLE to combine both a treatment and outcome model, we can
better identify the specific effect of pet ownership on
multi-dimensional well-being. Here are the steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Treatment model with propensity scores}: the initial phase of
  our analysis consists of generating propensity scores for the exposure
  for each participant. These scores quantify the probability of an
  individual having the treatment, conditional on their set of
  covariates. The scores emerge from a targeted machine learning model
  that accounts for high-dimensional confounders to estimate treatment
  assignment probabilities, namely pet ownership. \textbf{In plain
  terms,} we first calculate a score for each person that indicates how
  likely they are to experience the treatment based on various
  characteristics.This step is like determining each person's chances of
  having the treatment, given their particular life circumstances.
\item
  \textbf{Weighting via propensity scores}: upon computing the
  propensity scores, we assign an inverse probability weight to each
  dataset entry. These weights serve to equilibrate the distribution of
  observed covariates between the treated and untreated cohorts, thus
  attenuating the bias in the causal estimates. \textbf{In plain terms,}
  we use propensity scores to make the contrasts groups more comparable
  in a manner that emulates randomisation in experiments.
\item
  \textbf{Outcome models}: a second targeted machine learning model
  focuses on the outcome variables, encompassing multiple measures of
  the outcome distributed across different domains of interest. This
  model incorporates both the individual treatment statuses and the
  previously calculated weights, enhancing our capacity for causal
  inference. \textbf{In plain terms} we create a model that tries to
  predict well-being levels based on whether experiences the treatment
  under consideration, while also considering conditional on covarites.
\item
  **Doubly robust estimation*: Combines the treatment and outcome model
  to obtain robust results: only one of the two models needs to be
  correctly specified.
\item
  \textbf{Counterfactual contrasts}: a core component of TMLE is the
  projection of counterfactual outcomes. By combining estimates from the
  treatment and outcome models, TMLE enables the computation of
  potential well-being levels for each individual under dual treatment
  conditions---both with and without pet ownership. \textbf{In plain
  terms:} we use the models to estimate what someone's well-being would
  likely be in both scenarios: owning a pet and not owning one. Note
  that our shift estimand, described below, helps to make the
  assumptions required for such contrasts more credible. We will
  contrast the average population outcome if all were to own pets with
  the naturally occurring from the distribution of pet ownership in the
  treatment year (NZAVS wave 2019)
\item
  \textbf{Effect estimation}: the final analytical stage involves
  determining the average treatment effect by contrasting the estimated
  counterfactual outcomes.
\end{enumerate}

\subsection{Conclusions: Summary of
Advice}\label{conclusions-summary-of-advice}

\subsubsection{Overview of the steps}\label{overview-of-the-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Clarify the causal question:} prior to any analysis, it is
  crucial to explicitly define the causal question under examination.
\end{enumerate}

Suppose we wish to investigate the causal effect of religious-service
attendance on cooperation. As yet, there is no causal question. Within
the umbrella term of ``religious service attendance'' multiple scenarios
can be considered: attending religious service weekly service; attending
some religious service from a baseline of no attendance; losing
religious service attendance and others.

A clearly defined question might contrast might be: ``What is the
expected causal effect of attending religious service at least weekly
among those who do not attend weekly, contrasted with natural
expectation were no intervation to occur?'' (Note: this is a ``shift
intervention.'')

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Clearly define the target population}: for whom do we intend
  the results to generalise? For example, we might retrict our question
  to the population of people who identify as religious. Where relevant,
  survey weights should always be collected and used to obtain valid
  estimates for target population outcomes.
\item
  \textbf{Clearly state eligibility criteria.}: state
  inclusion/exclusion criteria to obtain valid causal estimates. Note
  that these criteria always relate to a target population.
\item
  \textbf{Ensure correct temporal order in the variables in ones data}:
  causality occurs in time. Confounders occur before exposures, which in
  turn must occur before the outcome.
\item
  \textbf{Balance confounders}: once the temporal structure is set, we
  may adjust for confounders that could distort the causal link between
  exposure and outcome.
\item
  \textbf{Include of baseline measures of the treatment and outcome}:
  with at least three waves of data, we should include baseline measures
  for both the treatment and the outcomes. This strategy serves two
  objectives: first, it augments control for confounding variables, and
  second, it permits differentiation between ``incidence'' and
  ``prevalence'' effects. \emph{Incidence effects} capture the emergence
  of new cases or conditions among individuals who acquire pets during
  the study. This facilitates an evaluation of the causal impact of pet
  adoption on well-being among those who were not pet owners at the
  baseline.
\item
  \textbf{Adjust for missing data}: we generally recommend using inverse
  probability of censoring weights which may carry fewer assumptions
  that multiply imputing missing values.
\item
  \textbf{Assess multiple dimensions of the outcome within the same
  study}: where scientificallly relevant, we recommend using an
  outcomewide approach (\citeproc{ref-vanderweele2020}{VanderWeele
  \emph{et al.} 2020}) to assess multiple outcomes within a single
  study. This approach has several benefits.
\end{enumerate}

First we obtain \emph{contextualised effects}: each outcome is evaluated
in context relative to the others. This facilitates a better
understanding of the importance of each individual effect within the
overarching construct of well-being.

Second, we \emph{mitigate} of spurious findings: by assessing multiple
outcomes simultaneously, we minimise the risk of cherry-picking cases
that confirm a preconceived hypothesis, thereby reducing the likelihood
of chance findings.

Third, we \emph{accelerate sientific understanding}: a comprehensive
assessment can fast-track our scientific insights into the potential
advantages and disadvantages of pet ownership on various aspects of
human well-being. The selection of outcomes below are based on previous
studies reflecting interest in the relationship between pet ownership
and (1) health, (2) embodied well-being and distress, (3) reflective
well-being and (4) social well-being

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\item
  \textbf{Use TMLE and machine learning}: Targeted Maximum Likelihood
  Estimation (TMLE) coupled with machine learning (the
  \texttt{SuperLearner} library in R (\citeproc{ref-polley2023}{Polley
  \emph{et al.} 2023})) has several advantages: first it reduces
  reliance on the assumption of a correctly specified model. The method
  is robust even if either the treatment model or the outcome model is
  incorrectly specified. Second, \emph{machine Learning for confounder
  balancing improves precision} further refines our ability to balance
  confounders, particularly when these are high-dimensional or interact
  in ways that cannot be known in advance
  (\citeproc{ref-duxedaz2021}{Díaz \emph{et al.} 2021}).
\item
  \textbf{Clearly state results using graphs}: it is often sensible to
  estimate effect using standardised outcomes which allows for ready
  graphical comparison. However, in some cases, effects on the data
  scale are more meaningful, in which case graphical comparisons may be
  misleading.
\item
  \textbf{Quantitatively assess robustness to unmeasured confounding}:
  report sensitivity analysis such as E-values.
\item
  \textbf{Measurement error}: note that all data, and in particular
  self-report data, may be subject to random measurement error. Given
  the limitations of self-report measures, the true effect sizes may
  differ from those estimated. Importantly, overly modest effects could
  arise, in part, from uncorrelated measurement inaccuracy in the
  treatment and outcomes.
\item
  \textbf{Generalisability and transportability}: findings should be
  interpreted within the context of the target population. Although the
  results may have broader relevance, direct extrapolation to different
  populations or sociocultural settings should only be undertaken
  cautiously
\end{enumerate}

14 \textbf{Theoretical and practical relevance}: when describing the
relevance of the data, it can be useful to state regression coefficients
from cross-sectional data using models that do not adequately obtain
casual effect estimates. In our experience, the results of ``standard''
models will be different, sometimes considerably so. Data simulations
may also help to drive home the importance of adopting a careful causal
inference approach.

\newpage{}

\subsubsection{Ethics}\label{ethics}

The NZAVS is reviewed every three years by the University of Auckland
Human Participants Ethics Committee. Our most recent ethics approval
statement is as follows: The New Zealand Attitudes and Values Study was
approved by the University of Auckland Human Participants Ethics
Committee on 26/05/2021 for six years until 26/05/2027, Reference Number
UAHPEC22576.

\subsubsection{Acknowledgements}\label{acknowledgements}

The New Zealand Attitudes and Values Study is supported by a grant from
the TempletoReligion Trust (TRT0196; TRT0418). JB received support from
the Max Planck Institute for the Science of Human History. The funders
had no role in preparing the manuscript or the decision to publish.

\subsubsection{Author Statement}\label{author-statement}

TBA

\newpage{}

\subsection{Appendix A. Measures}\label{appendix-a.-measures}

\paragraph{Age (waves: 1-15)}\label{age-waves-1-15}

We asked participants' age in an open-ended question (``What is your
age?'' or ``What is your date of birth'').

\paragraph{Disability (waves: 5-15)}\label{disability-waves-5-15}

We assessed disability with a one item indicator adapted from Verbrugge
(\citeproc{ref-verbrugge1997}{1997}), that asks ``Do you have a health
condition or disability that limits you, and that has lasted for 6+
months?'' (1 = Yes, 0 = No).

\paragraph{Education Attainment (waves: 1,
4-15)}\label{education-attainment-waves-1-4-15}

Participants were asked ``What is your highest level of
qualification?''. We coded participans highest finished degree according
to the New Zealand Qualifications Authority. Ordinal-Rank 0-10 NZREG
codes (with overseas school quals coded as Level 3, and all other
ancillary categories coded as missing)
See:https://www.nzqa.govt.nz/assets/Studying-in-NZ/New-Zealand-Qualification-Framework/requirements-nzqf.pdf

\paragraph{Employment (waves: 1-3,
4-11)}\label{employment-waves-1-3-4-11}

We asked participants ``Are you currently employed? (This includes
self-employed or casual work)''. * note: This question disappeared in
the updated NZAVS Technical documents (Data Dictionary).

\paragraph{European (waves: 1-15)}\label{european-waves-1-15}

Participants were asked ``Which ethnic group do you belong to (NZ census
question)?'' or ``Which ethnic group(s) do you belong to? (Open-ended)''
(wave: 3). Europeans were coded as 1, whereas other ethnicities were
coded as 0.

\paragraph{Ethnicity (waves: 3)}\label{ethnicity-waves-3}

Based on the New Zealand Cencus, we asked participants ``Which ethnic
group(s) do you belong to?''. The responses were: (1) New Zealand
European; (2) Māori; (3) Samoan; (4) Cook Island Māori; (5) Tongan; (6)
Niuean; (7) Chinese; (8) Indian; (9) Other such as DUTCH, JAPANESE,
TOKELAUAN. Please state:. We coded their answers into four groups:
Maori, Pacific, Asian, and Euro (except for Time 3, which used an
open-ended measure).

\paragraph{Gender (waves: 1-15)}\label{gender-waves-1-15}

We asked participants' gender in an open-ended question: ``what is your
gender?'' or ``Are you male or female?'' (waves: 1-5). Female was coded
as 0, Male was coded as 1, and gender diverse coded as 3
(\citeproc{ref-fraser_coding_2020}{Fraser \emph{et al.} 2020}). (or 0.5
= neither female nor male)

\paragraph{Income (waves: 1-3, 4-15)}\label{income-waves-1-3-4-15}

Participants were asked ``Please estimate your total household income
(before tax) for the year XXXX''. To stablise this indicator, we first
took the natural log of the response + 1, and then centred and
standardised the log-transformed indicator.

\paragraph{Number of Children (waves: 1-3,
4-15)}\label{number-of-children-waves-1-3-4-15}

We measured number of children using one item from Bulbulia
(\citeproc{ref-Bulbulia_2015}{2015}). We asked participants ``How many
children have you given birth to, fathered, or adopted. How many
children have you given birth to, fathered, or adopted?'' or ````How
many children have you given birth to, fathered, or adopted. How many
children have you given birth to, fathered, and/or parented?'' (waves:
12-15).

\paragraph{Political Orientation}\label{political-orientation}

We measured participants' political orientation using a single item
adapted from Jost (\citeproc{ref-jost_end_2006-1}{2006}).

``Please rate how politically liberal versus conservative you see
yourself as being.''

(1 = Extremely Liberal to 7 = Extremely Conservative)

\paragraph{NZSEI-13 (waves: 8-15)}\label{nzsei-13-waves-8-15}

We assessed occupational prestige and status using the New Zealand
Socio-economic Index 13 (NZSEI-13) (\citeproc{ref-fahy2017}{Fahy
\emph{et al.} 2017}). This index uses the income, age, and education of
a reference group, in this case the 2013 New Zealand census, to
calculate an score for each occupational group. Scores range from 10
(Lowest) to 90 (Highest). This list of index scores for occupational
groups was used to assign each participant a NZSEI-13 score based on
their occupation.

Participants were asked ``If you are a parent, what is the birth date of
your eldest child?''.

\paragraph{Living with Partner}\label{living-with-partner}

Participants were asekd ``Do you live with your partner?'' (1 = Yes, 0 =
No).

\paragraph{Living in an Urban Area (waves:
1-15)}\label{living-in-an-urban-area-waves-1-15}

We coded whether they are living in an urban or rural area (1 = Urban, 0
= Rural) based on the addresses provided.

We coded whether they are living in an urban or rural area (1 = Urban, 0
= Rural) based on the addresses provided.

\paragraph{NZ Deprivation Index (waves:
1-15)}\label{nz-deprivation-index-waves-1-15}

We used the NZ Deprivation Index to assign each participant a score
based on where they live (\citeproc{ref-atkinson2019}{Atkinson \emph{et
al.} 2019}). This score combines data such as income, home ownership,
employment, qualifications, family structure, housing, and access to
transport and communication for an area into one deprivation score.

\paragraph{NZ-Born (waves: 1-2,4-15)}\label{nz-born-waves-1-24-15}

We asked participants ``Which country were you born in?'' or ``Where
were you born? (please be specific, e.g., which town/city?)'' (waves:
6-15).

\paragraph{Mini-IPIP 6 (waves:
1-3,4-15)}\label{mini-ipip-6-waves-1-34-15}

We measured participants personality with the Mini International
Personality Item Pool 6 (Mini-IPIP6) (\citeproc{ref-sibley2011}{Sibley
\emph{et al.} 2011}) which consists of six dimensions and each
dimensions is measured with four items:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  agreeableness,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I sympathize with others' feelings.
  \item
    I am not interested in other people's problems. (r)
  \item
    I feel others' emotions.
  \item
    I am not really interested in others. (r)
  \end{enumerate}
\item
  conscientiousness,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I get chores done right away.
  \item
    I like order.
  \item
    I make a mess of things. (r)
  \item
    I ften forget to put things back in their proper place. (r)
  \end{enumerate}
\item
  extraversion,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I am the life of the party.
  \item
    I don't talk a lot. (r)
  \item
    I keep in the background. (r)
  \item
    I talk to a lot of different people at parties.
  \end{enumerate}
\item
  honesty-humility,

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I feel entitled to more of everything. (r)
  \item
    I deserve more things in life. (r)
  \item
    I would like to be seen driving around in a very expensive car. (r)
  \item
    I would get a lot of pleasure from owning expensive luxury goods.
    (r)
  \end{enumerate}
\item
  neuroticism, and

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I have frequent mood swings.
  \item
    I am relaxed most of the time. (r)
  \item
    I get upset easily.
  \item
    I seldom feel blue. (r)
  \end{enumerate}
\item
  openness to experience

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    I have a vivid imagination.
  \item
    I have difficulty understanding abstract ideas. (r)
  \item
    I do not have a good imagination. (r)
  \item
    I am not interested in abstract ideas. (r)
  \end{enumerate}
\end{enumerate}

Each dimension was assessed with four items and participants rated the
accuracy of each item as it applies to them from 1 (Very Inaccurate) to
7 (Very Accurate). Items marked with (r) are reverse coded.

\paragraph{Honesty-Humility-Modesty Facet (waves:
10-14)}\label{honesty-humility-modesty-facet-waves-10-14}

Participants indicated the extent to which they agree with the following
four statements from Campbell \emph{et al.}
(\citeproc{ref-campbell2004}{2004}) , and Sibley \emph{et al.}
(\citeproc{ref-sibley2011}{2011}) (1 = Strongly Disagree to 7 = Strongly
Agree)

\begin{verbatim}
i.  I want people to know that I am an important person of high status, (Waves: 1, 10-14)
ii. I am an ordinary person who is no better than others.
iii. I wouldn't want people to treat me as though I were superior to them.
iv. I think that I am entitled to more respect than the average person is.
\end{verbatim}

\subsubsection{Exposure variable}\label{exposure-variable}

HERE

\subsubsection{Health well-being
outcomes}\label{health-well-being-outcomes}

\subsubsection{Appendix B. Descriptive
Statistics}\label{appendix-b.-descriptive-statistics}

\subsubsection{Appendix D. Population Average Treatment
Effect}\label{appendix-d.-population-average-treatment-effect}

As indicated in the main manuscript, the Average Treatment Effects is
obtained by contrasting the expected outcome when a population sampled
is exposed to an exposure level, \(E[Y(A = a)]\), with the expected
outcome under a different exposure level, \(E[Y(A=a')]\).

For a binary treatment with levels \(A=0\) and \(A=1\), the Average
Treatment Effect (ATE), on the difference scale, is expressed:

\[ATE_{\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]\]

On the risk ratio scale, the ATE is expressed:

\[ATE_{\text{risk ratio}} = \frac{E[Y(1)|L]}{E[Y(0)|L]}\]

Other effect scales, such as the incidence rate ratio, incidence rate
difference, or hazard ratio, might also be of interest.

Here we estimate the Population Average Treatment Effect (PATE), which
denotes the effect the treatment would have on the New Population if
applied universally. This quantity can be expressed:

\[PATE_{\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)\]

\[PATE_{\text{risk ratio}} = f\left(\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\right)\]

where \(f\) is a function that incorporates post-stratification weights
\(W\) into the estimation of the expected outcomes from which we obtain
causal contrasts. Because the NZAVS is national probability sample,
i.e.~inverse probability of being sampled 1. However, to incorporate
gender, age, and ethnic differences we include post-stratification
weight into our outcome wide models.

\newpage{}

\subsection*{References}\label{references}
\addcontentsline{toc}{subsection}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-agnostic}
Agnostic notes on regression adjustments to experimental data:
Reexamining freedman{'}s critique (n.d.). Retrieved from
\url{https://projecteuclid.org/journals/annals-of-applied-statistics/volume-7/issue-1/Agnostic-notes-on-regression-adjustments-to-experimental-data--Reexamining/10.1214/12-AOAS583.full}

\bibitem[\citeproctext]{ref-athey2021}
Athey, S, and Wager, S (2021) Policy Learning With Observational Data.
\emph{Econometrica}, \textbf{89}(1), 133--161.
doi:\href{https://doi.org/10.3982/ECTA15732}{10.3982/ECTA15732}.

\bibitem[\citeproctext]{ref-atkinson2019}
Atkinson, J, Salmond, C, and Crampton, P (2019) \emph{NZDep2018 index of
deprivation, user{'}s manual.}, Wellington.

\bibitem[\citeproctext]{ref-bulbulia2022}
Bulbulia, JA (2022) A workflow for causal inference in cross-cultural
psychology. \emph{Religion, Brain \& Behavior}, \textbf{0}(0), 1--16.
doi:\href{https://doi.org/10.1080/2153599X.2022.2070245}{10.1080/2153599X.2022.2070245}.

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023a) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-bulbulia2023c}
Bulbulia, JA (2023b) Selection bias (with and without confounding)
explained with sequential causal diagrams. Retrieved from
\url{https://osf.io/cjgey}

\bibitem[\citeproctext]{ref-bulbulia2023a}
Bulbulia, JA, Afzali, MU, Yogeeswaran, K, and Sibley, CG (2023)
Long-term causal effects of far-right terrorism in {N}ew {Z}ealand.
\emph{PNAS Nexus}, \textbf{2}(8), pgad242.

\bibitem[\citeproctext]{ref-Bulbulia_2015}
Bulbulia, S, J. A. (2015) Religion and parental cooperation: An
empirical test of slone's sexual signaling model. In \&. V. S. J. Slone
D., ed., \emph{The attraction of religion: A sexual selectionist
account}, Bloomsbury Press, 29--62.

\bibitem[\citeproctext]{ref-calonico2022}
Calonico, S, Cattaneo, MD, Farrell, MH, and Titiunik, R (2022)
\emph{Rdrobust: Robust data-driven statistical inference in
regression-discontinuity designs}. Retrieved from
\url{https://CRAN.R-project.org/package=rdrobust}

\bibitem[\citeproctext]{ref-campbell2004}
Campbell, WK, Bonacci, AM, Shelton, J, Exline, JJ, and Bushman, BJ
(2004) Psychological entitlement: interpersonal consequences and
validation of a self-report measure. \emph{Journal of Personality
Assessment}, \textbf{83}(1), 29--45.
doi:\href{https://doi.org/10.1207/s15327752jpa8301_04}{10.1207/s15327752jpa8301\_04}.

\bibitem[\citeproctext]{ref-cole2010generalizing}
Cole, SR, and Stuart, EA (2010) Generalizing evidence from randomized
clinical trials to target populations: The ACTG 320 trial.
\emph{American Journal of Epidemiology}, \textbf{172}(1), 107--115.

\bibitem[\citeproctext]{ref-cui2020}
Cui, Y, Kosorok, MR, Sverdrup, E, Wager, S, and Zhu, R (2020) Estimating
heterogeneous treatment effects with right-censored data via causal
survival forests. Retrieved from
\url{https://arxiv.org/abs/2001.09887v5}

\bibitem[\citeproctext]{ref-duxedaz2021}
Díaz, I, Williams, N, Hoffman, KL, and Schenck, EJ (2021) Non-parametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association}.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-fahy2017}
Fahy, KM, Lee, A, and Milne, BJ (2017) \emph{New Zealand socio-economic
index 2013}, Wellington, New Zealand: Statistics New Zealand-Tatauranga
Aotearoa.

\bibitem[\citeproctext]{ref-foster2023}
Foster, DJ, and Syrgkanis, V (2023) Orthogonal statistical learning.
\emph{The Annals of Statistics}, \textbf{51}(3), 879--908.
doi:\href{https://doi.org/10.1214/23-AOS2258}{10.1214/23-AOS2258}.

\bibitem[\citeproctext]{ref-fraser_coding_2020}
Fraser, G, Bulbulia, J, Greaves, LM, Wilson, MS, and Sibley, CG (2020)
Coding responses to an open-ended gender measure in a new zealand
national sample. \emph{The Journal of Sex Research}, \textbf{57}(8),
979--986.
doi:\href{https://doi.org/10.1080/00224499.2019.1687640}{10.1080/00224499.2019.1687640}.

\bibitem[\citeproctext]{ref-greifer2023}
Greifer, N, Worthington, S, Iacus, S, and King, G (2023) \emph{Clarify:
Simulation-based inference for regression models}. Retrieved from
\url{https://iqss.github.io/clarify/}

\bibitem[\citeproctext]{ref-hernan2023}
Hernan, MA, and Robins, JM (2023) \emph{Causal inference}, Taylor \&
Francis. Retrieved from
\url{https://books.google.co.nz/books?id=/_KnHIAAACAAJ}

\bibitem[\citeproctext]{ref-hernan2017per}
Hernán, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and Díaz, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoffman2022}
Hoffman, KL, Schenck, EJ, Satlin, MJ, \ldots{} Díaz, I (2022) Comparison
of a target trial emulation framework vs cox regression to estimate the
association of corticosteroids with COVID-19 mortality. \emph{JAMA
Network Open}, \textbf{5}(10), e2234425.
doi:\href{https://doi.org/10.1001/jamanetworkopen.2022.34425}{10.1001/jamanetworkopen.2022.34425}.

\bibitem[\citeproctext]{ref-imai2008misunderstandings}
Imai, K, King, G, and Stuart, EA (2008) Misunderstandings between
experimentalists and observationalists about causal inference.
\emph{Journal of the Royal Statistical Society Series A: Statistics in
Society}, \textbf{171}(2), 481--502.

\bibitem[\citeproctext]{ref-jost_end_2006-1}
Jost, JT (2006) The end of the end of ideology. \emph{American
Psychologist}, \textbf{61}(7), 651--670.
doi:\href{https://doi.org/10.1037/0003-066X.61.7.651}{10.1037/0003-066X.61.7.651}.

\bibitem[\citeproctext]{ref-kennedy2023}
Kennedy, EH (2023) Towards optimal doubly robust estimation of
heterogeneous causal effects. \emph{Electronic Journal of Statistics},
\textbf{17}(2), 3008--3049.
doi:\href{https://doi.org/10.1214/23-EJS2157}{10.1214/23-EJS2157}.

\bibitem[\citeproctext]{ref-kitagawa2018}
Kitagawa, T, and Tetenov, A (2018) Who should be treated? Empirical
welfare maximization methods for treatment choice. \emph{Econometrica},
\textbf{86}(2), 591--616. Retrieved from
\url{https://www.jstor.org/stable/44955978}

\bibitem[\citeproctext]{ref-nie2021}
Nie, X, and Wager, S (2021) Quasi-oracle estimation of heterogeneous
treatment effects. \emph{Biometrika}, \textbf{108}(2), 299--319.
doi:\href{https://doi.org/10.1093/biomet/asaa076}{10.1093/biomet/asaa076}.

\bibitem[\citeproctext]{ref-ogburn2021}
Ogburn, EL, and Shpitser, I (2021) Causal modelling: The two cultures.
\emph{Observational Studies}, \textbf{7}(1), 179--183.
doi:\href{https://doi.org/10.1353/obs.2021.0006}{10.1353/obs.2021.0006}.

\bibitem[\citeproctext]{ref-polley2023}
Polley, E, LeDell, E, Kennedy, C, and Laan, M van der (2023)
\emph{SuperLearner: Super learner prediction}. Retrieved from
\url{https://CRAN.R-project.org/package=SuperLearner}

\bibitem[\citeproctext]{ref-sibley2011}
Sibley, CG, Luyten, N, Purnomo, M, \ldots{} Robertson, A (2011) The
Mini-IPIP6: Validation and extension of a short measure of the Big-Six
factors of personality in New Zealand. \emph{New Zealand Journal of
Psychology}, \textbf{40}(3), 142--159.

\bibitem[\citeproctext]{ref-stuart2018generalizability}
Stuart, EA, Ackerman, B, and Westreich, D (2018) Generalizability of
randomized trial results to target populations: Design and analysis
possibilities. \emph{Research on Social Work Practice}, \textbf{28}(5),
532--537.

\bibitem[\citeproctext]{ref-stuart2015}
Stuart, EA, Bradshaw, CP, and Leaf, PJ (2015) Assessing the
Generalizability of Randomized Trial Results to Target Populations.
\emph{Prevention Science}, \textbf{16}(3), 475--485.
doi:\href{https://doi.org/10.1007/s11121-014-0513-z}{10.1007/s11121-014-0513-z}.

\bibitem[\citeproctext]{ref-tchetgen2012}
Tchetgen, EJT, and VanderWeele, TJ (2012) On causal inference in the
presence of interference. \emph{Statistical Methods in Medical
Research}, \textbf{21}(1), 5575.

\bibitem[\citeproctext]{ref-vanderweele2015}
VanderWeele, TJ (2015) \emph{Explanation in causal inference: Methods
for mediation and interaction}, Oxford University Press.

\bibitem[\citeproctext]{ref-vanderweele2018}
VanderWeele, TJ (2018) On well-defined hypothetical interventions in the
potential outcomes framework. \emph{Epidemiology}, \textbf{29}(4), e24.
doi:\href{https://doi.org/10.1097/EDE.0000000000000823}{10.1097/EDE.0000000000000823}.

\bibitem[\citeproctext]{ref-vanderweele2022}
VanderWeele, TJ (2022) Constructed measures and causal inference:
Towards a new model of measurement for psychosocial constructs.
\emph{Epidemiology}, \textbf{33}(1), 141.
doi:\href{https://doi.org/10.1097/EDE.0000000000001434}{10.1097/EDE.0000000000001434}.

\bibitem[\citeproctext]{ref-vanderweele2017}
VanderWeele, TJ, and Ding, P (2017) Sensitivity analysis in
observational research: Introducing the e-value. \emph{Annals of
Internal Medicine}, \textbf{167}(4), 268--274.
doi:\href{https://doi.org/10.7326/M16-2607}{10.7326/M16-2607}.

\bibitem[\citeproctext]{ref-vanderweele2020}
VanderWeele, TJ, Mathur, MB, and Chen, Y (2020) Outcome-wide
longitudinal designs for causal inference: A new template for empirical
studies. \emph{Statistical Science}, \textbf{35}(3), 437466.

\bibitem[\citeproctext]{ref-vansteelandt2022}
Vansteelandt, S, and Dukes, O (2022) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657685.

\bibitem[\citeproctext]{ref-verbrugge1997}
Verbrugge, LM (1997) A global disability indicator. \emph{Journal of
Aging Studies}, \textbf{11}(4), 337--362.
doi:\href{https://doi.org/10.1016/S0890-4065(97)90026-8}{10.1016/S0890-4065(97)90026-8}.

\bibitem[\citeproctext]{ref-wager2018}
Wager, S, and Athey, S (2018) Estimation and inference of heterogeneous
treatment effects using random forests. \emph{Journal of the American
Statistical Association}, \textbf{113}(523), 1228--1242.
doi:\href{https://doi.org/10.1080/01621459.2017.1319839}{10.1080/01621459.2017.1319839}.

\bibitem[\citeproctext]{ref-williams2021}
Williams, NT, and Díaz, I (2021) \emph{Lmtp: Non-parametric causal
effects of feasible interventions based on modified treatment policies}.
doi:\href{https://doi.org/10.5281/zenodo.3874931}{10.5281/zenodo.3874931}.

\end{CSLReferences}



\end{document}
