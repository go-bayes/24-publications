% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={The Weirdest Causal Inferences in the World},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{The Weirdest Causal Inferences in the World}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-05-26}
\begin{document}
\maketitle
\begin{abstract}
The human sciences, like all sciences, should seek generalisation. For
this reason, and for ethical reasons, it is desirable to sample more
broadly than `Western, Educated, Industrialized, Rich, and Democratic'
(WEIRD) societies. However, restriction of the target population is
sometimes necessary. For example, we would not recruit young children
into studies on elderly care. Under which conditions is unrestricted
sampling desirable and undesirable? Here we use causal directed acyclic
graphs (causal DAGs) to clarify structural features of bias that recur
in measurement-error bias, censoring bias (target population restriction
at the end of a study), and source bias (target population restriction
at the start of a study). We define any study that exhibits these biases
as \textbf{weird} (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion),
clarifying why the first step in study design is to mitigate
``weirdness.'' We discuss the challenges of doing so in comparative
research.

\textbf{KEYWORDS}: \emph{Causal Inference}; \emph{Comparative};
\emph{Cross-Cultural}; \emph{DAGs}; \emph{Experiments};
\emph{Longitudinal}; \emph{Measurement Error Bias\textbf{; }Selection
Bias}; \textbf{Target Validity}, \textbf{WEIRD}
\end{abstract}

\subsection{Introduction}\label{introduction}

Human scientists ask and answer questions about humans, many of which
are causal. To ground these answers in facts, we collect data.

Most human scientists work in what Joseph Henrich, Steven Heine, and Ara
Norenzayan have termed `WEIRD' societies: `Western, Educated,
Industrialized, Rich, and Democratic Societies'
(\citeproc{ref-henrich2010weirdest}{Henrich \emph{et al.} 2010}).
Unsurprisingly, WEIRD samples are over-represented in human science
datasets (\citeproc{ref-arnett2008neglected}{Arnett 2008};
\citeproc{ref-sears1986college}{Sears 1986}). Henrich \emph{et al.}
(\citeproc{ref-henrich2010weirdest}{2010}) illustrate how WEIRD samples
differ from non-WEIRD samples in areas such as spatial cognition and
perceptions of fairness, while showing continuities in basic emotions
recognition, positive self-views, and motivation to punish antisocial
behaviour. Because science seeks generalisation wherever it can, they
urge sampling from non-WEIRD populations.

Recently, a host of institutional diversity and inclusion initiatives
have commended researchers to obtain data from global samples. The
motivation for these mission statements is ethically laudable, and the
injunction for a broader science of humanity also accords with
institutional missions. For example, the scientific mission of the
American Psychological Association (APA) is `to promote the advancement,
communication, and application of psychological science and knowledge to
benefit society and improve lives.' The APA does not state that it wants
to understand and benefit only North Atlantic Societies.\footnote{\url{https://www.apa.org/pubs/authors/equity-diversity-inclusion}}.
It is therefore tempting to use such a mission statement as an ideal by
which to evaluate the samples used in human scientific research.

Suppose we agree that promoting a globally diverse science makes ethical
sense. Does sampling from globally diverse populations always advance
this ideal? In some cases, restricting our source population makes
better scientific sense. For example, studying the psychological effects
of restorative justice among victims of violent crime in a population
that has not experienced it would be scientifically unsound and
ethically questionable. Similarly, investigating the health effects of
calorie restriction in children or the elderly, or the psychological
impact of vasectomy in biological females or hysterectomy in biological
males, would be inappropriate. It would all be `\textbf{weird}' --
`wrongly inferred effect relationship damaged'.

In these cases, the scientific questions pertained to a sub-sample of
the human population and could be sensibly restricted. However, even for
questions relating to all of humanity, sampling universally might be
undesirable. For example, if we were interested in the effects of a
vaccine on disease, sampling from one population might be as good as
sampling from all, sparing time and expense, which come with opportunity
costs. We might conclude that sampling universally, where unnecessary,
is wasteful and unethical.

These examples remind us of the importance of addressing questions of
sampling in relation to their context.

During the past twenty years, causal data science, also known as `causal
inference' or `CI', has enabled tremendous clarity for questions of
research design and analysis
(\citeproc{ref-richardson2014causal}{Richardson and Rotnitzky 2014}).
Here, we examine how workflows developed from causal inference clarify
threats and opportunities for comparative human research. Put
differently, causal inference helps us clarify when sample restriction
is desirable and when it is not. Not all questions are causal, of
course. However, because manifest associations in a dataset may not be
evidence of \emph{association} in the world, even those seeking
descriptive understanding benefit from causal inferential workflows
(\citeproc{ref-vansteelandt2022a}{Vansteelandt and Dukes 2022a}).

The remainder of this introduction reviews causal directed acyclic
graphs (causal DAGs). Readers familiar with causal diagrams may skip
this section. Because causal diagrams encode causal assumptions, we will
use the terms `structural' and `causal' synonymously. I encourage
readers unfamiliar with causal directed acyclic graphs to develop
familiarity before proceeding: (\citeproc{ref-barrett2021}{Barrett
2021}; \citeproc{ref-bulbulia2023}{Bulbulia 2023};
\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024 Chapter 6};
\citeproc{ref-mcelreath2020}{McElreath 2020} chapater 5,6;
\citeproc{ref-neal2020introduction}{Neal 2020};
\citeproc{ref-pearl2009a}{Pearl 2009}).

\textbf{Part 1} uses causal diagrams to clarify five structural features
of measurement-error bias. Understanding measurement error bias is
essential in all research, especially in comparative human science,
where it casts a long shadow.

\textbf{Part 2} examines structural sources of bias arising from
attrition and non-response, also known as `right-censoring bias' or
simply `censoring bias'. This term denotes a form of sample restriction
occurring after the start of a study. It may lead to bias in the absence
of confounding if the sample population at the end of the study differs
from the sample population at the start. For simplicity, we assume the
sample population at the start of the study is equivalent to the source
population, which is, in turn, equivalent to the target population of
interest.

\textbf{Part 3} considers threats to target validity at the start of
study, when there is a mismatch between the sample population at the
start of study and the target population. To simplify, in this section
we suppose that the sample population is equivalent to the source
population, and consider threats to `target validity' when the source
population and the target population do not match. We clarify `match'
and `mismatch' by focusing on structural threats to inference when the
sample population is (1) too restrictive (for example too WEIRD) (2)
Insufficiently restrictive (WEIRD is too weird).

Throughout, we shall consider that although the concepts of measurement
bias, right-censoring bias, and source bias (left-censoring bias) are
distinct, common structural motifs are shared by each. Causal directed
acyclic graphs clarify these recurring structural motifs, greatly
clarifying the tasks of comparative research design.

We begin with a brief overview of causal inference and causal diagrams
and our terminology.

\subsubsection{What is Causality?}\label{what-is-causality}

To quantify a causal effect, we must contrast the world as it is -- in
principle, observable -- with the world as it might have been -- in
principle, not observable.

Consider a binary treatment variable \(A \in \{0,1\}\) representing the
randomised administration of a vaccine to individuals \(i\) in the set
\(\{1, 2, \ldots, n\}\). \(A_i = 1\) denotes vaccine administration, and
\(A_i = 0\) denotes no vaccine. The potential outcomes for each
individual are \(Y_i(0)\) and \(Y_i(1)\), representing outcomes yet to
be realised before administration. Thus, they are called `potential' or
`counterfactual' outcomes. For an individual \(i\), we define a causal
effect as the contrast between the outcome observed under one
intervention level and the outcome observed under another. This
contrast, for the \(i^{th}\) individual, can be expressed on the
difference scale as:

\[
\text{Individual Treatment Effect} = Y_i(1) - Y_i(0)
\]

where the `Individual Treatment Effect' is the difference in a
predefined measure \(Y\) between receiving and not receiving the
treatment. \(Y_i(1) - Y_i(0) \neq 0\) denotes a causal effect of \(A\)
on \(Y\) for individual \(i\) on the difference scale. Similarly,
\(\frac{Y_i(1)}{Y_i(0)} \neq 1\) denotes a causal effect of treatment
\(A\) for individual \(i\) on the risk ratio scale. These quantities
cannot be computed from observational data for any individual \(i\).

Suppose Alice receives the vaccine (\(A_{\text{Alice}} = 1\)). If we
assume the realised outcome \(Y_{Alice}|A = 1\) equals the
counterfactual outcome \(Y_{Alice}(1)\), then \(Y_{Alice}(1)\) is
observed for Alice, but \(Y_{Alice}(0)\) remains counterfactual and
missing. Similarly, if Bob does not receive the vaccine, \(Y_{Bob}(0)\)
is observed for Bob, but \(Y_{Bob}(1)\) is not. The inability to observe
individual-level causal effects is the \emph{Fundamental Problem of
Causal Inference} (\citeproc{ref-holland1986}{Holland 1986};
\citeproc{ref-rubin1976}{Rubin 1976}). This problem has long puzzled
philosophers (\citeproc{ref-hume1902}{Hume 1902};
\citeproc{ref-lewis1973}{Lewis 1973}). However, although individual
causal effects are generally unobservable, we can sometimes recover
average causal effects by treatment group.

\subsubsection{How We Obtain Average Causal Effect Estimates from
Ideally Conducted Randomised
Experiments}\label{how-we-obtain-average-causal-effect-estimates-from-ideally-conducted-randomised-experiments}

The Average Treatment Effect (ATE) measures the difference in outcomes
between treated and control groups as follows:

\[
\text{Average Treatment Effect} = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
\]

Here, \(\mathbb{E}[Y(1)]\) and \(\mathbb{E}[Y(0)]\) represent the
average outcome for the target population if \emph{everyone} in the
population were subjected to the treatment and control conditions,
respectively.

In a randomised experiment, we estimate these averages under the
assumption that the sample population matches the target population. We
do this by considering the average observed and unobserved outcomes
under the treatment conditions:

\[
\text{ATE} = \left(\mathbb{E}[Y(1) | A = 1] + \mathbb{E}[Y(1) | A = 0]\right) - \left(\mathbb{E}[Y(0) | A = 0] + \mathbb{E}[Y(0) | A = 1]\right)
\]

Effective randomisation ensures that potential outcomes are similarly
distributed across both groups. Thus, any differences in the averages of
the treatment groups can be attributed to the treatment. Therefore, in
an ideally conducted randomised experiment, the average outcomes are
expected to be equal across different treatment conditions for the
population from which the sample is drawn:

\[
\widehat{\mathbb{E}}[Y(0) | A = 1] = \widehat{\mathbb{E}}[Y(0) | A = 0], \quad \widehat{\mathbb{E}}[Y(1) | A = 1] = \widehat{\mathbb{E}}[Y(1) | A = 0]
\]

This provides an unbiased estimate of the Average Treatment Effect:

\[
\widehat{\text{ATE}} = \widehat{\mathbb{E}}[Y | A = 1] - \widehat{\mathbb{E}}[Y | A = 0]
\]

Randomised controlled experiments are powerful because they evenly
distribute potential explanatory factors across treatment groups. We
cannot observe individual causal effects for Alice or Bob. However, for
the groups to which they have been randomised, we recover average causal
effects by a process of inference by elimination: randomisation rules
out alternative explanations.

Note that in the context of our imagined experiment,
\(\widehat{\text{ATE}}\) applies to the population from which the
experimental participants were drawn and is calculated on the difference
scale. A more explicit notation would define this effect estimate by
referencing its scale and population:
\(\widehat{\text{ATE}}^{a'-a}_{\text{S}}\), where \(a'-a\) denotes the
difference scale, and \(S\) denotes the source population. We will
return to this point in Part 2, but it is important to build intuition
early that in causal inference we must specify: (1) the causal effect of
interest; (2) a scale of contrast; and (3) a target population for whom
a causal effect estimate is meant to generalise.

\subsubsection{To obtain average causal effect estimates from
observational studies requires three fundamental
assumptions}\label{to-obtain-average-causal-effect-estimates-from-observational-studies-requires-three-fundamental-assumptions}

An observational study aims to estimate the average treatment effects in
a setting where researchers do not control treatments or randomise the
treatment assignments. We may only consistently obtain and estimate the
counterfactual contrasts under strict assumptions. There are three
fundamental assumptions for obtaining from observational data the
counterfactual quantities required to compute causal contrasts.

\subsubsection{To Obtain Average Causal Effect Estimates from
Observational Studies Requires Three Fundamental
Assumptions}\label{to-obtain-average-causal-effect-estimates-from-observational-studies-requires-three-fundamental-assumptions-1}

An observational study aims to estimate the average treatment effects
without researchers controlling treatments or randomising treatment
assignments. We can consistently estimate counterfactual contrasts only
under strict assumptions. There are three fundamental assumptions for
obtaining from observational data the counterfactual quantities required
to compute causal contrasts.

\paragraph{Assumption 1. Causal
Consistency}\label{assumption-1.-causal-consistency}

Causal consistency states that the observed outcome for each individual
under the treatment they actually received is equal to their potential
outcome under that treatment. This means if an individual \(i\) received
treatment \(A_i = 1\), their observed outcome \(Y_i\) is the same as
their potential outcome under treatment, denoted as \(Y_i(1)\).
Similarly, if they did not receive the treatment (\(A_i = 0\)), their
observed outcome is the same as their potential outcome without
treatment, denoted as \(Y_i(0)\), such that:

\[
Y_i = A_i \cdot Y_i(1) + (1 - A_i) \cdot Y_i(0)
\]

where:

\begin{itemize}
\tightlist
\item
  \(Y_i\) is the observed outcome for individual \(i\);
\item
  \(A_i\) is the treatment status for individual \(i\), with \(A_i = 1\)
  indicating treatment received and \(A_i = 0\) indicating no treatment;
\item
  \(Y_i(1)\) and \(Y_i(0)\) are the potential outcomes for individual
  \(i\) under treatment and no treatment, respectively.
\end{itemize}

The causal consistency assumption is necessary to link the theoretical
concept of potential outcomes --- the target quantities of interest ---
with observable data (see Bulbulia \emph{et al.}
(\citeproc{ref-bulbulia2023a}{2023})).

\paragraph{Assumption 2. Conditional Exchangeability (or
Ignorability)}\label{assumption-2.-conditional-exchangeability-or-ignorability}

Conditional exchangeability states that given a set of measured
covariates \(L\), the potential outcomes are independent of the
treatment assignment. Once we control for \(L\), the treatment
assignment \(A\) is as good as random with respect to the potential
outcomes:

\[
Y(a) \coprod A | L
\]

where:

\begin{itemize}
\tightlist
\item
  \(Y(a)\) represents the potential outcomes for a particular treatment
  level \(a\).
\item
  \(\coprod\) denotes conditional independence.
\item
  \(A\) represents the treatment levels to be contrasted.
\item
  \(L\) represents the measured covariates.
\end{itemize}

Under the conditional exchangeability assumption, any differences in
outcomes between treatment groups can be attributed to the treatment.
This assumption requires that all confounding variables affecting both
the treatment assignment \(A\) and the potential outcomes \(Y(a)\) are
measured and included in \(L\) (For further clarification, see Appendix
A).

\paragraph{Assumption 3. Positivity}\label{assumption-3.-positivity}

The positivity assumption requires that every individual in the
population has a non-zero probability of receiving each treatment level,
given their covariates. Formally,

\[
0 < Pr(A = a | L = l) < 1, \quad \forall a \in A, \, \forall l \in L \, \text{ such that } \, Pr(L = l) > 0
\]

where:

\begin{itemize}
\tightlist
\item
  \(A\) is the treatment or exposure variable.
\item
  \(L\) is a vector of covariates.
\item
  \(a\) and \(l\) represent specific values of treatment and covariates,
  respectively.
\end{itemize}

The positivity assumption, essential for valid treatment effect
estimates, requires that every individual has a non-zero chance of
receiving each treatment across all covariates in \(L\).\footnote{In
  practice, verifying this assumption faces two main challenges: a.
  \textbf{Data sparsity}: Certain covariate combinations are rare or
  unobserved in the data, making it difficult to empirically confirm
  positivity for these groups. b. \textbf{Model dependence}: Researchers
  rely on statistical models to estimate treatment probabilities for all
  covariate patterns due to data sparsity. These assessments are only as
  reliable as the models used, which may be subject to misspecification
  or inaccuracies.}

For a more detailed discussion, refer to Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}).

\subsubsection{Terminology}\label{terminology}

To avoid terminology confusion, we define the meanings of our terms:

\begin{itemize}
\item
  \textbf{Unit/individual}: An entity, such as an object, person, or
  culture. We will use the term `individual' in place of the more
  general term `unit'. Think `row' in one's dataset.
\item
  \textbf{Variable}: A feature of an individual, transient or permanent.
  `John was sleepy but is no longer.' `Alice was born in December.'
\item
  \textbf{Treatment}: Equivalent to `exposure', an event that might
  change a variable. `John was sleepy; we intervened with coffee; he's
  wide awake.' `Alice was born in December; there's nothing to change
  that.' The `cause'.
\item
  \textbf{Outcome}: The response variable or `effect'. In causal
  inference, we contrast `potential' or `counterfactual outcomes'. In
  observational or `real-world' studies where treatments are not
  randomised, the assumptions for obtaining contrasts of counterfactual
  outcomes are typically much stronger than in randomised controlled
  experiments.
\item
  \textbf{Confounding}: A state where the treatment and outcome share a
  common cause and no adjustment is made to remove the non-causal
  association, or where the treatment and outcome share a common effect,
  and adjustment is made for this common effect, or when the effect of
  the treatment and the outcome is mediated by a variable which is
  conditioned upon. In each case, the observed association will not
  reflect a causal association. Causal directed acyclic graphs clarify
  strategies for confounding control.
\item
  \textbf{Measurement}: A recorded trace of a variable, such as a column
  in one's dataset.
\item
  \textbf{Measurement error}: A misalignment between the true state of a
  variable and its recorded state. `Alice was born on 30/Nov; records
  were lost, and her birthday was recorded as 29/Nov.'
\item
  \textbf{Population}: An abstraction from statistics, denoting the set
  of all individuals defined by certain features. John belongs to the
  set of all individuals who ignore instructions.
\item
  \textbf{Super-population}: An abstraction, the population of all
  possible individuals of a given kind. John and Alice belong to a
  super-population of hominins.
\item
  \textbf{Restricted population}: Population \(p\) is restricted
  relative to another population \(P\) if the individuals \(p \in P\)
  share some but not all features of \(P\). `The living' are a
  restriction of hominins.
\item
  \textbf{Target population}: A restriction of the super-population
  whose features interest investigators. An investigator who defines
  their interests is a member of the population of `good investigators.'
\item
  \textbf{Source population}: The population from which the study's
  sample is drawn. Investigators wanted to recruit from a general
  population but recruited from the pool of first-year university
  psychology students.
\item
  \textbf{Baseline sample population}: The abstract set of individuals
  from which the units in one's study at treatment assignment belong,
  e.g.~`the set of all first-year university psychology students who
  might end up in this study'. To simplify, we will think of the
  baseline population as the \emph{source population.}
\item
  \textbf{Selection into the sample}: The process by which individuals
  are included in a population or sample. Selection occurs, and is under
  investigator control, when a target population is defined from a
  super-population, or when investigators apply eligibility criteria for
  inclusion in the analytic sample. Selection into the sample is often
  out of investigator control. Investigators might aspire to answering
  questions about all of humanity but find themselves limited to
  undergraduate samples. Investigators might sample from a source
  population but recover an analytic sample that differs from it in ways
  they cannot measure, such as mistrust of scientists. There is
  typically attrition of an analytic sample over time, and this is not
  typically fully within investigator control. Because the term
  `selection' has different meanings in different areas of human
  science, we will speak of `sample restriction.'
\item
  \textbf{Censored sample population}: The population from which the
  censored units are drawn. Censoring is uninformative if, for everyone
  in the baseline population, there is no effect of treatment (the sharp
  causal null hypothesis). Censoring is informative if there is an
  effect of the treatment, and this effect varies in at least one
  stratum of the baseline population. Note that uninformative censoring
  does not ensure valid inference for the target population even when
  valid inference is ensured for the baseline population. If the
  baseline population differs in the distribution of those features that
  modify the effect of the treatment, and no correction is applied,
  unbiased effect estimates for the baseline population will
  nevertheless be biased for the target population in at least one
  measure of effect (\citeproc{ref-greenland2009commentary}{Greenland
  2009}; \citeproc{ref-lash2020}{Lash \emph{et al.} 2020}). This is why
  it is important for investigators to state a causal effect of interest
  with respect to \emph{the full data} that includes the counterfactual
  quantities for the treatments to be compared in a clearly defined
  target population where all members of the target population are
  exposed to each level of treatment to be contrasted
  (\citeproc{ref-westreich2017}{Westreich \emph{et al.} 2017a}).
\item
  \textbf{Target Restriction Bias}: bias when the sample population at
  the end of study or the start of study, or both, differs in the
  distribution of effect-modifiers from the target population. Also
  called `selection restriction bias'.
\item
  \textbf{Generalisability}: A study's findings generalise to a target
  population if the effects observed in the study group are also valid
  for the target population for structurally valid reasons (i.e.,
  non-accidentally). Clearly, the similarity of the source population to
  the target population in study-relevant characteristics enhances the
  applicability of the findings to the target population. (see
  \textbf{Appendix B})
\item
  \textbf{Transportability:} When the study sample is not drawn from the
  target population, we cannot directly generalise the findings.
  However, under certain assumptions, we can transport the estimated
  causal effect from the source population to the target population.
  This involves adjusting for differences in the distributions of effect
  modifiers between the two populations. The closer the source
  population is to the target population, the more plausible the
  transportability assumptions and the less we need to rely on complex
  adjustment methods (see \textbf{Appendix B})
\item
  \textbf{Marginal effect}: Synonym for the average treatment effect ---
  always relative to some population investigators specify.
\item
  \textbf{Intention-to-treat effect}: The marginal effect of random
  treatment assignment.
\item
  \textbf{Per-protocol effect}: The effect of adherence to a randomly
  assigned treatment assignment if adherence were perfect
  (\citeproc{ref-hernan2017per}{Hern치n \emph{et al.} 2017}). We have no
  guarantee that the intention-to-treat effect will be the same as the
  per-protocol effect. A safe assumption is that:
\end{itemize}

\[
\widehat{ATE}_{\text{target}}^{\text{Per-Protocol}} \ne \widehat{ATE}_{\text{target}}^{\text{Intention-to-Treat}}
\]

When evaluating evidence for causality, in addition to specifying their
causal contrast, effect measure, and target population, investigators
should specify whether they are estimating an intention-to-treat or
per-protocol effect (\citeproc{ref-hernuxe1n2004}{Hern치n 2004};
\citeproc{ref-tripepi2007}{Tripepi \emph{et al.} 2007}).

\begin{itemize}
\item
  \textbf{WEIRD}: a sample that is `Western, Educated, Industrialized,
  Rich, and Democratic Societies'
  (\citeproc{ref-henrich2010weirdest}{Henrich \emph{et al.} 2010}).
\item
  \textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due to
  \textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion) a
  causal effect estimate that is not valid for the target population,
  either from confounding bias or from a mismatch between the sample
  population both at the start and end of study and the target
  population.
\end{itemize}

Note that our terminology differs in causal inference for the concepts
we have defined here (refer to Dahabreh \emph{et al.}
(\citeproc{ref-dahabreh2021study}{2021}); Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Westreich \emph{et al.}
(\citeproc{ref-westreich2017transportability}{2017b})). A clear
decomposition of key concepts needed to assess generalisability --- or
what we call `target validity' --- is given in Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}). For a less technical,
pragmatically useful discussion, refer to Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018}).

\subsubsection{Graphical Conventions}\label{graphical-conventions}

\begin{itemize}
\item
  \textbf{\(A\)}: Denotes the `treatment' or `exposure' --- a random
  variable, `the cause.'
\item
  \textbf{\(Y\)}: Denotes the outcome or response, measured at the end
  of the study. \(Y\) is the `effect'.
\item
  \textbf{\(L\)}: Denotes a measured confounder or set of confounders.
\item
  \textbf{\(U\)}: Denotes an unmeasured confounder or confounders.
\item
  \(\big(\mathbf{\mathcal{R} }\rightarrow \mathbf{A}\big)\): Denotes
  randomisation to treatment condition
  \(\big(\mathcal{R} \rightarrow A\big)\).
\item
  \textbf{Node}: Represents characteristics or features of units within
  a population on a causal diagram --- that is, a `variable.' In causal
  directed acyclic graphs (DAGs), we draw nodes with respect to the
  \emph{target population}, which is the population for whom
  investigators seek causal inferences (\citeproc{ref-suzuki2020}{Suzuki
  \emph{et al.} 2020}). Time-indexed node: \(X_t\) denotes relative
  chronology.
\item
  \textbf{Arrow} (\(\rightarrow\)): Denotes a causal relationship from
  the node at the base of the arrow (a `parent') to the node at the tip
  of the arrow (a `child'). In causal DAGs, it is conventional to
  refrain from drawing an arrow from treatment to outcome to avoid
  asserting a causal path from \(A\) to \(Y\) because our purpose is to
  ascertain whether causality can be identified for this path. All other
  nodes and paths --- including the absence of nodes and paths --- are
  typically assumed.
\item
  \textbf{Red Arrow} (\(\rightarrowred\)): Denotes a path of non-causal
  association between the treatment and outcome. Despite the arrows,
  this path is associational and may flow against time.
\item
  \textbf{Open Blue Arrow} (\(\rightarrowblue\)): Denotes effect
  modification, which occurs when the effect of treatment varies within
  levels of a covariate. We do not assess the causal effect of the
  effect-modifier on the outcome, recognising that it may be incoherent
  to consider intervening on the effect-modifier. However, if the
  distribution of effect modifiers in the sample population differs from
  that in the target population, then at least one measure of causal
  effect will differ.
\item
  \textbf{Boxed Variable} \(\big(\boxed{X}\big)\): Denotes conditioning
  or adjustment for \(X\).
\item
  \textbf{Red-Boxed Variable} \(\big(\boxedred{X}\big)\): Highlights the
  source of confounding bias from adjustment.
\item
  \textbf{Dashed Circle} \(\big(\circledotted{X}\big)\): Denotes no
  adjustment is made for a variable (implied for unmeasured
  confounders).
\item
  \textbf{\(\mathcal{G}\)}: Names a causal directed acyclic graph.
\end{itemize}

\subsubsection{Causal Directed Acyclic Graphs (causal
DAGs)}\label{causal-directed-acyclic-graphs-causal-dags}

In the 1990s, Judea Pearl showed that we can evaluate causal
dependencies using observable probability distributions
(\citeproc{ref-pearl1995}{Pearl 1995}, \citeproc{ref-pearl2009a}{2009}).
He also demonstrated that causal directed acyclic graphs (causal DAGs)
clarify the conditional dependencies among variables
(\citeproc{ref-pearl1995}{Pearl 1995}). Based on assumptions about
causal structure, researchers can identify causal effects from joint
distributions of observed data.

Pearl developed graphical rules known as d-separation
(\citeproc{ref-pearl1995}{Pearl 1995}):

\begin{itemize}
\tightlist
\item
  \textbf{Fork rule} (\(B \leftarrowNEW \boxed{A} \rightarrowNEW C\)):
  \(B\) and \(C\) are independent when conditioned on \(A\)
  (\(B \coprod C \mid A\)).
\item
  \textbf{Chain rule} (\(A \rightarrowNEW \boxed{B} \rightarrowNEW C\)):
  Conditioning on \(B\) blocks the path between \(A\) and \(C\)
  (\(A \coprod C \mid B\)).
\item
  \textbf{Collider rule}
  (\(A \rightarrowNEW \boxed{C} \leftarrowNEW B\)): \(A\) and \(B\) are
  independent until conditioned on \(C\), which introduces dependence
  (\(A \cancel{\coprod} B \mid C\)).
\end{itemize}

These rules lead to the backdoor criterion and `backdoor adjustment'
theorem, which provide algorithms for identifying causal effects based
on the structural assumptions encoded in a causal DAG
(\citeproc{ref-pearl1995}{Pearl 1995}).

Consider the following graphs:

\begin{itemize}
\tightlist
\item
  \textbf{\(\mathcal{G}_1\)}: If \(A\) and \(B\) are not causally
  related and share no common causes, \(A\) and \(B\) will not be
  statistically related.
\item
  \textbf{\(\mathcal{G}_2\)}: If \(A\) causes \(B\), and they share no
  common causes or their common causes are accounted for, \(A\) and
  \(B\) will be statistically related.
\item
  \textbf{\(\mathcal{G}_3\)}: If \(A\) causes \(B\) and \(A\) causes
  \(C\), then conditioning on \(A\) allows us to estimate the effect of
  \(B\) on \(C\).
\item
  \textbf{\(\mathcal{G}_4\)}: If \(A\) causes \(B\) and \(B\) causes
  \(C\), conditioning on \(B\) obscures the true causal effect of \(A\)
  on \(C\), making \(A\) independent of \(C\).
\item
  \textbf{\(\mathcal{G}_5\)}: If \(A\) causes \(C\) and \(B\) causes
  \(C\), conditioning on \(C\) associates \(A\) and \(B\), despite no
  direct causal effect.
\end{itemize}

If we assume that the variables in the graph correspond to Structural
Causal Models, all causal relationships can be defined by the elementary
structures presented above.

\subsubsection{Review of d-separation for Causal Identification on a
Graph}\label{review-of-d-separation-for-causal-identification-on-a-graph}

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologydirectedgraph

}

\end{table}%

\subsubsection{Effect-Modification on Causal Directed Acyclic Graphs:
`Off-Label'
Convention}\label{effect-modification-on-causal-directed-acyclic-graphs-off-label-convention}

The primary function of a causal directed acyclic graph is to clarify
relations of conditional independence Table~\ref{tbl-terminologygeneral}
for the purposes of causal identification. We have noted that the
modification of a causal effect within one or more strata of the target
population opens the possibility for biased average treatment effect
estimates when the distribution of these effect modifiers differs in the
sample population.

We do not generally represent non-linearities in causal directed acyclic
graphs, which are tools for obtaining relationships of conditional and
unconditional independence from assumed structural relationships encoded
in a causal diagram that may lead to a non-causal treatment/outcome
association.

Table~\ref{tbl-terminologygeneral} presents our convention for
highlighting a relationship of effect modification in settings where (1)
we assume no confounding of treatment and outcome and (2) there is
effect modification such that the effect of \(A\) on \(Y\) differs in at
least one stratum of the target population.

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologyeffectmodification

}

\end{table}%

To focus on effect modification, we do not draw a causal arrow from the
direct effect modifier \(F\) to the outcome \(Y\). This convention is
specific to this article (refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), pp.~126-127, for a discussion
of `noncausal' arrows).

\subsection{\texorpdfstring{Part 1: How Measurement Error Bias Makes
Your Causal Inferences \textbf{weird} (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and
\textbf{d}istortion)}{Part 1: How Measurement Error Bias Makes Your Causal Inferences weird (wrongly estimated inferences due to inappropriate restriction and distortion)}}\label{part-1-how-measurement-error-bias-makes-your-causal-inferences-weird-wrongly-estimated-inferences-due-to-inappropriate-restriction-and-distortion}

Measurements record reality, but they are not always accurate. When
variables are measured with error, our results can mislead. Every study
must therefore consider how its measurements might mislead. Causal
directed acyclic graphs (DAGs) can deepen understanding because, as
implied by the concept of `record', there are structural or causal
properties of measurement error. Understanding these properties can
greatly assist with study design, data collection, data analysis, and
inference.

Measurement error can take various forms, each with distinct
implications for causal inference. Causal diagrams clarify these types
of measurement error:

\begin{itemize}
\tightlist
\item
  \textbf{Independent/uncorrelated}: Errors in different variables do
  not influence each other.
\item
  \textbf{Independent and correlated}: Errors in different variables are
  related through a shared cause.
\item
  \textbf{Dependent and uncorrelated}: Errors in one variable influence
  the measurement of another, but these influences are not related
  through a shared cause.
\item
  \textbf{Dependent and correlated}: Errors in one variable influence
  the measurement of another, and these influences are related through a
  shared cause (\citeproc{ref-hernuxe1n2009}{Hern치n and Cole 2009};
  \citeproc{ref-vanderweele2012a}{VanderWeele and Hern치n 2012}).
\end{itemize}

The six examples presented in
Table~\ref{tbl-terminologymeasurementerror} illustrate structural
features of measurement error bias and clarify how they can affect the
accuracy of causal inferences.

\begin{table}

\caption{\label{tbl-terminologymeasurementerror}Example of measurement
error bias}

\centering{

\terminologymeasurementerror

}

\end{table}%

Understanding these types of measurement error helps researchers design
better studies, collect more accurate data, and apply analytical
techniques that address measurement error bias. As we will consider in
Parts 2 and 3, these four types of measurement error bias will enable us
to better clarify the promise and perils of comparative research.

\subsubsection{Example 1: Uncorrelated Errors under Sharp Null: No
Treatment
Effect}\label{example-1-uncorrelated-errors-under-sharp-null-no-treatment-effect}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_1\)
illustrates uncorrelated non-differential measurement error under the
`sharp-null,' which arises when the error terms in the exposure and
outcome are independent. In this setting, the structure of measurement
error is not expected to produce bias.

For example, consider a study investigating a causal effect of beliefs
in big Gods on social complexity in ancient societies. Imagine that
societies either randomly omitted or inaccurately recorded details about
their beliefs in big Gods and their social complexities. This might
happen due to the varying preservation of records across cultures,
unrelated to the actual beliefs or social complexities. In this
scenario, the errors in historical records for beliefs in big Gods and
for social complexity will be independent. Such errors may generally not
introduce bias --- suggesting an effect --- when there is no true effect
(although see Richardson and Robins
(\citeproc{ref-richardson2013}{2013}) for edge cases).

Generally, uncorrelated undirected errors will not be be weird
\textbf{weird} (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion)

\subsubsection{Example 2: Uncorrelated Errors under Treatment Effect
Biases True Effects toward the
Null}\label{example-2-uncorrelated-errors-under-treatment-effect-biases-true-effects-toward-the-null}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_2\)
illustrates uncorrelated non-differential measurement error, which
arises when the error terms in the exposure and outcome are independent
(information bias). In this setting, bias will typically attenuate a
true treatment effect.

Consider again the example of a study investigating a causal effect of
beliefs in big Gods on social complexity in ancient societies, where
there are uncorrelated errors in the treatment and outcome. In this
case, measurement error will typically make it seem that the true causal
effects of beliefs in big Gods are smaller than they are, or perhaps
even that such an effect is absent.

Uncorrelated undirected measurement error in the presence of a true
effect leads to distortion of true causal effects, inviting
\textbf{weird} results (\textbf{w}rongly \textbf{e}stimated inferences
due to \textbf{i}nappropriate \textbf{r}estriction and
\textbf{d}istortion)

\subsubsection{Example 3: Correlated Errors Non-Differential
(Undirected) Measurement
Errors}\label{example-3-correlated-errors-non-differential-undirected-measurement-errors}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_3\)
illustrates the structure of correlated non-differential (undirected)
measurement error bias, which arises when the error terms of the
treatment and outcome share a common cause.

Consider an example: imagine that societies with more sophisticated
record-keeping systems tend to offer more precise and comprehensive
records of both beliefs in big Gods and social complexity. In this
setting, it is the record-keeping systems that give an illusion of a
relationship between big Gods and social complexity. This might occur
without any effect of big-God beliefs on the measurement of social
complexity or vice versa. Nevertheless, the correlated sources of error
for both the exposure and outcome may suggest causation in its absence.

Correlated non-differential measurement error invites \textbf{weird}
results (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion)

\subsubsection{Example 4: Uncorrelated Directed Measurement Error:
Exposure Affects Error of
Outcome}\label{example-4-uncorrelated-directed-measurement-error-exposure-affects-error-of-outcome}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_4\)
illustrates the structure of uncorrelated differential (or directed)
measurement error, where a non-causal path is opened linking the
treatment, the outcome, or a common cause of the treatment and outcome.

Continuing with our previous example, imagine that beliefs in big Gods
lead to inflated records of social complexity in a culture's
record-keeping. This might happen because the record keepers in
societies that believe in big Gods prefer societies to reflect the
grandeur of their big Gods. Suppose further that cultures lacking
beliefs in big Gods prefer Bacchanalian-style feasting to
record-keeping. In this scenario, societies with record keepers who
believe in big Gods would appear to have more social complexity than
equally complex societies without such record keepers.

Uncorrelated directed measurement error bias also invites \textbf{weird}
results (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion)

\subsubsection{Example 5: Uncorrelated Directed Error: Outcome Affects
Error of
Exposure}\label{example-5-uncorrelated-directed-error-outcome-affects-error-of-exposure}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_5\)
illustrates the structure of uncorrelated differential (or directed)
measurement error, this time when the outcome affects the recording of
the treatment that preceded the outcome.

Consider if `history is written by the victors.' How might this affect
measurement error bias? Suppose that social complexity causes beliefs in
big Gods. Perhaps kings create big Gods after the image of kings. If the
kings prefer a history in which big Gods were historically present, this
might bias the historical record, opening a path of association that
reverses the order of causation. Such results would be \textbf{weird}:
(\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion)

\subsubsection{Example 6: Directed Error: Outcome Affects Error of
Exposure}\label{example-6-directed-error-outcome-affects-error-of-exposure}

Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_6\)
illustrates the structure of correlated differential (directed)
measurement error, which occurs when the exposure affects levels of
already correlated error terms.

Suppose social complexity produces a flattering class of religious
elites who tend to produce vainglorious depictions of kings and their
dominions, and also of the extent and scope of their society's beliefs
in big Gods. For example, such elites might tend to downplay widespread
cultural practices of worshipping lesser gods, inflate population
estimates, and overstate the range of their economies. In this scenario,
the errors of the exposure and of the outcome are both correlated and
differential.

Such results would be \textbf{weird}: (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and \textbf{d}istortion)

\subsubsection{Summary}\label{summary}

In \textbf{Part 1}, we examined four types of measurement error bias ---
independent, correlated, dependent, and correlated dependent. Not only
do the structural features of measurement error bias clarify why
measurement errors threatens causal inferences, they clarify how
measurement error make causal inferences weird. For example, when
measurement error is uncorrelated and undirected, inferences will be
biased toward the null.

Considerably more could be said about measurement error bias. For
example, VanderWeele and Hern치n (\citeproc{ref-vanderweele2012a}{2012})
demonstrate that, under specific conditions, we can infer the direction
of a causal effect from observed associations. Specifically, if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The association between the measured variables \(A^{\prime}_{1}\) and
  \(Y^{\prime}_{2}\) is positive,
\item
  The measurement errors for these variables are not correlated, and
\item
  We assume distributional monotonicity for the effect of \(A\) on \(Y\)
  (applicable when both are binary),
\end{enumerate}

then a positive observed association implies a positive causal effect
from \(A\) to \(Y\). Conversely, a negative observed association
provides stronger evidence for a negative causal effect if the error
terms are positively correlated than if they are independent. This
conclusion relies on the assumption of distributional monotonicity for
the effect of \(A\) on \(Y\). For now, the four elementary structures of
measurement error bias will enables us to clarify the connections
between the structures of measurement error bias, target-restriction
bias at the end of study, and target-restriction bias at the start of
study.

For now, we have examined how measurement error can bias causal effect
estimates, exposing investigators to \textbf{weird} findings
(\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion). In
\textbf{Part 1} we have focussed on the potential of measurement error
to cause distortion. Next we focus on structural features of bias when
there is inappropriate restriction of the the target population.

\subsection{\texorpdfstring{Part 2: How Target-Restriction Bias At The
End of Study Makes Your Causal Inferences weird (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and
\textbf{d}istortion)}{Part 2: How Target-Restriction Bias At The End of Study Makes Your Causal Inferences weird (wrongly estimated inferences due to inappropriate restriction and distortion)}}\label{part-2-how-target-restriction-bias-at-the-end-of-study-makes-your-causal-inferences-weird-wrongly-estimated-inferences-due-to-inappropriate-restriction-and-distortion}

Suppose the sample population at the start of a study matches the source
population from which it is drawn, and furthermore that this source
population aligns with the target population. Censoring, also called
`right-censoring', or attrition (and non-response), may bias causal
effect estimates in one of two ways: by opening pathways of confounding
bias -- distortion, or by inappropriately restricting the sample
population at the end of study so that it is no longer aligned with the
target population, as it was at the start of study. We next consider how
censoring can make a study \textbf{weird}: (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and \textbf{d}istortion).

\begin{table}

\caption{\label{tbl-terminologycensoring}Five examples of censoring
bias.}

\centering{

\terminologycensoring

}

\end{table}%

\subsubsection{Example 1: Confounding by common cause of treatment and
attrition}\label{example-1-confounding-by-common-cause-of-treatment-and-attrition}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_1\) illustrates
confounding by common cause of treatment and outcome in the censored
such that the potential outcomes of the population at baseline \(Y(a)\)
may differ from those of the censored population at the end of study
\(Y'(a)\) such that \(Y'(a) \neq Y(a)\).

Suppose investigators are interested in whether religious service
attendance affects volunteering. Suppose that an unmeasured variable,
loyality, affects religious service attendance, attrition, and
volunteering. The structure of this bias reveals an open backdoor path
from from the treatment to the outcome.

We have encountered this bias before. The structure we observe here is
one of correlated measurement errors
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_3\)). In this
example, attrition may exacerbate measurement error bias by opening a
path from
\(A \associationred U \associationred U_{\Delta{A}}  \associationred Y'\)

The results obtained from such a study would be distorted and so
\textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion).
Here, distortion operates through restriction of the target population
in the sample population at the end of study.

\subsubsection{Example 2: Treatment affects
censoring}\label{example-2-treatment-affects-censoring}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_2\) illustrates
confounding bias in which the treatment affects the censoring process.

Consider a study investigating the effects of mediation on well-being.
Suppose there is no treatment effect but that Buddha-like detachment
increases attrition. If \(\mathcal{G}_4\) faithfully represents reality,
there will be no bias in the treatment effect estimate. That is, there
will be no risk that attrition will induce the appearance of a causal
effect in its absence. The biasing path runs:
\(A \associationred U_{\Delta{A\to Y}}  \associationred Y'\).

We have encountered this structural bias before. The structure we
observe here is one of directed uncorrelated measurement error
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_4\)).
Randomisation ensures no backdoor paths. However, if the intervention
affects both attrition and bias in the outcome, this may exacerbate
measurement error bias.

The results obtained from this study would be distorted and so
\textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion).
Here, distortion operates through restriction of the target population
in the sample population at the end of study.

\subsubsection{Example 3: No treatment effect when outcome causing
censoring}\label{example-3-no-treatment-effect-when-outcome-causing-censoring}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_3\) illustrates the
structure of bias when there is no treatment effect yet the outcome
affects censoring.

If \(\mathcal{G}_3\) faithfully represents reality, there will be no
bias in the treatment effect estimate from attrition, even if there is
measurement error in the outcome. Recall again our measurement error
causal diagrams.

The structure we observe here is again familiar: it is one of undirected
uncorrelated measurement error
(Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_1\)). Here,
we would not expect attrition to induce or exaggerate the appearance of
a causal effect in its absence, for the same reason that uncorrelated
treatment errors do not produce results under the sharp null.

The results obtained from this study are not distorted. Through there is
restriction of the sample population, it is not a restriction of the
target population -- assuming the causal diagramme is drawn for the
target population as it should.

\subsubsection{Example 4: Treatment effect when outcome causes censoring
and there is a true treatment
effect}\label{example-4-treatment-effect-when-outcome-causes-censoring-and-there-is-a-true-treatment-effect}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_4\) illustrates the
structure of bias when the outcome affects censoring in the presence of
a treatment effect. In contrast to the previous example, here there is
scope for confounding bias.

Consider again a study investigating the effects of mediation on
well-being. This time suppose that Buddha-like detachment affects
attrition. As such, the investigators will observe a restricted range of
effect in the sample at the end of study compared to the sample at the
start of the study. The structure of bias in this example is not one of
measurement error. Rather, there is confounding of the per-protocal
effect of the meditation on well-being. Note that if the randomisation
were successful, the `intent-to-treat' effect would be unbiased.

The results obtained from this study would be distorted but they would
not necessarily be \textbf{very weird} if the treatment and the outcome
shared the same sign and we assume distributional monotonicity for the
effect of \(A\) on \(Y\) . In that case, the effect of sample
restriction would be reduced. Strictly speaking, however, results would
be \textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due
to \textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion).

\subsubsection{Example 5: Treatment effect and effect-modifiers differ
in censored (restriction bias without
confounding)}\label{example-5-treatment-effect-and-effect-modifiers-differ-in-censored-restriction-bias-without-confounding}

Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) represents a
setting in which there is a true treatment effect, but the distribution
of effect-modifiers -- variables that interact with the treatment --
differ among the sample at baseline and the sample at the end of study.
Knowing nothing else, we might expect this setting to be standard. Where
measured variables are sufficient to predict attrition, that is, where
missingness is at random, we can obtain valid estimates for a treatment
effect by inverse probability of treatment weighting
(\citeproc{ref-cole2008}{Cole and Hern치n 2008};
\citeproc{ref-leyrat2021}{Leyrat \emph{et al.} 2021}). In this approach,
the sample gives more weight to under-represented individuals owing to
drop-out. As with missing data imputation, IPW with censoring weights
also assumes that we can correctly model the missingness from the
observed data (\citeproc{ref-shiba2021}{Shiba and Kawahara
2021}).However, if missingness is not completely at random, then
identification may be compromised
(\citeproc{ref-malinsky2022semiparametric}{Malinsky \emph{et al.} 2022};
\citeproc{ref-tchetgen2017general}{Tchetgen Tchetgen and Wirth 2017}).

Note that Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) closely
resembles a measurement structure we have considered before, in
\textbf{Part 1:} Table~\ref{tbl-terminologymeasurementerror}
\(\mathcal{G}_2\) Replacing the unmeasured effect modifiers
\(\circledotted{F}\) and \(U_{\Delta F}\) in
Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) for
\(\circledotted{U_Y}\) in Table~\ref{tbl-terminologymeasurementerror}
\(\mathcal{G}_2\) reveals that the unmeasured effect modification in the
present setting can be viewed as an example of uncorrelated indepedent
measurment error when there is a treatment effect (i.e.~off the null.)

Here there is no distortion. Effect estimates are valid for the
end-of-study population. However the end-of-study sample population
would be an inappropriate restriction of the target population (the
sample at the start of study). Results here would be \textbf{weird}:
(\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion)
because there is \textbf{i}nappropriate \textbf{r}estriction.

\subsubsection{Summary}\label{summary-1}

In this section, we examined how right-censoring, or attrition, can lead
to biased causal effect estimates. Example 5 is particularly important
as it assumes no confounding but exhibits \textbf{i}nappropriate
\textbf{r}estriction. When the distribution of variables that modify
treatment effects differs between the sample population at the start and
end of the study, the average treatment effects will likely differ,
leading to biased estimates. To address this, researchers must ensure
that the distribution of potential outcomes at the end of the study
aligns with that of the target population. Techniques such as inverse
probability weighting and multiple imputation can help mitigate this
bias (refer to \citeproc{ref-bulbulia2024PRACTICAL}{Bulbulia 2024a}).

Attrition is nearly inevitable. Before seeking ambitious samples that
extend a species understanding, we must ensure our design is not
\textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion).

In \textbf{Part 3}, we will investigate target restriction bias at the
start of study (left-censoring), where structural motifs of measurement
error bias reappear.

\newpage{}

\subsection{\texorpdfstring{Part 3: How Target-Restriction Bias At The
Start of Study Makes Your Causal Inferences weird (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and
\textbf{d}istortion)}{Part 3: How Target-Restriction Bias At The Start of Study Makes Your Causal Inferences weird (wrongly estimated inferences due to inappropriate restriction and distortion)}}\label{part-3-how-target-restriction-bias-at-the-start-of-study-makes-your-causal-inferences-weird-wrongly-estimated-inferences-due-to-inappropriate-restriction-and-distortion}

In this part, we examine target-restriction bias that occurs at the
start of a study. There are several failure modes. The source population
from which participants are recruited might not align with the target
population. Even where there is such alignment the participants
recruited into a study might not align with the source population. For
simplicity we will imagine the sample population at the start of study
accuratedly aligns with the source population. Thus we will use `source
bias' synonymously with `target-restriction bias.' What constitutes
`alignment'? We say the sample is unrestrictive of the target population
if there are no differences between the sample and target population in
the distribution of variables that modify treatment effects.

\subsubsection{Sample-Restriction Bias Considered as
Collider-Restriction
Bias}\label{sample-restriction-bias-considered-as-collider-restriction-bias}

\begin{table}

\caption{\label{tbl-terminologyselectionrestrictionclassic}Collider-Stratification
bias at start of study (`M-bias')}

\centering{

\terminologyselectionrestrictionclassic

}

\end{table}%

Table~\ref{tbl-terminologyselectionrestrictionclassic} \(\mathcal{G}_1\)
illustrates an example of sample restriction bias at baseline in which
there is collider-restriction bias.

Suppose investigators want to estimate the causal effects of regular
physical activity, \(A\), and heart health, \(Y\), among adults visiting
a network of community health centers for routine check-ups.

Suppose there are two unmeasured variables that affect selection into
the study \(S=1\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Health Awareness, \(U1\), an unmeasured variable that influences both
  the probability of participating in the study, \(\boxed{S = 1}\), and
  the probability of being physically active, \(A\). Perhaps people with
  higher health awareness are both more likely to engage in physical
  activity and to participate in health-related studies.
\item
  Socioeconomic Status (SES), \(U2\), an unmeasured variable that
  influences both the probability of participating in the study,
  \(\boxed{S = 1}\), and heart health, \(Y\). We assume that individuals
  with higher SES have better access to healthcare and are more likely
  to participate in health surveys; they also tend to have better heart
  health from healthy lifestyles: joining expensive gyms, juicing, long
  vacations, and the like.
\end{enumerate}

As presented in Table~\ref{tbl-terminologyselectionrestrictionclassic}
\(\mathcal{G}_1\), there is collider-restriction bias from conditioning
on \(S=1\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\(U1\)}: Because individuals with higher health awareness are
  more likely to be both physically active and participate in the study,
  the subsample over-represents physically active individuals. This
  overestimates the prevalence of physical activity, setting up a bias
  in overstating the potential benefits of physical activity on heart
  health in the general population.
\item
  \textbf{\(U2\)}: Because individuals with higher SES may have better
  heart health from SES-related factors, this opens a confounding path
  from physical activity and heart health through the selected sample,
  setting up the investigators for the potentially erroneous inference
  that physical activity has a greater positive impact on heart health
  than it actually does in the general population. The actual effect of
  physical activity on heart health in the general population might be
  less pronounced than observed.
\end{enumerate}

It might seem as though researchers would need to sample from the target
population. However, by adjusting for health awareness or SES, or a
proxy of either, researchers may block the open
path.@tbl-terminologyselectionrestrictionclassic \(\mathcal{G}_2\)
presents this solution. However, this strategy will only provide an
unbiased effect estimate for the population if either there is no causal
effect for all strata of the selected sample (the sharp null hypothesis)
or there are no interactions between the distribution of effect
modifiers in the sample population and the target population.

The next series of examples illustrates challenges to obtaining valid
causal effect estimates in the presence of interactions.

\subsubsection{Sample-Restriction Bias Without Collider-Restriction
Bias}\label{sample-restriction-bias-without-collider-restriction-bias}

\textbf{Source bias or `Sample-Restriction-at-Baseline Bias'} occurs
when the sample population (source population) does not accurately
represent the group of interest (target population) in the distribution
of variables that modify treatment effects. Such bias occurs because the
selection into the study occurs on an effect modifier for the effect of
the exposure on the outcome. Note that although the causal effect of
\(A \to Y\) is unbiased for the exposed and unexposed in the source
population, the effect estimate does not generalise to the exposed and
unexposed in the target population. Even if there is no confounding,
causal inferences in this scenario will not generalise as we might hope
(\citeproc{ref-suzuki2016}{Suzuki \emph{et al.} 2016};
\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020};
\citeproc{ref-suzuki2014}{Suzuki and Yamamoto 2014}) (refer to
\textbf{Appendix C}, which provides a mathematical explanation, and
\textbf{Appendix D}, which simulates the effect).

\begin{table}

\caption{\label{tbl-terminologyselectionrestrictionbaseline}The
association in the population of selected individuals differs from the
causal association for the target population. Hern치n calls this scenario
`selection bias off the null' (\citeproc{ref-hernuxe1n2017}{Hern치n
2017}). Lu et al.~call this scenario `Type 2 selection bias'
(\citeproc{ref-lu2022}{Lu \emph{et al.} 2022}). We call this bias
`target restriction bias at baseline'.}

\centering{

\terminologyselectionrestrictionbaseline

}

\end{table}%

\subsubsection{Problem 1: Target population is not WEIRD; sample
population is
WEIRD}\label{problem-1-target-population-is-not-weird-sample-population-is-weird}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{1.1}\) presents a scenario in which there is target
restriction bias at baseline. Again, when the sample we obtain at
baseline differs from the target population in the distributions of
variables that modify treatment effects, effect-estimates may be biased,
even in the absence of confounding bias. Results may be \textbf{weird}
without being distorded from confounding bias.

Suppose investigators were in interested in the effects of a political
campaigning but only sampled from their preferred political party.
Results might distort results if the distribution of effect modifiers
varied by party. One such effect modifier might be `party affiliation'.
I think that this valid worry animates the call for broader sampling in
the human sciences.

Note that we have encountered
Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{1.1}\) \emph{twice} before. It is the same causal
directed acyclic graph as we found in
Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\). As we did
before, we may replacing the unmeasured effect modifiers
\(\circledotted{F}\) and \(U_{\Delta F}\) for \(\circledotted{U_Y}\) in
Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_2\) and
observe that we recover uncorrelated measurement error off the null
(i.e.~when there is a true treatment effect.)

The structural similarity suggests options might be easily overlooked.
Where the distributions of treatment-effect modifiers are known, and
measured, and where there are census (or other) weights available for
the distributions of effect modifiers in the target population, that it
may be possible to weight the sample to more closely approximate the
target population parameters of interest, refer to Stuart \emph{et al.}
(\citeproc{ref-stuart2015}{2015}).

Let \(\widehat{ATE}_{target}\) denote the population average treatment
effect for the target population. Let
\(\widehat{ATE}_{\text{restricted}}\) denote the average treatment
effect at the end of treatment. Let \(W\) denote a set of variables upon
which the restricted and target populations structurally differ. We say
that results \emph{generalise} if we can ensure that:

\[
\widehat{ATE}_{target} = \widehat{ATE}_{restricted}
\]

or if there is a known function such that:

\[
ATE_{target} \approx f_W(ATE_{\text{restricted}}, W)
\]

In most cases, \(f_W\) will be unknown, as it must account for potential
heterogeneity of effects and unobserved sources of bias. For further
discussion on this topic, see: Imai \emph{et al.}
(\citeproc{ref-imai2008misunderstandings}{2008}); Cole and Stuart
(\citeproc{ref-cole2010generalizing}{2010}); Stuart \emph{et al.}
(\citeproc{ref-stuart2018generalizability}{2018}).

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{1.2}\) provides a graphical representation of the
solution.

Importantly, if there is considerable heterogeneity, then we might not
know how to interpret the average treatment effect for the target
population. In comparative research, we are generally interested in
treatment heterogeneity. If we seek explicitly comparative models, we
will need to ensure validity for every sample that we compare. If one
stratum in the comparative study is \textbf{weird}: (\textbf{w}rongly
\textbf{e}stimated inferences due to \textbf{i}nappropriate
\textbf{r}estriction and \textbf{d}istortion), errors may propogate to
the remainder of the comparative study. To understand such propogation
we consider scenerios where explicit target restrictions at baseline
through the use of clearly defined `eligibility criteria' are desirable.

\subsubsection{Example 2: Target population is WEIRD; sample population
is not
WEIRD}\label{example-2-target-population-is-weird-sample-population-is-not-weird}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.1}\) presents a scenario in which the source population
does not meet eligibility criteria. Consider again the question of
whether vasectomy affects a sense of meaning and purpose in life.
Suppose further we want to evaluate effects in New Zealand among men
over the age of 40 who have no prior history of vasectomy, who are in
relationships with heterosexual partners. The target population is is a
stratum of WEIRD -- WEIRDER-THAN-WEIRD we might say. We should not
sample from young children, the elderly, and any who do not qualify. For
many scientific questions, a narrow population is desirable.

Note again Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.1}\) is identical to
Table~\ref{tbl-terminologycensoring} \(\mathcal{G}_5\) ---
right-censoring bias with effect modifiers in an otherwise unconfounded
study. The structure is also similar to
Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_2\) the
problem is structurally that of uncorrelated measurement error off the
null. Where it is the defusion of the effect-modifiers that causes we
may fix the measurement error by restricting the sample.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{2.2}\) presents a solution. Ensure eligibility criteria
are scientifically relevant and feasible. Sample from this eligible
population. With caution, apply survey or other weights where these
weights enable a closer approximate to the distributions of
effect-modifiers in the target population. Here, we avoid
\textbf{weird}: (\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion) by
imposing greater restriction on what had been an inappropriately
unrestricted target population.

\subsubsection{Example 3: Correlated Measurement Error of Covariates and
Outcome in the Absence of a Treatment
Effect}\label{example-3-correlated-measurement-error-of-covariates-and-outcome-in-the-absence-of-a-treatment-effect}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.1}\) considers the threats to target validity from
correlated measurement errors in the target population arising from
structured errors across heterogenous stratums. For simplicty imagine
the groups with structured errors are cultures. Even if the treatment is
measured without error, multiple sources of error may lead to
association without causation.

Suppose investigators plan a cross-cultural investigation to clarify the
relationship between interventions on religious service attendance
(\(A\)) and an outcome (\(Y\)) like charitable giving. They plan to
obtain measures of covariates \(L\) sufficient to control for
confounding. Suppose the investigators observe religious attendance so
that it is not measured with error (as did
\citeproc{ref-shaver2021comparison}{Shaver \emph{et al.} 2021}), yet
there is heterogeneity in the measurement of covariates \(L\) and the
outcome \(Y\). For example, if charitable giving measures are included
as baseline covariates in \(L\), measurement errors at baseline will be
correlated with outcome measures. Perhaps in certain cultures, religious
service is under-reported (associated with witchcraft), while in others,
it is over-reported. Suppose further that true covariates affect the
treatment and outcome. As shown in
Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.1}\), multiple paths of bias are opened.

Moreover, because measurements are causally related to the phenomena
they record, investigators cannot apply statistical tests to verify
whether measures are recorded with error
(\citeproc{ref-vanderweele2022}{VanderWeele 2022};
\citeproc{ref-vansteelandt2022}{Vansteelandt and Dukes 2022b}). Whether
the phenomena that investigators hope to measure are functionally
equivalent across cultural settings remains unknown, and can only be
discovered slowly, through patient, careful work with local experts.
Although big cross-cultural projects are preferred at certain science
journals, including multiple cultures into a single analysis imposes
considerable burdens on investigators. All sources of error must be
evaluated -- and error from one culture can poison the wells of others
at analysis.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{3.2}\) provides a sensible solution: restrict one's study
to those cultures where causality can be identified. Democritus wrote,
`I would rather discover one cause than gain the kingdom of Persia'
(\citeproc{ref-freeman1948ancilla}{Freeman 1948}). Paraphrasing
Democritus, we might say, `I should rather discover one WEIRD cause than
the kingdom of \textbf{weird} comparative research.'

\subsubsection{Example 4: Correlated Measurement Error of
Effect-Modifiers for an Overly Ambitious Target
Population}\label{example-4-correlated-measurement-error-of-effect-modifiers-for-an-overly-ambitious-target-population}

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{4.1}\) considers the threats to target validity from
correlated measurement errors in the target population arising from
structured errors linking measurements for the effect modifiers. Here,
we discover a familiar structural bias of correlated measuremen error
bias Table~\ref{tbl-terminologymeasurementerror} \(\mathcal{G}_3\)

Even if the treatment is randomised so that there are no open backdoor
paths, and even if the treatment and outcome are measured without error,
investigators will not be able to obtain valid estimates for
treatment-effect heterogeneity from their data, nor will they be able to
apply target-sample weights (such as census weights) to obtain valid
estimates for the populations in which the measurement errors of effect
modifiers are manifest.

Table~\ref{tbl-terminologyselectionrestrictionbaseline}
\(\mathcal{G}_{4.2}\) suggests that where measures of effect
modification are uncertain, it is best to consider settings in which the
measurements are reliable --- whether or not the settings are WEIRD.
Moreover, in comparative settings where multiple cultures are measured,
unless each is proven innocent of structural measurement bias, it is
generally best to report the results for each culture separately,
without attempting comparisons.

\subsection{Conclusions}\label{conclusions}

In causal inference, we begin by specifying clear treatments and
outcomes, defining the contrasts to be made for treatments at specific
levels, and identifying a target population for whom results generalise.
Although causal inference is gaining popularity, much work remains to
address the threats posed by measurement error bias to causal
inferences. These threats are particularly evident in the comparative
human sciences. Here, we have considered how problems of
target-population restriction at the end and beginning of a study can be
approached as variations on the motifs of measurement-error bias. Using
causal directed acyclic graphs, we have clarified the structural
features of bias that recur in measurement-error bias, censoring bias
(target population restriction at the end of a study), and source bias
(target population restriction at the start of a study).

We define any study that exhibits these biases as \textbf{weird}
(\textbf{w}rongly \textbf{e}stimated inferences due to
\textbf{i}nappropriate \textbf{r}estriction and \textbf{d}istortion).

It is laudable to seek species-level knowledge. However before venturing
into the gardens of human existence, we must tend to accessible gardens.
Cultivation of that garden is not easy because the long shadow of
measurement error casts it shade over all gardens.

\subsubsection{Workflow for Inferring Causal Effects from Real-World
Data}\label{workflow-for-inferring-causal-effects-from-real-world-data}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{State a well-defined intervention.} Clearly define the
  treatment or exposure to ensure precise implementation and
  interpretation.
\item
  \textbf{State a well-defined outcome.} Specify the outcome measure to
  avoid ambiguity and ensure consistency in data collection and
  analysis.
\item
  \textbf{Clarify the target population.} Define the population to whom
  the results will generalise to ensure relevance and applicability of
  the findings.
\item
  \textbf{Ensure treatments to be compared satisfy causal consistency.}
  Verify that the treatment conditions align with the theoretical
  framework and practical implementation.
\item
  \textbf{Evaluate whether treatment groups, conditional on measured
  covariates, are exchangeable.} Ensure that differences between groups
  are ignorable, confounding covariates across treatment levels are
  balanced, all backdoor paths between treatments and outcomes are
  closed, treatments and outcomes are d-separated, and there is no
  unmeasured confounding.
\item
  \textbf{Check if the positivity assumption is satisfied.} Confirm that
  all individuals have a non-zero probability of receiving each
  treatment level, given their covariates.
\item
  \textbf{Ensure that the measures relate to the scientific questions at
  hand}:
\item
  \textbf{Consider how structural bias might make results render results
  weird (}w\textbf{rongly }e\textbf{stimated inferences due to
  }i\textbf{nappropriate }r\textbf{estriction and }d\textbf{istortion).}
\item
  \textbf{Clearly communicate the reasoning, evidence, and
  decision-making that inform steps 1-8.} Provide transparent and
  thorough documentation of the causal inference process to support the
  validity and reliability of the conclusions.
\end{enumerate}

\newpage{}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or the
decision to publish it.

\subsection{Acknowledgements}\label{acknowledgements}

Errors are my own.

\newpage{}

\subsection{Appendix A: Glossary}\label{appendix-a-glossary}

\begin{table}

\caption{\label{tbl-experiments}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\newpage{}

\subsection{Appendix B: Generalisability and
Transportability}\label{appendix-b-generalisability-and-transportability}

\textbf{Generalisability:} When a study sample is drawn randomly from
the target population, we may generalise from the sample to the target
population as follows:

Suppose we sample randomly from the target population, where:

\begin{itemize}
\tightlist
\item
  \(n_S\) denotes the size of the study sample \(S\).
\item
  \(N_T\) denotes the total size of the target population \(T\).
\item
  \(\widehat{ATE}_{n_S}\) denotes the estimated average treatment effect
  in the study sample \(S\).
\item
  \(ATE_{T}\) denotes the true average treatment effect in the target
  population \(T\).
\end{itemize}

Assuming the rest of the causal inference workflow goes to plan
(randomisation succeeds, there is no measurement error, no model
misspecification, etc.), as the random sample size \(n_S\) increases,
the estimated treatment effect in the sample \(S\) converges in
probability to the true treatment effect in the target population \(T\):

\[
\lim_{n_S \to N_T} P(|\widehat{ATE}_{n_S} - ATE_{T}| < \epsilon) = 1
\]

for any small positive value of \(\epsilon\).

\textbf{Transportability:} When the study sample is not drawn from the
target population, we cannot directly generalise the findings. However,
under certain assumptions, we can transport the estimated causal effect
from the source population to the target population. This involves
adjusting for differences in the distributions of effect modifiers
between the two populations. The closer the source population is to the
target population, the more plausible the transportability assumptions
are, and the less we need to rely on complex adjustment methods.

Suppose we have a study sample \(n_S\) drawn from a source population
\(S\), and we want to estimate the average treatment effect in a target
population \(T\).

Define:

\begin{itemize}
\tightlist
\item
  \(\widehat{ATE}_{S}\) as the estimated average treatment effect in the
  source population \(S\).
\item
  \(\widehat{ATE}_{T}\) as the estimated average treatment effect in the
  target population \(T\).
\item
  \(f(n_S, R)\) as the mapping function that adjusts the estimated
  effect in the study sample using a set of measured covariates \(R\),
  allowing for valid projection to the target population.
\end{itemize}

The transportability assumption is that there exists a function \(f\)
such that:

\[
\widehat{ATE}_{T} = f(n_S, R)
\]

Finding a suitable function \(f\) is the central challenge in adjusting
for sampling bias and achieving transportability
(\citeproc{ref-bareinboim2013general}{Bareinboim and Pearl 2013};
\citeproc{ref-dahabreh2019generalizing}{Dahabreh \emph{et al.} 2019};
\citeproc{ref-westreich2017transportability}{Westreich \emph{et al.}
2017b}).

\subsection{Appendix C: Explanation for the Difference in Marginal
Effects between Censored and Uncensored
Populations}\label{appendix-c-explanation-for-the-difference-in-marginal-effects-between-censored-and-uncensored-populations}

\paragraph{Definitions:}\label{definitions}

\begin{itemize}
\tightlist
\item
  \textbf{\(A\)}: Exposure variable
\item
  \textbf{\(Y\)}: Outcome variable
\item
  \textbf{\(F\)}: Effect modifier
\item
  \textbf{\(C\)}: Indicator for the uncensored population (\(C = 0\)) or
  the censored population (\(C = 1\))
\end{itemize}

\paragraph{Average Treatment Effects:}\label{average-treatment-effects}

The average treatment effects for the uncensored and censored
populations are defined as:

\[
\Delta_{\text{uncensored}} = \mathbb{E}[Y(a^*) - Y(a) \mid C = 0]
\] \[
\Delta_{\text{censored}} = \mathbb{E}[Y(a^*) - Y(a) \mid C = 1]
\]

\paragraph{Potential Outcomes:}\label{potential-outcomes}

By causal consistency, potential outcomes can be expressed in terms of
observed outcomes:

\[
\Delta_{\text{uncensored}} = \mathbb{E}[Y \mid A=a^*, C=0] - \mathbb{E}[Y \mid A=a, C=0]
\] \[
\Delta_{\text{censored}} = \mathbb{E}[Y \mid A=a^*, C=1] - \mathbb{E}[Y \mid A=a, C=1]
\]

\paragraph{Law of Total Probability:}\label{law-of-total-probability}

Applying the Law of Total Probability, we can weight the average
treatment effects by the conditional probability of the effect modifier
\(F\):

\[
\Delta_{\text{uncensored}} = \sum_{f} \left\{\mathbb{E}[Y \mid A=a^*, F=f, C=0] - \mathbb{E}[Y \mid A=a, F=f, C=0]\right\} \times \Pr(F=f \mid C=0)
\] \[
\Delta_{\text{censored}} = \sum_{f} \left\{\mathbb{E}[Y \mid A=a^*, F=f, C=1] - \mathbb{E}[Y \mid A=a, F=f, C=1]\right\} \times \Pr(F=f \mid C=1)
\]

\paragraph{Assumption of Informative
Censoring:}\label{assumption-of-informative-censoring}

We assume that the effect modifier \(F\) has a different distribution in
the censored and uncensored populations:

\[
\Pr(F=f \mid C=0) \neq \Pr(F=f \mid C=1)
\]

Under this assumption, the probability weights used to calculate the
marginal effects for the uncensored and censored populations differ.

\paragraph{Effect Estimates for Censored and Uncensored
Populations:}\label{effect-estimates-for-censored-and-uncensored-populations}

Given that \(\Pr(F=f \mid C=0) \neq \Pr(F=f \mid C=1)\), we cannot
guarantee that:

\[
\Delta_{\text{uncensored}} = \Delta_{\text{censored}}
\]

The equality of marginal effects between the two populations will only
hold if there is a universal null effect across all units, by chance, or
under specific conditions discussed by VanderWeele and Robins
(\citeproc{ref-vanderweele2007}{2007}) and further elucidated by Suzuki
\emph{et al.} (\citeproc{ref-suzuki2013counterfactual}{2013}).
Otherwise:

\[
\Delta_{\text{uncensored}} \ne \Delta_{\text{censored}}
\]

Furthermore, VanderWeele (\citeproc{ref-vanderweele2012}{2012}) proved
that if there is effect modification of \(A\) by \(F\), there will be a
difference in at least one scale of causal contrast, such that:

\[
\Delta^{\text{risk ratio}}_{\text{uncensored}} \ne \Delta^{\text{risk ratio}}_{\text{censored}}
\]

or

\[
\Delta^{\text{difference}}_{\text{uncensored}} \ne \Delta^{\text{difference}}_{\text{censored}}
\]

For comprehensive discussions on sampling and inference, refer to
Dahabreh and Hern치n (\citeproc{ref-dahabreh2019}{2019}) and Dahabreh
\emph{et al.} (\citeproc{ref-dahabreh2021study}{2021}). \#\# Appendix D:
R Simulation to Clarify Why The Distribution of Effect Modifiers Matters
For Estimating Treatment Effects For A Target Population

First, we load the \texttt{stdReg} library, which obtains marginal
effect estimates by simulating counterfactuals under different levels of
treatment (\citeproc{ref-sjuxf6lander2016}{Sj칬lander 2016}). If a
treatment is continuous, the levels can be specified.

We also load the \texttt{parameters} library, which creates nice tables
(\citeproc{ref-parameters2020}{\textbf{parameters2020?}}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# to obtain marginal effects}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{requireNamespace}\NormalTok{(}\StringTok{\textquotesingle{}stdReg\textquotesingle{}}\NormalTok{, }\AttributeTok{quietly =} \ConstantTok{TRUE}\NormalTok{)) }\FunctionTok{install.packages}\NormalTok{(}\StringTok{\textquotesingle{}stdReg\textquotesingle{}}\NormalTok{)}
\FunctionTok{library}\NormalTok{(stdReg)}

\CommentTok{\#  to view data}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{requireNamespace}\NormalTok{(}\StringTok{\textquotesingle{}skimr\textquotesingle{}}\NormalTok{, }\AttributeTok{quietly =} \ConstantTok{TRUE}\NormalTok{)) }\FunctionTok{install.packages}\NormalTok{(}\StringTok{\textquotesingle{}skimr\textquotesingle{}}\NormalTok{)}
\FunctionTok{library}\NormalTok{(parameters)}

\CommentTok{\# to create nice tables}
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{requireNamespace}\NormalTok{(}\StringTok{\textquotesingle{}parameters\textquotesingle{}}\NormalTok{, }\AttributeTok{quietly =} \ConstantTok{TRUE}\NormalTok{)) }\FunctionTok{install.packages}\NormalTok{(}\StringTok{\textquotesingle{}parameters\textquotesingle{}}\NormalTok{)}
\FunctionTok{library}\NormalTok{(parameters)}
\end{Highlighting}
\end{Shaded}

Next, we write a function to simulate data for the sample and target
populations.

We assume the treatment effect is the same in the sample and target
population. We assume that the coefficient for the effect modifier and
the coefficient for interaction are the same. We assume no unmeasured
confounding throughout the study. We assume only selective attrition of
one effect modifier such that the baseline population differs from the
sample population at the end of the study.

That is: \textbf{the distribution of effect modifiers is the only
respect in which the sample will differ from the target population.}

This function will generate data under a range of scenarios.\footnote{See
  documentation in the \texttt{margot} package: Bulbulia
  (\citeproc{ref-margot2024}{2024b})}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# function to generate data for the sample and population, }
\CommentTok{\# along with precise sample weights for the population, there are differences }
\CommentTok{\# in the distribution of the true effect modifier but no differences in the treatment effect }
\CommentTok{\# or the effect modification. all that differs between the sample and the population is }
\CommentTok{\# the distribution of effect{-}modifiers.}

\CommentTok{\# reproducibility}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\CommentTok{\# simulate the data {-}{-} you can use different parameters}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ margot}\SpecialCharTok{::}\FunctionTok{simulate\_ate\_data\_with\_weights}\NormalTok{(}
  \AttributeTok{n\_sample =} \DecValTok{10000}\NormalTok{,}
  \AttributeTok{n\_population =} \DecValTok{100000}\NormalTok{,}
  \AttributeTok{p\_z\_sample =} \FloatTok{0.1}\NormalTok{,}
  \AttributeTok{p\_z\_population =} \FloatTok{0.5}\NormalTok{,}
  \AttributeTok{beta\_a =} \DecValTok{1}\NormalTok{,}
  \AttributeTok{beta\_z =} \FloatTok{2.5}\NormalTok{,}
  \AttributeTok{noise\_sd =} \FloatTok{0.5}
\NormalTok{)}

\CommentTok{\# inspect}
\CommentTok{\# skimr::skim(data)}
\end{Highlighting}
\end{Shaded}

We have generated both sample and population data.

Next, we verify that the distributions of effect modifiers differ in the
sample and in the target population:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain the generated data}
\NormalTok{sample\_data }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{sample\_data}
\NormalTok{population\_data }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{population\_data}

\CommentTok{\# check imbalance}
\FunctionTok{table}\NormalTok{(sample\_data}\SpecialCharTok{$}\NormalTok{z\_sample) }\CommentTok{\# type 1 is rare}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

   0    1 
9055  945 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(population\_data}\SpecialCharTok{$}\NormalTok{z\_population) }\CommentTok{\# type 1 is common}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    0     1 
49916 50084 
\end{verbatim}

The sample and population distributions differ.

Next, consider the question: `What are the differences in the
coefficients that we obtain from the study population at the end of the
study, compared with those we would obtain for the target population?'

First, we obtain the regression coefficients for the sample. They are as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model coefficients sample}
\NormalTok{model\_sample  }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(y\_sample }\SpecialCharTok{\textasciitilde{}}\NormalTok{ a\_sample }\SpecialCharTok{*}\NormalTok{ z\_sample, }
  \AttributeTok{data =}\NormalTok{ sample\_data)}

\CommentTok{\# summary}
\NormalTok{parameters}\SpecialCharTok{::}\FunctionTok{model\_parameters}\NormalTok{(model\_sample, }\AttributeTok{ci\_method =} \StringTok{\textquotesingle{}wald\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Parameter           | Coefficient |       SE |        95% CI | t(9996) |      p
-------------------------------------------------------------------------------
(Intercept)         |   -6.89e-03 | 7.38e-03 | [-0.02, 0.01] |   -0.93 | 0.350 
a sample            |        1.01 |     0.01 | [ 0.99, 1.03] |   95.84 | < .001
z sample            |        2.47 |     0.02 | [ 2.43, 2.52] |  104.09 | < .001
a sample 칑 z sample |        0.51 |     0.03 | [ 0.44, 0.57] |   14.82 | < .001
\end{verbatim}

Next, we obtain the regression coefficients for the weighted regression
of the sample. Notice that the coefficients are virtually the same:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model the sample weighted to the population, again note that these coefficients are similar }
\NormalTok{model\_weighted\_sample }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(y\_sample }\SpecialCharTok{\textasciitilde{}}\NormalTok{ a\_sample }\SpecialCharTok{*}\NormalTok{ z\_sample, }
  \AttributeTok{data =}\NormalTok{ sample\_data, }\AttributeTok{weights =}\NormalTok{ weights)}

\CommentTok{\# summary}
\FunctionTok{summary}\NormalTok{(parameters}\SpecialCharTok{::}\FunctionTok{model\_parameters}\NormalTok{(model\_weighted\_sample, }
  \AttributeTok{ci\_method =} \StringTok{\textquotesingle{}wald\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Parameter           | Coefficient |        95% CI |      p
----------------------------------------------------------
(Intercept)         |   -6.89e-03 | [-0.03, 0.01] | 0.480 
a sample            |        1.01 | [ 0.98, 1.04] | < .001
z sample            |        2.47 | [ 2.45, 2.50] | < .001
a sample 칑 z sample |        0.51 | [ 0.47, 0.55] | < .001

Model: y_sample ~ a_sample * z_sample (10000 Observations)
Residual standard deviation: 0.494 (df = 9996)
\end{verbatim}

We might be tempted to infer that weighting wasn't relevant to the
analysis. However, we'll see that such an interpretation would be a
mistake.

Next, we obtain model coefficients for the population. Note again there
is no difference -- only narrower errors owing to the large sample size.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model coefficients population {-}{-} note that these coefficients are very similar. }
\NormalTok{model\_population }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(y\_population }\SpecialCharTok{\textasciitilde{}}\NormalTok{ a\_population }\SpecialCharTok{*}\NormalTok{ z\_population, }
  \AttributeTok{data =}\NormalTok{ population\_data)}

\NormalTok{parameters}\SpecialCharTok{::}\FunctionTok{model\_parameters}\NormalTok{(model\_population, }\AttributeTok{ci\_method =} \StringTok{\textquotesingle{}wald\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Parameter                   | Coefficient |       SE |        95% CI | t(99996) |      p
----------------------------------------------------------------------------------------
(Intercept)                 |    2.49e-03 | 3.18e-03 | [ 0.00, 0.01] |     0.78 | 0.434 
a population                |        1.00 | 4.49e-03 | [ 0.99, 1.01] |   222.35 | < .001
z population                |        2.50 | 4.49e-03 | [ 2.49, 2.51] |   556.80 | < .001
a population 칑 z population |        0.50 | 6.35e-03 | [ 0.49, 0.51] |    78.80 | < .001
\end{verbatim}

Again, there is no difference. That is, we find that all model
coefficients are practically equivalent. The different distribution of
effect modifiers does not result in different coefficient values for the
treatment effect, the effect-modifier `effect,' or the interaction of
the effect modifier and treatment.

Consider why this is the case: in a large sample where the causal
effects are invariant -- as we have simulated them to be -- we will have
good replication in the effect modifiers within the sample, so our
statistical model can recover the \emph{coefficients} for the population
without challenge.

However, \emph{in causal inference, we are interested in the marginal
effect of the treatment. That is, we seek an estimate for the
counterfactual }contrast* in which everyone in a pre-specified
population was subject to one level of treatment compared with a
counterfactual condition in which everyone in a population was subject
to another level of the same treatment.*

\textbf{When the sample population differs in the distribution of effect
modifiers from the target population effect, the marginal effect
estimates will typically differ.}

To see this, we use the \texttt{stdReg} package to recover marginal
effect estimates, comparing (1) the sample ATE, (2) the true oracle ATE
for the population, and (3) the weighted sample ATE. We will use the
outputs of the same models above. The only difference is that we will
calculate marginal effects from these outputs. We will contrast a
difference from an intervention in which everyone receives treatment = 0
with one in which everyone receives treatment = 1; however, this choice
is arbitrary, and the general lessons apply irrespective of the
estimand.

First, consider this Average Treatment Effect for the sample population:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# What inference do we draw?  We cannot say the models are unbiased for the marginal effect estimates. }
\CommentTok{\# regression standardisation }
\FunctionTok{library}\NormalTok{(stdReg) }\CommentTok{\# to obtain marginal effects }

\CommentTok{\# obtain sample ate}
\NormalTok{fit\_std\_sample }\OtherTok{\textless{}{-}}\NormalTok{ stdReg}\SpecialCharTok{::}\FunctionTok{stdGlm}\NormalTok{(model\_sample, }\AttributeTok{data =}\NormalTok{ sample\_data, }\AttributeTok{X =} \StringTok{\textquotesingle{}a\_sample\textquotesingle{}}\NormalTok{)}

\CommentTok{\# summary}
\FunctionTok{summary}\NormalTok{(fit\_std\_sample, }\AttributeTok{contrast =} \StringTok{\textquotesingle{}difference\textquotesingle{}}\NormalTok{, }\AttributeTok{reference =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Formula: y_sample ~ a_sample * z_sample
Family: gaussian 
Link function: identity 
Exposure:  a_sample 
Reference level:  a_sample = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00     0.0000       0.00       0.00
1     1.06     0.0101       1.04       1.08
\end{verbatim}

The treatment effect is given as a 1.06 unit change in the outcome
across the sample population, with a confidence interval from 1.04 to
1.08.

Next, we obtain the true (oracle) treatment effect for the population
under the same intervention:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# note the population effect is different}

\CommentTok{\# obtain true ate}
\NormalTok{fit\_std\_population }\OtherTok{\textless{}{-}}\NormalTok{ stdReg}\SpecialCharTok{::}\FunctionTok{stdGlm}\NormalTok{(model\_population, }\AttributeTok{data =}\NormalTok{ population\_data, }\AttributeTok{X =} \StringTok{\textquotesingle{}a\_population\textquotesingle{}}\NormalTok{)}

\CommentTok{\# summary}
\FunctionTok{summary}\NormalTok{(fit\_std\_population, }\AttributeTok{contrast =} \StringTok{\textquotesingle{}difference\textquotesingle{}}\NormalTok{, }\AttributeTok{reference =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Formula: y_population ~ a_population * z_population
Family: gaussian 
Link function: identity 
Exposure:  a_population 
Reference level:  a_population = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00    0.00000       0.00       0.00
1     1.25    0.00327       1.24       1.26
\end{verbatim}

Note, the true treatment effect is a 1.25 unit change in the population,
with a confidence bound between 1.24 and 1.26. This is well outside the
ATE that we obtain from the sample population!

Next, consider the ATE in the weighted regression, where the sample was
weighted to the target population's true distribution of effect
modifiers:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# next try weights adjusted ate where we correctly assign population weights to the sample}
\NormalTok{fit\_std\_weighted\_sample\_weights }\OtherTok{\textless{}{-}}\NormalTok{ stdReg}\SpecialCharTok{::}\FunctionTok{stdGlm}\NormalTok{(model\_weighted\_sample, }\AttributeTok{data =}\NormalTok{ sample\_data, }\AttributeTok{X =} \StringTok{\textquotesingle{}a\_sample\textquotesingle{}}\NormalTok{)}

\CommentTok{\# this gives us the right answer}
\FunctionTok{summary}\NormalTok{(fit\_std\_weighted\_sample\_weights, }\AttributeTok{contrast =} \StringTok{\textquotesingle{}difference\textquotesingle{}}\NormalTok{, }\AttributeTok{reference =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Formula: y_sample ~ a_sample * z_sample
Family: gaussian 
Link function: identity 
Exposure:  a_sample 
Reference level:  a_sample = 0 
Contrast:  difference 

  Estimate Std. Error lower 0.95 upper 0.95
0     0.00     0.0000       0.00       0.00
1     1.25     0.0172       1.22       1.29
\end{verbatim}

We find that we obtain the population-level causal effect estimate with
accurate coverage by weighting the sample to the target population. So
with appropriate weights, our results generalise from the sample to the
target population.

\subsection{Lessons}\label{lessons}

\begin{itemize}
\tightlist
\item
  \textbf{Regression coefficients do not clarify the problem of
  sample/target population mismatch} --- or selection bias as discussed
  in this manuscript.
\item
  \textbf{Investigators should not rely on regression coefficients
  alone} when evaluating the biases that arise from sample attrition.
  This advice applies to both methods that authors use to investigate
  threats of bias. To implement this advice, authors must first take it
  themselves.
\item
  \textbf{Observed data are generally insufficient for assessing
  threats}. Observed data do not clarify structural sources of bias, nor
  do they clarify effect-modification in the full counterfactual data
  condition where all receive the treatment and all do not receive the
  treatment (at the same level).
\item
  \textbf{To properly assess bias, one needs access to the
  counterfactual outcome} --- what would have happened to the missing
  participants had they not been lost to follow-up or had they
  responded. The joint distributions over `full data' are inherently
  unobservable (\citeproc{ref-vanderlaan2011}{Van Der Laan and Rose
  2011}).
\item
  \textbf{In simple settings, like the one we just simulated, we can
  address the gap between the sample and target population using methods
  such as modelling the censoring (e.g., censoring weighting).} However,
  we never know what setting we are in or whether it is simple---such
  modelling must be handled with care. There is a large and growing
  epidemiology literature on this topic (see, for example, Li \emph{et
  al.} (\citeproc{ref-li2023non}{2023})).
\end{itemize}

\subsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-arnett2008neglected}
Arnett, JJ (2008) The neglected 95\%: Why american psychology needs to
become less american. \emph{American Psychologist}, \textbf{63}(7),
602--614.
doi:\href{https://doi.org/10.1037/0003-066X.63.7.602}{10.1037/0003-066X.63.7.602}.

\bibitem[\citeproctext]{ref-bareinboim2013general}
Bareinboim, E, and Pearl, J (2013) A general algorithm for deciding
transportability of experimental results. \emph{Journal of Causal
Inference}, \textbf{1}(1), 107--134.

\bibitem[\citeproctext]{ref-barrett2021}
Barrett, M (2021) \emph{Ggdag: Analyze and create elegant directed
acyclic graphs}. Retrieved from
\url{https://CRAN.R-project.org/package=ggdag}

\bibitem[\citeproctext]{ref-bulbulia2024PRACTICAL}
Bulbulia, J (2024a) A practical guide to causal inference in three-wave
panel studies. \emph{PsyArXiv Preprints}.
doi:\href{https://doi.org/10.31234/osf.io/uyg3d}{10.31234/osf.io/uyg3d}.

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-margot2024}
Bulbulia, JA (2024b) \emph{Margot: MARGinal observational
treatment-effects}.
doi:\href{https://doi.org/10.5281/zenodo.10907724}{10.5281/zenodo.10907724}.

\bibitem[\citeproctext]{ref-bulbulia2023a}
Bulbulia, JA, Afzali, MU, Yogeeswaran, K, and Sibley, CG (2023)
Long-term causal effects of far-right terrorism in {N}ew {Z}ealand.
\emph{PNAS Nexus}, \textbf{2}(8), pgad242.

\bibitem[\citeproctext]{ref-cole2008}
Cole, SR, and Hern치n, MA (2008) Constructing inverse probability weights
for marginal structural models. \emph{American Journal of Epidemiology},
\textbf{168}(6), 656--664.

\bibitem[\citeproctext]{ref-cole2010generalizing}
Cole, SR, and Stuart, EA (2010) Generalizing evidence from randomized
clinical trials to target populations: The ACTG 320 trial.
\emph{American Journal of Epidemiology}, \textbf{172}(1), 107--115.

\bibitem[\citeproctext]{ref-dahabreh2021study}
Dahabreh, IJ, Haneuse, SJA, Robins, JM, \ldots{} Hern치n, MA (2021) Study
designs for extending causal inferences from a randomized trial to a
target population. \emph{American Journal of Epidemiology},
\textbf{190}(8), 1632--1642.

\bibitem[\citeproctext]{ref-dahabreh2019}
Dahabreh, IJ, and Hern치n, MA (2019) Extending inferences from a
randomized trial to a target population. \emph{European Journal of
Epidemiology}, \textbf{34}(8), 719--722.
doi:\href{https://doi.org/10.1007/s10654-019-00533-2}{10.1007/s10654-019-00533-2}.

\bibitem[\citeproctext]{ref-dahabreh2019generalizing}
Dahabreh, IJ, Robins, JM, Haneuse, SJ, and Hern치n, MA (2019)
Generalizing causal inferences from randomized trials: Counterfactual
and graphical identification. \emph{arXiv Preprint arXiv:1906.10792}.

\bibitem[\citeproctext]{ref-freeman1948ancilla}
Freeman, K (1948) \emph{Ancilla to the pre-socratic philosophers},
Reprint edition, Cambridge, MA: Harvard University Press.

\bibitem[\citeproctext]{ref-greenland2009commentary}
Greenland, S (2009) Commentary: Interactions in epidemiology: Relevance,
identification, and estimation. \emph{Epidemiology}, \textbf{20}(1),
14--17.

\bibitem[\citeproctext]{ref-henrich2010weirdest}
Henrich, J, Heine, SJ, and Norenzayan, A (2010) The weirdest people in
the world? \emph{Behavioral and Brain Sciences}, \textbf{33}(2-3),
61--83.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernuxe1n2004}
Hern치n, MA (2004) A definition of causal effect for epidemiological
research. \emph{Journal of Epidemiology \& Community Health},
\textbf{58}(4), 265--271.
doi:\href{https://doi.org/10.1136/jech.2002.006361}{10.1136/jech.2002.006361}.

\bibitem[\citeproctext]{ref-hernuxe1n2017}
Hern치n, MA (2017) Invited commentary: Selection bias without colliders
\textbar{} american journal of epidemiology \textbar{} oxford academic.
\emph{American Journal of Epidemiology}, \textbf{185}(11), 1048--1050.
Retrieved from \url{https://doi.org/10.1093/aje/kwx077}

\bibitem[\citeproctext]{ref-hernuxe1n2009}
Hern치n, MA, and Cole, SR (2009) Invited commentary: Causal diagrams and
measurement bias. \emph{American Journal of Epidemiology},
\textbf{170}(8), 959--962.
doi:\href{https://doi.org/10.1093/aje/kwp293}{10.1093/aje/kwp293}.

\bibitem[\citeproctext]{ref-hernan2017per}
Hern치n, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-holland1986}
Holland, PW (1986) Statistics and causal inference. \emph{Journal of the
American Statistical Association}, \textbf{81}(396), 945--960.

\bibitem[\citeproctext]{ref-hume1902}
Hume, D (1902) \emph{Enquiries Concerning the Human Understanding: And
Concerning the Principles of Morals}, Clarendon Press.

\bibitem[\citeproctext]{ref-imai2008misunderstandings}
Imai, K, King, G, and Stuart, EA (2008) Misunderstandings between
experimentalists and observationalists about causal inference.
\emph{Journal of the Royal Statistical Society Series A: Statistics in
Society}, \textbf{171}(2), 481--502.

\bibitem[\citeproctext]{ref-lash2020}
Lash, TL, Rothman, KJ, VanderWeele, TJ, and Haneuse, S (2020)
\emph{Modern epidemiology}, Wolters Kluwer. Retrieved from
\url{https://books.google.co.nz/books?id=SiTSnQEACAAJ}

\bibitem[\citeproctext]{ref-lewis1973}
Lewis, D (1973) Causation. \emph{The Journal of Philosophy},
\textbf{70}(17), 556--567.
doi:\href{https://doi.org/10.2307/2025310}{10.2307/2025310}.

\bibitem[\citeproctext]{ref-leyrat2021}
Leyrat, C, Carpenter, JR, Bailly, S, and Williamson, EJ (2021) Common
methods for handling missing data in marginal structural models: What
works and why. \emph{American Journal of Epidemiology}, \textbf{190}(4),
663--672.

\bibitem[\citeproctext]{ref-li2023non}
Li, W, Miao, W, and Tchetgen Tchetgen, E (2023) Non-parametric inference
about mean functionals of non-ignorable non-response data without
identifying the joint distribution. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{85}(3),
913--935.

\bibitem[\citeproctext]{ref-lu2022}
Lu, H, Cole, SR, Howe, CJ, and Westreich, D (2022) Toward a Clearer
Definition of Selection Bias When Estimating Causal Effects.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{33}(5), 699--706.
doi:\href{https://doi.org/10.1097/EDE.0000000000001516}{10.1097/EDE.0000000000001516}.

\bibitem[\citeproctext]{ref-malinsky2022semiparametric}
Malinsky, D, Shpitser, I, and Tchetgen Tchetgen, EJ (2022)
Semiparametric inference for nonmonotone missing-not-at-random data: The
no self-censoring model. \emph{Journal of the American Statistical
Association}, \textbf{117}(539), 1415--1423.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in r and stan}, CRC press.

\bibitem[\citeproctext]{ref-neal2020introduction}
Neal, B (2020) Introduction to causal inference from a machine learning
perspective. \emph{Course Lecture Notes (Draft)}. Retrieved from
\url{https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf}

\bibitem[\citeproctext]{ref-pearl1995}
Pearl, J (1995) Causal diagrams for empirical research.
\emph{Biometrika}, \textbf{82}(4), 669--688.

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013) Single world intervention graphs:
A primer. In, Citeseer.

\bibitem[\citeproctext]{ref-richardson2014causal}
Richardson, TS, and Rotnitzky, A (2014) Causal etiology of the research
of james m. robins. \emph{Statistical Science}, \textbf{29}(4),
459--484.

\bibitem[\citeproctext]{ref-rubin1976}
Rubin, DB (1976) Inference and missing data. \emph{Biometrika},
\textbf{63}(3), 581--592.
doi:\href{https://doi.org/10.1093/biomet/63.3.581}{10.1093/biomet/63.3.581}.

\bibitem[\citeproctext]{ref-sears1986college}
Sears, DO (1986) College sophomores in the laboratory: Influences of a
narrow data base on social psychology's view of human nature.
\emph{Journal of Personality and Social Psychology}, \textbf{51}(3),
515.

\bibitem[\citeproctext]{ref-shaver2021comparison}
Shaver, JH, White, TA, Vakaoti, P, and Lang, M (2021) A comparison of
self-report, systematic observation and third-party judgments of church
attendance in a rural fijian village. \emph{Plos One}, \textbf{16}(10),
e0257160.

\bibitem[\citeproctext]{ref-shiba2021}
Shiba, K, and Kawahara, T (2021) Using propensity scores for causal
inference: Pitfalls and tips. \emph{Journal of Epidemiology},
\textbf{31}(8), 457--463.

\bibitem[\citeproctext]{ref-sjuxf6lander2016}
Sj칬lander, A (2016) Regression standardization with the R package
stdReg. \emph{European Journal of Epidemiology}, \textbf{31}(6),
563--574.
doi:\href{https://doi.org/10.1007/s10654-016-0157-3}{10.1007/s10654-016-0157-3}.

\bibitem[\citeproctext]{ref-stuart2018generalizability}
Stuart, EA, Ackerman, B, and Westreich, D (2018) Generalizability of
randomized trial results to target populations: Design and analysis
possibilities. \emph{Research on Social Work Practice}, \textbf{28}(5),
532--537.

\bibitem[\citeproctext]{ref-stuart2015}
Stuart, EA, Bradshaw, CP, and Leaf, PJ (2015) Assessing the
Generalizability of Randomized Trial Results to Target Populations.
\emph{Prevention Science}, \textbf{16}(3), 475--485.
doi:\href{https://doi.org/10.1007/s11121-014-0513-z}{10.1007/s11121-014-0513-z}.

\bibitem[\citeproctext]{ref-suzuki2013counterfactual}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2013) A
counterfactual approach to bias and effect modification in terms of
response types. \emph{BMC Medical Research Methodology}, \textbf{13}(1),
1--17.

\bibitem[\citeproctext]{ref-suzuki2016}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2016) A typology of
four notions of confounding in epidemiology. \emph{Journal of
Epidemiology}, \textbf{27}(2), 49--55.
doi:\href{https://doi.org/10.1016/j.je.2016.09.003}{10.1016/j.je.2016.09.003}.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-suzuki2014}
Suzuki, E, and Yamamoto, E (2014) Further refinements to the
organizational schema for causal effects. \emph{Epidemiology},
\textbf{25}(4), 618.
doi:\href{https://doi.org/10.1097/EDE.0000000000000114}{10.1097/EDE.0000000000000114}.

\bibitem[\citeproctext]{ref-tchetgen2017general}
Tchetgen Tchetgen, EJ, and Wirth, KE (2017) A general instrumental
variable framework for regression analysis with outcome missing not at
random. \emph{Biometrics}, \textbf{73}(4), 1123--1131.

\bibitem[\citeproctext]{ref-tripepi2007}
Tripepi, G, Jager, KJ, Dekker, FW, Wanner, C, and Zoccali, C (2007)
Measures of effect: Relative risks, odds ratios, risk difference, and
{`}number needed to treat{'}. \emph{Kidney International},
\textbf{72}(7), 789--791.
doi:\href{https://doi.org/10.1038/sj.ki.5002432}{10.1038/sj.ki.5002432}.

\bibitem[\citeproctext]{ref-vanderlaan2011}
Van Der Laan, MJ, and Rose, S (2011) \emph{Targeted Learning: Causal
Inference for Observational and Experimental Data}, New York, NY:
Springer. Retrieved from
\url{https://link.springer.com/10.1007/978-1-4419-9782-1}

\bibitem[\citeproctext]{ref-vanderweele2012}
VanderWeele, TJ (2012) Confounding and Effect Modification: Distribution
and Measure. \emph{Epidemiologic Methods}, \textbf{1}(1), 55--82.
doi:\href{https://doi.org/10.1515/2161-962X.1004}{10.1515/2161-962X.1004}.

\bibitem[\citeproctext]{ref-vanderweele2022}
VanderWeele, TJ (2022) Constructed measures and causal inference:
Towards a new model of measurement for psychosocial constructs.
\emph{Epidemiology}, \textbf{33}(1), 141.
doi:\href{https://doi.org/10.1097/EDE.0000000000001434}{10.1097/EDE.0000000000001434}.

\bibitem[\citeproctext]{ref-vanderweele2012a}
VanderWeele, TJ, and Hern치n, MA (2012) Results on differential and
dependent measurement error of the exposure and the outcome using signed
directed acyclic graphs. \emph{American Journal of Epidemiology},
\textbf{175}(12), 1303--1310.
doi:\href{https://doi.org/10.1093/aje/kwr458}{10.1093/aje/kwr458}.

\bibitem[\citeproctext]{ref-vanderweele2007}
VanderWeele, TJ, and Robins, JM (2007) Four types of effect
modification: a classification based on directed acyclic graphs.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{18}(5), 561--568.
doi:\href{https://doi.org/10.1097/EDE.0b013e318127181b}{10.1097/EDE.0b013e318127181b}.

\bibitem[\citeproctext]{ref-vansteelandt2022}
Vansteelandt, S, and Dukes, O (2022b) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657--685.

\bibitem[\citeproctext]{ref-vansteelandt2022a}
Vansteelandt, S, and Dukes, O (2022a) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657--685.

\bibitem[\citeproctext]{ref-westreich2017}
Westreich, D, Edwards, JK, Lesko, CR, Stuart, E, and Cole, SR (2017a)
Transportability of trial results using inverse odds of sampling
weights. \emph{American Journal of Epidemiology}, \textbf{186}(8),
1010--1014.
doi:\href{https://doi.org/10.1093/aje/kwx164}{10.1093/aje/kwx164}.

\bibitem[\citeproctext]{ref-westreich2017transportability}
Westreich, D, Edwards, JK, Lesko, CR, Stuart, E, and Cole, SR (2017b)
Transportability of trial results using inverse odds of sampling
weights. \emph{American Journal of Epidemiology}, \textbf{186}(8),
1010--1014.

\end{CSLReferences}



\end{document}
