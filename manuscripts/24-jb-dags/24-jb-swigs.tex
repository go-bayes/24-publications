% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Causal Inference: Interaction, Mediation, and Time-Varying Treatments},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Causal Inference: Interaction, Mediation, and Time-Varying
Treatments}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-06-10}
\begin{document}
\maketitle
\begin{abstract}
The analysis of `moderation', `interaction', `mediation', and
`longitudinal growth' is widespread in the human sciences, yet subject
to confusion. To clarify these concepts, it is essential to state causal
estimands, which requires specifying counterfactual contrasts for a
target population on an appropriate scale. Once causal estimands are
defined, we must consider their identification. I employ causal directed
acyclic diagrams (causal DAGs) and Single World Intervention Graphs to
elucidate identification workflows. I show that when multiple treatments
exist, common methods for statistical inference, such as multi-level
regressions and statistical structural equation models, cannot typically
recover the causal quantities we seek. By framing and addressing causal
questions of interaction, mediation, and time-varying treatments
properly, we can expose the limitations of popular methods and guide
researchers to a clearer understanding of the phenomena that animate our
interests. \textbf{KEYWORDS}: \emph{Causal Inference}; \emph{DAGs};
\emph{Evolution}; \emph{Mediation}; \emph{Moderation};
\emph{Longitudinal Growth}; Single World Intervention Graphs,
\emph{SWIGs}; \emph{Time-varying Treatments}
\end{abstract}

\subsection{Introduction}\label{id-introduction}

The young Charles Darwin was a keen fossil hunter and amateur geologist.
In August 1831, he accompanied the geologist Adam Sedgwick to the
Glyderau mountain range in northern Wales.

\begin{quote}
We spent many hours in Cwm Idwal, \ldots{} but neither of us saw a trace
of the wonderful glacial phenomena all around us; we did not notice the
plainly scored rocks, the perched boulders, the lateral and terminal
moraines. Yet these phenomena are so conspicuous that \ldots{} a house
burnt down by fire did not tell its story more plainly than did this
valley. If it had still been filled by a glacier, the phenomena would
have been less distinct than they now are.
(\citeproc{ref-darwin1887life}{Darwin 1887}: p.25)
\end{quote}

This `striking instance of how easy it is to overlook phenomena, however
conspicuous' (\citeproc{ref-darwin1887life}{Darwin 1887}: p.25) is cited
in cultural evolution to emphasise the importance of theory for
organising observations (\citeproc{ref-wilson2008evolution}{Wilson
2008}). However, the importance of theory to scientific discovery
carries broader relevance: it applies to the statistical methods
scientists routinely apply to the data they collect. Without a clear
framework that relates statistical models to observations, the
understanding we seek from our data remains elusive.

Across many human sciences, we apply statistical models to data and
report `moderation', `interaction', `mediation', and `longitudinal
growth'. How are we to interpret the results of these models? It is
often unclear. The confidence with which investigators report findings
does not make interpretation any clearer. The problem is that
investigators are typically interested in causal questions. However,
lacking the associations we obtain from our statistical models may
hallucinate true causal association and their signs
(\citeproc{ref-westreich2013}{Westreich and Greenland 2013}). As such,
it is often unclear whether the associations we obtain from our
statistical models are evidence for association, much less causation.

There is good news. Progress in the health sciences, computer science,
and economics has led to a common vocabulary with robust workflows that
allow investigators to formulate causal questions that may be addressed
with data, to evaluate the assumptions under which consistent estimates
may be obtained, to construct valid statistical estimators of these
quantities, and then -- at the end of the workflow -- to apply
statistical models. This conceptual framework is anchored in a
foundation of mathematical proofs that enable investigators to clarify,
communicate, and evaluate causal questions using observational data. The
consensus that has emerged in causal inference during the past several
decades is, in my view, as wide-ranging in its implications for the
human sciences as the theory of glaciation was to geology, or as
Darwin's theory of evolution was to biology. By reformulating questions
of interaction, mediation, and time-varying treatments as causal
questions, I hope to persuade those who are new to causal inference of
the framework's interest, relevance, and power.

Several excellent resources are available that clarify workflows for
causal inference, from stating causal questions to communicating results
(\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024};
\citeproc{ref-tlverse_handbook}{Laan \emph{et al.} 2023};
\citeproc{ref-montgomery2018}{Montgomery \emph{et al.} 2018};
\citeproc{ref-morgan2014}{Morgan and Winship 2014};
\citeproc{ref-neal2020introduction}{Neal 2020};
\citeproc{ref-pearl2009a}{Pearl 2009}; \citeproc{ref-grf2024}{Tibshirani
\emph{et al.} 2024}; \citeproc{ref-vanderweele2015}{VanderWeele 2015}).

Here, my ambition is modest.

\hyperref[id-sec-1]{Part 1} considers how to ask causal questions when
our interest is in comparing effect magnitudes between groups (effect
modification).

\hyperref[id-sec-2]{Part 2} considers how to ask causal questions when
our interest is in evaluating the joint effects of two independent
interventions (interaction).

\hyperref[id-sec-3]{Part 3} considers how to ask causal questions when
our interest is in evaluating the joint effects of two dependent
interventions (mediation analysis).

\hyperref[id-sec-4]{Part 4} considers how to ask causal questions when
our interest is in evaluating two or more sequential treatments of the
same kind (time-varying treatments).

I begin with a brief introduction to key concepts and terminology.

\subsubsection{Fundamental Assumptions for Causal
Inference}\label{fundamental-assumptions-for-causal-inference}

Consider indicators \(A\) and \(Y\) measuring states of the world. For
unit \(i\), we say that \(A_i\) causes \(Y_i\) if changing \(A_i\) from
one level, say \(A_i = a^*\), to another level, \(A_i = a\), leads to a
different outcome for \(Y_i\). We assume \(A_i\) occurs before \(Y_i\).
To compare these outcomes, we use the notation \(Y_i(\tilde{a})\), which
represents the outcome for unit \(i\) under the treatment level
\(A_i = \tilde{a}\). To determine whether \(Y_i(\tilde{a})\)
quantitatively differs under two treatment levels on the difference
scale, we would compute the contrast \(Y_i(a^*) - Y_i(a)\). If
\(Y_i(a^*) - Y_i(a) \neq 0\), we would say there is causal effect of
\(A\) on \(Y\) for individual \(i\). Following convention, we call \(A\)
the `treatment' or `exposure' and \(Y\) the `outcome'. Note that, for
any given application of \(A\) for unit \(i\), we can only observe one
level of treatment. Therefore, we refer to \(Y_i(a^*) - Y_i(a) \neq 0\)
as a counterfactual contrast, or equivalently, as a contrast of
potential outcomes. We note that because an individual may only receive
one of two treatments at any given time, individual causal effects
cannot generally be observed. However, when certain assumptions are
satisfied, we may compute average treatment effects by aggregating
individual observations under different treatment conditions. For a
binary treatment, the difference in the average of the potential
outcomes under two different treatment levels for the population from
which a sample is drawn may be expressed as the difference in mean
outcomes: \(\mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]\) or equivalently as the
average of the differences of the potential outcomes:
\(\mathbb{E}[Y(1) - Y(0)]\). This counterfactual contrast represents the
quantity obtained from an ideally conducted randomised controlled trial,
any common cause of the treatment and the outcome would occur only by
chance. There are three fundamental assumptions for computing average
treatment effects that, although generally satisfied in an ideally
randomised experiment may not be satisfied in observational or `real
world' data:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Causal Consistency}: Treatment levels remain consistent within
  the treatment arms to be compared. There must be at least two arms.
\item
  \textbf{(Conditional) Exchangeability}: Covariates that might affect
  outcomes under treatment are balanced across all arms (implied by
  randomisation).
\item
  \textbf{Positivity}: Each covariate that might affect treatment in the
  target population has a non-zero probability of being observed within
  each treatment condition (refer to Westreich and Cole
  (\citeproc{ref-westreich2010}{2010}); Bulbulia \emph{et al.}
  (\citeproc{ref-bulbulia2023a}{2023})).
\end{enumerate}

Note that we speak of an `ideal' experiment because real-world
experiments may fail these assumptions
(\citeproc{ref-bulbulia_2024_experiments}{Bulbulia 2024a};
\citeproc{ref-hernan2017per}{Hern치n \emph{et al.} 2017}). Our interest
here is restricted to observational or `real world' data.

\subsubsection{Schematic Workflow for Inferring Causal Effects from
Real-World Data Before Stating Statistical Estimators and Performing
Statistical
Analysis}\label{schematic-workflow-for-inferring-causal-effects-from-real-world-data-before-stating-statistical-estimators-and-performing-statistical-analysis}

In causal inference, we do not apply statistical models to data until
after we have stated a causal question and considered whether and how
the question may be identified from the data.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{State a well-defined intervention.} Clearly define the
  treatment (or equivalently exposure) that states the hypothetical
  intervention to which all population members will be exposed. The
  intervention `weight loss' is a vaguely stated intervention because
  there are many ways one can lose weight -- exercise, diet, depression,
  cancer, amputation, and others. The intervention `weight loss by at
  least 30 minutes of vigorous exercise each data' is more clearly
  defined
  (\citeproc{ref-hernan2008aObservationalStudiesAnalysedLike}{Hern치n
  \emph{et al.} 2008}).
\item
  \textbf{State a well-defined outcome.} Specify the outcome measure so
  that a causal contrast is interpretable. `Well-being' is a vaguely
  stated outcome. The outcome, `Psychological distress measured one year
  after the intervention using the Kessler-6 distress scale
  (\citeproc{ref-kessler2002}{Kessler \emph{et al.} 2002})' is more
  clearly defined.
\item
  \textbf{Clarify the target population.} Define the population to whom
  the results will generalise. The eligibility criteria for a study will
  define the source population from which units in the study are
  sampled. However, sampling from the source population may yeild a
  study population that differs from the source population in variables
  that modify the effects of treatment
  (\citeproc{ref-dahabreh2019generalizing}{Dahabreh \emph{et al.} 2019};
  \citeproc{ref-dahabreh2019}{Dahabreh and Hern치n 2019};
  \citeproc{ref-stuart2018generalizability}{Stuart \emph{et al.} 2018}).
  Investigators may also seek to generalise beyond the source
  population, which requires additional assumptions and may require
  additional knowledge (\citeproc{ref-bareinboim2013general}{Bareinboim
  and Pearl 2013}; \citeproc{ref-bulbulia2024wierd}{Bulbulia 2024b};
  \citeproc{ref-dahabreh2019}{Dahabreh and Hern치n 2019};
  \citeproc{ref-deffner2022}{Deffner \emph{et al.} 2022};
  \citeproc{ref-westreich2017transportability}{Westreich \emph{et al.}
  2017}).
\item
  \textbf{Evaluate whether treatment groups, conditional on measured
  covariates, are exchangeable.} The potential outcomes must be
  independent of treatment conditional on measured covariates
  (\citeproc{ref-angrist2009mostly}{Angrist and Pischke 2009};
  \citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024};
  \citeproc{ref-morgan2014}{Morgan and Winship 2014};
  \citeproc{ref-neal2020introduction}{Neal 2020}).
\item
  \textbf{Ensure treatments to be compared satisfy causal consistency.}
  The versions of treatment over which a causal effect is estimated must
  be independent of the versions of the potential outcomes to be
  compared conditional on measured covariates
  (\citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024};
  \citeproc{ref-vanderweele2013}{VanderWeele and Hernan 2013}).
\item
  \textbf{Check if the positivity assumption is satisfied.} There must
  be a non-zero probability of receiving each treatment level at every
  level of covariate required to satisfy the conditional exchangeability
  assumption, and if there are many versions of treatment, to satisfy
  the causal consistency assumption
  (\citeproc{ref-westreich2010}{Westreich and Cole 2010}).
\item
  \textbf{Ensure that the measures relate to the scientific questions at
  hand.} And in particular, evaluate structural features of measurement
  error bias (\citeproc{ref-bulbulia2024wierd}{Bulbulia 2024b};
  \citeproc{ref-hernan2024WHATIF}{Hernan and Robins 2024}).
\item
  \textbf{Consider strategies to ensure the study group measured at the
  end of the study represents the target population.} If the study
  population differs in the distribution of variables that modify the
  effect of a treatment on the outcome at both the beginning and end of
  treatment, the study will be biased when there is a treatment effect;
  as such, investigators must develop strategies to address attrition,
  non-response, and structural sources of bias from measurement error
  (\citeproc{ref-bulbulia2024wierd}{Bulbulia 2024b}).
\item
  \textbf{Clearly communicate the reasoning, evidence, and
  decision-making that inform steps 1-8.} Provide transparent and
  thorough documentation of the causal inference process. This includes
  detailing the assumptions, disagreements, and decisions
  (\citeproc{ref-ogburn2021}{Ogburn and Shpitser 2021}).
\end{enumerate}

\subsubsection{Conventions Used in This
Article}\label{conventions-used-in-this-article}

Table~\ref{tbl-terminologylocalconventions} reports our variables.
Table~\ref{tbl-terminologygeneral} describes our graphical conventions.
Here, we use two types of graphical tools to clarify causal questions:
causal directed acyclic graphs and Single World Intervention Graphs.

\begin{table}

\caption{\label{tbl-terminologylocalconventions}Terminology}

\centering{

\terminologylocalconventions

}

\end{table}%

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologygeneral

}

\end{table}%

Throughout, we will repeat our terminology and graphical conventions as
they are used. To begin, we define the following:

\begin{itemize}
\item
  \textbf{Node}: or equivalently a `variable,' denotes properties or
  characteristics of units within a population. In causal directed
  acyclic graphs, we draw nodes with respect to features in a
  \emph{target population}, which is the population for whom we seek
  causal inferences (\citeproc{ref-suzuki2020}{Suzuki \emph{et al.}
  2020}). A time-indexed node, \(X_t\), allows us to index measurements
  within time intervals \(t \in 1\dots T\), denoting relative
  chronology. If relative timing is not known, we may use
  \(X_{\phi t}\). The directions of arrows on a causal directed acyclic
  graph imply causation, and causation implies temporal order.
\item
  \textbf{Arrow} (\(\rightarrowNEW\)): Denotes a causal relationship
  from the node at the base of the arrow (a `parent') to the node at the
  tip of the arrow (a `child'). In causal directed acyclic graphs, we
  refrain from drawing an arrow from treatment to outcome to avoid
  asserting a causal path from \(A\) to \(Y\). Our purpose is to
  ascertain whether causality can be identified for this path. All other
  nodes and paths, including the absence of nodes and paths, are
  typically assumed.
\item
  \textbf{Boxed Variable} \(\boxed{X}\): Denotes conditioning or
  adjustment for \(X\).
\end{itemize}

Judea Pearl demonstrated that causal dependencies in a directed acyclic
graph could be evaluated using observable probability distributions
according to rules known as `d-separation'
(\citeproc{ref-pearl1995}{Pearl 1995}, \citeproc{ref-pearl2009a}{2009}).

The rules, presented in Table~\ref{tbl-terminologydirectedgraph}, are as
follows:

\begin{enumerate}[a)]
     \item  {\bf Fork rule} ($B \leftarrowNEW \boxed{A} \rightarrowNEW C$): $B$ and $C$ are independent when conditioning on $A$: ($B \coprod C \mid A$).
     \item  {\bf Chain rule} ($A \rightarrowNEW \boxed{B} \rightarrowNEW C$): Conditioning on $B$ blocks the path between $A$ and $C$: ($A \coprod C \mid B$).
     \item  {\bf Collider rule} ($A \rightarrowNEW \boxed{C} \leftarrowNEW B$): $A$ and $B$ are independent until conditioning on $C$, which introduces dependence: ($A \cancel{\coprod} B \mid C$). 
 \end{enumerate}

From these rules, Pearl derived a `backdoor adjustment theorem', which
provides an identification algorithm for causal identification based on
the structural assumptions encoded in a causal directed acyclic graph
Pearl (\citeproc{ref-pearl2009a}{2009}): In a causal directed acyclic
graph (DAG), a set of variables \(L\) satisfies the backdoor adjustment
theorem relative to the treatment \(A\) and the outcome \(Y\) if \(L\)
blocks every path between \(A\) and \(Y\) that contains an arrow
pointing into \(A\) (a backdoor path). Formally, \(L\) must:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Not be a descendant of \(A\).
\item
  Block all backdoor paths from \(A\) to \(Y\).
\end{enumerate}

If \(L\) satisfies these conditions, the causal effect of \(A\) on \(Y\)
is identified by conditioning on
\(\boxed{L}\)(\citeproc{ref-pearl2009a}{Pearl 2009}). Here, I will
assume readers are familiar with causal directed acyclic graphs.
Accessible introductions to causal directed acyclic graphs can be found
in Pearl (\citeproc{ref-pearl2009a}{2009}); Barrett
(\citeproc{ref-barrett2021}{2021}); McElreath
(\citeproc{ref-mcelreath2020}{2020}); Neal
(\citeproc{ref-neal2020introduction}{2020}); Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}); Bulbulia
(\citeproc{ref-bulbulia2023}{2023}). (For an introduction to Single
World Intervention Graphs, used below, refer to Richardson and Robins
(\citeproc{ref-richardson2013}{2013a}); Richardson and Robins
(\citeproc{ref-richardson2013swigsprimer}{2013b}).)

\begin{table}

\caption{\label{tbl-terminologydirectedgraph}Elements of Causal Graphs}

\centering{

\terminologydirectedgraph

}

\end{table}%

\newpage{}

\subsection{Part 1: Interaction as
`Effect-Modification'}\label{id-sec-1}

We have said that in causal inference, we must explicitly define our
causal question before applying statistical models to data. What
question might the analysis of interaction answer? In causal inference,
we think of interaction in two ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Interaction as Effect-Modification from a Single
  Intervention}: We want to understand how an intervention varies in its
  effect across the strata of the target population in which we are
  interested. For example, we might ask: does the one-year effect of
  attending weekly religious service differ among people born in
  Australia compared with people born in Egypt? Note that here, we do
  not imagine intervening on birthplace.
\item
  \textbf{Interaction as Joint Intervention}: We want to understand
  whether the combined effects of two treatments administered together
  differ from the separate effect of each treatment acting alone. For
  example, we might ask: does the one-year effect of attending weekly
  religious service and the one-year effect of being at least one
  standard deviation above population average wealth differ from not
  attending any religious service and being at the population average in
  wealth? Here there are two interventions that might act individually,
  separately, or in concert.
\end{enumerate}

\hyperref[id-sec-1]{Part 1} considers interaction as
effect-modification. Readers who do not wish to use the `effect
modification' may prefer the term `moderation.'

\subsubsection{Effect-Modification}\label{effect-modification}

First, we define the `sharp-null hypothesis' as the supposition that
there is no effect of the exposure on the outcome for any unit in the
target population. Unless the sharp-null hypothesis is false, there may
be effect modification (Bulbulia
(\citeproc{ref-bulbulia2024wierd}{2024b})). The variability of
individual units cannot be directly evaluated: recall each unit may
receive only one treatment. However, the variability within groups of
units may be quantified and compared. For any study worth conducting, we
cannot evaluate whether the sharp-null hypothesis is false (otherwise,
why conduct the study?). Therefore, we must assume that treatment
effects may be heterogeneous. We might seek to qualitatively evaluate
such heterogeneity (refer to Tibshirani \emph{et al.}
(\citeproc{ref-grf2024}{2024}); Vansteelandt and Dukes
(\citeproc{ref-vansteelandt2022a}{2022})). Alternatively, we might seek
to compare the effects of interventions between groups.

\begin{table}

\caption{\label{tbl-terminologyeffectmodification}Conventions for
representing effect modification}

\centering{

\terminologyeffectmodification

}

\end{table}%

Table~\ref{tbl-terminologyeffectmodification} describes conventions to
clarify how to ask a causal question of effect-modification. We assume
no confounding of the treatment on the outcome and that \(A\) has been
randomised (i.e.~\(\mathcal{R} \rightarrowNEW A\)). As such, we will not
use causal directed acyclic graphs to evaluate a treatment effect. We
will assume \(\mathcal{R}  \to A \to Y\).

To sharpen focus on our interest in effect modification, we will not
draw a causal arrow from the direct effect modifier \(F\) to the outcome
\(Y\). This convention is specific to this article. (Refer to Hernan and
Robins (\citeproc{ref-hernan2024WHATIF}{2024}), pp.~126-127, for a
discussion of `noncausal' arrows.)

\begin{table}

\caption{\label{tbl-terminologyeffectmodificationtypes}Effect
Modification}

\centering{

\terminologyeffectmodificationtypes

}

\end{table}%

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_1\),
we represent that \(F\) is a direct effect modifier for the effect of
\(A\) on \(Y\). The open arrow indicates that we are not attributing
causality to \(F\). Because our estimand does not involve intervening on
\(Z\), there is no need to close its backdoor paths. Note that if \(F\)
were to affect \(A\), we could still estimate the effect-modification of
\(A\) on \(Y\) because \(F\) has no causal interpretation. However, if
\(A\) were to cause \(F\), and \(F\) were to cause \(Y\), then by the
chain rule (recall Table~\ref{tbl-terminologygeneral}
\(\mathcal{G}_4\)), conditioning on \(F\) would bias the effect estimate
of \(A\) on \(Y\).

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_2\),
we represent that \(F\) is an unobserved direct effect modifier of \(A\)
to \(Y\). When the distribution of direct effect modifiers \(F\) differs
between two populations and effect modification is non-linear, marginal
treatment effects between populations will generally differ and will not
easily transport from one population to another. The concept of an
average treatment effect has no meaning without a population over which
the effect marginalises. This point, although obvious, has profound
implications when investigators seek to assess whether their research
generalises; refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), Bulbulia
(\citeproc{ref-bulbulia2024wierd}{2024b}). For example, if the study
population differs in the distribution of features that modify a
treatment effect, and no correction is applied, effect estimates will be
biased for the target population in at least one measure of effect
(\citeproc{ref-bulbulia2024wierd}{Bulbulia 2024b};
\citeproc{ref-greenland2009commentary}{Greenland 2009};
\citeproc{ref-lash2020}{Lash \emph{et al.} 2020})

We present two candidate effect modifiers in
Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_3\).
Notice that whether a variable is an effect modifier also depends on
which other variables are included in the model. Here, \(F\) is a direct
effect modifier and \(G\), a descendant of \(F\), is an indirect effect
modifier. Suppose we were interested in whether treatment effects vary
(on the difference scale) within levels of \(F\). For example, imagine
\(F\) is childhood deprivation, \(G\) is educational achievement, \(A\)
is a government educational initiative, and \(Y\) is recycling. If we
were to condition on \(F\), we would not observe effect modification by
education \(G\) for the effect of the government initiative \(A\) on
recycling behaviour \(Y\): \(\boxed{F}\) blocks the path
\(G \association \boxed{F} \association Y\).

We present the same causal structure in
Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_4\).
However, we do not condition on the direct effect modifier \(F\), but
rather condition only on \(G\), the indirect effect modifier. In this
scenario, we would find that the effectiveness of the government
initiative \(A\) on recycling behaviour \(Y\) varies by educational
achievement \(G\). Thus, we would observe \(G\) as an effect modifier
because this path is open: \(G \association F \association Y\).

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_5\),
suppose we add another variable to our model, depression, denoted by
\(B\). We imagine \(B\) to be a stable trait or that investigators
measured childhood depression (that is, \(B\) precedes \(G\)). Suppose
we do not condition on the direct effect modifier \(F\) (childhood
deprivation), but we condition on educational attainment (\(G\)) and
depression (\(B\)). In this graph, \(G\) is a collider of \(F\) and
\(B\). Thus, conditioning on \(G\) (but not \(F\)) opens a path from
\(B \association G \association Z \association Y\). The investigators
would find evidence for effect modification by depression on the
effectiveness of the government intervention \(A\) on recycling (\(Y\)).
However, they should not interpret this result to mean that if levels of
depression were to change within the population the treatment effect
would change. \(B\) is not causally related to \(Y\) in this scenario.
Here, association is not causation.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}_6\),
we will not find evidence for effect modification for \(B\) and \(G\)
because conditioning on \(F\) blocks the flow of information that was
open in \(\mathcal{G}_4\) and \(\mathcal{G}_5\). This again underscores
the relativity of effect modification to (1) the structure of causality
in the world and (2) a researcher's statistical modelling strategy.

These examples reveal the power---and simplicity---of causal diagrams to
`transform the obvious'. Using causal directed acyclic graphs and
Pearl's rules of d-separation, it is clear that the analysis of effect
modification cannot be conducted without reference to an assumed causal
order and an explicit statement about which variables within that order
investigators have included in their statistical models
(\citeproc{ref-vanderweele2012}{VanderWeele 2012}). Investigators and
policymakers might make incorrect decisions without understanding effect
modification. For more on the topic of effect modification, refer to
(\citeproc{ref-suzuki2013counterfactual}{Suzuki \emph{et al.} 2013};
\citeproc{ref-vanderweele2012}{VanderWeele 2012};
\citeproc{ref-vanderweele2007}{VanderWeele and Robins 2007}).

\subsubsection{Example Showing Scale Dependence of
Effect-Modification}\label{example-showing-scale-dependence-of-effect-modification}

Suppose we are interested in whether treatment varies across levels of
another variable, an effect modifier. We next illustrate how causal
inferences about the presence or absence of effect modification depend
on the scale that is used to measure the contrast. We show that an
effect modifier on the ratio scale may not be an effect modifier on the
difference scale, and vice versa.

Recall individual treatment effects are not observed. Assume a binary
treatment is randomised, and we have \(A = a \in \{0,1\}\). We are
interested in comparing the magnitude of this treatment effect across
two levels of \(F = f \in \{0,1\}\).

We define the average treatment effects for each group under each
intervention as follows: \[
\mathbb{E}[Y \mid A = 0, F = 1] = \mu_{01}, \quad \mathbb{E}[Y \mid  A = 1, F = 1] = \mu_{11}
\] \[
\mathbb{E}[Y \mid  A = 0, F = 0] = \mu_{00}, \quad \mathbb{E}[Y \mid A = 1, F = 0] = \mu_{10}
\]

The treatment effect for each group on the difference scale (absolute
scale) is given:

\[
\text{ATE}_{F = 0} = \mu_{10} - \mu_{00}
\]

\[
\text{ATE}_{F = 1} = \mu_{11} - \mu_{01}
\]

The treatment effect on the ratio scale (relative scale) for each group
is:

\[
\text{RR}_{F = 0} = \frac{\mu_{10}}{\mu_{00}}
\] \[
\text{RR}_{F = 1} = \frac{\mu_{11}}{\mu_{01}}
\]

We say there is effect modification on the difference scale if: \[
\text{ATE}_{Z = 1} \neq \text{ATE}_{Z = 0} \implies \mu_{11} - \mu_{01} \neq \mu_{10} - \mu_{00}
\]

We say there is effect modification on the ratio scale if: \[
\text{RR}_{Z = 1} \neq \text{RR}_{Z = 0} \implies \frac{\mu_{11}}{\mu_{01}} \neq \frac{\mu_{10}}{\mu_{00}}
\]

We have stated each causal question in relation to well-defined causal
contrast and population, here defined by membership in \(F\).

Imagine we obtain the following estimates from our study:

Outcomes under A = 0:

\begin{itemize}
\tightlist
\item
  \(\mu_{00} = 5\)
\item
  \(\mu_{01} = 15\)
\end{itemize}

Outcomes under A = 1:

\begin{itemize}
\tightlist
\item
  \(\mu_{10} = 10\)
\item
  \(\mu_{11} = 20\)
\end{itemize}

Next, we calculate the treatment effects on the difference and ratio
scales for each group:

\textbf{Difference Scale:}

\[
\text{ATE}_{F = 0} = \mu_{10} - \mu_{00} = 10 - 5 = 5
\] \[
\text{ATE}_{F = 1} = \mu_{11} - \mu_{01} = 20 - 15 = 5
\]

Both groups have the same treatment effect on the difference scale,
\(\text{ATE}_{F = 0} = \text{ATE}_{F = 1} = 5\). We conclude there is no
evidence for effect modification on the difference scale.

\textbf{Ratio Scale:} \[
\text{RR}_{F = 0} = \frac{\mu_{10}}{\mu_{00}} = \frac{10}{5} = 2.00
\] \[
\text{RR}_{F = 1} = \frac{\mu_{11}}{\mu_{01}} = \frac{20}{15} \approx 1.33
\]

The treatment effect on the ratio scale is different between the two
groups, \(\text{RR}_{F = 0} = 2 \neq \text{RR}_{F = 1} \approx 1.33\).
Hence, we find evidence for effect modification on the ratio scale.

The discrepancy in evidence for effect modification depending on the
scale we choose arises because the two scales measure different aspects
of the treatment effect: the absolute difference in outcomes versus the
relative change in outcomes. Parallel considerations apply to the
analysis of interaction, where we imagine a joint intervention. We next
consider interaction as a joint intervention.

\subsection{Part 2: Interaction}\label{id-sec-2}

\subsubsection{Introducing Single World Intervention
Graphs}\label{introducing-single-world-intervention-graphs}

When evaluating evidence for interaction, we must assess whether the
combined effects of two treatments differ from the unique effects of
each treatment relative to a baseline where neither treatment is
administered. Understanding multiple interventions can be facilitated by
using Single World Intervention Graphs (SWIGs)
(\citeproc{ref-richardson2013}{Richardson and Robins 2013a}).

SWIGs employ Pearl's rules of d-separation but offer additional benefits
by graphically representing the complex factorisations required for
identification, presenting distinct interventions in separate graphs.
The first advantage is \textbf{greater precision and clarity}: SWIGs
allow us to consider identification conditions for each counterfactual
outcome individually. Such precision is useful because identification
conditions may differ for one, but not another, of the treatments to be
compared. Node-splitting also makes it easier to determine
identification conditions that are obscured in causal directed acylic
graphs, for an example refer to \hyperref[id-app-c]{Appendix C}). The
second advantage \textbf{Single World Intervention Graphs unify the
potential outcomes framework with Pearl's structural causal model
framework}: any causal relationship that can be represented in a causal
directed acyclic graph can als be represented in a Single World
Intervention Graph (\citeproc{ref-richardson2013swigsprimer}{Richardson
and Robins 2013b}).

\begin{table}

\caption{\label{tbl-swigtable}Single World Interventions Graphs
(\(\mathcal{G}_{3-4}\)) present separate causal diagrams for each
treatment to be contrasted. A Single World Intervention Template
(\(\mathcal{G}_{2}\)) is a `graph value function' that produces the
individual counterfactual graphs
(\citeproc{ref-richardson2013}{Richardson and Robins 2013a}).
Contrastingly, causal directed acyclic graphs, such as
\(\mathcal{G}_1\), require positing interventional distributions. The
formalism that underpins these interventional distributions is
mathematically equivalent to that of the potential outcomes framework,
assuming the errors of the underlying structural causal models that
define the nodes on which interventions occur are independent
(\citeproc{ref-richardson2013}{Richardson and Robins 2013a}). SWIGs not
only allow us to evaluate identification when errors are not
independent, but they also permit the comparison of distinct
interventions to our causal diagram. This is particularly useful when
considering more than one point intervention. An example of is provided
in \hyperref[id-app-b]{Appendix B}.}

\centering{

\swigtable

}

\end{table}%

\paragraph{Single World Intervention Graphs Work by
Node-Splitting}\label{single-world-intervention-graphs-work-by-node-splitting}

We create a Single World Intervention Graph by `node-splitting' at each
intervention such that the random variable that is intervened upon is
presented on one side and the level at which the random variable is
fixed is presented on the other.

Consider a template graph Table~\ref{tbl-swigtable} \(\mathcal{G}\).
Applying node-splitting to \(A\) involves creating separate graphs for
each value of \(A\) to be contrasted.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{SWIG for \(A\) = 0}: Denoted as \(\mathcal{G}_{A=0}\), this
  graph shows the hypothetical scenario where \(A\) is set to 0.
\item
  \textbf{SWIG for \(A\) = 1}: Denoted as \(\mathcal{G}_{A=1}\), this
  graph shows the hypothetical scenario where \(A\) is set to 1.
\end{enumerate}

In these graphs, the node corresponding to the outcome \(A\) is split,
relabelled with the random and fixed component, and then each node that
follows is labelled with the fixed component until the next
intervention. Here, \(Y\) is the only variable to follow \(A\) and it is
relabelled either \(Y(0)\) or \(Y(1)\) corresponding to whether \(A=1\)
or \(A=0\); hence \(Y\) is relabelled as either \(Y(0)\) or \(Y(1)\).
Note that we do not place both \(Y(0)\) and \(Y(1)\) on the same Single
World Intervention Graph because the variables are not jointly observed.
Hence, we evaluate \(Y(0)\coprod A = 0| L\) and
\(Y(1)\coprod A = 1 | L\) separately.

\subsubsection{Interaction as a Joint
Intervention}\label{interaction-as-a-joint-intervention}

We now use Single World Intervention Graphs (SWIGs) to clarify the
concept of causal interaction as a joint intervention.

Consider two treatments, denoted as \(A\) and \(B\), and a single
outcome, \(Y\). A joint intervention causal interaction examines whether
the combined effect of \(A\) and \(B\) on \(Y\) (denoted as \(Y(a,b)\))
is greater than, less than, or equal to the effect of each individual
treatment. What does this mean?

First, we obtain the expected outcomes when the entire target population
is treated at each level of the treatments to be compared. These
potential outcomes are illustrated in Table~\ref{tbl-interactionpuzzle}:

\begin{itemize}
\tightlist
\item
  Table~\ref{tbl-interactionpuzzle} \(\mathcal{G}_1\): Neither treatment
  \(A\) nor treatment \(B\) is given.
\item
  Table~\ref{tbl-interactionpuzzle} \(\mathcal{G}_2\): Both treatment
  \(A\) and treatment \(B\) are given.
\item
  Table~\ref{tbl-interactionpuzzle} \(\mathcal{G}_3\): Treatment \(A\)
  is given, and treatment \(B\) is not given.
\item
  Table~\ref{tbl-interactionpuzzle} \(\mathcal{G}_4\): Treatment \(A\)
  is not given, and treatment \(B\) is given.
\end{itemize}

By comparing these expected outcomes, we can determine the presence and
nature of causal interaction between treatments \(A\) and \(B\) with
respect to the outcome \(Y\).

\begin{table}

\caption{\label{tbl-interactionpuzzle}}

\centering{

\captionsetup{labelsep=none}

\interactionpuzzle

}

\end{table}%

\subsubsection{Example}\label{example}

Consider the effect of beliefs in big Gods (exposure \(A\)) and a
culture's monumental architecture (exposure \(B\)) on social complexity
(outcome \(Y\)). Both interventions have equal status; we are not
investigating effect modification of one by the other. The interventions
must be well-defined. We must state, understand, and obtain measures for
the quantities `big Gods', `monumental architecture', and `social
complexity' measured at a clearly stated time interval after the
interventions are first observed.

We need to state a population and scale to assess the individual and
combined effects of \(A\) and \(B\). The units in the study draw from
this population---say they are the societies of primary urban genesis
(\citeproc{ref-wheatley1971pivot}{Wheatley 1971}). We look for evidence
of causal interaction on the difference scale. Evidence for interaction
would be present if the following inequality were to hold. Where,

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[Y(1,1)]\): mean outcome for those jointly exposed to both
  treatments, big Gods and big architecture.
\item
  \(\mathbb{E}[Y(1,0)]\): mean outcome for those exposed only to the
  treatment big Gods.
\item
  \(\mathbb{E}[Y(0,1)]\): mean outcome for those exposed only to the
  treatment big architecture.
\item
  \(\mathbb{E}[Y(0,0)]\): mean outcome for those exposed to neither
  treatment, big Gods nor big architecture.
\end{itemize}

Suppose outcomes are well-defined. We say there is evidence for
interaction on the additive scale if

\[
\bigg(\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) - \bigg[ \bigg(\underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) + \bigg(\underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \bigg)\bigg] \neq 0 
\]

This equation simplifies to

\[ 
\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} + \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \neq 0 
\]

A positive value would indicate evidence for additive interaction. A
negative value would indicate evidence for sub-additive interaction. A
value near zero would imply no reliable evidence for interaction.

Table~\ref{tbl-interactionpuzzle} presents each counterfactual
intervention. We can read from the graphs that identification in each
\(\mathcal{G}_{\Tilde{a}, \Tilde{b}}\) requires conditioning on all
confounders of \(A\), \(L_A\), and all confounders of \(B\), \(L_B\).

As with effect modification, evidence for causal interaction may differ
depending on the measurement scale one chooses to assess it
(\citeproc{ref-vanderweele2012}{VanderWeele 2012};
\citeproc{ref-vanderweele2014}{VanderWeele and Knol 2014}). Evidence for
the strength of a causal effect estimate for interaction in the presence
of effect modification will differ depending on whether the effect is
measured on the ratio scale as opposed to the difference scale (see:
VanderWeele and Knol (\citeproc{ref-vanderweele2014}{2014}), who
recommends using the causal difference scale for most policy settings).

Note that if \(A\) and \(B\) were to affect each other, we would need to
collect time series data and estimate causal effects using causal
mediation analysis. Indeed, if there has been a co-evolution of
religious culture, political and religious theatres, and urban
density---as archaeologists have long reported
(\citeproc{ref-decoulanges1903}{De Coulanges 1903};
\citeproc{ref-wheatley1971pivot}{Wheatley 1971})---mediation analysis is
better motivated. However, the demands for causal mediation analysis are
more stringent than those of causal interaction analysis. We consider
these next.

\subsection{Part 3: Causal Mediation Analysis}\label{id-sec-3}

In 1992, Robins and Greenland demonstrated that decomposing the total
effect into natural direct and indirect effects clarifies the objectives
of causal mediation analysis (\citeproc{ref-robins1992}{Robins and
Greenland 1992}). This landmark paper has been to mediation analysis of
what ``On the Origin of Species'' has been to evolutionary biology.
However, mediation analysis in the human sciences is rife with
confusion. The primary source of this confusion is applying statistical
models to data without first defining the causal quantities of interest.
Associations derived from mediation analysis do not necessarily imply
causation and are typically uninterpretable. This section outlines how
to formulate causal questions in mediation analysis.

\subsubsection{Defining a Mediation Analysis
Estimand}\label{defining-a-mediation-analysis-estimand}

To understand causal mediation, we deconstruct the total effect into
natural direct and indirect effects.

Again, the total effect of treatment \(A\) on outcome \(Y\) is defined
as the difference between potential outcomes when the treatment is
applied versus when it is not. The estimand for the total (or average,
or `marginal') treatment effect is given:

\[
\text{Total Treatment Effect} = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
\]

The total effect can be further decomposed into direct and indirect
effects, addressing questions of mediation. The potential outcome
\(Y(1)\), considering the mediator, expands to:

\[ 
\mathbb{E}[Y(1)] = \mathbb{E}[Y(1, M(1))]
\]

This considers the effect of the exposure \(A = 1\) and the mediator at
its natural value when \(A = 1\). Similarly, the potential outcome
\(\mathbb{E}[Y(0)]\), considering the mediator, expands to:

\[ 
\mathbb{E}[Y(0)] = \mathbb{E}[Y(0, M(0))]
\]

This quantity denotes the effect of exposure \(A = 0\) and the mediator
at its natural value when \(A = 0\).

Next, we clarify our estimand by decomposing the Total Effect (TE) into
the Natural Direct Effect (NDE) and the Natural Indirect Effect (NIE).

\textbf{Natural Direct Effect (NDE)} is the effect of the treatment on
the outcome while maintaining the mediator at the level it would have
been if the treatment had not been applied:

\[
\text{Natural Direct Effect} = \textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]
\]

Here, the counterfactual quantities not directly realised in the data
are highlighted in blue: \(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\).
Notice we add this term to the potential outcomes when \(A = 0\),
recalling \(\mathbb{E}[Y(0, M(0))] = Y(0)\).

\textbf{Natural Indirect Effect (NIE)} is the effect of the exposure on
the outcome that is mediated. To obtain these quantities, we compare the
potential outcome \(Y\) under treatment, where the mediator assumes its
natural level under treatment, with the potential outcome when the
mediator assumes its natural value under no treatment:

\[
\text{Natural Indirect Effect} = \mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}
\]

Here, the counterfactual quantities not directly realised in the data
are again highlighted in blue:
\(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\). Notice we subtract this
term from the potential outcomes when \(A = 1\), recalling
\(\mathbb{E}[Y(1, M(1))] = \mathbb{E}[Y(1)]\).

By rearranging this decomposition, we find that the total effect (TE) is
the sum of the NDE and NIE. This is shown by adding and subtracting the
term \(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\) to our equation:

\[
\text{Total Effect (TE)} = \underbrace{\bigg\{\mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\bigg\}}_{\text{Natural Indirect Effect (NIE)}} + \underbrace{\bigg\{\textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]\bigg\}}_{\text{Natural Direct Effect (NDE)}}
\]

\begin{table}

\caption{\label{tbl-mediationpuzzle}In causal mediation, the quantities
that we require to obtain natural direct and indirect effects, namely
\(\mathbb{E}[Y\big(1,M(0)\big)]\), cannot be experimentally observed
because we cannot treat someone and observe the level of their mediator
if they were not treated.}

\centering{

\mediationpuzzle

}

\end{table}%

Table~\ref{tbl-mediationpuzzle} presents a conceptual challenge for
causal mediation analysis. Suppose we randomise a binary treatment
\(A \in \{0,1\}\). Although randomising \(A\) does not ensure there is
no confounding of the mediator/outcome path, we assume no unmeasured
confounding for either the treatment or the mediator. (We will relax
this assumption in the next section.)

Table~\ref{tbl-mediationpuzzle} \(\mathcal{G}_1\) is a Single World
Intervention Template (SWIT), which generates Single World Intervention
Graphs (SWIGs) for each condition.

Table~\ref{tbl-mediationpuzzle} \(\mathcal{G}_2\) presents
counterfactual outcomes for condition \(A = 0\); here, the natural value
of \(M\) is \(M(a = 0)\), and the counterfactual outcome is given by
\(Y\big(\textcolor{cyan}{0}, M(\textcolor{cyan}{0})\big)\).

Table~\ref{tbl-mediationpuzzle} \(\mathcal{G}_3\) presents
counterfactual outcomes for condition \(A = 1\); here, the natural value
of \(M\) is \(M(a = 1)\), and the counterfactual outcome is given by
\(Y\big(\textcolor{cyan}{1}, M(\textcolor{cyan}{1})\big)\).

These Single World Intervention Graphs clarify that we cannot identify
natural direct and indirect effects from observations on individual
units under treatment because \(\mathbb{E}[Y(1, M(0))]\) is not
observable. (\citeproc{ref-shi2021}{Shi \emph{et al.} 2021};
\citeproc{ref-steen2017}{Steen \emph{et al.} 2017};
\citeproc{ref-valeri2014}{Valeri \emph{et al.} 2014};
\citeproc{ref-vanderweele2015}{VanderWeele 2015};
\citeproc{ref-vanderweele2014a}{VanderWeele and Vansteelandt 2014};
\citeproc{ref-vansteelandt2012}{Vansteelandt \emph{et al.} 2012}).
Expressing these quantities requires a counterfactual framework. Here,
we see that a counterfactual formulation of mediation analysis has made
the familiar strange. However, under assumptions, we can sometimes
recover natural direct and indirect effects from data
(\citeproc{ref-vanderweele2015}{VanderWeele 2015}), given that our
interest is in contrasts obtained for the target population, not for
individuals, where we assume no causal effects are directly observed.

\subsubsection{Assumptions of Causal Mediation
Analysis}\label{assumptions-of-causal-mediation-analysis}

Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\) presents a Single
World Intervention Template (SWIT) that specifies the assumptions
required for inferring natural direct and indirect effects. This
template highlights that, when estimating natural mediated effects, we
only intervene on the treatment. Therefore, we must infer the mediated
effect of the treatment under the condition that the mediator is set to
zero.

Additionally, Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\) also
clarifies the assumptions needed for inferring controlled direct
effects, where the mediator is fixed to a level specified by the
investigators. In this scenario, we obtain causal contrasts by fixing
variables to specific states.

Consider the hypothesis that cultural beliefs in `big Gods' influence
social complexity, with political authority mediating. Assuming we have
well-defined interventions and outcomes, what requirements are necessary
to decompose this causal effect into natural direct and indirect
effects?

\begin{table}

\caption{\label{tbl-medationassumptions}Assumptions of Causal Mediation
Analysis}

\centering{

\mediationassumptionsswig

}

\end{table}%

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{No unmeasured exposure-outcome confounder}
\end{enumerate}

This requirement is expressed as \(Y(a,m) \coprod A | L\). After
accounting for the covariates in set \(L\), there must be no unmeasured
confounders influencing cultural beliefs in Big Gods (\(A\)) and social
complexity (\(Y\)). For example, if our study examines the causal effect
of cultural beliefs in Big Gods (the exposure) on social complexity (the
outcome), and the covariates in \(L\) include factors such as geographic
location and historical context, we need to ensure that these covariates
effectively block any confounding paths between \(A\) and \(Y\). The
relevant path in Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\)
is shown `confounder of path \(A \to Y\).'

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{No unmeasured mediator-outcome confounder}
\end{enumerate}

This requirement is expressed as \(Y(a,m) \coprod M | Z\). After
controlling for the covariate set \(Z\), we must ensure that no other
unmeasured confounders affect political authority (\(M\)) and social
complexity (\(Y\)). For instance, if trade networks affect political
authority and social complexity, we must account for trade networks to
block the path linking our mediator and outcome. Furthermore, we must
assume the absence of any other confounders for the mediator-outcome
path. The relevant path in Table~\ref{tbl-medationassumptions}
\(\mathcal{G}_1\) is shown `confounder \(M \to Y\).'

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{No unmeasured exposure-mediator confounder}
\end{enumerate}

This requirement is expressed as: \(M(a) \coprod A | Q\). After
controlling for the covariate set \(Q\), we must ensure that no
additional unmeasured confounders affect cultural beliefs in Big Gods
(\(A\)) and political authority (\(M\)). For example, the capability to
construct large ritual theatres may influence the belief in Big Gods and
the level of political authority. If we have indicators for this
technology measured before the emergence of Big Gods (these indicators
being \(Q\)), we must assume that accounting for \(Q\) closes the
backdoor path between the exposure and the mediator. The relevant path
in Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\) is shown
`confounder of path \(A \to M\).'

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{No mediator-outcome confounder affected by the exposure}
\end{enumerate}

This requirement is expressed as: \(Y(a,m) \coprod M(a^*) | Z\). We must
ensure that no variables confounding the relationship between political
authority and social complexity in \(Z\) are themselves influenced by
the cultural beliefs in Big Gods (\(A\)). For example, when studying the
effect of cultural beliefs in Big Gods (\(A\), the exposure) on social
complexity (\(Y\), the outcome) as mediated by political authority
(mediator), there can be no un-modelled factors, such as trade networks
(\(Z\)), that influence both political authority and social complexity
and are themselves affected by the belief in Big Gods. The relevant path
in Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\) is shown
`confounder of path \(M \to Y\).'

Assumption 4, that there is no exposure-induced confounding in the
mediator-outcome relationship, often poses a considerable obstacle for
causal mediation analysis. When the exposure influences a confounder of
the mediator and outcome, we face a dilemma. Without adjusting for this
confounder, a backdoor path between the mediator and the outcome remains
open. However, by adjusting for it, we partially obstruct the path
between the exposure and the mediator, leading to bias. In this setting,
we cannot recover the natural direct and indirect effects directly from
any observational data and may need to settle for investigating
controlled direct effects, which stipulate fixed values for the
mediator, or consider estimating the jointly mediated effects of \(Z\)
and \(M\) together, or evaluate an analogue to the natural direct effect
by obtaining random draws from the paths for which the relevant paths
are obscured (\citeproc{ref-Diaz2023}{D캼패az \emph{et al.} 2023};
\citeproc{ref-robins2010alternative}{Robins and Richardson 2010};
\citeproc{ref-vanderweele2014effect}{VanderWeele \emph{et al.} 2014};
\citeproc{ref-vanderweele2015}{VanderWeele 2015};
\citeproc{ref-vanderweele2017mediation}{VanderWeele and Tchetgen
Tchetgen 2017}; \citeproc{ref-vo2024recanting}{Vo \emph{et al.} 2024}).

Notice again that assumptions for causal effect estimation are
considerably stricter than has been appreciated in the structural
equation modelling traditions. Natural direct effect estimates and
natural indirect effect estimates require conceptualising a
counterfactual that is never directly observed from the data, namely:
\(\textcolor{blue}{Y(1, M(0))}\). See: VanderWeele
(\citeproc{ref-vanderweele2015}{2015}).

\subsubsection{Controlled Direct
Effects}\label{controlled-direct-effects}

Consider another identification challenge, as described in template
Table~\ref{tbl-medationassumptions} \(\mathcal{G}_1\). Suppose we aim to
understand the effect of a stringent pandemic lockdown, \(A\), on
psychological distress, \(Y\), focusing on trust in government, \(M\),
as a mediator. Further, suppose that pandemic lockdowns may plausibly
influence attitudes towards the government through pathways that also
affect psychological distress. For instance, people might trust the
government more when it provides income relief payments, which may also
reduce psychological distress.

Under the rules of d-separation, conditioning on income relief payments,
denoted as \(Z\), would attenuate the natural value of the mediator,
trust in the government, under exposure to the lockdowns. This blocking
of the exposure's effect is represented by the causal path
\(A \to \boxed{Z} \rightarrowdotted Y\). Additionally, the causal path
\(A \to \boxed{Z} \rightarrowdotted M\) partially blocks the exposure's
effect on the mediator. However, if we do not condition on \(Z\), the
path from trust in government, \(M\), to psychological distress, \(Y\),
would be confounded by the common cause \(Z\), hence:
\(Y \leftarrowred Z \rightarrowred M\).

In such a scenario, it would not be feasible to consistently decompose
the total effect of the exposure (pandemic lockdowns) on the outcome
(psychological distress) into natural indirect and direct effects.
However, if all other assumptions were to hold, we might obtain an
unbiased estimate for the controlled direct effect of pandemic lockdowns
on psychological distress as a fixed level of government trust.

Table~\ref{tbl-medationassumptions} \(\mathcal{G}_2\) presents the
weaker assumptions required to identify a controlled direct effect. We
might examine the effect of the pandemic lockdown if we could intervene
and set everyone's trust in government to, say, one standard deviation
above the baseline, compared with fixing trust in government to the
average level at baseline. We might use modified treatment policies
(described below) that specify interventions as functions of the data.
For instance, we might investigate interventions that `shift only those
whose mistrust of government was below the mean level of trust at
baseline and compare these potential outcomes with those observed.'
Asking and answering precisely formulated causal questions such as this
might lead to clearer policy advice, especially in situations where
policymakers can influence public attitudes towards the government; see:
Williams and D칤az (\citeproc{ref-williams2021}{2021}); D칤az \emph{et
al.} (\citeproc{ref-duxedaz2021}{2021}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2022}{2022}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2023}{2023}).

In any case, I hope this discussion of causal mediation analysis
clarifies that it would be unwise to simply examine the coefficients
obtained from structural equation models and interpret them as
meaningful as in statistical mediation analysis. To answer any causal
question, we must first state it, with respect to clearly defined
counterfactual contrasts and a target population. Once we state our
causal question, we find have no guarantees that these coefficients are
interpretable (\citeproc{ref-vanderweele2015}{VanderWeele 2015}).

For those interested in statistical estimators for causal mediation
analysis, I recommend visiting the CMAverse website
\url{https://bs1125.github.io/CMAverse/articles/overview.html}, accessed
12 December 2023. This excellent resource provides comprehensive
documentation, software, and practical examples, including sensitivity
analyses. Next, we will consider more complex scenarios that involve
feedback between treatments and confounders across multiple time points,
settings in which traditional statistical methods also fail to provide
valid causal inferences.

\subsection{Part 4: Time-fixed and Time-Varying Sequential Treatments
(Treatment Strategies, Modified Treatment Policies)}\label{id-sec-4}

Our discussion of causal mediation analysis focused on how effects from
two sequential exposures may combine to influence an outcome.

This concept can be expanded to investigate the causal effects of
multiple sequential exposures, referred to as `treatment regimes',
`treatment strategies', or `modified treatment policies'. Researchers
often use longitudinal growth and multi-level models in many human
sciences, where longitudinal data are collected. How should we interpret
the coefficients of these models?

As before, to answer a causal question, we must first clearly state it.
This involves specifying the counterfactual contrast of interest,
including the treatments to be compared, the scale on which the contrast
will be computed, and the population for whom inferences are valid.
Without this precision, our statistical models lack clear
interpretations.

\subsubsection{Worked Example: Does Marriage Affect
Happiness?}\label{worked-example-does-marriage-affect-happiness}

Richard McElreath considers whether marriage affects happiness and
provides a simulation to clarify how age structure complicates causal
inferences (\citeproc{ref-mcelreath2020}{McElreath 2020 pp. 123--144}).
We expand on this example by first clearly stating a causal question and
then considering how time-varying confounding invalidates the use of
standard estimation methods such as multi-level regression.

Let \(A_t = 1\) denote the state of being married at time \(t\) and
\(A_t = 0\) denote the state of not being married, where
\(t \in \{0, 1, \tau\}\) and \(\tau\) is the end of the study.
\(Y_\tau\) denotes happiness at the end of study. For simplicity, assume
this concept is well-defined and measured without error.

The table below reveals four treatment strategies and six causal
contrasts that we may estimate for each treatment strategy combination.

\textbf{Treatment Strategies:}

\begin{longtable}[]{@{}ll@{}}
\caption{Table outlines four fixed treatment regimens and six causal
contrasts in time-series data where exposure varies. These labels apply
only to the two time
points.}\label{tbl-regimens-marriage}\tabularnewline
\toprule\noalign{}
Regime & Counterfactual Outcome \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Regime & Counterfactual Outcome \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Always married & \(Y(1,1)\) \\
Never married & \(Y(0,0)\) \\
Divorced & \(Y(1,0)\) \\
Gets married & \(Y(0,1)\) \\
\end{longtable}

\textbf{Causal Contrasts:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{Table outlines four fixed treatment regimens and six causal
contrasts in time-series data where exposure varies. These labels apply
only to the two time
points.}\label{tbl-regimens-marriage-contrasts}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Comparison
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Comparison
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Always married vs.~Never married & \(\mathbb{E}[Y(1,1) - Y(0,0)]\) \\
Always married vs.~Divorced & \(\mathbb{E}[Y(1,1) - Y(1,0)]\) \\
Always married vs.~Gets married & \(\mathbb{E}[Y(1,1) - Y(0,1)]\) \\
Never married vs.~Divorced & \(\mathbb{E}[Y(0,0) - Y(1,0)]\) \\
Never married vs.~Gets married & \(\mathbb{E}[Y(0,0) - Y(0,1)]\) \\
Divorced vs.~Gets married & \(\mathbb{E}[Y(1,0) - Y(0,1)]\) \\
\end{longtable}

To answer our causal question, we need to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Specify Treatments}: Define the treatment strategies being
  compared (e.g., always married vs.~never married).
\item
  \textbf{Define the Contrast}: State the counterfactual contrast of
  interest (e.g., \(\mathbb{E}[Y(1,1) - Y(0,0)]\)).
\item
  \textbf{Identify the Population}: Specify the population for which the
  inferences are valid (e.g., adults aged 20-40).
\end{enumerate}

\begin{table}

\caption{\label{tbl-swigtabledeveloped}Single World Intervention Graph
for sequential treatments.}

\centering{

\swigtabledeveloped

}

\end{table}%

\subsubsection{Time-Varying Confounding with Treatment-confounder
Feedback}\label{time-varying-confounding-with-treatment-confounder-feedback}

Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_1\) and
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_2\) represent two
subsets of possible confounding structures for a treatment regime
conducted over two intervals. Covariates in \(L_t\) denote measured
confounders, and \(U\) denotes unmeasured confounders. \(A_t\) denotes
the treatment, `Marriage Status,' at time \(t\). \(Y\) denotes
`Happiness' measured at the end of the study.

Consider the structure of confounding presented in
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_1\). To close the
backdoor path from \(A_1\) to \(Y\), we must condition on \(L_0\). To
close the backdoor path from \(A_2\) to \(Y\), we must condition on
\(L_2\). However, \(L_2\) is a collider of treatment \(A_1\) and
unmeasured confounders, such that conditioning on \(L_2\) opens a
backdoor path between \(A_1\) and \(Y\). This path is highlighted in
red:
\(A_1 \associationred L_2({\mathbf{\tilde{a_1}}}) \associationred U \associationred ({\mathbf{\tilde{a_1}, \tilde{a_2}}})\).

If Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_1\) faithfully
represents causality, it might seem that we cannot obtain valid
inferences for any of the six causal contrasts we have defined. Indeed,
using standard methods, we could not obtain valid causal inferences.
However, Robins (\citeproc{ref-robins1986}{1986}) first described a
consistent estimation function that can be constructed where there is
time-varying confounding (refer to Robins \emph{et al.}
(\citeproc{ref-robins2004effects}{2004}), Hern치n \emph{et al.}
(\citeproc{ref-hernan2004STRUCTURAL}{2004})).

Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_3\) presents a Single
World Intervention Template that clarifies how identification may be
obtained in fixed treatment regimes where there is time-varying
confounding as observed in Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}_1\). When constructing a Single World Intervention Graph
(or Template), we obtain factorisations for counterfactual outcomes
under a specific treatment regime by employing `node-splitting,' such
that all nodes following an intervention are relabelled as
counterfactual states under the preceding intervention. After
node-splitting, a fixed intervention is no longer a random variable.
Thus, under fixed treatment regimes, the counterfactual states that
follow an intervention are independent of the states that occur before
node-splitting if there are no backdoor paths into the random partition
of the node that has been split.

If all backdoor paths are closed into the random partitions of the nodes
on which interventions occur, we can graphically verify that the
treatment is independent of the counterfactual outcome for that
intervention node. Where there are multiple interventions, we ensure
sequential exchangeability at the following node---which we likewise
split and relabel---by closing all backdoor paths between the random
portion of the following treatment node. We have sequential independence
if, for each intervention node, all backdoor paths are closed (refer to
Robins and Richardson (\citeproc{ref-robins2010alternative}{2010});
Richardson and Robins (\citeproc{ref-richardson2013swigsprimer}{2013b});
Richardson and Robins (\citeproc{ref-richardson2023potential}{2023})).

The Single World Intervention Template
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_3\) makes it clear that
sequential identification may be obtained. \(A_1\) is d-separated from
\(Y\) by conditioning on \(L_0\); \(A_2\) is d-separated from \(Y\) by
conditioning on \(L_2\).

Notice that we cannot estimate the combined effect of a treatment
strategy over \(A_1\) and \(A_2\) by employing regression, multi-level
regression, statistical structural equation models, or propensity score
matching. However, special estimators may be constructed (refer to
Robins (\citeproc{ref-robins1986}{1986}); Robins \emph{et al.}
(\citeproc{ref-robins2004effects}{2004}); Van Der Laan and Rose
(\citeproc{ref-vanderlaan2011}{2011}); D캼패az \emph{et al.}
(\citeproc{ref-diaz2021nonparametric}{2021})). For recent reviews of
special estimators refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}); Chatton \emph{et al.}
(\citeproc{ref-chatton2020}{2020}); Van Der Laan and Rose
(\citeproc{ref-vanderlaan2018}{2018}); Chatton and Rohrer
(\citeproc{ref-chatton2024causal}{2024})).

\subsubsection{\texorpdfstring{Time-Varying Confounding \emph{without}
Treatment-Confounder
Feedback}{Time-Varying Confounding without Treatment-Confounder Feedback}}\label{time-varying-confounding-without-treatment-confounder-feedback}

Consider how we may have time-varying confounding in the absence of
treatment-confounder feedback. Suppose we are interested in computing a
causal effect estimate for a two-treatment `marriage' intervention on
`happiness'. We assume that all variables are well-defined, that
`marriage' can be intervened upon, that we have specified a target
population, and that our questions are scientifically interesting. Here,
we focus on the challenges in addressing certain causal questions with
time-varying confounding without treatment confounder feedback.
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_1\) presents such a
structure of time-varying confounding.

Let \(U_{AL}\) denotes an over-confident personality, an unmeasured
variable that is causally associated with decisions to marry early and
with income. We do not suppose that \(U_{AL}\) affects happiness. Taken
in isolation, \(U_{AL}\) is not a confounder.

Let \(L_t\) denote income. Suppose that income affects whether one stays
married. For example, suppose it takes wealth to divorce. We can sharpen
focus on risks of time-varying confounding by assuming that income
itself does not affect happiness. Even with this weaker assumption, we
shall see a problem arises.

\(U_{AY}\) denotes a common cause of income, \(L_2\), and of happiness
at the end of the study, \(Y\). For example, \(U_{AY}\) might denote
educational opportunities, which by supposition affects both income and
happiness. Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_2\) presents
the confounding structure for this problem in its simplest form. To
declutter, we remove the baseline measurement of \(L_0\), which we
assume to be measured.

Notice that in this example, there is no treatment-confounder feedback.
We have not imagined that marriage affects wealth, or even that wealth
affects happiness. To obtain valid causal inference for the effect of
\(A_2\) on \(Y\), we must adjust for \(L_2\) {[}otherwise:
\(A_t\associationred L_t \associationred U_{AL}\associationred Y(a)\){]}.
However, \(L_2\) is a collider of \(U_{AL}\) and \(U_{AY}\). In this
setting, adjusting for \(L_2\) opens the path:

\[
A_1 \associationred U_{AL} \associationred L_2({\mathbf{\tilde{a_1}}})  \associationred U_{AY} \associationred Y({\mathbf{\tilde{a_1}, \tilde{a_2}}})
\]

We have confounding without treatment-confounder feedback (refer to
Hernan and Robins (\citeproc{ref-hernan2024WHATIF}{2024}))

Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_4\) clarifies that
sequential exchangeability can be obtained in the fixed treatment
regime. To estimate the effect of \(A_2\) on \(Y\), we must condition on
\(L_2\). When estimating the effect of \(A_1\) on \(Y\), all backdoor
paths are closed because \(L_2({\mathbf{\tilde{a_1}}})\) is a collider,
and \(A_0 \coprod Y({\mathbf{\tilde{a_1}, \tilde{a_2}}})\). Note that
because a Singal World Intervention Template does not represent the
joint distributions of more than one treatment, treatment sequence, or
time-varying treatment, to evaluate the conditional independences we
must specify the interventions of interest for \(A_1\) and \(A_2\). That
is, we would need to evaluate at least two Single World Intervention
Graphs that correspond to the treatment level we wish to contrast. Note
further that because there is time-varying confounding, we cannot use
standard estimators such as multi-level regression or structural
equation models. Estimation must occur stepwise (refer, for example to
D캼패az \emph{et al.} (\citeproc{ref-diaz2021nonparametric}{2021}),
Williams and D칤az (\citeproc{ref-williams2021}{2021}).{]}

\subsubsection{Confounding Under Dynamic Treatment Strategies (Modified
Treatment
Policies)}\label{confounding-under-dynamic-treatment-strategies-modified-treatment-policies}

In a dynamic treatment strategy, or `modified treatment policy,' the
value at which a treatment is fixed is a function of events leading up
to it.

Suppose we were interested in the population average effect of divorce
on happiness if divorce was only permitted for those with incomes.

This question is easy to ask but deceptively difficult to answer. For
example, we cannot fit an interaction of time \(\times\) social status
\(\times\) marriage status because marital status might affect personal
wealth. Yet even if marriage did not affect personal wealth, as in
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_4\), regression would
not produce valid estimates for the counterfactual question we asked.

To sharpen focus, imagine that we obtained indicators of wealth at
baseline.

Suppose we want to consider the following fixed treatment strategy:

\(g^\phi(\cdot)\): remain married for at least two additional years:

\[
A_t^{+}(\mathbf{g}^\phi) = \mathbf{g}^\phi (A_{t}) = \begin{cases} 
   a_{1} = 1 & \\ 
   a_{2} = 1 &   
\end{cases}
\]

This regime is identified. The setting is identical to
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_3\) however with no
unmeasured variables and no arrow from \(A_1\) to \(L_2\).

However, every causal contrast requires a comparison of at least two
interventions.

We next consider the treatment policy \(g^{\lambda}(\cdot)\), divorce
only if one's personal wealth is at least 50\% greater than average and
one would have divorced in the absence of intervention; otherwise,
enforce marriage:

\[
A_t^{+}(\mathbf{g}^{\lambda}) = \mathbf{g}^{\lambda}(A_{t}) = \begin{cases} 
   a_{1} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_1 = 0 \\ 
   a_{2} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_2 = 0 \\ 
   a_{t} = 1 & \text{otherwise} 
\end{cases}
\]

Notice that for the treatment policy \(\mathbf{g}^\lambda(\cdot)\),
treatment is computed as a function of income at both the natural value
of \(A_t\) and of wealth \(L_t\). Again, to declutter our graphs, we
leave \(L\) at baseline off the graph, noting that adjustment at
baseline does not change the confounding structure.

Template Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_5\) presents
this confounding structure. To convey the dependence of the fixed node
on covariate history under treatment, we use Richardson and Robins
(\citeproc{ref-richardson2013}{2013a})`s conventions and draw a dashed
line (\(\rightarrowdottedgreen\)) to indicate paths from the variables
on which the time-varying treatment regime depends to the deterministic
portion of the intervention node. This strategy clarifies that setting
the treatment level requires information about prior variables,
including the 'natural value of the treatment' in the absence of any
intervention (\citeproc{ref-young2014identification}{Young \emph{et al.}
2014}).

The reason for noting these dependencies on a Single World Intervention
Graph (SWIG) is that such dependencies impose stronger identification
conditions. At every time \(t\), \(A_t\) must be conditionally
independent not only of the potential outcome at the end of the study
but also of any future variable that might lead to a non-causal
association between future treatments and the potential outcome at the
end of the study. We clarify this additional requirement for
\emph{strong sequential exchangeability} in the next section.

\paragraph{Identification of Dynamic Time-Varying Treatment Strategies
using an Extension of Robin's Dynamic
G-formula}\label{identification-of-dynamic-time-varying-treatment-strategies-using-an-extension-of-robins-dynamic-g-formula}

\hyperref[id-app-c]{Appendix C} describes Richardson and Robins
extension of Robins (\citeproc{ref-robins1986}{1986}) dynamic g-formula.
Essentially, the algorithm can be stated as follows.

\textbf{Step 1}: where \(\mathbf{g}(\cdot)\) is a modified treatment
policy, identify all the variables that influence the outcome
\(Y(\mathbf{g})\), excluding those that are current or past treatment
variables or covariates.

\textbf{Step 2}: For each treatment at time \(t\), check if the
treatment is independent of the variables identified in \textbf{Step 1},
after accounting for past covariates and treatments, in each Single
World Intervention Graph where the treatment values are fixed. This step
amounts to removing the dotted green arrows from the dynamic Single
World Intervention Graph in Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}_5\), and doing so gives us
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_4\). For each time
point, we recover a set of future counterfactual variables that includes
the potential outcome for the treatment regime under consideration,
\(Y(\mathbf{g})\), and other variables that the treatment might affect,
including the natural value of future treatments. All backdoor paths
must be closed to each member of this set of counterfactual variables.
We call the more stringent assumptions required for identification in
time-varying treatments (or equivalently longitudinal modified treatment
policies (\citeproc{ref-diaz2023lmtp}{D칤az \emph{et al.} 2023})):
\textbf{strong sequential exchangeability}.

Where:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{\(\mathbb{Z}_t(\mathbf{a}^*)\)}: denotes the subset of
  vertices in \(\mathcal{G}(\mathbf{a}^*)\) corresponding to
  \(\mathbb{Z}_t(\mathbf{g})\).
\item
  \textbf{\(A_t(\mathbf{a}^*) = a^*_t\)}: denotes the specific value of
  the treatment variable at time \(t\) under the intervention
  \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{L}}_t(\mathbf{a}^*)\)}: denotes the set of
  covariates up to time \(t\) under the intervention \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{A}}_{t-1}(\mathbf{a}^*)\)}: denotes the set of
  past treatment variables up to time \(t-1\) under the intervention
  \(\mathbf{a}^*\).
\end{enumerate}

Applying Richardson and Robins (\citeproc{ref-richardson2013}{2013a})'s
dynamic extended g-formula, we obtain the following sets of future
variables for which each current treatment must be independent:

\[
\begin{aligned}
\mathbb{Z}(\mathbf{g}) &= \{A_1, L_1(\mathbf{g}), A_1(\mathbf{g}), A_2(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_1(\mathbf{g}) &= \{A_1(\mathbf{g}), L_1(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_2(\mathbf{g}) &= \{Y(\mathbf{g})\}
\end{aligned}
\]

Having determined which variables must remain conditionally independent
of each treatment in a sequence of dynamic treatments to be compared, we
then consider whether strong sequential exchangeability holds. We do
this by inspecting template Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}_4\) (recall this is Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}_5\) without the dashed green arrows). On inspection of
\(\mathcal{G}_4\) (the dynamic SWIG without dashed green arrows), we
discover that this dynamic treatment strategy is not identified because
we have the following open backdoor path:

\[
A_1 \associationred U_{AL} \associationred L_2(\mathbf{g})
\]

We also have:

\[
A_1 \associationred U_{AL} \associationred L_2(\mathbf{g}) \associationred A_2(\mathbf{g})
\]

Strong sequential exchangeability fails for \(A_1\).

We might consider lowering our sights and estimating a fixed or
time-varying treatment strategy that can be identified.

Note that certain time-varying treatment strategies impose weaker
assumptions than time-fixed strategies. For example, with a continuous
intervention, we might consider intervening only if the observed
treatment does not reach a specific threshold, such as:

\[
\mathbf{g}^{\phi} (A_i) = \begin{cases}  
\mu_A & \text{if } A_i < \mu_A \\ 
A_i & \text{otherwise} 
\end{cases}
\]

This is a weaker intervention than setting everyone whose natural value
of treatment is above this threshold to precisely the threshold's value:

\[
\mathbf{g}^{\lambda} (A_i) = \begin{cases}   
\mu_A & \text{if } A_i \neq \mu_A \\ 
A_i & \text{otherwise} 
\end{cases}
\]

Whereas \(\mathbf{g}^{\lambda}\) sets everyone in the population to the
same treatment level, \(\mathbf{g}^{\phi}\) sets only those below a
certain threshold to a fixed level but does not estimate treatment
effects for those above (\citeproc{ref-hoffman2023}{Hoffman \emph{et
al.} 2023}). We can also write stochastic treatment functions
(\citeproc{ref-diaz2021nonparametric}{D캼패az \emph{et al.} 2021};
\citeproc{ref-diaz2012population}{Mu침oz and Van Der Laan 2012};
\citeproc{ref-vanderweele2014a}{VanderWeele and Vansteelandt 2014};
\citeproc{ref-young2014identification}{Young \emph{et al.} 2014}).

Of course, the details of every problem must be developed in relation to
the scientific context and the practical questions that address gaps in
present science. However, causal inference teaches us that the questions
we ask---seemingly coherent and tractable questions such as whether
marriage makes people happy---demand considerable scrutiny to become
interpretable. When such questions are made interpretable, causal
inference often reveals that answers may elude us, regardless of the
quality and abundance of our data, or even if we randomise
interventions. Modest treatment functions, however, might be more
credible and useful for many scientific and practical questions. Such
functions cannot be estimated using the models routinely taught in the
human sciences, such as multi-level modelling and statistical structural
equation modelling.

\subsection{Conclusions}\label{id-sec-5}

Philosophical interests in causality are ancient. Democritus once
declared, ``I would rather discover one cause than gain the kingdom of
Persia'' (\citeproc{ref-freeman1948ancilla}{Freeman 1948}). Hume
provided a general account of causality by referencing counterfactuals:
``\ldots{} where, if the first object had not been, the second never
would have existed'' (\citeproc{ref-hume1902}{Hume 1902}). However, it
was not until Jerzy Neyman's master's thesis that a quantitative
analysis of causality was formalised
(\citeproc{ref-neyman1923}{Splawa-Neyman 1990}). Remarkably, Neyman's
work went largely unnoticed until the 1970s, when Harvard statistician
Donald Rubin formalised what became known as the `Rubin Causal Model'
(also the Rubin-Neyman Causal Model) (\citeproc{ref-holland1986}{Holland
1986}; \citeproc{ref-rubin1976}{Rubin 1976}).

In 1986, Harvard statistician James Robins extended the potential
outcomes framework to time-varying treatments, laying the foundation for
powerful new longitudinal data science methods
(\citeproc{ref-robins1986}{Robins 1986}). Judea Pearl introduced
directed acyclic graphs, making identification problems transparent and
accessible to non-specialists (\citeproc{ref-pearl1995}{Pearl 1995}).
Robins and Richardson extended Pearl's graphical models to evaluate
counterfactual causal contrasts on graphs, building on Robins' earlier
work. Concurrently, the causal revolution in economics opened new,
fertile frontiers in causal data sciences. By the early 2000s, targeted
learning frameworks were being developed
(\citeproc{ref-vanderlaan2011}{Van Der Laan and Rose 2011}), along with
causal mediation analysis methods (\citeproc{ref-Diaz2023}{D캼패az \emph{et
al.} 2023}; \citeproc{ref-pearl2009a}{Pearl 2009};
\citeproc{ref-robins1992}{Robins and Greenland 1992};
\citeproc{ref-rudolph2024mediation}{Rudolph \emph{et al.} 2024};
\citeproc{ref-vanderweele2015}{VanderWeele 2015};
\citeproc{ref-vanderweele2014a}{VanderWeele and Vansteelandt 2014};
\citeproc{ref-vansteelandt2012}{Vansteelandt \emph{et al.} 2012}), and
techniques for analysing time-varying treatments
(\citeproc{ref-diaz2012population}{Mu침oz and Van Der Laan 2012};
\citeproc{ref-richardson2013}{Richardson and Robins 2013a};
\citeproc{ref-richardson2023potential}{Richardson and Robins 2023};
\citeproc{ref-robins1986}{Robins 1986};
\citeproc{ref-robins2008estimation}{Robins and Hernan 2008};
\citeproc{ref-robins1999}{Robins \emph{et al.} 1999};
\citeproc{ref-shpitser2022multivariate}{Shpitser \emph{et al.} 2022};
\citeproc{ref-young2014identification}{Young \emph{et al.} 2014}).

Readers should note that the causal inference literature contains
vigorous debates at the horizons of discovery. However, there is a
shared consensus about the foundations of causal inference and a common
conceptual and mathematical vocabulary within which to express
disagreements and accumulate progress---a hallmark of a productive
science.

Despite the progress and momentum of the causal revolution in certain
human sciences, many areas have yet to participate and benefit. The
demands for researchers to acquire new skills, coupled with the
intensive requirement for data collection, have significant implications
for research design, funding, and the accepted pace of scientific
publishing. To foster essential changes in causal inference education
and practice, the human sciences need to shift from a predominantly
output-focused, correlation-reporting culture to a slow, careful,
creative culture that promotes retraining and funds time-series data
collection. Such investments are worthwhile. Much as Darwin's theory
transformed the biological sciences from speculative taxonomy, causal
inference will transform the human sciences from butterfly collections
of correlations to causal inferential sciences capable of addressing the
causal questions that animate our curiosities.

\newpage{}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or deciding
to publish it.

\newpage{}

\paragraph{Appendix A: Glossary}\label{id-app-a}

\begin{table}

\caption{\label{tbl-gloassary}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\newpage{}

\subsection{Appendix B Single World Intervention Graphs Eludicate
Complex Identification Problems}\label{id-app-b}

\begin{table}

\caption{\label{tbl-pearltable}On the limitations of causal directed
acyclic graphs compared to Single World Intervention Graphs.}

\centering{

\pearltable

}

\end{table}%

According to Pearl (\citeproc{ref-pearl2009a}{2009}), example 11.3.3.
\(Y(x_0, x_1)\) is not independent of \(X_1\) given Z and \(X_0\).
Template \(\mathcal{G}_2\) and Single World Intervention Graphs
\(\mathcal{G}_2-6\) examine counterfactual independence. Counterfactual
nodes are obtained by node-splitting. \(\rightarrowlightgray\) denotes a
backdoor path that is closed when a treatment is fixed.
\(\rightarrowcyan\) highlights identifying paths for \(X_0 = x_0\) and
\(X_1 = x_1\). Robins and Richardson
(\citeproc{ref-robins2010alternative}{2010}) uses a variation of
\(\mathcal{G}_2\) to show that there is sequential exchangeability of
\(X_t \forall t: Y(x_1, x_0)\coprod X_0\) (unconditionally) and
\(Y(x_1, x_0)\coprod X_1(x_0) | Z(x_0), X_0\). By causal consistency
\(Z(x_0) = Z|X_0 = x_0\). Single world interventions
\(\mathcal{G}_{3-6}\) make this sequential exchangeability clear (refer
to Richardson and Robins (\citeproc{ref-richardson2013}{2013a})). Such
clarity is, in my view, an excellent reason to use Single World
Intervention Graphs.

\newpage{}

\subsection{Appendix C Richardson and Robin's Extended Dynamic
G-formula}\label{id-app-c}

Richardson and Robins (\citeproc{ref-richardson2013}{2013a}) propose an
extension of Robins (\citeproc{ref-robins1986}{1986})'s dynamic
g-formula for identifying causality under dynamic treatment regimes.
Here, I reproduce the key details of their identification algorithm. I
refer readers to Richardson and Robins
(\citeproc{ref-richardson2013}{2013a}) for the full algorithm and its
proofs.

First, define the set of counterfactual variables in our dynamic Single
World Intervention Graph (or Template):

\(\mathbb{A}^+(\mathbf{g})\): denotes the set of modified treatment
variables under a dynamic regime \(\mathbb{V}(\mathbf{g})\): denotes the
set of counterfactual nodes following treatments.
\(\mathbb{W}(\mathbf{g})\): denotes the combined set of all
counterfactual variables under a dynamic regime corresponding to
Table~\ref{tbl-swigtabledeveloped} \(\mathbf{G}_4\).

Richardson and Robins (\citeproc{ref-richardson2013}{2013a}) define this
set as follows:

\[
\mathbb{W}(\mathbf{g}) \equiv \mathbb{A}^+(\mathbf{g}) \cup \mathbb{V}(\mathbf{g})
\]

Next, at each intervention node \(t\), our task is to find all ancestors
of \(Y(\mathbf{g})\) in \(\mathbb{W}(\mathbf{g})\) that are not in the
set of current or past treatment covariates. Richardson and Robins
(\citeproc{ref-richardson2013}{2013a}) define this set as follows:

\[
\mathbb{Z}_t(\mathbf{g}) \equiv \text{an}_{\mathcal{G}(\mathbf{g})}(Y(\mathbf{g})) \setminus (\mathbb{L}_t(\mathbf{g}) \cup \mathbb{A}_t(\mathbf{g}) \cup \mathbb{A}^+(\mathbf{g}))
\]

Third, our task is to map \(\mathbb{Z}\) to a new Single World
Intervention Graph \(\mathcal{G}(\mathbf{a}^*)\), where the intervention
\(\mathbf{a}^*\) is a specific value of \(A = a\) assigned under
\(f^g(\cdot)\).

This new \texttt{dSWIG} or
\texttt{dynamic\ Single\ World\ Intervention\ Graph}
\(\mathcal{G}(\mathbf{a}^*)\) is simply the original dSWIG
\(\mathcal{G}(\mathbf{g})\) with the dashed arrows removed.

Fourth, our task is to ensure conditional independence of the treatment
\(A_t = a^*\) with members of the set \(\mathbb{Z}_t\), for all
\(\mathbf{a}^*\) (fixed nodes) and all time points \(t \in 1...\tau\),
where \(\tau\) is the end of the study. Richardson and Robins
(\citeproc{ref-richardson2013}{2013a}) define this set as follows:

\[
\mathbb{Z}_t(\mathbf{a}^*) \coprod I(A_t(\mathbf{a}^*) = a^*_t) \mid \bar{\mathbb{L}}_t(\mathbf{a}^*), \bar{\mathbb{A}}_{t-1}(\mathbf{a}^*) = \bar{\mathbf{a}^*}_{t-1}
\]

where the authors use \(I\) to denote the indicator function:

\[
I(A_k(\mathbf{a}^*) = a^*_t) = 
\begin{cases} 
1 & \text{if } A_k(\mathbf{a}^*) = a^*_t, \\
0 & \text{otherwise}.
\end{cases}
\]

where:

\begin{itemize}
\tightlist
\item
  \textbf{\(\mathbb{Z}_t(\mathbf{a}^*)\)}: denotes the subset of
  vertices in \(\mathcal{G}(\mathbf{a}^*)\) corresponding to
  \(\mathbb{Z}_t(\mathbf{g})\).
\item
  \textbf{\(A_t(\mathbf{a}^*) = a^*_t\)}: denotes the specific value of
  the treatment variable at time \(t\) under the intervention
  \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{L}}_t(\mathbf{a}^*)\)}: denotes the set of
  covariates up to time \(t\) under the intervention \(\mathbf{a}^*\).
\item
  \textbf{\(\bar{\mathbb{A}}_{t-1}(\mathbf{a}^*)\)}: denotes the set of
  past treatment variables up to time \(t-1\) under the intervention
  \(\mathbf{a}^*\).
\end{itemize}

In the example describe in Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}_4\), \(\mathbb{Z}_t(\mathbf{g})\), we apply Richardson and
Robins (\citeproc{ref-richardson2013}{2013a})'s dynamic extended
g-formula, and obtain:

\[
\begin{aligned}
\mathbb{Z}(\mathbf{g}) &= \{A_1, L_1(\mathbf{g}), A_1(\mathbf{g}), A_2(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_1(\mathbf{g}) &= \{A_1(\mathbf{g}), L_1(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_2(\mathbf{g}) &= \{Y(\mathbf{g})\}
\end{aligned}
\]

Then we check conditional independencies for each treatment on
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}_4\) (which is
\(\mathcal{G}_5\) without the dashed green arrows). We inspect this
template and learn the dynamic treatment strategy under consideration is
not identified.

\newpage{}

\subsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-angrist2009mostly}
Angrist, JD, and Pischke, J-S (2009) \emph{Mostly harmless econometrics:
An empiricist's companion}, Princeton University Press.

\bibitem[\citeproctext]{ref-bareinboim2013general}
Bareinboim, E, and Pearl, J (2013) A general algorithm for deciding
transportability of experimental results. \emph{Journal of Causal
Inference}, \textbf{1}(1), 107--134.

\bibitem[\citeproctext]{ref-barrett2021}
Barrett, M (2021) \emph{Ggdag: Analyze and create elegant directed
acyclic graphs}. Retrieved from
\url{https://CRAN.R-project.org/package=ggdag}

\bibitem[\citeproctext]{ref-bulbulia_2024_experiments}
Bulbulia, J (2024a) Confounding in experiments. \emph{PsyArXiv}.
doi:\href{https://doi.org/10.31234/osf.io/6rnj5}{10.31234/osf.io/6rnj5}.

\bibitem[\citeproctext]{ref-bulbulia2024wierd}
Bulbulia, J (2024b) The weirdest causal inferences: Why comparative
cultural research requires a causal understanding of measurement error
bias. \emph{PsyArXiv}.
doi:\href{https://doi.org/10.31234/osf.io/kj7rv}{10.31234/osf.io/kj7rv}.

\bibitem[\citeproctext]{ref-bulbulia2023}
Bulbulia, JA (2023) Causal diagrams (directed acyclic graphs): A
practical guide.

\bibitem[\citeproctext]{ref-bulbulia2023a}
Bulbulia, JA, Afzali, MU, Yogeeswaran, K, and Sibley, CG (2023)
Long-term causal effects of far-right terrorism in {N}ew {Z}ealand.
\emph{PNAS Nexus}, \textbf{2}(8), pgad242.

\bibitem[\citeproctext]{ref-chatton2020}
Chatton, A, Le Borgne, F, Leyrat, C, \ldots{} Foucher, Y (2020)
G-computation, propensity score-based methods, and targeted maximum
likelihood estimator for causal inference with different covariates
sets: a comparative simulation study. \emph{Scientific Reports},
\textbf{10}(1), 9219.
doi:\href{https://doi.org/10.1038/s41598-020-65917-x}{10.1038/s41598-020-65917-x}.

\bibitem[\citeproctext]{ref-chatton2024causal}
Chatton, A, and Rohrer, JM (2024) The causal cookbook: Recipes for
propensity scores, g-computation, and doubly robust standardization.
\emph{Advances in Methods and Practices in Psychological Science},
\textbf{7}(1), 25152459241236149.

\bibitem[\citeproctext]{ref-dahabreh2019}
Dahabreh, IJ, and Hern치n, MA (2019) Extending inferences from a
randomized trial to a target population. \emph{European Journal of
Epidemiology}, \textbf{34}(8), 719--722.
doi:\href{https://doi.org/10.1007/s10654-019-00533-2}{10.1007/s10654-019-00533-2}.

\bibitem[\citeproctext]{ref-dahabreh2019generalizing}
Dahabreh, IJ, Robins, JM, Haneuse, SJ, and Hern치n, MA (2019)
Generalizing causal inferences from randomized trials: Counterfactual
and graphical identification. \emph{arXiv Preprint arXiv:1906.10792}.

\bibitem[\citeproctext]{ref-darwin1887life}
Darwin, C (1887) \emph{The life and letters of charles darwin, volume i}
(F. Darwin, Ed.), New York: D. Appleton; Company. Retrieved from
\url{https://charles-darwin.classic-literature.co.uk/the-life-and-letters-of-charles-darwin-volume-i/}

\bibitem[\citeproctext]{ref-decoulanges1903}
De Coulanges, F (1903) \emph{La cit칠 antique: 칄tude sur le culte, le
droit, les institutions de la gr칟ce et de rome}, Hachette.

\bibitem[\citeproctext]{ref-deffner2022}
Deffner, D, Rohrer, JM, and McElreath, R (2022) A Causal Framework for
Cross-Cultural Generalizability. \emph{Advances in Methods and Practices
in Psychological Science}, \textbf{5}(3), 25152459221106366.
doi:\href{https://doi.org/10.1177/25152459221106366}{10.1177/25152459221106366}.

\bibitem[\citeproctext]{ref-duxedaz2021}
D칤az, I, Williams, N, Hoffman, KL, and Schenck, EJ (2021) Non-parametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association}.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-diaz2023lmtp}
D칤az, I, Williams, N, Hoffman, KL, and Schenck, EJ (2023) Nonparametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association},
\textbf{118}(542), 846--857.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-diaz2021nonparametric}
D캼패az, I, Hejazi, NS, Rudolph, KE, and Der Laan, MJ van (2021)
Nonparametric efficient causal mediation with intermediate confounders.
\emph{Biometrika}, \textbf{108}(3), 627--641.

\bibitem[\citeproctext]{ref-Diaz2023}
D캼패az, I, Williams, N, and Rudolph, KE (2023) \emph{Journal of Causal
Inference}, \textbf{11}(1), 20220077.
doi:\href{https://doi.org/doi:10.1515/jci-2022-0077}{doi:10.1515/jci-2022-0077}.

\bibitem[\citeproctext]{ref-freeman1948ancilla}
Freeman, K (1948) \emph{Ancilla to the pre-socratic philosophers},
Reprint edition, Cambridge, MA: Harvard University Press.

\bibitem[\citeproctext]{ref-greenland2009commentary}
Greenland, S (2009) Commentary: Interactions in epidemiology: Relevance,
identification, and estimation. \emph{Epidemiology}, \textbf{20}(1),
14--17.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernan2008aObservationalStudiesAnalysedLike}
Hern치n, MA, Alonso, A, Logan, R, \ldots{} Robins, JM (2008)
Observational studies analyzed like randomized experiments: An
application to postmenopausal hormone therapy and coronary heart
disease. \emph{Epidemiology}, \textbf{19}(6), 766.
doi:\href{https://doi.org/10.1097/EDE.0b013e3181875e61}{10.1097/EDE.0b013e3181875e61}.

\bibitem[\citeproctext]{ref-hernan2004STRUCTURAL}
Hern치n, MA, Hern치ndez-D칤az, S, and Robins, JM (2004) A structural
approach to selection bias. \emph{Epidemiology}, \textbf{15}(5),
615--625. Retrieved from \url{https://www.jstor.org/stable/20485961}

\bibitem[\citeproctext]{ref-hernan2017per}
Hern치n, MA, Robins, JM, et al. (2017) Per-protocol analyses of pragmatic
trials. \emph{N Engl J Med}, \textbf{377}(14), 1391--1398.

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and D칤az, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoffman2022}
Hoffman, KL, Schenck, EJ, Satlin, MJ, \ldots{} D칤az, I (2022) Comparison
of a target trial emulation framework vs cox regression to estimate the
association of corticosteroids with COVID-19 mortality. \emph{JAMA
Network Open}, \textbf{5}(10), e2234425.
doi:\href{https://doi.org/10.1001/jamanetworkopen.2022.34425}{10.1001/jamanetworkopen.2022.34425}.

\bibitem[\citeproctext]{ref-holland1986}
Holland, PW (1986) Statistics and causal inference. \emph{Journal of the
American Statistical Association}, \textbf{81}(396), 945--960.

\bibitem[\citeproctext]{ref-hume1902}
Hume, D (1902) \emph{Enquiries Concerning the Human Understanding: And
Concerning the Principles of Morals}, Clarendon Press.

\bibitem[\citeproctext]{ref-kessler2002}
Kessler, R~C, Andrews, G, Colpe, L~J, \ldots{} Zaslavsky, A~M (2002)
Short screening scales to monitor population prevalences and trends in
non-specific psychological distress. \emph{Psychological Medicine},
\textbf{32}(6), 959--976.
doi:\href{https://doi.org/10.1017/S0033291702006074}{10.1017/S0033291702006074}.

\bibitem[\citeproctext]{ref-tlverse_handbook}
Laan, M van der, Coyle, J, Hejazi, N, Malenica, I, Phillips, R, and
Hubbard, A (2023) \emph{Targeted learning in r: Causal data science with
the tlverse software ecosystem}, Collins Foundation Press. Retrieved
from \url{https://tlverse.org/tlverse-handbook/index.html}

\bibitem[\citeproctext]{ref-lash2020}
Lash, TL, Rothman, KJ, VanderWeele, TJ, and Haneuse, S (2020)
\emph{Modern epidemiology}, Wolters Kluwer. Retrieved from
\url{https://books.google.co.nz/books?id=SiTSnQEACAAJ}

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in {R} and {S}tan}, CRC press.

\bibitem[\citeproctext]{ref-montgomery2018}
Montgomery, JM, Nyhan, B, and Torres, M (2018) How conditioning on
posttreatment variables can ruin your experiment and what to do about
It. \emph{American Journal of Political Science}, \textbf{62}(3),
760--775.
doi:\href{https://doi.org/10.1111/ajps.12357}{10.1111/ajps.12357}.

\bibitem[\citeproctext]{ref-morgan2014}
Morgan, SL, and Winship, C (2014) \emph{Counterfactuals and causal
inference: Methods and principles for social research}, 2nd edn,
Cambridge: Cambridge University Press.
doi:\href{https://doi.org/10.1017/CBO9781107587991}{10.1017/CBO9781107587991}.

\bibitem[\citeproctext]{ref-diaz2012population}
Mu침oz, ID, and Van Der Laan, M (2012) Population intervention causal
effects based on stochastic interventions. \emph{Biometrics},
\textbf{68}(2), 541--549.

\bibitem[\citeproctext]{ref-neal2020introduction}
Neal, B (2020) Introduction to causal inference from a machine learning
perspective. \emph{Course Lecture Notes (Draft)}. Retrieved from
\url{https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf}

\bibitem[\citeproctext]{ref-ogburn2021}
Ogburn, EL, and Shpitser, I (2021) Causal modelling: The two cultures.
\emph{Observational Studies}, \textbf{7}(1), 179--183.
doi:\href{https://doi.org/10.1353/obs.2021.0006}{10.1353/obs.2021.0006}.

\bibitem[\citeproctext]{ref-pearl1995}
Pearl, J (1995) Causal diagrams for empirical research.
\emph{Biometrika}, \textbf{82}(4), 669--688.

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013a) Single world intervention graphs:
A primer. In, Citeseer. Retrieved from
\url{https://core.ac.uk/display/102673558}

\bibitem[\citeproctext]{ref-richardson2013swigsprimer}
Richardson, TS, and Robins, JM (2013b) Single world intervention graphs:
A primer. In \emph{Second UAI workshop on causal structure learning,
{B}ellevue, {W}ashington}, Citeseer. Retrieved from
\url{https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=07bbcb458109d2663acc0d098e8913892389a2a7}

\bibitem[\citeproctext]{ref-richardson2023potential}
Richardson, TS, and Robins, JM (2023) Potential outcome and decision
theoretic foundations for statistical causality. \emph{Journal of Causal
Inference}, \textbf{11}(1), 20220012.

\bibitem[\citeproctext]{ref-robins1986}
Robins, J (1986) A new approach to causal inference in mortality studies
with a sustained exposure period---application to control of the healthy
worker survivor effect. \emph{Mathematical Modelling}, \textbf{7}(9-12),
1393--1512.

\bibitem[\citeproctext]{ref-robins2008estimation}
Robins, J, and Hernan, M (2008) Estimation of the causal effects of
time-varying exposures. \emph{Chapman \& Hall/CRC Handbooks of Modern
Statistical Methods}, 553--599.

\bibitem[\citeproctext]{ref-robins1992}
Robins, JM, and Greenland, S (1992) Identifiability and exchangeability
for direct and indirect effects. \emph{Epidemiology}, \textbf{3}(2),
143--155.

\bibitem[\citeproctext]{ref-robins1999}
Robins, JM, Greenland, S, and Hu, F-C (1999) Estimation of the causal
effect of a time-varying exposure on the marginal mean of a repeated
binary outcome. \emph{Journal of the American Statistical Association},
\textbf{94}(447), 687--700.
doi:\href{https://doi.org/10.1080/01621459.1999.10474168}{10.1080/01621459.1999.10474168}.

\bibitem[\citeproctext]{ref-robins2004effects}
Robins, JM, Hern치n, MA, and SiEBERT, U (2004) Effects of multiple
interventions. \emph{Comparative Quantification of Health Risks: Global
and Regional Burden of Disease Attributable to Selected Major Risk
Factors}, \textbf{1}, 2191--2230.

\bibitem[\citeproctext]{ref-robins2010alternative}
Robins, JM, and Richardson, TS (2010) Alternative graphical causal
models and the identification of direct effects. \emph{Causality and
Psychopathology: Finding the Determinants of Disorders and Their Cures},
\textbf{84}, 103--158.

\bibitem[\citeproctext]{ref-rubin1976}
Rubin, DB (1976) Inference and missing data. \emph{Biometrika},
\textbf{63}(3), 581--592.
doi:\href{https://doi.org/10.1093/biomet/63.3.581}{10.1093/biomet/63.3.581}.

\bibitem[\citeproctext]{ref-rudolph2024mediation}
Rudolph, KE, Williams, NT, and Diaz, I (2024) {Practical causal
mediation analysis: extending nonparametric estimators to accommodate
multiple mediators and multiple intermediate confounders}.
\emph{Biostatistics}, kxae012.
doi:\href{https://doi.org/10.1093/biostatistics/kxae012}{10.1093/biostatistics/kxae012}.

\bibitem[\citeproctext]{ref-shi2021}
Shi, B, Choirat, C, Coull, BA, VanderWeele, TJ, and Valeri, L (2021)
CMAverse: A suite of functions for reproducible causal mediation
analyses. \emph{Epidemiology}, \textbf{32}(5), e20--e22.

\bibitem[\citeproctext]{ref-shpitser2022multivariate}
Shpitser, I, Richardson, TS, and Robins, JM (2022) Multivariate
counterfactual systems and causal graphical models. In
\emph{Probabilistic and causal inference: The works of {J}udea {P}earl},
813--852.

\bibitem[\citeproctext]{ref-neyman1923}
Splawa-Neyman (1990) On the application of probability theory to
agricultural experiments. Essay on principles. Section 9. \emph{English
Translation with Discussion, Statistical Science}, 463--480.

\bibitem[\citeproctext]{ref-steen2017}
Steen, J, Loeys, T, Moerkerke, B, and Vansteelandt, S (2017) Medflex: An
{R} package for flexible mediation analysis using natural effect models.
\emph{Journal of Statistical Software}, \textbf{76}, 1--46.

\bibitem[\citeproctext]{ref-stuart2018generalizability}
Stuart, EA, Ackerman, B, and Westreich, D (2018) Generalizability of
randomized trial results to target populations: Design and analysis
possibilities. \emph{Research on Social Work Practice}, \textbf{28}(5),
532--537.

\bibitem[\citeproctext]{ref-suzuki2013counterfactual}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2013) A
counterfactual approach to bias and effect modification in terms of
response types. \emph{BMC Medical Research Methodology}, \textbf{13}(1),
1--17.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-grf2024}
Tibshirani, J, Athey, S, Sverdrup, E, and Wager, S (2024) \emph{Grf:
Generalized random forests}. Retrieved from
\url{https://github.com/grf-labs/grf}

\bibitem[\citeproctext]{ref-valeri2014}
Valeri, L, Lin, X, and VanderWeele, TJ (2014) Mediation analysis when a
continuous mediator is measured with error and the outcome follows a
generalized linear model. \emph{Statistics in Medicine},
\textbf{33}(28), 4875--4890.

\bibitem[\citeproctext]{ref-vanderlaan2011}
Van Der Laan, MJ, and Rose, S (2011) \emph{Targeted Learning: Causal
Inference for Observational and Experimental Data}, New York, NY:
Springer. Retrieved from
\url{https://link.springer.com/10.1007/978-1-4419-9782-1}

\bibitem[\citeproctext]{ref-vanderlaan2018}
Van Der Laan, MJ, and Rose, S (2018) \emph{Targeted Learning in Data
Science: Causal Inference for Complex Longitudinal Studies}, Cham:
Springer International Publishing. Retrieved from
\url{http://link.springer.com/10.1007/978-3-319-65304-4}

\bibitem[\citeproctext]{ref-vanderweele2012}
VanderWeele, TJ (2012) Confounding and Effect Modification: Distribution
and Measure. \emph{Epidemiologic Methods}, \textbf{1}(1), 55--82.
doi:\href{https://doi.org/10.1515/2161-962X.1004}{10.1515/2161-962X.1004}.

\bibitem[\citeproctext]{ref-vanderweele2015}
VanderWeele, TJ (2015) \emph{Explanation in causal inference: Methods
for mediation and interaction}, Oxford University Press.

\bibitem[\citeproctext]{ref-vanderweele2013}
VanderWeele, TJ, and Hernan, MA (2013) Causal inference under multiple
versions of treatment. \emph{Journal of Causal Inference},
\textbf{1}(1), 1--20.

\bibitem[\citeproctext]{ref-vanderweele2014}
VanderWeele, TJ, and Knol, MJ (2014) A tutorial on interaction.
\emph{Epidemiologic Methods}, \textbf{3}(1), 33--72.

\bibitem[\citeproctext]{ref-vanderweele2007}
VanderWeele, TJ, and Robins, JM (2007) Four types of effect
modification: a classification based on directed acyclic graphs.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{18}(5), 561--568.
doi:\href{https://doi.org/10.1097/EDE.0b013e318127181b}{10.1097/EDE.0b013e318127181b}.

\bibitem[\citeproctext]{ref-vanderweele2017mediation}
VanderWeele, TJ, and Tchetgen Tchetgen, EJ (2017) Mediation analysis
with time varying exposures and mediators. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{79}(3),
917--938.

\bibitem[\citeproctext]{ref-vanderweele2014effect}
VanderWeele, TJ, Vansteelandt, S, and Robins, JM (2014) Effect
decomposition in the presence of an exposure-induced mediator-outcome
confounder. \emph{Epidemiology}, \textbf{25}(2), 300--306.

\bibitem[\citeproctext]{ref-vanderweele2014a}
VanderWeele, T, and Vansteelandt, S (2014) Mediation analysis with
multiple mediators. \emph{Epidemiologic Methods}, \textbf{2}(1),
95--115.

\bibitem[\citeproctext]{ref-vansteelandt2012}
Vansteelandt, S, Bekaert, M, and Lange, T (2012) Imputation strategies
for the estimation of natural direct and indirect effects.
\emph{Epidemiologic Methods}, \textbf{1}(1), 131--158.

\bibitem[\citeproctext]{ref-vansteelandt2022a}
Vansteelandt, S, and Dukes, O (2022) Assumption-lean inference for
generalised linear model parameters. \emph{Journal of the Royal
Statistical Society Series B: Statistical Methodology}, \textbf{84}(3),
657--685.

\bibitem[\citeproctext]{ref-vo2024recanting}
Vo, T-T, Williams, N, Liu, R, Rudolph, KE, and D캼az, I (2024) Recanting
twins: Addressing intermediate confounding in mediation analysis.
\emph{arXiv Preprint arXiv:2401.04450}.

\bibitem[\citeproctext]{ref-westreich2010}
Westreich, D, and Cole, SR (2010) Invited commentary: positivity in
practice. \emph{American Journal of Epidemiology}, \textbf{171}(6).
doi:\href{https://doi.org/10.1093/aje/kwp436}{10.1093/aje/kwp436}.

\bibitem[\citeproctext]{ref-westreich2017transportability}
Westreich, D, Edwards, JK, Lesko, CR, Stuart, E, and Cole, SR (2017)
Transportability of trial results using inverse odds of sampling
weights. \emph{American Journal of Epidemiology}, \textbf{186}(8),
1010--1014.

\bibitem[\citeproctext]{ref-westreich2013}
Westreich, D, and Greenland, S (2013) The table 2 fallacy: Presenting
and interpreting confounder and modifier coefficients. \emph{American
Journal of Epidemiology}, \textbf{177}(4), 292--298.

\bibitem[\citeproctext]{ref-wheatley1971pivot}
Wheatley, P (1971) \emph{The pivot of the four quarters: A preliminary
enquiry into the origins and character of the ancient chinese city},
Chicago: Aldine Publishing Company, 602.

\bibitem[\citeproctext]{ref-williams2021}
Williams, NT, and D칤az, I (2021) \emph{{l}mtp: Non-parametric causal
effects of feasible interventions based on modified treatment policies}.
doi:\href{https://doi.org/10.5281/zenodo.3874931}{10.5281/zenodo.3874931}.

\bibitem[\citeproctext]{ref-wilson2008evolution}
Wilson, DS (2008) Evolution and religion: The transformation of the
obvious. In J. Bulbulia, R. Sosis, E. Harris, R. Genet, C. Genet, and K.
Wyman, eds., \emph{The evolution of religion: Studies, theories, \&
critiques}, Santa Margarita, CA: Collins Foundation Press, 23--29.

\bibitem[\citeproctext]{ref-young2014identification}
Young, JG, Hern치n, MA, and Robins, JM (2014) Identification, estimation
and approximation of risk under interventions that depend on the natural
value of treatment using observational data. \emph{Epidemiologic
Methods}, \textbf{3}(1), 1--19.

\end{CSLReferences}



\end{document}
