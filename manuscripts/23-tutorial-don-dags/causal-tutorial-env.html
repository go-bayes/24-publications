<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.523">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>causal-tutorial-env</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="causal-tutorial-env_files/libs/clipboard/clipboard.min.js"></script>
<script src="causal-tutorial-env_files/libs/quarto-html/quarto.js"></script>
<script src="causal-tutorial-env_files/libs/quarto-html/popper.min.js"></script>
<script src="causal-tutorial-env_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="causal-tutorial-env_files/libs/quarto-html/anchor.min.js"></script>
<link href="causal-tutorial-env_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="causal-tutorial-env_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="causal-tutorial-env_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="causal-tutorial-env_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="causal-tutorial-env_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<p>​​— title: “Causal Inference in Environmental Psychology” abstract: | This chapter offers an introduction to causal inference within environmental psychology, emphasising the use of causal diagrams (Directed Acyclic Graphs — DAGs) to evaluate strategies for confounding control. It is structured into four sections: (1) a primer on principles of causal inference, (2) a tutorial on constructing causal diagrams, (3) practical examples of their application, and (4) guidelines for effective reporting. In settings where the structure of confounding is unclear or contested, we recommend creating multiple causal diagrams and performing corresponding analyses. That is, present a spectrum of results linked to each credible causal diagram. authors: - name: Joseph A. Bulbulia orcid: 0000-0002-5861-2056 email: joseph.bulbulia@vuw.ac.nz affiliation: name: Victoria University of Wellington, New Zealand, School of Psychology, Centre for Applied Cross-Cultural Research department: Psychology/Centre for Applied Cross-Cultural Research city: Wellington country: New Zealand url: www.wgtn.ac.nz/cacr - name: Donald W Hine orcid: 0000-0002-3905-7026 email: donald.hine@canterbury.ac.nz affiliation: name: University of Canterbury, School of Psychology, Speech and Hearing city: Canterbury country: New Zealand url: https://profiles.canterbury.ac.nz/Don-Hine keywords: - DAGS - Causal Inference - Confounding - Environmental - Psychology - Panel format: pdf: sanitize: true keep-tex: true link-citations: true colorlinks: true documentclass: article classoption: [singlecolumn] lof: false lot: false number-sections: false number-depth: 4 highlight-style: github geometry: - top=30mm - left=20mm - heightrounded header-includes: - date: last-modified execute: echo: false warning: false include: true eval: true fontfamily: libertinus bibliography: /Users/joseph/GIT/templates/bib/references.bib csl: ./camb-a.csl</p>
<hr>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Causal inference addresses a core question: how does an intervention on a ‘treatment’ variable affect an ‘outcome’ variable? This field moves beyond identifying correlations to quantifying causal effects. While causal understanding is widespread across species <span class="citation" data-cites="mancuso2018revolutionary">[@mancuso2018revolutionary]</span>, methods for quantitatively estimating effects are relatively recent developments.</p>
<p>Randomised controlled experiments, considered the “gold standard” for measuring causal effects, face limitations related to cost, practicality, ethics, and potential biases <span class="citation" data-cites="hernan2017per montgomery2018">[@hernan2017per; @montgomery2018]</span>. Observational data, which are more readily available, offer alternatives – provided that the causal inferences we draw from observational data are valid. Regrettably, however, the practice of analysing observational data and reporting associations without adequately addressing confounding biases is misleading <span class="citation" data-cites="westreich2013 robins1986 hernan2023 bulbulia2023a">[@westreich2013; @robins1986; @hernan2023; @bulbulia2023a]</span>. Advances in causal inference methods from biostatistics and computer science show promise <span class="citation" data-cites="vanderweele2015">[@vanderweele2015]</span>. This chapter provides and overview of these methods and explains how their application to questions in environmental psychology.</p>
<p><a href="#sec-part1"><strong>Part 1: An Overview of the Potential Outcomes Framework for Causal Inference</strong></a> introduces the potential outcomes framework and the <a href="#sec-three-fundamental-assumptions"><strong>three fundamental assumptions</strong></a> necessary for causal inferences <span class="citation" data-cites="hernan2023">[@hernan2023]</span>. Here, we discover that causal inference hinges on our ability to use data to compute contrasts between <em>counterfactual</em> outcomes <span class="citation" data-cites="westreich2012berkson hernan2017per westreich2015 robins2008estimation">[@westreich2012berkson; @hernan2017per; @westreich2015; @robins2008estimation]</span>.</p>
<p><strong>Part 2: Causal Diagrams - Visually Understanding Confounding</strong> offers an introduction to causal diagrams or “Directed Acyclic Graphs (DAGs)” to represent causal relationships and assumptions <span class="citation" data-cites="pearl2009a">[@pearl2009a]</span>. It outlines basic strategies for their construction and interpretation, introducing <a href="#sec-five-elementary"><strong>the five elementary graphical structures of causality</strong></a>.</p>
<p><strong>Part 3: Using Causal Diagrams for Causal Identification - Worked Examples</strong> presents <strong>seven everyday use cases</strong> to illustrate <a href="#sec-four-rules"><strong>four fundamental rules for evaluating confounding</strong></a> in practice.</p>
<p><strong>Part 4: Practical Guide For Constructing Causal Diagrams and Reporting Results When Causal Structure is Unclear</strong> offers reporting guidelines, advocating for multiple causal diagrams to explore confounding under ambiguous causal assumptions or data.</p>
</section>
<section id="section-part1" class="level2">
<h2 class="anchored" data-anchor-id="section-part1">Part 1: An Overview of the Potential Outcomes Framework for Causal Inference</h2>
<p>The potential outcomes framework for causal inference originated in the work of Jerzy Neyman to evaluate the effectiveness of agricultural experiments <span class="citation" data-cites="neyman1923">[@neyman1923]</span>. It was later extended by Harvard statistician Donald Rubin, who demonstrated the framework may also facilitate causal inferences in non-experimental settings <span class="citation" data-cites="rubin1976">[@rubin1976]</span>. Jamie Robins further generalised this framework to assess confounding in complex scenarios involving multiple and time-varying treatments <span class="citation" data-cites="robins1986">[@robins1986]</span>.</p>
<p>A fundamental principle in the potential outcomes framework is the concept of “counterfactual contrast” or “estimand.” To quantify causal effects, one must compare the outcomes under different intervention or treatment scenarios. Notably, prior to any intervention, these scenarios are purely hypothetical. Post-intervention, only one scenario is actualised for each realised treatment, leaving the alternative as a non-observed counterfactual. For any individual unit to be treated, that only one of the two possible outcomes is realised underscores a critical property of causality: causality is <strong>not directly observable</strong> <span class="citation" data-cites="hume1902">[@hume1902]</span>. Causal inference, therefore, can only quantify causal effects by combining data with counterfactual simulation <span class="citation" data-cites="edwards2015 bulbulia2023a">[@edwards2015; @bulbulia2023a]</span>. The concept of a counterfactual data science – may sound strange. However, anyone who has encountered a randomised experiment has encountered counterfactual data science. Before building intuitions for causal inference from the familiar example of experiments, let’s first build intuitions for the idea that causal quantities are never directly observed.</p>
<section id="the-fundamental-problem-of-causal-inference-causal-contrasts-are-not-directly-observed" class="level4">
<h4 class="anchored" data-anchor-id="the-fundamental-problem-of-causal-inference-causal-contrasts-are-not-directly-observed">The Fundamental Problem of Causal Inference: Causal Contrasts are Not Directly Observed</h4>
<p>Imagine you are at a pivotal juncture in your life. You have just completed your undergraduate studies and have been accepted into your dream Environmental Psychology program at the University of Canterbury. You are set to relocate to Christchurch, New Zealand. However, while making preparations, you receive a job offer from Acme Nuclear Fuels, a leader in renewable energy. Should you embark on graduate study or take the job? The course your life will take under each decision would appear to differ — your lifestyle, income, social networks, relationships, and perhaps even sense of life purpose hang in the balance. Which choice aligns with your ideal future?</p>
<p>Formally, let <span class="math inline">\(D\)</span> denote your decision, where <span class="math inline">\(D = 1\)</span> means attending graduate school and <span class="math inline">\(D = 0\)</span> means joining the workforce. Let <span class="math inline">\(Y\)</span> denote your life outcome. We use the symbol <span class="math inline">\(|\)</span> to denote conditionality such that the outcome. <span class="math inline">\(Y(1)\)</span> denotes your life outcome when <span class="math inline">\(Y|D=1\)</span>; <span class="math inline">\(Y(0)\)</span> denotes your life outcome when <span class="math inline">\(Y|D=0\)</span>. Your two potential outcomes under each path are described are given as <span class="math inline">\(Y_{\text{you}}(1)\)</span> and <span class="math inline">\(Y_{\text{you}}(0)\)</span>. Conceptually, to quantify the <em>magnitude</em> of the effect of your choice, we must calculate the difference:</p>
<p><span class="math display">\[Y_{\text{you}}(1) - Y_{\text{you}}(0)\]</span></p>
<p>Yet, this difference cannot be calculated from data because when you choose one path, you obscure the other:</p>
<p><span class="math display">\[
(Y_{\text{you}}|D_{\text{you}} = 1) = Y_{\text{you}}(1) \quad \text{implies} \quad Y_{\text{you}}(0)|D_{\text{you}} = 1~ \text{is counterfactual}.
\]</span></p>
<p>This expression means: “The outcome we observe under option <span class="math inline">\(D = 1\)</span> can be measured. However, because option <span class="math inline">\(D = 0\)</span> is not realised, the outcome under option <span class="math inline">\(D=0\)</span> cannot be measured. Thus, the contrast between these two outcomes cannot be computed. At least one outcome remains purely counterfactual.</p>
<p>The same problem arises if you select <span class="math inline">\(D = 0\)</span>. Then, the outcome under <span class="math inline">\(D=1\)</span> remains counterfactual. And so we cannot compute the contrast:</p>
<p><span class="math display">\[
(Y_{\text{you}}|D_{\text{you}} = 0) = Y_{\text{you}}(0) \quad \text{implies} \quad Y_{\text{you}}(1)|D_{\text{you}} = 0~ \text{is counterfactual}.
\]</span></p>
<p>Of course, you regularly make principled decisions about your life based on past experiences, instincts, and knowledge. Nevertheless, the <em>data</em> that you require to quantitatively compare life outcomes under one decision as opposed to the other is not available. Life, as it would have unfolded under the option you do not select, remains counterfactual – it cannot be directly measured. A quantitative causal contrast here is not a matter of factual data science. This example, although contrived, perhaps resonates with similar crossroads you have encountered in your life. The dilemmas that you faced at these crossroads underscore what is known as “The fundamental problem of causal inference” <span class="citation" data-cites="rubin2005 holland1986">[@rubin2005; @holland1986]</span>: for any individual case, we cannot observe the potential outcomes that we require to quantify the magnitude of an individual causal contrast.</p>
<p>The fundamental problem of causal inference never goes away. However, by collecting, organising, and aggregating data under certain assumptions, we can obtain valid quantitative causal contrasts from data for <em>average treatment effects</em>. To clarify these assumptions, we next consider how experiments attach magnitudes to missing counterfactual outcomes to obtain average treatment effects.</p>
</section>
<section id="causal-inference-in-experiments-is-a-missing-data-problem" class="level3">
<h3 class="anchored" data-anchor-id="causal-inference-in-experiments-is-a-missing-data-problem">Causal inference in Experiments is a Missing Data Problem</h3>
<p>Let us transition from the topic of life decisions to an example of relevance to environmental psychology, namely, estimating the average causal effect of easy access to urban green spaces on subjective happiness, hereafter referred to as “happiness.” We assume this outcome is measurable and represent it with <span class="math inline">\(Y\)</span>.</p>
<p>For simplicity, we classify the intervention “ample access to green space” as a binary variable. Define <span class="math inline">\(A = 1\)</span> as “having ample access to green space” and <span class="math inline">\(A = 0\)</span> as “lacking ample access to green space.” We assume these conditions are mutually exclusive. This simplification does not limit the generality of our conclusions; the points we make about experiments also apply to continuous treatments. It is crucial in causal inference to specify the population for whom we seek to evaluate causal effects, or the “target population.” In this case, our target population is residents of New Zealand in the 2020s.</p>
<p>A preliminary causal question – defined as a causal contrast or “estimand” might, therefore be:</p>
<p>“In New Zealand, does proximity to abundant green spaces increase self-perceived happiness compared to environments lacking such spaces?”</p>
<p>Of course it would be unethical to experimentally randomise individuals into different green-space access conditions. However, for the purposes of illustration, assume experimentalists could assign people randomly to high and low green space access without objection or harm.</p>
<p>As alluded to earlier, the first point to note in the context of causal inference is that even well-designed experiments confront the challenge of missing values in the potential outcomes. Once an individual is assigned to one treatment condition, we cannot observe that individual’s outcome for the condition not assigned. The fundamental problem of causal inference remains constant: for each individual, we can only observe one of the potential outcomes at any given time. Breaking down the Average Treatment Effect (ATE) into observed and unobserved outcomes yields the following equation:</p>
<p><span class="math display">\[
\text{Average Treatment Effect} = \left(\underbrace{\underbrace{\mathbb{E}[Y(1)|A = 1]}_{\text{observed}} + \underbrace{\mathbb{E}[Y(1)|A = 0]}_{\text{unobserved}}}_{\text{treated}}\right) - \left(\underbrace{\underbrace{\mathbb{E}[Y(0)|A = 0]}_{\text{observed}} + \underbrace{\mathbb{E}[Y(0)|A = 1]}_{\text{unobserved}}}_{\text{untreated}}\right).
\]</span></p>
<p>In this expression, <span class="math inline">\(\mathbb{E}[Y(1)|A = 1]\)</span> represents the average outcome when the treatment is given, which is observable. However, <span class="math inline">\(\mathbb{E}[Y(1)|A = 0]\)</span> represents the average outcome if the treatment had been given to those who were untreated, which remains unobservable. Similarly, the quantity <span class="math inline">\(\mathbb{E}[Y(0)|A = 1]\)</span> also remains unobservable.</p>
<p>It is hopefully evident from this brief application of the potential outcomes framework to experiments that the fundamental problem of causal inference is an ever-present concern even in experiments. For each participant, it is impossible to determine the outcome they would have experienced under an alternative treatment condition. You cannot quantitatively describe the life you would have led had you chosen the job at Acme Nuclear Fuels instead of attending the University of Canterbury. Nor, if you lived your life in a leafy suburb, could you determine how happy you would have been if your life had been devoid of green space?</p>
</section>
<section id="in-experiments-random-treatment-assignment-balances-confounders-across-treatments" class="level3">
<h3 class="anchored" data-anchor-id="in-experiments-random-treatment-assignment-balances-confounders-across-treatments">In Experiments, Random Treatment Assignment Balances Confounders Across Treatments</h3>
<p>How do experiments manage to estimate average treatment effects despite the inherent challenges? The solution involves addressing the concept of “confounding.” Consider the concept of “confounding by common cause.” This occurs when one or more variables causally affect both the intervention under study (the “treatment” or “exposure”) and the outcome of interest, leading to a non-causal association between the treatment and outcome. By “non-causal,” we mean that if we intervened in the treatment but not the confounder, the outcome would not change. The common cause creates a misleading or exaggerated relationship that may be mistakenly interpreted as causal. For instance, when assessing the impact of access to green space on happiness, it is possible that the association could be entirely explained by income. If so, then an observed association between access to green space and happiness would be entirely misleading. Were we to relocate low-income individuals to high-access green areas, we might not affect subjective happiness at all. Thus, accurately identifying and adjusting for confounding by common cause is crucial for determining the true causal relationship between two variables, ensuring that the observed association is not merely a result of extraneous influences.</p>
<p>We can express this principle of no confounding mathematically in two complementary ways (where <span class="math inline">\(A \coprod B\)</span> signifies that <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span>, and vice versa):</p>
<ol type="1">
<li><strong>Potential Outcomes Independent of Treatment (given L):</strong> <span class="math inline">\(Y(a) \coprod A \mid L\)</span></li>
<li><strong>Treatment Assignment Independent of Potential Outcomes (given L):</strong> <span class="math inline">\(A \coprod Y(a) \mid L\)</span></li>
</ol>
<p>These formulations are crucial when working with causal diagrams, which visually encode these principles. The key idea is straightforward: ensuring a balance of confounders across treatment groups is fundamental to experimental and observational causal inference strategies. Randomisation facilitates this balance, achieving <span class="math inline">\(A \coprod Y(a)\)</span>.</p>
</section>
<section id="sec-three-fundamental-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="sec-three-fundamental-assumptions">The Three Fundamental Assumptions of Causal Inference</h3>
<p>Reviewing causal inference in experimental settings highlights three core assumptions essential for causal analysis.</p>
<section id="fundamental-assumption-1-conditional-exchangeability" class="level4">
<h4 class="anchored" data-anchor-id="fundamental-assumption-1-conditional-exchangeability">Fundamental Assumption 1: Conditional Exchangeability</h4>
<p>We say that conditional exchangeability holds if the potential outcomes and treatment assignments are statistically independent, considering all measured confounders. It enables us to attribute observed group differences directly to the treatment. Randomisation provides <em>unconditional</em> exchangeability, simplifying the analytical process.</p>
<section id="challenge-in-satisfying-conditional-exchangeability-in-observational-settings" class="level5">
<h5 class="anchored" data-anchor-id="challenge-in-satisfying-conditional-exchangeability-in-observational-settings">Challenge in Satisfying Conditional Exchangeability in Observational Settings</h5>
<p>Achieving conditional exchangeability is challenging in observational studies. This condition requires the groups being compared to be similar in every aspect except for the treatment. Consider the example of the effect of living near green spaces on subjective happiness. In real-world data, individuals with access to green spaces may differ from those without access in several ways:</p>
<ul>
<li><strong>Socioeconomic status</strong>: the economic capacity of individuals often determines their living environments, thereby affecting their access to quality green spaces.</li>
<li><strong>Age demographics</strong>: different age groups have unique preferences and necessities regarding green spaces, which could influence the observed outcomes.</li>
<li><strong>Mental health</strong>: pre-existing conditions might lead individuals to seek out or avoid green spaces, complicating the causal pathway.</li>
<li><strong>Lifestyle choices</strong>: the proximity to green spaces could correlate with a more active, outdoor lifestyle preference. Does the observed effect on well-being directly result from the green space, or does it indicate a healthier lifestyle?</li>
<li><strong>Personal values and social connections</strong>: environmental values and community ties may influence both the choice of residence and the utilisation of green spaces.</li>
</ul>
<p>These and other unmeasured factors can introduce biases, complicating the interpretation of causal relationships in observational studies.</p>
</section>
</section>
</section>
<section id="summary-part-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-part-1">Summary Part 1</h3>
<p>In Part 1, we explored the fundamental problem of causal inference, focusing on the critical distinction between correlation – associations in the data, and causation – the contrast between potential outcomes only one of which, at most, can be observed. We discussed how controlled experiments facilitate the estimation of average treatment effects (ATE) by systematically manipulating the variable of interest, allowing for the distribution of variables that might affect the outcome to be balanced across the treatment conditions. The discussion then shifted to observational data, emphasising the challenges inherent in extracting causal relationships from data without the benefit of controlled interventions. We underscored the necessity of three key assumptions —- conditional exchangeability, causal consistency, and positivity—for inferring average treatment effects from observational data. These assumptions ensure that the treatment groups are comparable, the treatment effect is consistent across the population, and every individual has a non-zero probability of receiving each treatment level, respectively. As we transition to discussing causal diagrams, it is essential to recognise that these graphical tools offer a systematic approach to identifying and controlling for confounding variables, thus aiding researchers in satisfying the first of the three fundamental assumptions required for causal inference. Causal diagrams, however, do not obviate the need for these assumptions; instead, they provide a framework for evaluating whether and how the first of the three assumptions – conditional exchangeability – may be satisfied in a given study.</p>
<section id="fundamental-assumption-2-causal-consistency" class="level4">
<h4 class="anchored" data-anchor-id="fundamental-assumption-2-causal-consistency">Fundamental Assumption 2: Causal Consistency</h4>
<p>We say that causal consistency holds if there is no heterogeneity in the treatments that would prevent us from assuming that the observed outcomes under treatments correspond to their potential outcomes. For an individual ‘i’, we must be able to assume:</p>
<p><span class="math display">\[
\begin{aligned}
Y_{i}(1) &amp;= (Y_{i}|A_{i} = 1) \quad \text{(Potential outcome if treated)} \\
Y_{i}(0) &amp;= (Y_{i}|A_{i} = 0) \quad \text{(Potential outcome if untreated)}
\end{aligned}
\]</span></p>
<p>If this assumption holds, as well as the assumptions of conditional exchangeability and positivity (reviewed below), we can calculate the Average Treatment Effect (ATE) from observed data as:</p>
<p><span class="math display">\[
\begin{aligned}
\text{ATE} &amp;= \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)] \\
&amp;= \mathbb{E}(Y|A=1) - \mathbb{E}(Y|A=0)
\end{aligned}
\]</span></p>
<p>This contrast assumes that the potential outcome under treatment is observable when the treatment is administered, setting <span class="math inline">\(Y_i(a)\)</span> to <span class="math inline">\(Y_i|A_i=a\)</span>.</p>
<p>The standardisation of treatments in randomised controlled experiments generally ensures the validity of the causal consistency assumption, which is seldom disputed. However, in observational settings, we cannot typically control the treatments that people receive. This fact imposes considerable challenges for satisfying this assumption. (Discussed in <a href="#appendix-b">Appendix B</a>)</p>
<section id="challenges-in-satisfying-the-causal-consistency-assumption-in-observational-settings" class="level5">
<h5 class="anchored" data-anchor-id="challenges-in-satisfying-the-causal-consistency-assumption-in-observational-settings">Challenges in Satisfying the Causal Consistency Assumption in Observational Settings</h5>
<p>Again we consider our interest in quantifying the causal effect of living near green spaces. The definition of “proximity to green spaces” itself, varies significantly, leading to a diverse range of experiences classified under the same “treatment.” Focussing on the variability of the green spaces themselves, this includes:</p>
<ul>
<li><strong>Diversity of green spaces</strong>: Green spaces’ ecological richness and visual appeal vary significantly. Equating well-maintained parks with neglected wild areas does not provide a like-for-like comparison.</li>
<li><strong>Availability of amenities</strong>: facilities such as walking paths and benches significantly impact the spaces’ usability and enjoyment.</li>
<li><strong>Size and type of green space</strong>: the benefits derived from an urban garden versus a vast forest differ markedly, emphasising the need to consider the nature of the green space in the analysis.</li>
</ul>
</section>
</section>
<section id="fundamental-assumption-3-positivity" class="level4">
<h4 class="anchored" data-anchor-id="fundamental-assumption-3-positivity">Fundamental Assumption 3: Positivity</h4>
<p>We must assume that there is a non-zero probability of receiving each treatment level within covariate-defined subgroups.</p>
<p><span class="math display">\[
P(A = a | L= l) &gt; 0
\]</span></p>
<p>This assumption is also met by the <em>control</em> that experimentalists exert over randomised controlled experiments and is rarely stated explicitly. However, in observational settings, this condition must be verified to avoid extrapolating results beyond observed data.</p>
<section id="challenges-in-satisfying-the-positivity-assumption-in-observational-settings-the-relevant-treatments-do-not-exist-in-the-data" class="level5">
<h5 class="anchored" data-anchor-id="challenges-in-satisfying-the-positivity-assumption-in-observational-settings-the-relevant-treatments-do-not-exist-in-the-data">Challenges in Satisfying The Positivity Assumption in Observational Settings: The Relevant Treatments Do Not Exist in The Data</h5>
<p>Positivity demands that each individual has the possibility of experiencing <em>every</em> level of the treatment to be compared. However, real-world constraints, such as housing availability in specific locales, may preclude some groups from accessing varied green spaces. Where the treatments of interest are absent or scarcely represented in our dataset, the resulting causal inferences will lack empirical support. Consequently, any coefficients derived will represent extrapolations from statistical models, challenging the validity of our causal inferences <span class="citation" data-cites="westreich2010 hernan2023">[@westreich2010; @hernan2023]</span>.</p>
</section>
</section>
</section>
</section>
<section id="part-2-causal-diagrams---a-visual-approach-to-understanding-confounding" class="level2">
<h2 class="anchored" data-anchor-id="part-2-causal-diagrams---a-visual-approach-to-understanding-confounding">Part 2: Causal Diagrams - A Visual Approach to Understanding Confounding</h2>
<p>We now introduce causal diagrams, beginning with essential terminology. Grasping this vocabulary is crucial for effectively employing causal diagrams, though it may initially seem daunting. After laying out the terms, we will consider practical examples, uncovering the various forms of confounding embedded within four principal causal structures. Identifying and understanding these structures is vital for their application in real-world analyses. Refer to <a href="#appendix-a"><strong>Appendix A</strong></a> for a detailed glossary.</p>
<section id="elements-of-causal-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="elements-of-causal-diagrams">Elements of Causal Diagrams</h3>
<p>Causal diagrams distil the essence of causal relationships within a system into visual representations. At their core, these diagrams consist of:</p>
<section id="nodes" class="level4">
<h4 class="anchored" data-anchor-id="nodes">1. <strong>Nodes</strong></h4>
<p>Nodes represent variables or events within a causal framework. Each node stands for a distinct element that either exerts influence or is subject to influence within the system. Nodes encapsulate the components of our causal inquiry. They denote: (1) treatment(s) (2) outcome(s) or (3) confounders.</p>
</section>
<section id="arrowsedges" class="level4">
<h4 class="anchored" data-anchor-id="arrowsedges">2. <strong>Arrows/Edges</strong></h4>
<p>Arrows indicate the direction and presence of causal relationships between the variables denoted by nodes. Directed edges trace the assumed flow of causal influence. The originating variable is called a ‘parent’, and the receiving variable is called a ‘child.’ These arrows define the causal architecture of the system, illustrating how we assume one variable causally affects another. Notably, the representation of causal relationships through arrows remains the same whether the assumed influence is linear or non-linear.</p>
</section>
<section id="conditioning" class="level4">
<h4 class="anchored" data-anchor-id="conditioning">3. <strong>Conditioning</strong></h4>
<p>In causal data science, deciding which variables to adjust for is crucial for estimating the true causal effect unconfounded by other factors. We denote a decision to “control for” or equivalently “condition on” or equivalently “adjust for” a variable by enclosing it in a box.</p>
</section>
</section>
<section id="the-rules-of-d-separation" class="level3">
<h3 class="anchored" data-anchor-id="the-rules-of-d-separation">The Rules of D-separation</h3>
<p>Judea Pearl demonstrated how the rules of d-separation allow us to analyse relationships within causal diagrams <span class="citation" data-cites="pearl1995">[@pearl1995]</span>. These rules allow us to identify confounders and develop strategies for obtaining valid causal inferences from statistical associations in the data <span class="citation" data-cites="pearl1995">[@pearl1995]</span>.</p>
<p><strong>Key Concepts</strong></p>
<section id="dependence" class="level4">
<h4 class="anchored" data-anchor-id="dependence">Dependence</h4>
<p>Denoted as <span class="math inline">\(A \cancel\coprod B\)</span>, indicating that the probability distributions of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are interrelated. Knowledge about one variable provides insights into the other, suggesting a potential causal or associational link.</p>
</section>
<section id="independence" class="level4">
<h4 class="anchored" data-anchor-id="independence">Independence</h4>
<p>Denoted as <span class="math inline">\(A \coprod B\)</span>, signifying that the probability distributions of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent. Information about one variable reveals nothing about the other, indicating no direct causal or associational connection.</p>
</section>
<section id="blocked-paths-and-d-separation" class="level4">
<h4 class="anchored" data-anchor-id="blocked-paths-and-d-separation">Blocked Paths and D-Separation</h4>
<p>A path is considered “blocked” when a node on this path prevents causal influence from propagating between variables. D-separation occurs when all paths between two variables are blocked (<span class="math inline">\(A \coprod B\)</span>), indicating no direct statistical association between them. This condition is crucial for enabling unbiased causal inference.</p>
</section>
<section id="open-paths-d-connection" class="level4">
<h4 class="anchored" data-anchor-id="open-paths-d-connection">Open Paths &amp; D-connection</h4>
<p>If at least one path between variables remains unblocked, allowing for the transmission of causal influence, the variables are considered d-connected (<span class="math inline">\(A \cancel\coprod B\)</span>). This condition suggests a statistical association, warranting further analysis to understand the nature of the bias in the statistical association between the treatment and outcome.</p>
</section>
</section>
<section id="sec-five-elementary" class="level3">
<h3 class="anchored" data-anchor-id="sec-five-elementary">The Five Elementary Graphical Structures of Causality and Four Rules for Confounding Control</h3>
<p>To uncover causal insights from statistical relationships, it is essential to understand five basic graphical structures. We next examine these structures, remembering that achieving balance in confounders across treatments requires ensuring statistical independence between potential outcomes and treatment (<span class="math inline">\(A\coprod Y(a)|L\)</span>) within groups defined by measured covariates <span class="math inline">\(L\)</span>.</p>
<section id="causal-structure-1-absence-of-causality-two-variables-with-no-arrows" class="level4">
<h4 class="anchored" data-anchor-id="causal-structure-1-absence-of-causality-two-variables-with-no-arrows">Causal Structure 1: Absence of Causality: Two Variables with No Arrows</h4>
<p>When any arrows do not connect <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we assume do not share a causal relationship and are statistically independent. Graphically, we represent this relationship as:</p>
<p><span class="math display">\[\xorxA\]</span></p>
</section>
<section id="causal-structure-2-direct-causation-between-two-variables" class="level4">
<h4 class="anchored" data-anchor-id="causal-structure-2-direct-causation-between-two-variables">Causal Structure 2: Direct Causation Between Two Variables</h4>
<p>A causal arrow (<span class="math inline">\(A \to B\)</span>) signifies that changes in variable <span class="math inline">\(A\)</span> directly cause changes in variable <span class="math inline">\(B\)</span>, creating a statistical dependence between them. This direct causal link is graphically depicted as:</p>
<p><span class="math display">\[\xtoxA\]</span></p>
</section>
<section id="causal-structure-3-the-fork-structure---common-cause-scenario" class="level4">
<h4 class="anchored" data-anchor-id="causal-structure-3-the-fork-structure---common-cause-scenario">Causal Structure 3: The Fork Structure - Common Cause Scenario</h4>
<p>The fork structure, indicated by <span class="math inline">\(A \rightarrow B\)</span> and <span class="math inline">\(A \rightarrow C\)</span>, denotes the assumption that <span class="math inline">\(A\)</span> is a common cause that influences both <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. Graphically:</p>
<p><span class="math display">\[\fork\]</span></p>
<p>Pearl proved that when we condition on the common cause <span class="math inline">\(A\)</span> (indicated by <span class="math inline">\(\boxed{A}\)</span>), <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> become conditionally independent <span class="citation" data-cites="pearl2009a">[@pearl2009a]</span>. By adjusting for the common cause, any non-causal association between <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> is effectively blocked at node <span class="math inline">\(A\)</span>.</p>
<section id="motivating-example" class="level5">
<h5 class="anchored" data-anchor-id="motivating-example">Motivating Example</h5>
<p>Suppose our observations reveal that areas with higher rates of bicycle commuting also present lower average levels of psychological distress. Does using bicycle commuting directly reduce average psychological distress? Not necessarily. A common environmental factor might influence both. Consider sunshine hours as the common cause:</p>
<ul>
<li>Sunshine (<span class="math inline">\(A\)</span>) encourages the use of bicycles (<span class="math inline">\(B\)</span>).</li>
<li>Sunshine (<span class="math inline">\(A\)</span>) contributes to lower psychological distress (<span class="math inline">\(C\)</span>).</li>
</ul>
<p>According to the rules of d-separation, if we were to account for the common cause (sunshine hours), isolating days with similar levels of sunshine, the apparent link between bicycle commuting and psychological distress levels would dissipate. Adjusting for the fork’s common cause would eliminate the spurious association we have assumed in this example.</p>
</section>
</section>
<section id="sec-four-rules" class="level4">
<h4 class="anchored" data-anchor-id="sec-four-rules">Rule 1: The Fork Rule</h4>
<p>If interested in the causal effect of <span class="math inline">\(B \to C\)</span>, condition on <span class="math inline">\(\boxed{A}\)</span>.</p>
</section>
<section id="causal-structure-4.-the-chain-structure-a-mediator" class="level4">
<h4 class="anchored" data-anchor-id="causal-structure-4.-the-chain-structure-a-mediator">Causal Structure 4. The Chain Structure: A Mediator</h4>
<p>The chain structure (<span class="math inline">\(A \rightarrow B \rightarrow C\)</span>) illustrates a setting in which <span class="math inline">\(A\)</span> causes <span class="math inline">\(B\)</span>, and <span class="math inline">\(B\)</span> subsequently causes <span class="math inline">\(C\)</span>. Conditioning on the intermediary variable <span class="math inline">\(B\)</span> (represented by <span class="math inline">\(\boxed{B}\)</span>) interrupts the causal pathway, rendering <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span> conditionally independent. Graphically, we represent this relationship as:</p>
<p><span class="math display">\[\chain\]</span></p>
<section id="motivating-example-1" class="level5">
<h5 class="anchored" data-anchor-id="motivating-example-1">Motivating Example</h5>
<p>Suppose we wanted to assess the effect of green space renovation in urban areas (<span class="math inline">\(A\)</span>) on local community engagement (<span class="math inline">\(B\)</span>), which subsequently reduces neighbourhood crime rates (<span class="math inline">\(C\)</span>). Assume the renovation of green spaces <span class="math inline">\((A) \rightarrow\)</span> boosts community engagement <span class="math inline">\((B) \rightarrow\)</span>, which then leads to a decrease in crime rates (<span class="math inline">\(C\)</span>).</p>
<p>According to the rules of d-separation, controlling for the mediator, community engagement, in this case, might hide the broader effect of green space renovation. If the primary path through which green space renovation affects crime rates is via enhanced community engagement, then adjusting for community engagement could misleadingly suggest that green space renovation does not directly influence crime rates. This example underscores the necessity of carefully considering mediators when examining the effects of environmental changes on social outcomes.</p>
</section>
<section id="rule-2.-the-chain-rule" class="level5">
<h5 class="anchored" data-anchor-id="rule-2.-the-chain-rule">Rule 2. The Chain Rule</h5>
<p>If investigating the <em>total</em> causal effect of <span class="math inline">\(A\to C\)</span>, <em>avoid</em> conditioning on the mediator (<span class="math inline">\(B\)</span>).</p>
<p><strong>Important note:</strong> A “total” causal effect may combine several causal chains in complex systems. Identifying a mediating role for focus (<span class="math inline">\(B\)</span>) is a valuable finding about the <em>mechanism</em> through which the supplement might operate. Assessing causal mediation requires further assumptions, which we will not discuss here <span class="citation" data-cites="vanderweele2015 bulbulia2023">[@vanderweele2015; @bulbulia2023]</span>.</p>
</section>
</section>
<section id="causal-structure-5-the-collider-structure-a-common-effect" class="level4">
<h4 class="anchored" data-anchor-id="causal-structure-5-the-collider-structure-a-common-effect">Causal Structure 5: The Collider Structure: A Common Effect</h4>
<p>The collider (<span class="math inline">\(A\to C\)</span>, <span class="math inline">\(B \to C\)</span>) features two factors independently causing a common effect. Initially, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> lack association. Conditioning on the collider <span class="math inline">\(C\)</span> (or its descendant) introduces a spurious statistical association between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Graphically:</p>
<p><span class="math display">\[\immorality\]</span></p>
<section id="motivating-example-2" class="level5">
<h5 class="anchored" data-anchor-id="motivating-example-2">Motivating Example</h5>
<p>Suppose we were interested in whether access to green spaces (<span class="math inline">\(A\)</span>) causes people to become happier (<span class="math inline">\(B\)</span>)? Suppose we were to control for a variable <span class="math inline">\(C\)</span> – say health – which is a common effect of the treatment <span class="math inline">\(A\)</span> (access to green space) and the outcome <span class="math inline">\(B\)</span> (happiness). Here, conditioning on <span class="math inline">\(C\)</span> would open a non-causal path between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. That is, if <span class="math inline">\(A\)</span> causes <span class="math inline">\(C\)</span> and <span class="math inline">\(B\)</span> also causes <span class="math inline">\(C\)</span>, controlling for <span class="math inline">\(C\)</span> can induce a spurious association between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Consider:</p>
<ol type="1">
<li><p>Among unhealthy individuals (low <span class="math inline">\(C\)</span>), those with high access to green space (<span class="math inline">\(A\)</span>) may appear less happy (<span class="math inline">\(B\)</span>) from other factors that both reduce happiness and health. In this group, a negative correlation between green space and happiness may be observed, but it is not necessarily causal.</p></li>
<li><p>Among healthy individuals (high <span class="math inline">\(C\)</span>), those with low access to green space may appear happier from other factors that increase happiness and health. Within this group, a negative correlation between green space and happiness may also be observed.</p></li>
</ol>
<p>In this scenario, the relationship between green space access and happiness, when health is controlled for, introduces a spurious negative association. This association is non-causal because it arises from controlling for a collider, health. Without controlling for health, assuming there are no other confounding paths between green space access and happiness, the misleading statistical association would not be present.</p>
<p>This example illustrates the risk of confounding the analysis by conditioning on an outcome influenced by both variables of interest.</p>
</section>
</section>
<section id="rule-3-the-collider-rule-when-assessing-the-causal-effect-of-ato-b-do-not-conditioning-on-a-collider-c-or-its-descendants.-doing-so-may-introduce-an-association-that-appears-causal-but-is-not." class="level4">
<h4 class="anchored" data-anchor-id="rule-3-the-collider-rule-when-assessing-the-causal-effect-of-ato-b-do-not-conditioning-on-a-collider-c-or-its-descendants.-doing-so-may-introduce-an-association-that-appears-causal-but-is-not."><strong>Rule 3: The Collider Rule:</strong> when assessing the causal effect of <span class="math inline">\(A\to B\)</span>, do not conditioning on a collider (<span class="math inline">\(C\)</span>) or its descendants. Doing so may introduce an association that appears causal but is not.</h4>
</section>
<section id="we-build-all-complex-causal-relationships-from-the-five-elemental-structures-of-causation" class="level4">
<h4 class="anchored" data-anchor-id="we-build-all-complex-causal-relationships-from-the-five-elemental-structures-of-causation">We build all complex causal relationships from the five elemental structures of causation</h4>
<p>All forms of confounding bias stem from combinations of the five basic causal structures we have outlined (absence/presence of cause, forks, chains, and colliders). Understanding these elements in isolation and combination allows us to identify potential confounders based on our assumptions about the world as encoded in a causal diagram. Here we consider an example that combines two structures: the collider structure (<span class="math inline">\(A \rightarrowred \boxed{C} \leftarrowred B\)</span> and basic causality (<span class="math inline">\(C\rightarrowNEW D\)</span>), This combination produce confounding by proxy: <span class="math inline">\(A \rightarrowred \boxed{D} \leftarrowred B\)</span>.</p>
<p>Causation implies statistical association. As such, causal inheritance implies <em>statistical dependence by inheritance</em>. The property of statistical inheritance makes descendants act as stand-ins or proxies for their parents.</p>
<section id="motivating-example-3" class="level5">
<h5 class="anchored" data-anchor-id="motivating-example-3">Motivating Example</h5>
<p>Consider again the example of whether access to urban green spaces (<span class="math inline">\(A\)</span>) affects wealth (<span class="math inline">\(B\)</span>). Imagine they do not, but both independently contribute to well-being (<span class="math inline">\(C\)</span>). Suppose that the only people who respond to our survey are those who are high in well-being. In effect, our survey is conditioning on one population stratum (<span class="math inline">\(D\)</span>), which is a descendant of the collider – well-being. Initially, green spaces and income independently affect well-being. However, when we specifically analyse data based on willingness to participate in the survey (<span class="math inline">\(\boxed{D}\)</span>), we may inadvertently induce an association between green space access and socioeconomic status, inferring that those with access to green space tend to have a lower income.</p>
<p><span class="math display">\[\immoralityChildA\]</span></p>
<p>Colliders and their descendants set subtle “traps” that might induce spurious associations.</p>
<p>However, as we shall see in the next section, conditioning on proxies of unmeasured confounders opens possibilities for confounding control beyond our measured variables. We can sometimes leverage proxies to reduce bias in our causal inferences.</p>
</section>
<section id="rule-4-the-proxy-rule" class="level5">
<h5 class="anchored" data-anchor-id="rule-4-the-proxy-rule">Rule 4: The Proxy Rule</h5>
<p>Conditioning on a descendant is akin to conditioning on its parent. Put differently, a descendant is a *proxy$ for its parent. Avoid conditioning on descendants in settings where conditioning on the parent would induce misleading associations.</p>
</section>
</section>
<section id="role-of-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="role-of-assumptions">Role of Assumptions</h4>
<p>Causal diagrams bring structure to complex environmental psychology systems. They promote critical thinking about relationships, improving study design and the chances of isolating true causal effects. However, causal diagrams cannot avoid assumptions. Observational data alone cannot prove causation: many diagrams are typically consistent with the data. The power of causal diagrams lies in helping investigators understand how their assumptions and the data interact. However, we should create causal diagrams in collaboration with subject area experts because every path except the <span class="math inline">\(A\to Y\)</span> path is assumed. When experts disagree, we should propose multiple causal diagrams to reflect the implications of disagreements for causal inference and report the outcomes of their corresponding confounding control strategies.</p>
</section>
</section>
<section id="causal-diagrams-and-the-identification-problem-in-causal-inference" class="level3">
<h3 class="anchored" data-anchor-id="causal-diagrams-and-the-identification-problem-in-causal-inference">Causal Diagrams and the Identification Problem in Causal Inference</h3>
<p>The <strong>identification problem</strong> centres on whether we can derive the true causal effect of a treatment (<span class="math inline">\(A\)</span>) on an outcome (<span class="math inline">\(Y\)</span>) from observed data. Causal diagrams, rooted in <strong>structural assumptions</strong> about the underlying causal relationships, are indispensable for tackling this challenge. Crucially, we cannot prove these assumptions from data alone.</p>
<p>Addressing the identification problem has two core components:</p>
<section id="evaluating-bias-the-absence-of-causality" class="level4">
<h4 class="anchored" data-anchor-id="evaluating-bias-the-absence-of-causality">1. <strong>Evaluating bias the absence of causality</strong></h4>
<p>Before attributing any statistical association to causality, we must eliminate non-causal sources of correlation. We do this by:</p>
<ul>
<li>Identifying factors that influence both treatment (<span class="math inline">\(A\)</span>) and outcome (<span class="math inline">\(Y\)</span>).</li>
<li>Developing adjustment strategies to control for confounders.</li>
<li>Blocking backdoor paths that create indirect, non-causal links between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>. By adjusting for confounders, we aim to achieve d-separation between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</li>
</ul>
</section>
<section id="evaluating-bias-in-the-presence-of-causality" class="level4">
<h4 class="anchored" data-anchor-id="evaluating-bias-in-the-presence-of-causality">2. <strong>Evaluating bias in the presence of causality</strong></h4>
<p>After addressing potential confounders, we must ensure any remaining association between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> reflects a true causal relationship. We address <strong>over-conditioning bias</strong> by:</p>
<ul>
<li>Avoiding mediator bias</li>
<li>Avoiding collider bias</li>
<li>Verifying that any association between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> after in unbiased after all adjustments.</li>
</ul>
<p>Thus, causal inference demands a delicate balance: identify and control for confounders but avoid introducing new biases.</p>
</section>
</section>
<section id="how-to-create-causal-diagrams-to-address-identification-problems-sec-how-to-create-causal-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="how-to-create-causal-diagrams-to-address-identification-problems-sec-how-to-create-causal-diagrams">How to Create Causal Diagrams to Address Identification Problems {sec-how-to-create-causal-diagrams}</h3>
<section id="step-1.-clarify-the-research-question-evaluated-by-the-diagram" class="level4">
<h4 class="anchored" data-anchor-id="step-1.-clarify-the-research-question-evaluated-by-the-diagram">Step 1. Clarify the Research Question Evaluated by the Diagram</h4>
<p>State the problem your diagram addresses and the population to whom the problem applies. Causal identification strategies may vary by question. For example, the confounding control strategy for evaluating the path <span class="math inline">\(L\to Y\)</span> will differ from that of assessing the path <span class="math inline">\(A\to Y\)</span>. For this reason, reporting coefficients other than the association between <span class="math inline">\(A \to Y\)</span> is typically ill-advised; see <span class="citation" data-cites="westreich2013">@westreich2013</span>; <span class="citation" data-cites="mcelreath2020">@mcelreath2020</span>; <span class="citation" data-cites="bulbulia2023">@bulbulia2023</span>.</p>
</section>
<section id="step-2.-include-all-common-causes-of-the-exposure-and-outcome" class="level4">
<h4 class="anchored" data-anchor-id="step-2.-include-all-common-causes-of-the-exposure-and-outcome">Step 2. Include all common causes of the exposure and outcome</h4>
<p>Include both measured and unmeasured common causes and group functionally similar common causes under a single variable (e.g., <span class="math inline">\(L_0\)</span> for demographics).</p>
</section>
<section id="step-3.-include-all-ancestors-of-measured-confounders-linked-with-the-treatment-the-outcome-or-both" class="level4">
<h4 class="anchored" data-anchor-id="step-3.-include-all-ancestors-of-measured-confounders-linked-with-the-treatment-the-outcome-or-both">Step 3. Include all ancestors of measured confounders linked with the treatment, the outcome, or both</h4>
<p>Such inclusion helps address unmeasured confounding and reduce biases like M-bias. Again, group functionally similar variables for a simplified visual representation.</p>
</section>
<section id="step-4.-explicitly-state-assumptions-about-relative-timing" class="level4">
<h4 class="anchored" data-anchor-id="step-4.-explicitly-state-assumptions-about-relative-timing">Step 4. Explicitly state assumptions about relative timing</h4>
<p>Use time subscripts (e.g., <span class="math inline">\(L_0\)</span>, <span class="math inline">\(A_1\)</span>, <span class="math inline">\(Y_2\)</span>) to denote the assumed order of events <strong>Requirement</strong> causal diagrams must be acyclic (no feedback loops) for clear causal direction.</p>
</section>
<section id="step-5.-arrange-temporal-order-of-causality-visually" class="level4">
<h4 class="anchored" data-anchor-id="step-5.-arrange-temporal-order-of-causality-visually">Step 5. Arrange temporal order of causality visually</h4>
<p><em>Time orders causality; the spatial layout of your causal diagram should, therefore, respect time.</em></p>
<p>Left-to-right or top-to-bottom flows aid understanding of causal assertions <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>. As we shall repeatedly consider in <a href="#sec-part3"><strong>Part 3</strong></a>, establishing temporal ordering is necessary for evaluating identification problems.</p>
</section>
<section id="step-6.-box-variables-are-those-variables-that-we-adjust-for-to-control-confounding" class="level4">
<h4 class="anchored" data-anchor-id="step-6.-box-variables-are-those-variables-that-we-adjust-for-to-control-confounding">Step 6. Box variables are those variables that we adjust for to control confounding</h4>
<p>Typically, you will only box treatments and outcomes if they are measured with error.</p>
</section>
<section id="step-7.-represent-paths-structurally-not-parametrically" class="level4">
<h4 class="anchored" data-anchor-id="step-7.-represent-paths-structurally-not-parametrically">Step 7. Represent paths structurally, not parametrically</h4>
<p>Focus on whether paths exist, not their functional form (linear, non-linear, etc.). Parametric descriptions are not relevant for bias evaluation in a causal diagram. (For an explanation of causal interaction and diagrams, see: <span class="citation" data-cites="bulbulia2023">@bulbulia2023</span>.)</p>
</section>
<section id="step-8.-minimise-paths-to-those-necessary-for-the-identification-problem" class="level4">
<h4 class="anchored" data-anchor-id="step-8.-minimise-paths-to-those-necessary-for-the-identification-problem">Step 8. Minimise paths to those necessary for the identification problem</h4>
<p>Reduce clutter; only include paths critical for a specific question (e.g., backdoor paths, mediators).</p>
</section>
<section id="step-9.-consider-potential-unmeasured-confounders" class="level4">
<h4 class="anchored" data-anchor-id="step-9.-consider-potential-unmeasured-confounders">Step 9. Consider Potential Unmeasured Confounders</h4>
<p>Use your domain knowledge to hypothesise where unmeasured confounders might occur. Draw unmeasured confounders on your causal diagram.</p>
</section>
<section id="step-10.-state-graphical-conventions" class="level4">
<h4 class="anchored" data-anchor-id="step-10.-state-graphical-conventions"><strong>Step 10. State Graphical Conventions</strong></h4>
<p>Explain your symbol use (e.g., red for open backdoor paths). Consistency aids interpretation, and verbal descriptions add accessibility.</p>
</section>
</section>
</section>
<section id="section-part3" class="level2">
<h2 class="anchored" data-anchor-id="section-part3">Part 3. Using Causal Diagrams for Causal Identification - Worked Examples</h2>
<section id="notation" class="level3">
<h3 class="anchored" data-anchor-id="notation">Notation</h3>
<p>Causal diagrams use specific symbols to represent elements essential in causal inference <span class="citation" data-cites="pearl1995 pearl2009 greenland1999">[@pearl1995; @pearl2009; @greenland1999]</span>. However, as mentioned, no agreed-upon convention exists for creating causal diagrams. We list the symbols and conventions we use in this chapter in <a href="#tbl-01" class="quarto-xref">Table&nbsp;1</a>.</p>
<ul>
<li><strong><span class="math inline">\(A\)</span></strong> is the treatment or exposure variable – the intervention or condition whose effect on an outcome is under investigation. <strong>This symbol represents the cause</strong>.</li>
<li><strong><span class="math inline">\(Y\)</span></strong> is the outcome variable – the effect or result that is being studied. <strong>This symbol represents the effect</strong>.</li>
<li><strong><span class="math inline">\(L\)</span></strong> includes all measured confounders – variables that may affect both the treatment and the outcome.</li>
<li><strong><span class="math inline">\(U\)</span></strong> includes unmeasured confounders – variables not included in the analysis that could influence both the treatment and the outcome, potentially leading to biased conclusions.</li>
<li><strong><span class="math inline">\(M\)</span></strong> is a mediator variable – a factor through which the treatment affects the outcome. The focus here is on identifying the total effect of treatment <span class="math inline">\(A\)</span> on an outcome <span class="math inline">\(Y\)</span>. Still, it is also essential to understand how controlling for mediators can affect estimates of this total effect.</li>
</ul>
<div id="tbl-01" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Terminology used in this article for causal diagrams. The graph is adapted from <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>.
</figcaption>
<div aria-describedby="tbl-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">

</div>
</figure>
</div>
<p>We next describe our graphical conventions and causal diagrams. Again, because conventions may differ, it is always important to state them explicitly when reporting causal diagrams. <a href="#tbl-02" class="quarto-xref">Table&nbsp;2</a> describes the basic conventions that we employ in this chapter.</p>
<div id="tbl-02" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Basic conventions for causal diagrams (adapted from <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>).
</figcaption>
<div aria-describedby="tbl-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">

</div>
</figure>
</div>
</section>
<section id="graphical-table" class="level3">
<h3 class="anchored" data-anchor-id="graphical-table">Graphical Table</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> provides seven worked examples that put causal diagrams to work. Our example will focus on the question of whether access to green space affects happiness and approach this question by focusing on how different assumptions about (i) the structure of the world and (ii) the observational data that have been collected may affect strategies for confounding control and the confidence in our results. Each example refers to a row in the table.</p>
<div id="tbl-04" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Worked examples: This table is adapted from <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>.
</figcaption>
<div aria-describedby="tbl-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">

</div>
</figure>
</div>
</section>
<section id="the-problem-of-confounding-by-a-common-cause" class="level3">
<h3 class="anchored" data-anchor-id="the-problem-of-confounding-by-a-common-cause">1. The problem of confounding by a common cause</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 1 describes the confounding problem of a common cause. We encountered this problem in Part 1. Such confounding arises when there is a variable or set of variables, denoted by <span class="math inline">\(L\)</span>, that influence both the exposure, denoted by <span class="math inline">\(A\)</span>, and the outcome, denoted by <span class="math inline">\(Y.\)</span> Because <span class="math inline">\(L\)</span> is a common cause of both <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>, <span class="math inline">\(L\)</span> may create a statistical association between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> that does not reflect a causal association.</p>
<p>For instance, in the context of green spaces, consider people who live closer to green spaces (exposure <span class="math inline">\(A\)</span>) and their experience of improved happiness (outcome <span class="math inline">\(Y\)</span>). A common cause might be socioeconomic status <span class="math inline">\(L\)</span>. Individuals with higher socioeconomic status might have the financial capacity to afford housing near green spaces and simultaneously afford better healthcare and lifestyle choices, contributing to greater happiness. Thus, although the data may show a statistical association between living closer to green spaces <span class="math inline">\(A\)</span> and greater happiness <span class="math inline">\(Y\)</span>, this association might not reflect a direct causal relationship owing to confounding by socioeconomic status <span class="math inline">\(L\)</span>.</p>
<p>How might we obtain balance in this confounder to compare the treatments? Addressing confounding by a common cause involves adjusting for the confounder in one’s statistical model. We may adjust through regression, or more complicated methods, such as the inverse probability of treatment weighting, marginal structural models, and others see <span class="citation" data-cites="hernán2023">@hernán2023</span>. Such adjustment effectively closes the backdoor path from the exposure to the outcome. Equivalently, conditioning on <span class="math inline">\(L\)</span> d-separates <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 1, Column 3, emphasises that a confounder by common cause must precede both the exposure and the outcome. While it is often clear that a confounder precedes the exposure (e.g., a person’s country of birth), the timing might be uncertain in other cases. We assert its temporal precedence by positioning the confounder before the exposure in our causal diagrams. However, such a timing assumption might be strong when relying on cross-sectional data. Exploring causal scenarios where the confounder follows the treatment or outcome can be insightful in such cases. Causal diagrams are instrumental in examining possible timings and their implications for causal inference.</p>
<p>Next, we examine the effects of conditioning on a variable that is an effect of the treatment.</p>
</section>
<section id="mediator-bias" class="level3">
<h3 class="anchored" data-anchor-id="mediator-bias">2. Mediator Bias</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 1 presents a problem of mediator bias. Consider again whether proximity to green spaces, <span class="math inline">\(A\)</span>, affects happiness, <span class="math inline">\(Y\)</span>. Suppose that physical activity is a mediator, <span class="math inline">\(L\)</span>.</p>
<p>To fill out the example, imagine that living close to green spaces <span class="math inline">\(A\)</span> influences physical activity <span class="math inline">\(L\)</span>, subsequently affecting happiness <span class="math inline">\(Y\)</span>. If we were to condition on physical activity <span class="math inline">\(L\)</span>, assuming it to be a confounder, we would then bias our estimates of the total effect of proximity to green spaces <span class="math inline">\(A\)</span> on happiness <span class="math inline">\(Y\)</span>. Such a bias arises because of the chain rule. Conditioning on <span class="math inline">\(L\)</span> “d-separates” the total effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span>. This phenomenon is known as mediator bias. Notably, <span class="citation" data-cites="montgomery2018">@montgomery2018</span> finds dozens of examples of mediator bias in <em>experiments</em> in which control is made for variables that occur after the treatment. For example, obtaining demographic and other information from participants <em>after</em> a study is an invitation to mediator bias. If the treatment affects these variables, and the variables affect the outcome (as we assume by controlling for them), then researchers may induce mediator bias.</p>
<p>To avoid mediator bias when estimating a total causal effect, we should never condition on a mediator! The surest way to prevent this problem is to ensure that <span class="math inline">\(L\)</span> occurs before the treatment <span class="math inline">\(A\)</span> and before the outcome <span class="math inline">\(Y\)</span>. We present this solution in <a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 2 Col 3.</p>
</section>
<section id="confounding-by-collider-stratification-conditioning-on-a-common-effect" class="level3">
<h3 class="anchored" data-anchor-id="confounding-by-collider-stratification-conditioning-on-a-common-effect">3. Confounding by Collider Stratification (Conditioning on a Common Effect)</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 1 presents a problem of collider bias. Conditioning on a common effect, or collider stratification, occurs when a variable, denoted by <span class="math inline">\(L\)</span>, is influenced by both the exposure, denoted by <span class="math inline">\(A\)</span>, and the outcome, denoted by <span class="math inline">\(Y\)</span>.</p>
<p>Let us assume initial independence: the choice to live closer to green spaces (exposure <span class="math inline">\(A\)</span>) and happiness (outcome <span class="math inline">\(Y\)</span>) are independent: <span class="math inline">\(A \coprod Y(a)\)</span>.</p>
<p>We furthermore assume physical health <span class="math inline">\(L\)</span> is an effect of green space access, and happiness increases physical health. Thus, <span class="math inline">\(L\)</span> is an effect of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>. If we were to condition on <span class="math inline">\(L\)</span> in this setting, we would introduce <em>collider stratification bias</em>. When we control for the common effect <span class="math inline">\(L\)</span> (physical health), we may inadvertently introduce confounding. This happens because knowing something about <span class="math inline">\(L\)</span> gives us information about both <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>. If someone were high on physical health but low an access to greenspace, this would imply that they are higher in happiness. Likewise, if someone were low in physical health but high in access to green space, this would imply lower happiness. As a result of our conditioning strategy, it would appear that access to green space and happiness are negatively associated. However, if we were to avoid conditioning on the common outcome, we would find that the treatment and outcome are not associated.</p>
<p>How can we avoid collider bias, the temporal sequence of measurement affords a powerful strategy:</p>
<p>Ensure all common causes of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> – call them <span class="math inline">\(L\)</span> – are measured before the treatment <span class="math inline">\(A\)</span> occurs. Ensure further that <span class="math inline">\(Y\)</span> occurs after <span class="math inline">\(A\)</span> occurs. If the confounder <span class="math inline">\(L\)</span> is not measured, ensure that conditioning on its downstream proxy, <span class="math inline">\(L'\)</span> does not induce collider or mediator biases.</p>
<p>By adhering to this sequence, we can mitigate the risk of collider stratification bias and better understand the causal relationships between exposure, outcome, and their common effects.</p>
</section>
<section id="confounding-by-conditioning-on-a-descendant-of-a-confounder" class="level3">
<h3 class="anchored" data-anchor-id="confounding-by-conditioning-on-a-descendant-of-a-confounder">4. Confounding by Conditioning on a Descendant of a Confounder</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 4 presents a problem of collider bias by decent. Recall the rules of d-separation also apply to conditioning on descendants of a confounder. Thus, we may unwittingly evoke confounding by proxy when conditioning on a measured descendant of an unmeasured collider.</p>
<p>For example, if doctor visits were encoded in our data, and doctor visits were an effect of poor health, conditioning on doctor visits would function similarly to conditioning on poor health in the previous example, introducing collider confounding.</p>
</section>
<section id="m-bias-conditioning-on-pre-exposure-collider" class="level3">
<h3 class="anchored" data-anchor-id="m-bias-conditioning-on-pre-exposure-collider">5. M-bias: Conditioning on Pre-Exposure Collider</h3>
<p>There are only five elementary structures of causality. Every confounding scenario can be developed from these five elementary structures. We next consider how we may combine these elementary causal relationships in causal diagrams to create effective strategies for confounding control.</p>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 5 presents a form of pre-exposure over-conditioning confounding known as “M-bias”. This bias combines the collider structure and the fork structure, revealing what might not otherwise be obvious: it is possible to induce confounding even if we ensure that all variables have been measured <strong>before</strong> the treatment. The collider structure is evident in the path <span class="math inline">\(U_Y \to L_0\)</span> and <span class="math inline">\(U_A \to L_0\)</span>. The collider rule shows that conditioning on <span class="math inline">\(L_0\)</span> opens a path between <span class="math inline">\(U_Y\)</span> and <span class="math inline">\(U_A\)</span>. What is the result? We find that <span class="math inline">\(U_Y\)</span> is associated with the outcome <span class="math inline">\(Y\)</span> and <span class="math inline">\(U_A\)</span> is associated with treatment <span class="math inline">\(A\)</span>. This is a fork (common cause) structure. The association between treatment and outcome opened by conditioning on <span class="math inline">\(L\)</span> arises from an open back-door path that occurs from the collider structure. We thus have confounding. How might such confounding play out in a real-world setting?</p>
<p>In the context of green spaces, consider the scenario where an individual’s level of physical activity <span class="math inline">\(L\)</span> is influenced by an unmeasured factor related to their propensity to live near green spaces <span class="math inline">\(A\)</span> – say childhood upbringing. Suppose further that another unmeasured factor – say a genetic factor – increases both physical activity <span class="math inline">\(L\)</span> and happiness <span class="math inline">\(Y\)</span>. Here, physical activity <span class="math inline">\(L\)</span> does not affect the decision to live near green spaces <span class="math inline">\(A\)</span> or happiness <span class="math inline">\(Y\)</span> but is a descendent of unmeasured variables that do. If we were to condition on physical activity <span class="math inline">\(L\)</span> in this scenario, we would create the bias just described – “M-bias.”</p>
<p>How shall we respond to this problem? The solution is straightforward. If <span class="math inline">\(L\)</span> is neither a common cause of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> nor the effect of a shared common cause, then <span class="math inline">\(L\)</span> should not be included in a causal model. In terms of the conditional exchangeability principle, we find <span class="math inline">\(A \coprod Y(a)\)</span> yet <span class="math inline">\(A \cancel{\coprod} Y(a)| L\)</span>. So we should not condition on <span class="math inline">\(L\)</span>: do not control for exercise <span class="citation" data-cites="cole2010">[@cole2010]</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</section>
<section id="conditioning-on-a-descendent-may-sometimes-reduce-confounding" class="level3">
<h3 class="anchored" data-anchor-id="conditioning-on-a-descendent-may-sometimes-reduce-confounding">6. Conditioning on a Descendent May Sometimes Reduce Confounding</h3>
<p>In <a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> Row 6, we encounter a causal diagram in which an unmeasured confounder opens a back-door path that links the treatment and outcome. Here, we consider how we may use the rules of d-separation to obtain unexpected strategies for confounding control.</p>
<p>Returning to our green space example, suppose an unmeasured genetic factor <span class="math inline">\(U\)</span> affects one’s desire to seek out isolation in green spaces <span class="math inline">\(A\)</span> and independently affects one’s happiness <span class="math inline">\(Y\)</span>. Were such an unmeasured confounder to exist we could not obtain an unbiased estimate for the causal effect of green space access on happiness. We have, it seems, intractable confounding.</p>
<p>However, imagine a variable <span class="math inline">\(L^\prime\)</span>, a trait expressed later in life that arises from this genetic factor. If such a trait could be measured, even though the trait <span class="math inline">\(L'\)</span> is expressed after the treatment and outcome have occurred, controlling for <span class="math inline">\(L'\)</span> would enable investigators to close the backdoor path between the treatment and the outcome. This strategy works because a measured effect is a <em>proxy</em> for its cause <span class="math inline">\(U\)</span>, the unmeasured confounder. By conditioning on the late-adulthood trait, <span class="math inline">\(L'\)</span>, we partially condition on its cause, <span class="math inline">\(U\)</span>, the confounder of <span class="math inline">\(A \to Y\)</span>. Thus, not all effective confounding control strategies need to rely on measuring pre-exposure variables. Thus, the elementary causal structures reveal a possibility for confounding control by condition on a post-outcome variable. This strategy is not intuitive. Although a common cause must occur before a treatment (and outcome), its proxy need not! If we have a measure for the latter but not the former, we should condition on the post-treatment proxy of a pre-treatment common cause.</p>
</section>
<section id="confounding-control-with-three-waves-of-data-is-powerful-and-reveals-possibilities-for-estimating-an-incident-exposure-effect" class="level3">
<h3 class="anchored" data-anchor-id="confounding-control-with-three-waves-of-data-is-powerful-and-reveals-possibilities-for-estimating-an-incident-exposure-effect">7. Confounding Control with Three Waves of Data is Powerful and Reveals Possibilities for Estimating an “Incident Exposure” Effect</h3>
<p><a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> row 7 presents another setting in which there is unmeasured confounding. In response to this problem, we use the rules of d-separation to develop a data collection and modelling strategy that may greatly reduce the influence of unmeasured confounding. <a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a> row 7 col 3, by collecting data for both the treatment and the outcome at baseline and controlling for baseline values of the treatment and outcome, any unmeasured association between the treatment <span class="math inline">\(A_1\)</span> and the outcome <span class="math inline">\(Y_2\)</span> would need to be <em>independent</em> of their baseline measurements. As such, including the baseline treatment and outcome, along with other measured covariates that might be measured descendants of unmeasured confounders, is a strategy that exerts considerable confounding control <span class="citation" data-cites="vanderweele2020">[@vanderweele2020]</span>.</p>
<p>Furthermore, this causal graph makes evident a second benefit of this strategy. Returning to our example, a model that controls for baseline exposure would require that people initiate a change from the <span class="math inline">\(A_0\)</span> observed baseline level. Thus, by controlling for the baseline value of the treatment, we may learn about the causal effect of shifting one’s access to green space status. This effect is called the “incident exposure effect.” The incident exposure effect better emulates a “target trial” or the organisation of observational data into a hypothetical experiment in which there is a “time-zero” initiation of treatment in the data; see <span class="citation" data-cites="hernán2016">@hernán2016</span>; <span class="citation" data-cites="danaei2012">@danaei2012</span>; <span class="citation" data-cites="vanderweele2020">@vanderweele2020</span>; <span class="citation" data-cites="bulbulia2022">@bulbulia2022</span>. Without controlling for the baseline treatment, we could only estimate a “prevalent exposure effect.” If the initial exposure caused people some people to be miserable, we would not be able to track this outcome. The prevalent exposure effect would mask it, distorting causal inferences for the quantity of interest, namely, what would happen, on average, if people were to shift to having greater greenspace access.</p>
<p>Finally, we obtain further control for unmeasured confounding by controlling for both the baseline treatment and the baseline outcome. For an unmeasured confounder to affect both the treatment and the outcome (and unmeasured fork structure), it would need to do so independently of the baseline measures of the treatment and exposure <span class="citation" data-cites="vanderweele2020">[@vanderweele2020]</span>.</p>
<p>Thus, we generally require repeated measures on the same unit over time intervals to obtain an incident exposure effect and exert more robust control for unmeasured confounding using past states of the treatment and outcome. We must then model the treatments and outcomes as separate elements in our statistical model.</p>
</section>
</section>
<section id="section-part4" class="level2">
<h2 class="anchored" data-anchor-id="section-part4">Part 4. Practical Guide For Constructing Causal Diagrams and Reporting Results When Causal Structure is Unclear</h2>
<section id="cross-sectional-designs" class="level3">
<h3 class="anchored" data-anchor-id="cross-sectional-designs">Cross-sectional designs</h3>
<p>In environmental psychology, researchers often grapple with whether causal inferences can be drawn from cross-sectional data, especially when longitudinal data are unavailable. The challenge is common to cross-sectional designs. However, it is important to appreciate that even longitudinal studies require careful assumption management. We next discuss how causal diagrams can guide inference in both data types, with examples relevant to environmental psychologists.</p>
<section id="graphically-encode-causal-assumptions" class="level4">
<h4 class="anchored" data-anchor-id="graphically-encode-causal-assumptions">1. Graphically encode causal assumptions</h4>
<p>Causal inference turns on assumptions. Although cross-sectional analyses typically demand much stronger assumptions owing to the snapshot nature of data, these assumptions, when transparently articulated, do not permanently bar causal analysis. By stating different assumptions and modelling the data following these assumptions, we might find that certain causal conclusions are robust to these differences. Where the implications of different assumptions disagree, we can better determine the forms of data collection that would be required to settle such differences. Below we consider an example where assumptions point to different conclusions, revealing the benefits of collecting time-series data to assess whether a variable is a confounder or a mediator.</p>
</section>
<section id="time-invariant-confounders" class="level4">
<h4 class="anchored" data-anchor-id="time-invariant-confounders">2. Time-invariant confounders</h4>
<p>In cross-sectional studies, some confounders are inherently stable over time, such as ethnicity, year and place of birth, and biological gender. For environmental psychologists examining the relationship between access to natural environments and psychological well-being, these stable confounders can be adjusted for without concern for introducing bias from mediators or colliders. For example, conditioning on one’s year of birth can help isolate recent urban development’s effect on mental health, independent of generational differences in attitudes toward green spaces.</p>
</section>
<section id="stable-confounders" class="level4">
<h4 class="anchored" data-anchor-id="stable-confounders">3. Stable confounders</h4>
<p>While not immutable, other confounders are less likely to be influenced by the treatment. Variables such as sexual orientation, educational attainment, and often income level fall into this category. For instance, the effect of exposure to polluted environments on cognitive outcomes can be analysed by conditioning on education level, assuming that recent exposure to pollution is unlikely to change someone’s educational history retroactively.</p>
</section>
<section id="timing-and-reverse-causation" class="level4">
<h4 class="anchored" data-anchor-id="timing-and-reverse-causation">4. Timing and reverse causation</h4>
<p>The sequence of treatment and outcome is crucial. Sometimes, the temporal order is clear, reducing concerns about reverse causation. Mortality is a definitive outcome where the timing issue is unambiguous. If researching the effects of air quality on mortality, the causal direction (poor air quality leading to higher mortality rates) is straightforward. However, consider the relationship between socio-economic status and health outcomes; the direction of causality is complex because socioeconomic factors can influence health (through access to resources), and poor health can affect socio-economic status (through reduced earning capacity).</p>
</section>
<section id="create-causal-diagrams" class="level4">
<h4 class="anchored" data-anchor-id="create-causal-diagrams">5. Create causal diagrams</h4>
<p>Given the complexity of environmental influences on psychological outcomes, it’s prudent to construct multiple causal diagrams to cover various hypothetical scenarios. For example, when studying the effect of community green space on stress reduction, one diagram might assume the direct benefits of green space on stress. At the same time, another might include potential mediators like physical activity. By analysing and reporting findings based on multiple diagrams, researchers can explore the robustness of their conclusions across different theoretical frameworks and sets of assumptions.</p>
<p><a href="#tbl-cs" class="quarto-xref">Table&nbsp;4</a> describes ambiguous confounding control arising from cross-sectional data. Suppose again we are interested in the causal effect of access to greenspace, denoted by <span class="math inline">\(A\)</span> on “happiness,” denoted by <span class="math inline">\(Y\)</span>. We are uncertain whether exercise, denoted by <span class="math inline">\(L\)</span>, is a common cause of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> and thus a confounder or whether exercise is a mediator along the path from <span class="math inline">\(A\)</span> to <span class="math inline">\(Y\)</span>. That is: (1) those who exercise might seek access to green space, and (2) exercise might increase happiness. Alternatively, the availability of green space might encourage physical activity, which could subsequently affect happiness. Causal diagrams can disentangle these relationships by explicitly representing potential paths, thereby guiding appropriate strategies for confounding control selection. We recommend using multiple causal diagrams to investigate the consequences of different plausible structural assumptions.</p>
<p><strong>Assumption 1: Exercise is a common cause of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span></strong>, this scenario is presented in <a href="#tbl-cs" class="quarto-xref">Table&nbsp;4</a> row 1. Here, our strategy for confounding control is to estimate the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> conditioning on <span class="math inline">\(L\)</span>.</p>
<p><strong>Assumption 2: Exercise is a mediator of <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span></strong>, this scenario is presented in <a href="#tbl-cs" class="quarto-xref">Table&nbsp;4</a> row 2. Here, our strategy for confounding control is simply estimating the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> without including <span class="math inline">\(L\)</span> (assuming there are no other common causes of the treatment and outcome).</p>
<div id="tbl-cs" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: This table is adapted from <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>
</figcaption>
<div aria-describedby="tbl-cs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">

</div>
</figure>
</div>
<p>We can simulate data and run separate regressions to clarify how answers may differ, reflecting the different conditioning strategies embedded in the different assumptions. The following simulation generates data from a process in which exercise is a mediator (Scenario 2). (See Appendix C)</p>
<div class="cell" data-tbl-cap="Code for a simulation of a data generating process in which the effect of exercise (L) fully mediates the effect of greenspace (A) on happiness (Y).">
<div class="cell-output cell-output-stderr">
<pre><code>#StandWithUkraine</code></pre>
</div>
<div class="cell-output-display">

</div>
</div>
<p>This table presents the conditional treatment effect estimates. We present code for obtaining marginal treatment effects in <a href="#appendix-c">Appendix C</a></p>
<p>On the assumptions outlined in <a href="#tbl-cs" class="quarto-xref">Table&nbsp;4</a> row 1, in which we <em>assert</em> that exercise is a confounder, the average treatment effect of access to green space on happiness is ATE = 2.92, CI = [2.66, 3.21].</p>
<p>On the assumptions outlined in <a href="#tbl-cs" class="quarto-xref">Table&nbsp;4</a> row 2, in which we <em>assert</em> that exercise is a mediator, the average treatment effect of access to green space on happiness is ATE = -0.27, CI = [-0.52, -0.01].</p>
<p>Note that although the mediator <span class="math inline">\(L\)</span> is “highly significant”, including it in the model is a mistake. We obtain a negative effect estimate for the causal effect of green space access on happiness.</p>
<p>With only cross-sectional data, we must infer the results are inconclusive. Such understanding, although not the definitive answer we sought, is progress. The result tells us we should not be overly confident with our analysis (whatever p-values we recover!), and it clarifies that longitudinal data are needed.</p>
<p>These findings illustrate the role that assumptions about the relative timing of exercise as a confounder or as a mediator play.</p>
</section>
</section>
<section id="recommendations-for-conducting-and-reporting-causal-analyses-with-cross-sectional-data" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-conducting-and-reporting-causal-analyses-with-cross-sectional-data">Recommendations for Conducting and Reporting Causal Analyses with Cross-Sectional Data</h3>
<p>When analysing and reporting analyses with cross-sectional data, researchers face the challenge of making causal inferences without the benefit of temporal information.</p>
<p>The following recommendations aim to guide researchers in navigating these challenges effectively:</p>
<p><strong>Warning</strong>: before proceeding with cross-sectional analysis, examine whether panel data are available. Longitudinal data can provide crucial temporal information that aids in establishing causality, offering a more robust framework for causal inference. If longitudinal data are unavailable, the recommendations above become even more critical for using cross-sectional data best.</p>
<section id="draw-multiple-causal-diagrams" class="level4">
<h4 class="anchored" data-anchor-id="draw-multiple-causal-diagrams">1. <strong>Draw multiple causal diagrams</strong></h4>
<p>Draw various causal diagrams to represent different theoretical assumptions about the relationships and timing of variables relevant to an identification problem. This approach comprehensively examines possible causal pathways, clarifying variables’ roles as confounders, mediators, or colliders. For example, in studying the effect of urban green spaces on mental health, consider diagrams that account for both direct effects and pathways involving mediators like physical activity or social interaction.</p>
</section>
<section id="perform-and-report-analyses-for-each-assumption" class="level4">
<h4 class="anchored" data-anchor-id="perform-and-report-analyses-for-each-assumption">2. <strong>Perform and report analyses for each assumption</strong></h4>
<p>Conduct and transparently report separate analyses for each scenario your causal diagrams depict. This practice ensures that your study is theoretically grounded for each model. Presenting results from each analytical approach and the underlying assumptions and statistical methods promotes a balanced interpretation of findings. Although this practice may be unfamiliar to some editors and reviewers, it is crucial to address the inherent challenges of cross-sectional analysis by expanding the scope of investigation beyond a single hypothesis.</p>
</section>
<section id="interpret-findings-with-attention-to-ambiguities" class="level4">
<h4 class="anchored" data-anchor-id="interpret-findings-with-attention-to-ambiguities">3. <strong>Interpret findings with attention to ambiguities</strong></h4>
<p>Interpret results carefully, highlighting any ambiguities or inconsistencies across analyses. Discuss how varying assumptions about structural relationships and the timing of events can lead to divergent conclusions. For instance, exploring the theoretical and empirical implications of access to green spaces appears to positively affect mental health when considering exercise as a mediator but a negative effect when considered a confounder.</p>
</section>
<section id="report-divergent-findings" class="level4">
<h4 class="anchored" data-anchor-id="report-divergent-findings">4. <strong>Report divergent findings</strong></h4>
<p>Approach conclusions with caution, especially when findings suggest differing practical implications. Acknowledge the limitations of cross-sectional data in establishing causality and the potential for alternative explanations.</p>
</section>
<section id="identify-avenues-for-future-research" class="level4">
<h4 class="anchored" data-anchor-id="identify-avenues-for-future-research">5. <strong>Identify avenues for future research</strong>:</h4>
<p>Target future research that could clarify ambiguities. Consider the design of longitudinal studies or experiments capable of clarifying these ambiguities.</p>
</section>
<section id="supplement-observational-data-with-simulated-data" class="level4">
<h4 class="anchored" data-anchor-id="supplement-observational-data-with-simulated-data">6. <strong>Supplement observational data with simulated data</strong></h4>
<p>Leverage data simulation to understand the complexities of causal inference. Simulating data based on various theoretical models allows researchers to explore the impact of different assumptions on their findings. This method tests analytical strategies under controlled conditions, assessing the robustness of conclusions against assumption violations or unobserved confounders.</p>
</section>
<section id="conduct-sensitivity-analyses-to-assess-robustness" class="level4">
<h4 class="anchored" data-anchor-id="conduct-sensitivity-analyses-to-assess-robustness">7. <strong>Conduct sensitivity analyses to assess robustness</strong></h4>
<p>implement sensitivity analyses to determine how dependent conclusions are on specific assumptions or parameters within your causal model. Use data simulation as a tool for these analyses, evaluating the sensitivity of results to various theoretical and methodological choices.</p>
<p>Cross-sectional data are limiting; however, by appropriately bounding uncertainties in your causal inferences, you may use them to advance understanding. May your clarity and caution serve as an example for others.</p>
</section>
</section>
<section id="longitudinal-designs" class="level3">
<h3 class="anchored" data-anchor-id="longitudinal-designs">Longitudinal Designs</h3>
<p>Causation occurs in time. Longitudinal designs offer a substantial advantage over cross-sectional designs for causal inference because sequential measurements allow us to capture causation and quantify its magnitude. We typically do not need to assert timing as in cross-sectional data settings. Because we know when variables have been measured, we can reduce ambiguity about the directionality of causal relationships. For instance, tracking changes in “happiness” following changes in access to green spaces over time can more definitively suggest causation than cross-sectional snapshots.</p>
<p>Despite this advantage, longitudinal researchers still face assumptions regarding the absence of unmeasured confounders or the stability of measured confounders over time. These assumptions must be explicitly stated. As with cross-sectional designs, wherever assumptions differ, researchers should draw different causal diagrams that reflect these assumptions and subsequently conduct and report separate analyses.</p>
<p>In this section, we simulate a dataset to demonstrate the benefits of incorporating both baseline exposure and baseline outcomes into analysing the effect of access to open green spaces on happiness. This approach allows us to control for initial levels of exposure and outcomes, offering a clearer understanding of the causal relationship. <a href="#appendix-d-simulation-of-different-confounding-control-strategies">Appendix D</a> provides the code. <a href="#appendix-e-non-parametric-estimation-of-average-treatment-effects-using-causal-forests-appendix-causal-forests">Appendix E</a> provides an example of a non-parametric estimator for the causal effect. As mentioned before, by conditioning on baseline levels of access to green spaces and baseline mental health, researchers can more accurately estimate the <em>incident effect</em> of changes in green space access on changes in mental health. <a href="#tbl-lg" class="quarto-xref">Table&nbsp;5</a> offers an example of how we may use multiple causal diagrams to clarify the problem and our confounding control strategy.</p>
<div id="tbl-lg" class="anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-lg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: This table is adapted from <span class="citation" data-cites="bulbulia2023">[@bulbulia2023]</span>
</figcaption>
<div aria-describedby="tbl-lg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">

</div>
</figure>
</div>
<p>Our analysis assessed the average treatment effect (ATE) of access to green spaces on happiness across three distinct models: uncontrolled, standard controlled, and interaction controlled. These models were constructed using a hypothetical cohort of 10,000 individuals, incorporating baseline exposure to green spaces (<span class="math inline">\(A_0\)</span>), baseline happiness (<span class="math inline">\(Y_0\)</span>), baseline confounders (<span class="math inline">\(L_0\)</span>), and an unmeasured confounder (<span class="math inline">\(U\)</span>). The detailed simulation process and model construction are given in <a href="#appendix-simulate-longitudinal-ate">Appendix D</a>.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: grf</code></pre>
</div>
</div>
<p>The ATE estimates from these models provide critical insights into the effects of green space exposure on individual happiness while accounting for various confounding factors. The model without control variables estimated ATE = 1.55, CI = [1.47, 1.63], significantly overestimating the treatment effect. Incorporating standard covariate control reduced this estimate to ATE = 0.86, CI = [0.8, 0.92], aligning more closely with the expected effect but still overestimating. Most notably, the model that included interactions among baseline exposure, outcome, and confounders yielded ATE = 0.29, CI = [0.27, 0.31], approximating the true effect of 0.3. This finding underscores the importance of including baseline values of the exposure and outcome wherever these data are available.</p>
</section>
<section id="recommendations-for-conducting-and-reporting-causal-analyses-with-longitudinal-data" class="level3">
<h3 class="anchored" data-anchor-id="recommendations-for-conducting-and-reporting-causal-analyses-with-longitudinal-data">Recommendations for Conducting and Reporting Causal Analyses with Longitudinal Data</h3>
<p>Longitudinal data offer strong advantages for causal inference by enabling researchers to establish the relative timing of confounders, treatments, and outcomes. The temporal sequence of events is crucial for establishing causality because causality occurs in time. The following recommendations aim to guide researchers in leveraging longitudinal data effectively to conduct and report causal analyses:</p>
<section id="draw-multiple-causal-diagrams-1" class="level4">
<h4 class="anchored" data-anchor-id="draw-multiple-causal-diagrams-1">1. <strong>Draw multiple causal diagrams</strong></h4>
<ul>
<li><strong>Identification problem diagram</strong>: begin by constructing a causal diagram that outlines your initial assumptions about the relationships among variables, identifying potential confounders and mediators. This diagram should illustrate the complexity of the identification problem.</li>
<li><strong>Solution diagram</strong>: next, create a separate causal diagram that proposes solutions to the identified problems. This may involve highlighting variables for conditioning to isolate the causal effect of interest or suggesting novel pathways for investigation. Having distinct diagrams for the problem and its proposed solutions clarifies your study’s analytic strategy and theoretical underpinning.</li>
</ul>
<p><a href="#tbl-lg" class="quarto-xref">Table&nbsp;5</a> provides an example of a table with multiple causal diagrams clarifying potential sources of confounding threats and reports strategies for addressing them.</p>
</section>
<section id="attempt-longitudinal-designs-with-at-least-three-waves-of-data" class="level4">
<h4 class="anchored" data-anchor-id="attempt-longitudinal-designs-with-at-least-three-waves-of-data">2. **Attempt longitudinal designs with at least three waves of data</h4>
<p>Incorporating data from at least three intervals considerably enhances your ability to infer causal relationships. This approach allows for the examination of temporal precedence and lagged effects. For example, by adjusting for physical activity measured before the treatment, we can ensure that physical activity does not result from a new initiation to green spaces, which we establish by measuring green space access at baseline. Establishing chronological order in the temporal sequence of events allows us to avoid confounding problems 1-4 in <a href="#tbl-04" class="quarto-xref">Table&nbsp;3</a>.</p>
</section>
<section id="calculate-average-treatment-effects-for-a-clearly-specified-target-population" class="level4">
<h4 class="anchored" data-anchor-id="calculate-average-treatment-effects-for-a-clearly-specified-target-population">3. Calculate Average Treatment Effects for a clearly specified target population**</h4>
<p>Estimating the average treatment effect (ATE) across the entire study population provides a comprehensive measure of the intervention’s effects. This step is crucial for understanding the treatment’s overall effect and generalising findings to broader populations.</p>
</section>
<section id="where-causality-is-unclear-report-results-for-multiple-causal-graphs" class="level4">
<h4 class="anchored" data-anchor-id="where-causality-is-unclear-report-results-for-multiple-causal-graphs">4. Where causality is unclear, report results for multiple causal graphs</h4>
<p>Given that the true causal structure may be complex and partially unknown, analysing and reporting results under each plausible causal diagram is prudent. This practice acknowledges the uncertainty inherent in causal modelling and demonstrates the robustness of findings across different theoretical frameworks.</p>
</section>
<section id="conduct-sensitivity-analyses" class="level4">
<h4 class="anchored" data-anchor-id="conduct-sensitivity-analyses">5. Conduct sensitivity analyses</h4>
<p>Sensitivity analyses are essential for assessing the robustness of your findings to various assumptions within the causal model. These analyses can include simulations, as illustrated in Appendices C and D, to explore the impact of unmeasured confounding, model misspecification, and alternative causal pathways on the study conclusions. Sensitivity analyses help to identify the conditions under which the findings hold, enhancing the credibility of the causal inferences. (For more about addressing missing data, see: <span class="citation" data-cites="bulbulia2024PRACTICAL">[@bulbulia2024PRACTICAL]</span>.)</p>
</section>
<section id="address-missing-data-at-baseline-and-study-attrition" class="level4">
<h4 class="anchored" data-anchor-id="address-missing-data-at-baseline-and-study-attrition">6. <strong>Address missing data at baseline and study attrition</strong></h4>
<p>Longitudinal studies often need help with missing data and attrition, which can introduce bias and affect the validity of causal inferences. Implement and report strategies for handling missing data, such as multiple imputation or sensitivity analyses that assess the bias arising from missing responses at the study’s conclusion. (For more about addressing missing data, see: <span class="citation" data-cites="bulbulia2024PRACTICAL">[@bulbulia2024PRACTICAL]</span>).</p>
<p>By following these recommendations, you will more effectively navigate the inherent limitations of observational longitudinal data, improving the quality of your causal inferences.</p>
</section>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This chapter has introduced the potential outcomes framework for causal inference and using directed acyclic graphs (DAGs) in environmental psychology. In <a href="#section-part1"><strong>Part 1</strong></a> we discussed three critical assumptions necessary for estimating average treatment effects from data:</p>
<ol type="1">
<li><strong>Conditional Exchangeability</strong>: This assumption posits that treatment allocation is randomised and independent of potential outcomes, conditional on measured covariates.</li>
<li><strong>Causal Consistency</strong>: This assumption asserts that the outcome observed under the treatment condition corresponds to the outcome that would have been observed had the unit received the treatment, and similarly for the control condition.</li>
<li><strong>Positivity</strong>: This assumption asserts that every unit has a non-zero probability of receiving any treatments under comparison.</li>
</ol>
<p>Although randomised controlled experiments naturally satisfy these assumptions through design—randomisation ensures exchangeability, control guarantees consistency, and design secures positivity -— observational studies typically do not. To obtain consistent causal estimates from observational data, we must assess the extent to which these assumptions can be satisfied.</p>
<p>In <a href="#sec-part2"><strong>Part 2</strong></a>, we explained how causal diagrams work and described their utility in addressing the assumption of conditional exchangeability, or the “no unmeasured confounders” assumption. We identified <a href="#sec-five-elementary">five fundamental structures</a> underlying all causal relationships. We discovered <a href="#sec-four-rules">four elementary rules</a> for evaluating the implications of conditioning on elements within these structures regarding observable statistical associations in data. Thus, causal diagrams provide a simplified visual language for translating complex causal relationships into data observations. However, the relationships in these diagrams represent assertions that are not directly verifiable from the data. The causal relationships between treatments and outcomes are the only relationships not based on assertion. Causal diagrams help us identify structural sources of bias in the statistical associations between treatments and outcomes that may arise from assumed causal relationships, potentially associating treatments with outcomes irrespective of causal links.</p>
<p>In <a href="#section-part3"><strong>Part 3</strong></a>*, we applied causal diagrams to seven common confounding scenarios, demonstrating that a causal diagram needs to highlight only those aspects of a causal setting relevant for assessing structural sources of bias linking treatment and outcome in a non-causal manner. We focused on omitting nodes and paths not directly necessary for our stated identification problem, emphasising that causal diagrams are tailored to context-dependent questions and our assumptions about the world’s causal structure.</p>
<p>In <a href="#section-part4"><strong>Part 4</strong></a>, we showed how investigators might create multiple causal diagrams when the structure of a causal problem is ambiguous and illustrated the benefits of this approach through data simulation. We provided guidelines for reporting in scenarios where only cross-sectional data are available or when researchers have access to repeated measures of longitudinal data.</p>
<p>Although this discussion has focused on seven specific applications of causal diagrams, their applicability extends much further. The straightforward rules governing how variables become associated or disassociated through conditioning on nodes within basic structures enable the use of causal diagrams for quantitatively exploring causality in myriad questions. These applications transcend effective modelling strategies and informing data collection strategies, including adopting repeated measures designs.</p>
<p>We hope this chapter will inspire environmental psychologists to deepen their understanding of causal inference and incorporate causal diagrams into their research practices. The methodologies for distinguishing causation from correlation are well-established; powerful tools for causal inference are accessible. There is no longer any justification for reporting associations and speculating about causes. It is within your reach to quantify magnitudes of causality conditional on assumptions encoded in your causal graphs.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="funding" class="level2">
<h2 class="anchored" data-anchor-id="funding">Funding</h2>
<p>This work is supported by a grant from the Templeton Religion Trust (TRT0418). JB received support from the Max Planck Institute for the Science of Human History. The funders had no role in preparing the manuscript or deciding to publish it.</p>
</section>
<section id="contributions" class="level2">
<h2 class="anchored" data-anchor-id="contributions">Contributions</h2>
<p>DH proposed the chapter. JB developed the approach and wrote the first draft. Both authors contributed substantially to the final work.</p>
<!-- 

### The Four Elementary Rules For Evaluating Confounding

To review, causal diagrams allow researchers to visualise and systematically identify potential confounders and strategies for adjusting for them. There are five basic graphical structures:

#### 1. **Causality Absent**  $A$ does not cause $B$: absent any common causes, there is no statistical association between them.

$$\xorxA$$ 

#### 2. **Causality Present**  $A$ causes $B$: absent conditioning that blocks them, $A$ and $B$ will be statistically associated.

$$\xtoxA$$

#### 3. **The Fork Structure** $A$ causes $B$ and $A$ causes $C$: absent conditioning on $A$, $B$ and $C$ will be statistically associated. Conditional on $A$, $B$ and $C$ will be independent.

$$\forkTINY$$

#### 4. **The Chain Structure**  $A$ causes $B$ and $B$ causes $C$: absent conditioning on $B$, $A$ and $C$ will be statistically associated. Conditioning on $B$, $A$ and $C$ will be independent. 

$$\chainTINY$$ 

#### 5. **A Collider Structure**  $A$ causes $C$ and $B$ causes $C$: absent conditioning on $C$, $A$ and $B$ will be statistically independant. Conditioning on $C$, $A$ and $B$ will be statistically associated. 

$$\immoralityTINY$$

From these five elementary structures, we discovered four rules that allow us to use these structures to evaluate confounding and its control:

#### 1. **The Fork Rule** 

When a common cause influences treatment and outcome, condition on the common cause to avoid bias.

#### 2. **The Chain Rule**

  (i)  For total effect estimates, avoid conditioning on mediators within the causal path.
  (ii) For mediation analysis, ensure potential confounders do not introduce bias. )(Note: mediation analysis is complex [@vanderweele2015; @vansteelandt2012; @bulbulia2023].)

#### 3. **The Collider Rule**

Conditioning on a common effect opens a path between the two variables that cause it.  

#### 4. **The Proxy Rule**

Conditioning on a descendant is a proxy for conditioning on its parent.  -->
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" role="list">

</div>
<div style="page-break-after: always;"></div>
</section>
<section id="appendix-a" class="level2">
<h2 class="anchored" data-anchor-id="appendix-a">Appendix A: Glossary</h2>
<p>This appendix provides a glossary of common terminology in causal inference.</p>
<p><strong>Acyclic</strong>: a causal diagram cannot contain feedback loops. More precisely, no variable can be an ancestor or descendant of itself. If variables are repeatedly measured here, it is vital to index nodes by the relative timing of the nodes.</p>
<p><strong>Adjustment set</strong>: a collection of variables we must either condition upon or deliberately avoid conditioning upon to obtain a consistent causal estimate for the effect of interest <span class="citation" data-cites="pearl2009">[@pearl2009]</span>.</p>
<p><strong>Ancestor (parent)</strong>: a node with a direct or indirect influence on others, positioned upstream in the causal chain.</p>
<p>**Arrow denotes a causal relationship linking nodes.</p>
<p><strong>Backdoor path</strong>: a “backdoor path” between a treatment variable, <span class="math inline">\(A\)</span>, and an outcome variable, <span class="math inline">\(Y\)</span>, is a sequence of links in a causal diagram that starts with an arrow into <span class="math inline">\(A\)</span> and reaches <span class="math inline">\(Y\)</span> through common causes, introducing potential confounding bias such that statistical association does not reflect causality. To estimate the causal effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> without bias, these paths must be blocked by adjusting for confounders. The backdoor criterion guides the selection of variables for adjustment to ensure unbiased causal inference.</p>
<p><strong>Conditioning</strong>: explicitly accounting for a variable in our statistical analysis to address the identification problem. In causal diagrams, we usually represent conditioning by drawing a box around a node of the conditioned variable, for example, <span class="math inline">\(\boxed{L_{0}}\to A_{1} \to L_{2}\)</span>. We do not box exposures and outcomes because we assume they are included in a model by default. Depending on the setting, we may condition by regression stratification, inverse probability of treatment weighting, g-methods, doubly robust machine learning algorithms, or other methods. We do not cover such methods in this tutorial; however, see <span class="citation" data-cites="hernan2023">@hernan2023</span>.</p>
<p><strong>Counterfactual</strong>: a hypothetical outcome that would have occurred for the same individuals under a different treatment condition than the one they experienced.</p>
<p><strong>Direct effect</strong>: the portion of the total effect of a treatment on an outcome that is not mediated by other variables within the causal pathway.</p>
<p><strong>Collider</strong>: a variable in a causal diagram at which two incoming paths meet head-to-head. For example, if <span class="math inline">\(A \rightarrowred \boxed{L} \leftarrowred Y\)</span>, then <span class="math inline">\(L\)</span> is a collider. If we do not condition on a collider (or its descendants), the path between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span> remains closed. Conditioning on a collider (or its descendants) will induce an association between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p><strong>Confounder</strong>: a member of an adjustment set. Notice a variable is a ‘confounder’ in relation to a specific adjustment set. ‘Confounder’ is a relative concept <span class="citation" data-cites="lash2020">[@lash2020]</span>.</p>
<p><strong>D-separation</strong>: in a causal diagram, a path is ‘blocked’ or ‘d-separated’ if a node along it interrupts causation. Two variables are d-separated if all paths connecting them are blocked, making them conditionally independent. Conversely, unblocked paths result in ‘d-connected’ variables, implying potential dependence <span class="citation" data-cites="pearl1995">[@pearl1995]</span>.</p>
<p><strong>Descendant (child)</strong>: a node directly or indirectly influenced by upstream nodes (parents).</p>
<p><strong>Effect-modifier</strong>: a variable is an effect-modifier, or ‘effect-measure modifier’ if its presence changes the magnitude or direction of the effect of an exposure or treatment on an outcome across the levels or values of this variable. In other words, the impact of the exposure is different at different levels of the effect modifier.</p>
<p><strong>External validity</strong>: the extent to which causal inferences can be generalised to other populations, settings, or times, also called “Target Validity.”</p>
<p><strong>Identification problem</strong>: the challenge of estimating the causal effect of a variable by adjusting for measured variables on units in a study. Causal diagrams were developed to address the identification problem by application of the rules of d-separation to a causal diagram.</p>
<p><strong>Indirect effect (mediated effect)</strong>: The portion of the total effect transmitted through a mediator variable.</p>
<p><strong>Internal validity</strong>: the degree to which the design and conduct have prevented bias, ensuring that the causal relationship observed can be confidently attributed to the treatment and not to other factors.</p>
<p><strong>Instrumental variable</strong>: an ancestor of the exposure but not of the outcome. An instrumental variable affects the outcome only through its effect on the exposure and not otherwise. Whereas conditioning on a variable causally associated with the outcome rather than with the exposure will generally increase modelling precision, we should refrain from conditioning on instrumental variables <span class="citation" data-cites="cinelli2022">[@cinelli2022]</span>. Second, when an instrumental variable is the descendant of an unmeasured confounder, we should generally condition the instrumental variable to provide a partial adjustment for a confounder.</p>
<p><strong>Mediator</strong>: a variable that transmits the effect of the treatment variable on the outcome variable, part of the causal pathway between treatment and outcome.</p>
<p><strong>Modified Disjunctive Cause Criterion</strong>: <span class="citation" data-cites="vanderweele2019">@vanderweele2019</span> recommends obtaining a maximally efficient adjustment, which he calls a ‘confounder set’ A member of this set is any set of variables that can reduce or remove structural sources of bias. The strategy is as follows:</p>
<ol type="a">
<li>Control for any variable that causes the exposure, the outcome, or both.</li>
<li>Control for any proxy for an unmeasured variable that is a shared cause of the exposure and outcome.</li>
<li>Define an instrumental variable as a variable associated with the exposure but does not influence the outcome independently, except through the exposure. Exclude any instrumental variable that is not a proxy for an unmeasured confounder from the confounder set <span class="citation" data-cites="vanderweele2019">[@vanderweele2019]</span>.</li>
</ol>
<p>Note that the concept of a ‘confounder set’ is broader than that of an ‘adjustment set.’ Every adjustment set is a member of a confounder set. Hence, the Modified Disjunctive Cause Criterion will eliminate bias when the data permit. However, a confounder set includes variables that reduce bias in cases where confounding cannot be eliminated.</p>
<p><strong>Node</strong>: characteristic or features of units in a population (‘variable’) represented on a causal diagram. In a causal diagram, nodes are drawn with reference to variable distributions for the target population.</p>
<p><strong>Randomisation</strong>: The process of randomly assigning subjects to different treatments or control groups to eliminate selection bias in experimental studies.</p>
<p><strong>Reverse causation</strong>: <span class="math inline">\(\atoyassert\)</span>, but in reality <span class="math inline">\(\ytoa\)</span></p>
<p><strong>Statistical model:</strong> a mathematical representation of the relationships between variables in which we quantify covariances and their corresponding uncertainties in the data. Statistical models typically correspond to multiple causal structures <span class="citation" data-cites="pearl2018 vanderweele2022b hernan2023">[@pearl2018; @vanderweele2022b; @hernan2023]</span>. That is, the causes of such covariances cannot be identified without assumptions.</p>
<p><strong>Structural model:</strong> defines assumptions about causal relationships. Causal diagrams graphically encode these assumptions <span class="citation" data-cites="hernan2023">[@hernan2023]</span>, leaving out the assumption about whether the exposure and outcome are causally associated. We can only compute causal effects outside of randomised experiments with structural models. A structural model is needed to interpret the statistical findings in causal terms. Structural assumptions should be developed in consultation with experts. The role of structural assumptions when interpreting statistical results needs to be better understood across many human sciences and forms the motivation for my work here.</p>
<p><strong>Time-varying confounding:</strong> occurs when a confounder that changes over time acts as a mediator or collider in the causal pathway between exposure and outcome. Controlling for such a confounder can introduce bias. Not controlling for it can retain bias.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="appendix-b" class="level2">
<h2 class="anchored" data-anchor-id="appendix-b">Appendix B: Causal Consistency in observational settings</h2>
<p>In observational research, there are typically multiple versions of the treatment. The theory of causal inference under multiple versions of treatment proves we can consistently estimate causal effects where the different versions of treatment are conditionally independent of the outcomes <span class="citation" data-cites="vanderweele2009 vanderweele2013 vanderweele2018">[@vanderweele2009, @vanderweele2009; @vanderweele2013; @vanderweele2018]</span></p>
<p>Let <span class="math inline">\(\coprod\)</span> denote independence. Where there are <span class="math inline">\(K\)</span> different versions of treatment <span class="math inline">\(A\)</span> and no confounding for <span class="math inline">\(K\)</span>’s effect on <span class="math inline">\(Y\)</span> given measured confounders <span class="math inline">\(L\)</span> such that</p>
<p><span class="math display">\[
Y(k) \coprod K | L
\]</span></p>
<p>Then it can be proved that causal consistency follows. According to the theory of causal inference under multiple versions of treatment, the measured variable <span class="math inline">\(A\)</span> functions as a “coarsened indicator” for estimating the causal effect of the multiple versions of treatment <span class="math inline">\(K\)</span> on <span class="math inline">\(Y(k)\)</span> <span class="citation" data-cites="vanderweele2009 vanderweele2013 vanderweele2018">[@vanderweele2009; @vanderweele2013; @vanderweele2018]</span>.</p>
<p>In the context of green spaces, let <span class="math inline">\(A\)</span> represent the general action of moving closer to any green space and <span class="math inline">\(K\)</span> represent the different versions of this treatment. For instance, <span class="math inline">\(K\)</span> could denote moving closer to different green spaces such as parks, forests, community gardens, or green spaces with varying amenities and features.</p>
<p>Here, the conditional independence implies that, given measured confounders <span class="math inline">\(L\)</span> (e.g.&nbsp;socioeconomic status, age, personal values), the type of green space one moves closer to (<span class="math inline">\(K\)</span>) is independent of the outcomes <span class="math inline">\(Y(k)\)</span> (e.g.&nbsp;mental well-being under the <span class="math inline">\(K\)</span> conditions). In other words, the version of green space one chooses to live near does not affect the <span class="math inline">\(K\)</span> potential outcomes, provided the confounders <span class="math inline">\(L\)</span> are appropriately controlled for in our statistical models.</p>
<p>Put simply, strategies for confounding control and consistently estimating causal effects when multiple treatment versions converge. However, the quantities we estimate under multiple treatment versions might need clearer interpretations. For example, we cannot readily determine which of the many treatment versions is most causally efficacious and which lack any causal effect or are harmful.</p>
<div style="page-break-after: always;"></div>
<section id="appendix-c" class="level3">
<h3 class="anchored" data-anchor-id="appendix-c">Appendix C Simulation of Cross-Sectional Data to Compute the Average Treatment Effect When Conditioning on a Mediator</h3>
<p>This appendix outlines a simulation designed to demonstrate the potential pitfalls of conditioning on a mediator in cross-sectional analyses. The simulation explores the scenario where the effect of access to green space (<span class="math inline">\(A\)</span>) on happiness (<span class="math inline">\(Y\)</span>) is fully mediated by exercise (<span class="math inline">\(L\)</span>). This setup aims to illustrate how incorrect assumptions about the role of a variable (mediator vs.&nbsp;confounder) can lead to misleading estimates of the Average Treatment Effect (ATE).</p>
<section id="methodology" class="level4">
<h4 class="anchored" data-anchor-id="methodology">Methodology</h4>
<ol type="1">
<li><p><strong>Data Generation</strong>: We simulate a dataset for 1,000 individuals, where access to green space (<span class="math inline">\(A\)</span>) influences exercise (<span class="math inline">\(L\)</span>), which in turn affects happiness (<span class="math inline">\(Y\)</span>$). The simulation is based on predefined parameters that establish L as a mediator between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>Parameter Definitions</strong>:</p>
<ul>
<li>The probability of access to green space (<span class="math inline">\(A\)</span>) is set at 0.5.</li>
<li>The effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(L\)</span> (exercise) is quantified by <span class="math inline">\(\beta = 2\)</span>.</li>
<li>The effect of <span class="math inline">\(L\)</span> on <span class="math inline">\(Y\)</span> (happiness) is quantified by <span class="math inline">\(\delta = 1.5\)</span>.</li>
<li>Standard deviations for <span class="math inline">\(L\)</span> and <span class="math inline">\(Y\)</span> are set at 1 and 1.5, respectively.</li>
</ul></li>
<li><p><strong>Model Specifications</strong>:</p>
<ul>
<li><strong>Model 1</strong> (Correct Assumption): fits a linear regression model assuming <span class="math inline">\(L\)</span> as a mediator, including both <span class="math inline">\(A\)</span> and <span class="math inline">\(L\)</span> as regressors on <span class="math inline">\(Y\)</span>. This model aligns with the data-generating process and correctly identifies L as a mediator.</li>
<li><strong>Model 2</strong> (Incorrect Assumption): fits a linear regression model including only <span class="math inline">\(A\)</span> as a regressor on <span class="math inline">\(Y\)</span>, omitting the mediator <span class="math inline">\(L\)</span>. This model assesses the direct effect of A on Y without accounting for mediation.</li>
</ul></li>
<li><p><strong>Analysis and Comparison</strong>: The analysis compares the estimated effects of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> under both model specifications. By including <span class="math inline">\(L\)</span> as a predictor in Model 1, we account for its mediating role, whereas Model 2 overlooks this aspect by excluding <span class="math inline">\(L\)</span> from the analysis.</p></li>
<li><p><strong>Presentation</strong>: The results are displayed in a comparative table formatted for publication. The table contrasts the regression coefficients and significance levels obtained under each model, highlighting the impact of correctly versus incorrectly assuming the role of <span class="math inline">\(L\)</span> in the relationship between <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
</ol>
<div class="cell" data-tbl-cap="Code for a simulation of a data generating process in which the effect of exercise (L) fully mediates the effect of greenspace (A) on happiness (Y).">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load libraries</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="sc">!</span><span class="fu">require</span>(kableExtra)<span class="er">)</span>{<span class="fu">install.packages</span>(<span class="st">"kableExtra"</span>)} <span class="co"># tables</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(gtsummary)){<span class="fu">install.packages</span>(<span class="st">"gtsummary"</span>)} <span class="co"># tables</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># simulation seed</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co">#  reproducibility</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># define the parameters </span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span> <span class="co"># Number of observations</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fl">0.5</span>  <span class="co"># Probability of A = 1 (access to greenspace)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="dv">0</span> <span class="co"># Intercept for L (exercise)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">=</span> <span class="dv">2</span>  <span class="co"># Effect of A on L </span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>gamma <span class="ot">=</span> <span class="dv">1</span> <span class="co"># Intercept for Y </span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>delta <span class="ot">=</span> <span class="fl">1.5</span> <span class="co"># Effect of L on Y</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>sigma_L <span class="ot">=</span> <span class="dv">1</span> <span class="co"># Standard deviation of L</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>sigma_Y <span class="ot">=</span> <span class="fl">1.5</span> <span class="co"># Standard deviation of Y</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate the data: fully mediated effect by L</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, p) <span class="co"># binary exposure variable</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>L <span class="ot">=</span> alpha <span class="sc">+</span> beta<span class="sc">*</span>A <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_L) <span class="co"># mediator L affect by A</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> gamma <span class="sc">+</span> delta<span class="sc">*</span>L <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, sigma_Y) <span class="co"># Y affected only by L,</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># make the data frame</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">A =</span> A, <span class="at">L =</span> L, <span class="at">Y =</span> Y)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># fit regression in which L is assumed to be a mediator</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># (cross-sectional data is consistent with this model)</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>fit_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>( Y <span class="sc">~</span> A <span class="sc">+</span> L, <span class="at">data =</span> data)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># fit regression in which L is assumed to be a mediator</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># (cross-sectional data is also consistent with this model)</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>fit_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>( Y <span class="sc">~</span> A, <span class="at">data =</span> data)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># create gtsummary tables for each regression model</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>table1 <span class="ot">&lt;-</span> gtsummary<span class="sc">::</span><span class="fu">tbl_regression</span>(fit_1)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>table2 <span class="ot">&lt;-</span> gtsummary<span class="sc">::</span><span class="fu">tbl_regression</span>(fit_2)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="co"># merge the tables for comparison</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>table_comparison <span class="ot">&lt;-</span> gtsummary<span class="sc">::</span><span class="fu">tbl_merge</span>(</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(table1, table2),</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">tab_spanner =</span> <span class="fu">c</span>(<span class="st">"Model: Exercise assumed confounder"</span>, </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"Model: Exercise assumed to be a mediator"</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="co"># make latex table (for publication)</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>markdown_table_0 <span class="ot">&lt;-</span> <span class="fu">as_kable_extra</span>(table_comparison, </span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">format =</span> <span class="st">"latex"</span>, </span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">booktabs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a><span class="co"># print latex table (note, you might prefer "markdown" or another format)                                </span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>markdown_table_0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following code snippet is designed to estimate the Average Treatment Effect (ATE) using the <code>clarify</code> package in R, which is referenced here as <span class="citation" data-cites="greifer2023">[@greifer2023]</span>. The procedure involves two primary steps: simulating coefficient distributions for regression models and then calculating the ATE based on these simulations. This process is applied to two distinct models to demonstrate the effects of including versus excluding a mediator variable in the analysis.</p>
</section>
</section>
<section id="steps-to-estimate-the-ate" class="level3">
<h3 class="anchored" data-anchor-id="steps-to-estimate-the-ate">Steps to Estimate the ATE</h3>
<ol type="1">
<li><p><strong>Load the <code>clarify</code> Package</strong>: This package provides functions to simulate regression coefficients and compute average marginal effects (AME), robustly facilitating the estimation of ATE.</p></li>
<li><p><strong>Set seed</strong>: <code>set.seed(123)</code> ensures that the results of the simulations are reproducible, allowing for consistent outcomes across different code runs.</p></li>
<li><p><strong>Simulate the data distribution</strong>:</p>
<ul>
<li><code>sim_coefs_fit_1</code> and <code>sim_coefs_fit_2</code> are generated using the <code>sim</code> function from the <code>clarify</code> package, applied to two fitted models (<code>fit_1</code> and <code>fit_2</code>). These functions simulate the distribution of coefficients based on the specified models, capturing the uncertainty around the estimated parameters.</li>
</ul></li>
<li><p><strong>Calculate ATE</strong>:</p>
<ul>
<li>For both models, the <code>sim_ame</code> function calculates the ATE as the marginal risk difference (RD) when the treatment variable (<code>A</code>) is present (<code>A == 1</code>). This function uses the simulated coefficients to estimate the treatment effect across the simulated distributions, providing a comprehensive view of the ATE under each model.</li>
<li>To streamline the output, the function is set to verbose mode off (<code>verbose = FALSE</code>).</li>
</ul></li>
<li><p><strong>Results</strong>:</p>
<ul>
<li>Summaries of these estimates (<code>summary_sim_est_fit_1</code> and <code>summary_sim_est_fit_2</code>) are obtained, providing detailed statistics including the estimated ATE and its 95% confidence intervals (CI).</li>
</ul></li>
<li><p><strong>Presentation: report ATE and CIs</strong>:</p>
<ul>
<li>Using the <code>glue</code> package, the ATE and its 95% CIs for both models are formatted into a string for easy reporting. This step transforms the statistical output into a more interpretable form, highlighting the estimated treatment effect and its precision.</li>
</ul></li>
</ol>
<div class="cell" data-tbl-cap="Code for calculating the average treatment effect as contrasts between simulated outcomes for the entire population.">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use `clarify` package to obtain ATE</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(clarify)){<span class="fu">install.packages</span>(<span class="st">"clarify"</span>)} <span class="co"># clarify package</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate fit 1 ATE</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>sim_coefs_fit_1 <span class="ot">&lt;-</span> <span class="fu">sim</span>(fit_1)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>sim_coefs_fit_2 <span class="ot">&lt;-</span> <span class="fu">sim</span>(fit_2)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal risk difference ATE, simulation-based: model 1 (L is a confounder)</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>sim_est_fit_1 <span class="ot">&lt;-</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sim_ame</span>(</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    sim_coefs_fit_1,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">var =</span> <span class="st">"A"</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> A <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrast =</span> <span class="st">"RD"</span>,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal risk difference ATE, simulation-based: model 2 (L is a mediator)</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>sim_est_fit_2 <span class="ot">&lt;-</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sim_ame</span>(</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    sim_coefs_fit_2,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">var =</span> <span class="st">"A"</span>,</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> A <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrast =</span> <span class="st">"RD"</span>,</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain summaries</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>summary_sim_est_fit_1 <span class="ot">&lt;-</span> <span class="fu">summary</span>(sim_est_fit_1, <span class="at">null =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">RD</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">0</span>))</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>summary_sim_est_fit_2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(sim_est_fit_2, <span class="at">null =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">RD</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">0</span>))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co"># reporting </span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># ate for fit 1, with 95% CI</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>ATE_fit_1 <span class="ot">&lt;-</span> glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ATE =</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="st">                        {round(summary_sim_est_fit_1[3, 1], 2)},</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="st">                        CI = [{round(summary_sim_est_fit_1[3, 2], 2)},</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="st">                        {round(summary_sim_est_fit_1[3, 3], 2)}]"</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co"># ate for fit 2, with 95% CI</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>ATE_fit_2 <span class="ot">&lt;-</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>  glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ATE = {round(summary_sim_est_fit_2[3, 1], 2)},</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="st">                        CI = [{round(summary_sim_est_fit_2[3, 2], 2)},</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="st">                        {round(summary_sim_est_fit_2[3, 3], 2)}]"</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="upshot-of-the-simulation-and-analysis" class="level3">
<h3 class="anchored" data-anchor-id="upshot-of-the-simulation-and-analysis">Upshot of the Simulation and Analysis</h3>
<ul>
<li><p><strong>Model 1 (L as a Confounder)</strong>: this analysis assumes that <code>L</code> is a confounder in the relationship between the treatment (<code>A</code>) and the outcome (<code>Y</code>), and thus, it includes <code>L</code> in the model. The ATE estimated here reflects the effect of <code>A</code> while controlling for <code>L</code>.</p></li>
<li><p><strong>Model 2 (L as a Mediator)</strong>: in contrast, this analysis considers <code>L</code> to be a mediator, and the model either includes <code>L</code> explicitly in its estimation process or excludes it to examine the direct effect of <code>A</code> on <code>Y</code>. The approach to mediation analysis here is crucial as it influences the interpretation of the ATE.</p></li>
</ul>
<p>By comparing the ATEs from both models, researchers can understand the impact of mediation (or the lack thereof) on the estimated treatment effect. This comparison sheds light on how assumptions about variable roles (confounder vs.&nbsp;mediator) can significantly alter causal inferences drawn from cross-sectional data.</p>
<p><strong>Wherever it is uncertain whether a variable is a confounder or a mediator, we suggest creating two causal diagrams and reporting both analyses</strong></p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="appendix-d" class="level2">
<h2 class="anchored" data-anchor-id="appendix-d">Appendix D: Simulation of Different Confounding Control Strategies</h2>
<p>This appendix outlines the methodology and results of a data simulation designed to compare different strategies for controlling confounding in the context of environmental psychology research. Specifically, the simulation examines the effect of access to open green spaces (treatment, <span class="math inline">\(A_1\)</span>) on happiness (outcome, <span class="math inline">\(Y_2\)</span>) while addressing the challenge of unmeasured confounding. The simulation incorporates baseline measures of exposure and outcome (<span class="math inline">\(A_0\)</span>, <span class="math inline">\(Y_0\)</span>), baseline confounders (<span class="math inline">\(L_0\)</span>), and an unmeasured confounder (<span class="math inline">\(U\)</span>) to evaluate the effectiveness of different analytical approaches.</p>
<section id="methodology-1" class="level3">
<h3 class="anchored" data-anchor-id="methodology-1">Methodology</h3>
<p>1.<strong>Load Libraries <code>kableExtra</code>, <code>gtsummary</code>, and <code>grf</code>.</strong></p>
<ol type="1">
<li><p><strong>Target</strong>: we simulate data for 10,000 individuals, including baseline exposure to green spaces (<span class="math inline">\(A_0\)</span>), baseline happiness (<span class="math inline">\(Y_0\)</span>), baseline confounders (<span class="math inline">\(L_0\)</span>), and an unmeasured confounder (<span class="math inline">\(U\)</span>). The simulation uses a logistic model for treatment assignment and a linear model for the continuous outcome, incorporating interactions to assess how baseline characteristics modify the treatment effect.</p></li>
<li><p><strong>Set seed and simulate the data distribution</strong>:</p>
<ul>
<li>Treatment assignment coefficients: <span class="math inline">\(\beta_{A0} = 0.25\)</span>, <span class="math inline">\(\beta_{Y0} = 0.3\)</span>, <span class="math inline">\(\beta_{L0} = 0.2\)</span>, and <span class="math inline">\(\beta_{U} = 0.1\)</span>.</li>
<li>Outcome model coefficients: <span class="math inline">\(\delta_{A1} = 0.3\)</span>, <span class="math inline">\(\delta_{Y0} = 0.9\)</span>, <span class="math inline">\(\delta_{A0} = 0.1\)</span>, <span class="math inline">\(\delta_{L0} = 0.3\)</span>, with an interaction effect (<span class="math inline">\(\theta_{A0Y0L0} = 0.5\)</span>) indicating the combined influence of baseline exposure, outcome, and confounders on the follow-up outcome.</li>
</ul></li>
<li><p><strong>Model comparison</strong>:</p>
<ul>
<li><strong>No control model</strong>: estimates the effect of <span class="math inline">\(A_1\)</span> on <span class="math inline">\(Y_2\)</span> without controlling for any confounders.</li>
<li><strong>Standard covariate control model</strong>: controls for baseline confounders (<span class="math inline">\(L_0\)</span>) alongside treatment (<span class="math inline">\(A_1\)</span>).</li>
<li><strong>Baseline exposure and outcome model</strong>: extends the standard model by including baseline treatment and outcome (<span class="math inline">\(A_0\)</span>, <span class="math inline">\(Y_0\)</span>) and their interaction with <span class="math inline">\(L_0\)</span>.</li>
</ul></li>
<li><p><strong>Results</strong>: each model’s effectiveness in estimating the true treatment effect is assessed by comparing regression outputs. The simulation evaluates how well each model addresses the bias introduced by unmeasured confounding and the role of baseline characteristics in modifying treatment effects.</p></li>
<li><p><strong>Presentation</strong>: the results are synthesised in a comparative table, formatted using the <code>kableExtra</code> {<span class="citation" data-cites="zhu2021KableExtra">@zhu2021KableExtra</span>] and <code>gtsummary</code> packages <span class="citation" data-cites="gtsummary2021">[@gtsummary2021]</span>, highlighting the estimated treatment effects and their statistical significance across models.</p></li>
</ol>
<p>Overall, we use the simulation to illustrate the importance of incorporating baseline characteristics and their interactions to mitigate the influence of unmeasured confounding.</p>
<p>Here is the simulation and modelling code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(kableExtra)){<span class="fu">install.packages</span>(<span class="st">"kableExtra"</span>)} <span class="co"># causal forest</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(gtsummary)){<span class="fu">install.packages</span>(<span class="st">"gtsummary"</span>)} <span class="co"># causal forest</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(grf)){<span class="fu">install.packages</span>(<span class="st">"grf"</span>)} <span class="co"># causal forest</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># r_texmf()eproducibility</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set number of observations</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span> </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># baseline covariates</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>U <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n) <span class="co"># Unmeasured confounder</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>A_0 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">plogis</span>(U)) <span class="co"># Baseline exposure</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>Y_0 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> U, <span class="at">sd =</span> <span class="dv">1</span>) <span class="co"># Baseline outcome</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>L_0 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> U, <span class="at">sd =</span> <span class="dv">1</span>) <span class="co"># Baseline confounders</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients for treatment assignment</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>beta_A0 <span class="ot">=</span> <span class="fl">0.25</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>beta_Y0 <span class="ot">=</span> <span class="fl">0.3</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>beta_L0 <span class="ot">=</span> <span class="fl">0.2</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>beta_U <span class="ot">=</span> <span class="fl">0.1</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate treatment assignment</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>A_1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="at">prob =</span> <span class="fu">plogis</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">+</span> </span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>                                    beta_A0 <span class="sc">*</span> A_0 <span class="sc">+</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>                                    beta_Y0 <span class="sc">*</span> Y_0 <span class="sc">+</span> </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>                                    beta_L0 <span class="sc">*</span> L_0 <span class="sc">+</span> </span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>                                    beta_U <span class="sc">*</span> U))</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients for continuous outcome</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>delta_A1 <span class="ot">=</span> <span class="fl">0.3</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>delta_Y0 <span class="ot">=</span> <span class="fl">0.9</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>delta_A0 <span class="ot">=</span> <span class="fl">0.1</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>delta_L0 <span class="ot">=</span> <span class="fl">0.3</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>theta_A0Y0L0 <span class="ot">=</span> <span class="fl">0.5</span> <span class="co"># Interaction effect between A_1 and L_0</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>delta_U <span class="ot">=</span> <span class="fl">0.05</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate continuous outcome including interaction</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>Y_2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>             <span class="at">mean =</span> <span class="dv">0</span> <span class="sc">+</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>               delta_A1 <span class="sc">*</span> A_1 <span class="sc">+</span> </span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>               delta_Y0 <span class="sc">*</span> Y_0 <span class="sc">+</span> </span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>               delta_A0 <span class="sc">*</span> A_0 <span class="sc">+</span> </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>               delta_L0 <span class="sc">*</span> L_0 <span class="sc">+</span> </span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>               theta_A0Y0L0 <span class="sc">*</span> Y_0 <span class="sc">*</span> </span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>               A_0 <span class="sc">*</span> L_0 <span class="sc">+</span> </span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>               delta_U <span class="sc">*</span> U,</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>             <span class="at">sd =</span> .<span class="dv">5</span>)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># assemble data frame</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Y_2, A_0, A_1, L_0, Y_0, U)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="co"># model: no control</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>fit_no_control <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y_2 <span class="sc">~</span> A_1, <span class="at">data =</span> data)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="co"># model: standard covariate control</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>fit_standard <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y_2 <span class="sc">~</span> A_1 <span class="sc">+</span> L_0, <span class="at">data =</span> data)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a><span class="co"># model: interaction with baseline confounders, and baseline outcome and exposure</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>fit_interaction  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y_2 <span class="sc">~</span> A_1 <span class="sc">*</span> (L_0 <span class="sc">+</span> A_0 <span class="sc">+</span> Y_0), <span class="at">data =</span> data)</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a><span class="co"># create gtsummary tables for each regression model</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>tbl_fit_no_control<span class="ot">&lt;-</span> <span class="fu">tbl_regression</span>(fit_no_control)  </span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>tbl_fit_standard <span class="ot">&lt;-</span> <span class="fu">tbl_regression</span>(fit_standard)</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>tbl_fit_interaction <span class="ot">&lt;-</span> <span class="fu">tbl_regression</span>(fit_interaction)</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="co"># get only the treatment variable</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>tbl_list_modified <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">list</span>(</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>  tbl_fit_no_control,</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>  tbl_fit_standard,</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>  tbl_fit_interaction),</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a><span class="cf">function</span>(tbl) {</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>  tbl <span class="sc">%&gt;%</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>    <span class="fu">modify_table_body</span>(<span class="sc">~</span> .x <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(variable <span class="sc">==</span> <span class="st">"A_1"</span>))</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="co"># merge tables</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>table_comparison <span class="ot">&lt;-</span> <span class="fu">tbl_merge</span>(</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>  <span class="at">tbls =</span> tbl_list_modified,</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>  <span class="at">tab_spanner =</span> <span class="fu">c</span>(</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>    <span class="st">"No Control"</span>,</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Standard"</span>,</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Interaction"</span>)</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>  <span class="fu">modify_table_styling</span>(</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    <span class="at">column =</span> <span class="fu">c</span>(p.value_1, p.value_2, p.value_3),</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>    <span class="at">hide =</span> <span class="cn">TRUE</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="co"># latex table for publication</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>markdown_table <span class="ot">&lt;-</span></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_kable_extra</span>(table_comparison, <span class="at">format =</span> <span class="st">"latex"</span>, <span class="at">booktabs =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">latex_options =</span> <span class="st">"scale_down"</span>)</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(markdown_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, in the following code snippet, we calculate the Average Treatment Effect (ATE) using simulation-based approaches for two distinct models: one with standard covariate control and another incorporating interaction. This approach leverages the <code>clarify</code> package in R, which facilitates the simulation and interpretation of estimated coefficients from linear models to derive ATEs under different modelling assumptions <span class="citation" data-cites="greifer2023">[@greifer2023]</span>.</p>
<p>First, we use the <code>sim</code> function from the <code>clarify</code> package to generate simulated coefficient distributions for the standard model (<code>fit_standard</code>) and the interaction model (<code>fit_interaction</code>). This step is crucial for capturing the uncertainty in our estimates arising from sampling variability.</p>
<p>Next, we employ each model’s <code>sim_ame</code> function to compute the average marginal effects (AME), focusing on the treatment variable (<code>A_1</code>). The calculation is done under the assumption that all individuals are treated (i.e., <code>A_1 == 1</code>), and we specify the contrast type as “RD” (Risk Difference) to directly obtain the ATE (Average Treatment Effect). The <code>sim_ame</code> function simulates the treatment effect across the distribution of simulated coefficients, providing a robust estimate of the ATE and its variability.</p>
<p>The summaries of these simulations (<code>summary_sim_est_fit_std</code> and <code>summary_sim_est_fit_int</code>) are then extracted to provide concise estimates of the ATE along with 95% confidence intervals (CIs) for both the standard and interaction models. This step is essential for understanding the magnitude and precision of the treatment effects estimated by the models.</p>
<p>Finally, we use the <code>glue</code> package to format these estimates into a human-readable form, presenting the ATE and its corresponding 95% CIs for each model. This presentation facilitates clear communication of the estimated treatment effects, allowing for direct comparison between the models and highlighting the impact of including baseline characteristics and their interactions on estimating the ATE <span class="citation" data-cites="hester2022GLUE">[@hester2022GLUE]</span>.</p>
<p>This simulation-based approach to estimating the ATE underscores the importance of considering model complexity and the roles of confounders and mediators in causal inference analyses. By comparing the ATE estimates from different models, we can assess the sensitivity of our causal conclusions to various assumptions and modelling strategies.</p>
<div class="cell" data-tbl-cap="Code for calculating the average treatment effect.">
<div class="sourceCode cell-code" id="cb6" data-lst-cap="Code."><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ate-sim-long</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Code for calculating the average treatment effect."</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># use `clarify` package to obtain ATE</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(clarify)){<span class="fu">install.packages</span>(<span class="st">"clarify"</span>)} <span class="co"># clarify package</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate fit 1 ATE</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>sim_coefs_fit_no_control<span class="ot">&lt;-</span> <span class="fu">sim</span>(fit_no_control)  </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>sim_coefs_fit_std <span class="ot">&lt;-</span> <span class="fu">sim</span>(fit_standard)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>sim_coefs_fit_int <span class="ot">&lt;-</span> <span class="fu">sim</span>(fit_interaction)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal risk difference ATE, no controls</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>sim_est_fit_no_control <span class="ot">&lt;-</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sim_ame</span>(</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    sim_coefs_fit_no_control,</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">var =</span> <span class="st">"A_1"</span>,</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> A_1 <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrast =</span> <span class="st">"RD"</span>,</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal risk difference ATE, simulation-based: model 1 (L is a confounder)</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>sim_est_fit_std <span class="ot">&lt;-</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sim_ame</span>(</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    sim_coefs_fit_std,</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">var =</span> <span class="st">"A_1"</span>,</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> A_1 <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrast =</span> <span class="st">"RD"</span>,</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal risk difference ATE, simulation-based: model 2 (L is a mediator)</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>sim_est_fit_int <span class="ot">&lt;-</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sim_ame</span>(</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    sim_coefs_fit_int,</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">var =</span> <span class="st">"A_1"</span>,</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">subset =</span> A_1 <span class="sc">==</span> <span class="dv">1</span>,</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrast =</span> <span class="st">"RD"</span>,</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain summaries</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>summary_sim_coefs_fit_no_control <span class="ot">&lt;-</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(sim_est_fit_no_control, <span class="at">null =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">RD</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">0</span>))</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>summary_sim_est_fit_std <span class="ot">&lt;-</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(sim_est_fit_std, <span class="at">null =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">RD</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">0</span>))</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>summary_sim_est_fit_int <span class="ot">&lt;-</span></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>(sim_est_fit_int, <span class="at">null =</span> <span class="fu">c</span>(<span class="st">`</span><span class="at">RD</span><span class="st">`</span> <span class="ot">=</span> <span class="dv">0</span>))</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a><span class="co"># get coefficients for reporting</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="co"># ate for fit 1, with 95% CI</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>ATE_fit_no_control  <span class="ot">&lt;-</span> glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ATE = {round(summary_sim_coefs_fit_no_control[3, 1], 2)}, </span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a><span class="st">  CI = [{round(summary_sim_coefs_fit_no_control[3, 2], 2)},</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a><span class="st">  {round(summary_sim_coefs_fit_no_control[3, 3], 2)}]"</span></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="co"># ate for fit 2, with 95% CI</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>ATE_fit_std <span class="ot">&lt;-</span> glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>  <span class="st">"ATE = {round(summary_sim_est_fit_std[3, 1], 2)}, </span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="st">  CI = [{round(summary_sim_est_fit_std[3, 2], 2)},</span></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="st">  {round(summary_sim_est_fit_std[3, 3], 2)}]"</span></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a><span class="co"># ate for fit 3, with 95% CI</span></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>ATE_fit_int <span class="ot">&lt;-</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>  glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ATE = {round(summary_sim_est_fit_int[3, 1], 2)},</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a><span class="st">    CI = [{round(summary_sim_est_fit_int[3, 2], 2)},</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a><span class="st">    {round(summary_sim_est_fit_int[3, 3], 2)}]"</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a><span class="co"># coefs they used in the manuscript</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Using the <code>clarify</code> package, we infer the ATE for the standard model is ATE = 0.86, CI = [0.8, 0.92].</p>
<p>Using the <code>clarify</code> package, we infer the ATE for the model that conditions on the baseline exposure and baseline outcome to be: ATE = 0.29, CI = [0.27, 0.31], which is close to the values supplied to the data-generating mechanism.</p>
<p><strong>Take-home message:</strong> The baseline exposure and baseline outcome are often the most important variables to include for confounding control. The baseline exposure also allows us to estimate an incident-exposure effect. For this reason, we should endeavour to obtain at least three waves of data such that these variables and other baseline confounders are included at time 0, the exposure is included at time 1, and the outcome is included at time 2.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="appendix-e" class="level2">
<h2 class="anchored" data-anchor-id="appendix-e">Appendix E: Non-parametric Estimation of Average Treatment Effects Using Causal Forests {#appendix-causal-forests}</h2>
<p>This appendix provides a practical example of estimating average treatment effects (ATE) using a non-parametric approach, specifically applying causal forests. Unlike traditional regression models, causal forests allow for estimating treatment effects without imposing strict assumptions about the form of the relationship between treatment, covariates, and outcomes. This flexibility makes them particularly useful for analysing complex datasets where the treatment effect may vary across observations.</p>
<section id="causal-forest-model-implementation" class="level4">
<h4 class="anchored" data-anchor-id="causal-forest-model-implementation">Causal Forest Model Implementation</h4>
<ol type="1">
<li><p><strong>Libraries</strong>: the implementation begins with loading the necessary R libraries: <code>grf</code> for estimating conditional and average treatment effects using causal forests and <code>glue</code> for formatting the results for reporting.</p></li>
<li><ol type="1">
<li><strong>Data generation</strong>: the code assumes the presence of a data frame <code>data</code> generated from the previous code snippet containing the variables:</li>
</ol>
<ul>
<li><code>A_1</code>: Treatment indicator.</li>
<li><code>L_0</code>: A covariate.</li>
<li><code>Y_2</code>: Outcome of interest.</li>
<li><code>A_0</code> and <code>Y_0</code>: Baseline exposure and outcome, respectively.</li>
</ul>
<p>Treatment (<code>W</code>) and outcome (<code>Y</code>) vectors are extracted from <code>data</code> alongside a matrix <code>X</code> that includes covariates and baseline characteristics.</p></li>
<li><p><strong>Causal Forest model</strong>: a causal forest model is fitted using the <code>causal_forest</code> function from the <code>grf</code> package <span class="citation" data-cites="grf2024">[@grf2024]</span>. This function takes the covariate matrix <code>X</code>, the outcome vector <code>Y</code>, and the treatment vector <code>W</code> as inputs, and it returns a model object that can be used for further analysis.</p></li>
<li><p><strong>Average Treatment Effect estimation</strong>: the <code>average_treatment_effect</code> function computes the ATE from the fitted causal forest model. This step is crucial as it quantifies the overall impact of the treatment across the population, adjusting for covariates included in the model.</p></li>
<li><p><strong>Reporting</strong>: The estimated ATE and its standard error (se) are extracted and formatted for reporting using the <code>glue</code> package <span class="citation" data-cites="hester2022GLUE">[@hester2022GLUE]</span>. This facilitates clear communication of the results, showing the estimated effect size and its uncertainty.</p></li>
</ol>
</section>
<section id="key-takeaways" class="level4">
<h4 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h4>
<ul>
<li><p><strong>Flexibility and robustness</strong>: causal forests offer a robust way to estimate treatment effects without making parametric solid assumptions. This approach is particularly advantageous in settings where the treatment effect may vary with covariates or across different subpopulations.</p></li>
<li><p><strong>ATE estimation</strong>: the model estimates the ATE as the difference in expected outcomes between treated and untreated units, averaged across the population. This estimate reflects the overall effect of the treatment, accounting for the distribution of covariates in the sample.</p></li>
<li><p><strong>Convergence to the true value</strong>: we find that the estimated ATE by the causal forest model converges to the actual value used in the data-generating process (assumed to be 0.3). This demonstrates the effectiveness of causal forests in uncovering the true treatment effect from complex data.</p></li>
</ul>
<p>This example underscores the utility of semi-parametric and non-parametric methods, such as causal forests, in causal inference analyses.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load causal forest library </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grf) <span class="co"># estimate conditional and average treatment effects</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glue) <span class="co"># reporting </span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  'data' is our data frame with columns 'A_1' for treatment, 'L_0' for a covariate, and 'Y_2' for the outcome</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  we also have the baseline exposure 'A_0' and 'Y_0'</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  ensure W (treatment) and Y (outcome) are vectors</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(data<span class="sc">$</span>A_1)  <span class="co"># Treatment</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(data<span class="sc">$</span>Y_2)  <span class="co"># Outcome</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(data[, <span class="fu">c</span>(<span class="st">"L_0"</span>, <span class="st">"A_0"</span>, <span class="st">"Y_0"</span>)])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># fit causal forest model </span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>fit_causal_forest <span class="ot">&lt;-</span> <span class="fu">causal_forest</span>(X, Y, W)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate the average treatment effect (ATE)</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>ate <span class="ot">&lt;-</span> <span class="fu">average_treatment_effect</span>(fit_causal_forest)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># make data frame for reporting using "glue' </span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>ate<span class="ot">&lt;-</span> <span class="fu">data.frame</span>(ate)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># obtain ate for report</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>ATE_fit_causal_forest <span class="ot">&lt;-</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  glue<span class="sc">::</span><span class="fu">glue</span>(</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ATE = {round(ate[1, 1], 2)}, se = {round(ate[2, 1], 2)}"</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Causal forest estimates the average treatment effect as ATE = 0.3, se = 0.01. This approach converges to the true value supplied to the generating mechanism of 0.3</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Note that when we draw a chronologically ordered path from left to right, the M shape for which “M-bias” takes its name changes to an E shape. We shall avoid proliferating jargon and retain the term “M bias.”<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>