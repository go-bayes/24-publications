---
title: "Moderation, Interaction, Mediation, and Time-Varying Treatments Clarified Using Causal Directed Acyclic Graphs (DAGs) and Single World Intervention Graphs (SWIGs)"
abstract: |
  The analysis of 'moderation', 'interaction', 'mediation', and 'longitudinal growth' is widespread in the human sciences, yet confusion persists. We leverage decades of advancements in causal inference to explain why the quantities derived from statistical models are often ambiguous, despite model sophistication. We emphasise the necessity of (1) clearly stating a causal question and (2) assessing the identifiability of the question with available data before statistical analysis. Without these steps, confusion is inevitable. Properly framing and addressing causal questions, especially in settings with heterogeneous and multiple treatments, reveals the limitations of popular methods and guides researchers towards more effective approaches.
  
  **KEYWORDS**: *Causal Inference*; *SWIGs*; *DAGs*; *Evolution*; *Mediation*; *Longitudinal Growth*; *Time-varying Treatments*
author: 
  - name: Joseph A. Bulbulia
    affiliation: Victoria University of Wellington, New Zealand
    orcid: 0000-0002-5861-2056
    email: joseph.bulbulia@vuw.ac.nz
    corresponding: no
editor_options: 
  chunk_output_type: console
format:
  pdf:
    sanitise: true
    keep-tex: true
    link-citations: true
    colorlinks: true
    documentclass: article
    classoption: [single column]
    lof: false
    lot: false
    geometry:
      - top=30mm
      - left=25mm
      - heightrounded
      - headsep=22pt
      - headheight=11pt
      - footskip=33pt
      - ignorehead
      - ignorefoot
    template-partials: 
      - /Users/joseph/GIT/templates/quarto/title.tex
    header-includes:
      - \input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
date: last-modified
execute:
  echo: false
  warning: false
  include: true
  eval: true
fontfamily: libertinus
bibliography: /Users/joseph/GIT/templates/bib/references.bib
csl: /Users/joseph/GIT/templates/csl/camb-a.csl
---


```{r}
#| label: load-libraries
#| echo: false
#| include: false
#| eval: true

## WARNING SET THIS PATH TO YOUR DATA ON YOUR SECURE MACHINE. 
# pull_path <-
#   fs::path_expand(
#     #"/Users/joseph/v-project\ Dropbox/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs_refactor/nzavs_data_23"
#     "/Users/joseph/Library/CloudStorage/Dropbox-v-project/Joseph\ Bulbulia/00Bulbulia\ Pubs/DATA/nzavs-current/r-data/nzavs_data_qs"
#   )
# 


push_mods <-  fs::path_expand(
  "/Users/joseph/Library/CloudStorage/Dropbox-v-project/data/nzvs_mods/24/church-prosocial-v7"
)


#tinytext::tlmgr_update()

# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
#source("/Users/joseph/GIT/templates/functions/libs2.R")
# # WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI
# source("/Users/joseph/GIT/templates/functions/funs.R")

#ALERT: UNCOMMENT THIS AND DOWNLOAD THE FUNCTIONS FROM JB's GITHUB

# source(
#   "https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R"
# )
# 
# source(
#   "https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R"
# )

# check path:is this correct?  check so you know you are not overwriting other directors
#push_mods

# for latex graphs
# for making graphs
library("tinytex")
library("extrafont")
library("tidyverse")
library("kableExtra")
#devtools::install_github("go-bayes/margot")
library(margot)
loadfonts(device = "all")
```



## Introduction

Human scientists apply statistical models to data and report 'interaction', 'moderation', and 'mediation' using both cross-sectional and time-series data. What do these concepts mean? It is generally unclear. The confidence with which investigators report their findings does not make the concepts any clearer.

Several decades of progress in causal inference offer hope for better. Here we explain the importance of stating a clearly defined causal question at the outset and examine what is needed for identifying complex treatment effects from data. We demonstrate that thoughtful use of graphical causal models greatly eases this burden.

We begin by clarifying basic concepts and graphical conventions.


### Terminology

**Causality**: A cause, $A$, affects an outcome, $Y$, if changing the cause from one level, $A_i = a^*$, to another level, $A_i = a$, results in a different outcome. We write this as $Y_i(a^*) - Y_i(a) \neq 0$. This quantity represents the contrast for individual $i$ between measurable outcomes under two states of the world: one where $A = a^*$ and the other where $A = a$. We call the variable of interest, $A$, a 'treatment' or an 'exposure'. We refer to the outcome under treatment, $Y(A = a)$, as the potential or counterfactual outcome. The terms "potential outcome" and "counterfactual outcome" are interchangeable. The observed outcome is given as $Y|A=a$. At the individual level, we can generally observe at most $Y_i|A_i =a$ or $Y_i|A_i =a^*$, but not both.

**Causal Inference**: We cannot observe individual causal effects, but we can compute average treatment effects by aggregating individual observations by treatment conditions. For a binary treatment, we express this as the difference in mean outcomes by treatment condition: $E[Y(1)] - E[Y(0)]$ or equivalently as the mean difference in outcomes by treatment condition $E[Y(1) - Y(0)]$. This counterfactual contrast represents the quantity (on the difference scale) that we obtain for a sample population from an ideally conducted randomised controlled trial â€”an 'experiment'. Ideal experiments imply the following assumptions:

1. **Causal Consistency**: Treatment levels remain consistent within the treatment arms to be compared (implied by "control").
2. **Exchangeability**: Covariates that might affect outcomes under treatment are balanced across all arms (implied by 'randomisation').
3. **Positivity**: Each covariate that might affect treatment in the target population has a non-zero probability of being observed within each treatment condition to be compared (implied by the combination of randomisation and a clearly defined target population).

Of course, experiments as realised often deviate from the ideal, leading to potential failure of these assumptions. In observational or "real-world" settings, none of these assumptions are guaranteed, and worse, only the positivity assumption can be verified by data. To understand the causal effects of interventions using real-world data, we must:

1. **State a well-defined intervention.**
2. **State a well-defined outcome.**
3. **Clarify the target population.**
4. **Ensure treatments to be compared satisfy causal consistency.**
5. **Evaluate whether treatment groups, conditional on measured covariates, are exchangeable.** This means differences must be ignorable, confounding covariates across treatment levels must be balanced, all backdoor paths between treatments and outcomes must be closed, treatments and outcomes must be d-separated, and there must be no unmeasured confounding. Although terminology varies, the goal remains the same: ensuring non-random "real-world" data can be modelled to emulate a randomised controlled experiment.
6. **Check if the positivity assumption is satisfied.**
7. **Clearly communicate the reasoning, evidence, and decision-makeing that inform steps 1-6.**

**Confounding**: Treatment and outcome are associated independently of causality. 

### Meaning of Symbols

To clarify the concepts of interaction, moderation, and mediation, we will use causal graphical methods. For a review of causal directed acyclic graphs @pearl; @mcelreath2020; @neal2020introduction; @hernan2024WHATIF. For a review of single world intervention graphs see @richardson2013swigsprimer. I will assume some familarity with causal DAGs when introducing single world interventiong graphs. 

**$A$**: Denotes the "treatment" or "exposure" - a random variable. This is the variable for which we seek to understand the effect of intervening on it. It is the "cause."

**$\bar{A}$**: Denotes a sequence of treatments.

**$Y$**: Denotes the outcome or response, measured at the end of study -- the "effect."

**$L$**: Denotes a measured confounder or set of confounders -- variables required for conditional exchangeability.

**$U$**: Denotes an unmeasured confounder or confounders.

**$\mathcal{R}$**: Denotes chance assignment to treatment condition, as when treatment assignment is randomised.

**$\mathcal{G}$**: Denotes a graph, here, a causal directed acyclic graph.

@tbl-terminologylocalconventions reports our graphical conventions.

::: {#tbl-terminologylocalconventions}
```{=latex}
\terminologylocalconventions
```
Terminology
:::


### Elements of Causal Graphs

**Node**: A node or vertex represents characteristics or features of units within a population on a causal diagram, which we call a "variable." In causal directed acyclic graphs (DAGs), we draw nodes with respect to the *target population*, which is the population for whom investigators seek causal inferences [@suzuki2020]. A time-indexed node, $X_t$, denotes relative chronology.

**Edge without an Arrow** ($\association$): This path indicates association without asserting causality.

**Arrow** ($\rightarrowNEW$): This denotes a causal relationship from the node at the base of the arrow (a 'parent') to the node at the tip of the arrow (a 'child'). In causal DAGs, we refrain from drawing an arrow from treatment to outcome to avoid asserting a causal path from $A$ to $Y$. Our purpose is to ascertain whether causality can be identified for this path. All other nodes and paths, including the absence of nodes and paths, are typically assumed.

**Red Arrow** ($\rightarrowred$): This path represents a non-causal association between the treatment and outcome. Despite the arrows, this path is associational and may flow against time.

**Dashed Arrow** ($\rightarrowdotted$): This denotes a true association between the treatment and outcome that becomes partially obscured when conditioning on a mediator, assuming $A$ causes $Y$.

**Dashed Red Arrow** ($\rightarrowdottedred$): This highlights over-conditioning bias from conditioning on a mediator.

**Open Blue Arrow** ($\rightarrowblue$): This highlights effect modification, which occurs when the levels of the effect of treatment vary within levels of a covariate. We do not assess the causal effect of the effect-modifier on the outcome, recognising that it may be incoherent to consider intervening on the effect-modifier.

**Boxed Variable** $\boxed{X}$: This indicates conditioning or adjustment for $X$. 

**Red-Boxed Variable** $\boxedred{X}$: This highlights the source of confounding bias from adjustment.

**Dashed Circle** $\circledotted{X}$: This indicates no adjustment is made for a variable (implied for unmeasured confounders).

**$\big(\mathcal{R} \rightarrow A\big)$**: This denotes randomisation into the treatment condition.

**Node Splitting** $\switbasic$: This is used in Single World Intervention Graphs (SWIGs) to denote counterfactual histories that arise following interventions. Node splitting allows investigators to separately evaluate identification for each counterfactual to be contrasted. All causal DAGs can be restated using SWIGs. However, each SWIG may encode at most one level of treatment or one sequence of treatments. To avoid proliferating graphs, we may use a Single World Intervention Template to denote the graph-valued function from which multiple SWIGs may be generated.

**Green Dashed Arrow** $\rightarrowdottedgreen$: This indicates dependency in dynamic sequential treatment strategies where the 'natural value' of a treatment value under a specific treatment regime depends on the values obtained from the counterfactual histories that precede the node in a SWIG. Dynamic strategies enable flexible, realistic causal inferences but impose stronger identification assumptions. For example, arrows to the "natural value" of the treatment may compromise sequential exchangeability, threatening identification (refer to @richardson2013).


@tbl-terminologylocalconventions reports our graphical conventions.


::: {#tbl-terminologygeneral}
```{=latex}
\terminologygeneral
```
Elements of Causal Graphs 
:::



{{< pagebreak >}}

## Part 1: Interaction

In causal data science, we think of interaction in two ways:

1. **Interaction as Effect-Modification of a Single Intervention**: We examine how the effect of one intervention varies across different strata of the population. For example, we ask if religious service attendance affects charitable giving differently among people born in Australia versus those born in Egypt. We do not intervene on birthplace.

2. **Interaction as the Combined Effect of a Double Intervention**: We consider how administering two treatments together affects outcomes compared to each treatment alone. For example, we ask if the combined effect of religious service attendance and wealth on charitable giving differs from the effect of either factor alone.

When interested in a single intervention, we use 'effect-modification' and 'moderation' interchangeably. When focusing on a double intervention, we use the term 'interaction'. Note that 'interaction' also applies to biological synergisms and other contexts, but we restrict our discussion to heterogeneity and double interventions.

For both effect-modification and double intervention interactions, we must specify the scale at which we measure contrasts. Evidence of interaction on one scale may not appear on another. Effect-modification is often termed 'effect-measure modification'. We will restrict our analysis to causal contrasts on the additive scale.

Before applying statistical models to data, we explicitly define our causal questions, the scale of measurement, and the target population. We specify if we are interested in single intervention contrasts across covariate levels or double intervention contrasts. Addressing interaction questions underscores the importance of clearly stating causal questions before data analysis. The term "interaction" does not clarify a target of interest. Without a target, we cannot now how to interpret the results of our statitical models, even when they are unconfounded.

### Effect-Modification

The 'sharp-null hypothesis' states that there is no effect of the exposure on the outcome for any unit in the target population. Unless the 'sharp-null hypothesis' is false, there may be effect-modification. For any study worth conducting, we cannot evaluate whether the sharp-null hypothesis is false (otherwise, why conduct the study?). Therefore, we must assume that treatment effects may be heterogeneous.

::: {#tbl-terminologyeffectmodification}
```{=latex}
\terminologyeffectmodification
```
Conventions for representing effect modification
:::

@tbl-terminologyeffectmodification presents our graphical conventions for describing effect modification. We assume no confounding of the treatment on the outcome and that $A$ has been randomised (i.e. $\mathcal{R} \rightarrowNEW A$). To simplify, we do not include randomisation in our graphs. We draw an open blue arrow to highlight our interest in effect modification. This convention is specific to this article. Refer to @hernan2024WHATIF, pp. 126-127, for a discussion of "noncausal" arrows. According to @hernan2024WHATIF, essentially all arrows are non-causal until proven causal, or in their words, '... arrows simply encode, via d-separation, the conditional independencies satisfied by the variables on the diagram and on the associated SWIG'. This is correct. However, our purpose here is to underscore that effect-modification inherently avoids causal interpretations for the variables investigators use to qualitatively evaluate treatment-effect heterogeneity.

::: {#tbl-terminologyeffectmodificationtypes}
```{=latex}
\terminologyeffectmodificationtypes
```
Effect Modification
:::

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}1$, we represent that $Z$ is a direct effect modifier for the effect of $A$ on $Y$. The open arrow indicates that we are not attributing causality to $Z$. Because our estimand does not involve intervening on $Z$, there is no need to close its backdoor paths.

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}2$, we represent that $Z$ is an unobserved direct effect modifier of $A$ to $Y$. When the distribution of direct effect modifiers $Z$ differs between two populations and effect modification is non-linear, marginal treatment effects between populations will generally differ and will not easily transport from one population to another (see Appendix X). The concept of an average treatment effect has no meaning without a population over which the effect marginalises. This point, although obvious, has profound implications for generalising research.

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}3$, we present two candidate effect modifiers. Whether a variable is an effect modifier also depends on which other variables are included in the model. Here, $Z$ is a direct effect modifier and $G$, a descendant of $Z$, is an indirect effect modifier. Suppose we are interested in whether treatment effects vary (on the difference scale) within levels of $G$. For example, imagine $Z$ is childhood deprivation, $G$ is educational achievement, $A$ is a government educational initiative, and $Y$ is recycling. If we condition on $Z$, we would not observe effect modification by education $G$ for the effect of the government initiative $A$ on recycling behaviour $Y$.

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}4$, we present the same causal structure. However, we do not condition on the direct effect modifier $Z$, but rather condition only on $G$, the indirect effect modifier. In this scenario, we would find that the effectiveness of the government initiative $A$ on recycling behaviour $Y$ varies by educational achievement $G$. Thus, we observe $G$ as an effect modifier.

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}5$, we add another variable to our model, depression, denoted by $B$. We imagine $B$ to be a stable trait or that investigators measured childhood depression (that is, $B$ precedes $G$). Suppose we do not condition on the direct effect modifier $Z$ (childhood deprivation), but we condition on educational attainment ($G$) and depression ($B$). In this graph, $G$ is a collider of $Z$ and $B$. Thus, conditioning on $G$ (but not $Z$) opens a path from $B \association G \association Z \association Y$, and investigators would find evidence for effect modification by depression on the effectiveness of the government intervention $A$ on recycling ($Y$).

In @tbl-terminologyeffectmodificationtypes $\mathcal{G}6$, we will not find evidence for effect modification for $B$ and $G$ because conditioning on $Z$ blocks the flow of information that was open in $\mathcal{G}4$ and $\mathcal{G}5$.

Using causal directed acyclic graphs, we can demonstrate that the concept of 'effect modifier' cannot be stated without reference to an assumed causal order and an explicit statement about which variables within that order are modelled [@vanderweele2012]. Without a clear understanding of effect modification, investigators and policymakers might make incorrect decisions. For example, they might think that religious people are more receptive to government promotion of recycling. However, investigators have only randomised the treatment. Estimating conditional associations between the treatment and other variables measured at baseline does not address the question of whether treatment effects would vary if investigators intervened on other measured variables. More fundamentally, whether a variable is an 'effect modifier' cannot be stated without reference to its position in the assumed causal order [@vanderweele2012; @vanderweele2007; @suzuki2013counterfactual].

### Worked Example Showing Scale Dependence

We are interested in whether treatment varies across levels of another variable, an effect modifier. Here, we explain how the presence or absence of effect modification can depend on the scale used to measure the effect. Specifically, an effect modifier on the ratio scale may not be an effect modifier on the difference scale, and vice versa.

Individual treatment effects are not observed. We obtain the average outcomes in each group as follows:
$$
\mathbb{E}[Y \mid Z = 1, T = 0] = \mu_{01}, \quad \mathbb{E}[Y \mid Z = 1, T = 1] = \mu_{11}
$$
$$
\mathbb{E}[Y \mid Z = 0, T = 0] = \mu_{00}, \quad \mathbb{E}[Y \mid Z = 0, T = 1] = \mu_{10}
$$

The treatment effect on the difference scale (absolute scale) for each group is:
$$
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01}
$$
$$
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00}
$$

The treatment effect on the ratio scale (relative scale) for each group is:
$$
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}}
$$
$$
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}}
$$

No Effect Modification on the Difference Scale:
$$
\text{ATE}_{Z = 1} = \text{ATE}_{Z = 0} \implies \mu_{11} - \mu_{01} = \mu_{10} - \mu_{00}
$$

Effect Modification on the Ratio Scale:
$$
\text{RR}_{Z = 1} \neq \text{RR}_{Z = 0} \implies \frac{\mu_{11}}{\mu_{01}} \neq \frac{\mu_{10}}{\mu_{00}}
$$

Next an example. C onsider the following hypothetical data:

Group 0:
    - $\mu_{00} = 5$
    - $\mu_{01} = 15$

Group 1:
    - $\mu_{10} = 10$
    - $\mu_{11} = 20$

We calculate the treatment effects on the difference and ratio scales for each group:

Difference Scale:
$$
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00} = 10 - 5 = 5
$$
$$
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01} = 20 - 15 = 5
$$

Both groups have the same treatment effect on the difference scale, $\text{ATE}_{Z = 0} = \text{ATE}_{Z = 1} = 5$. We conclude there is no effect modification on the difference scale.

Ratio Scale:
$$
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}} = \frac{10}{5} = 2.00
$$
$$
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}} = \frac{20}{15} \approx 1.33
$$

The treatment effect on the ratio scale is different for the two groups, $\text{RR}_{Z = 0} = 2 \neq \text{RR}_{Z = 1} \approx 1.33$. Hence, we find evidence for effect modification on the ratio scale. This discrepancy arises because the two scales measure different aspects of the treatment effect: the absolute difference in outcomes versus the relative change in outcomes.

### Introducing Single World Intevention Graphs

Investigators are often interested in evaluating the effects of multiple treatments. The remainder of the examples we consider below require stating these causal quantities to be contrasted from multiple treatments. Single World Intervention Graphs, developed by James Richardson and Jamie Robins and colleagues, allow investigators to clearly state the counterfactual quantities to be contrasted under different treatments and treatment regimes. Before discussing the concept of interaction as a double-intervention, we introduce Richardson and Robin's graphical tool.

::: {#tbl-swigtable}
```{=latex}
\swigtable
```
Single World Interventions Recover separate caual diagrams for each treatment to be contrasted.
:::

@tbl-swigtable $\mathcal{G}$ 1 is a causal directed acyclic graph, where the associated factorisation of the joint distribution is given:

$$
P(y, a, l) = P(l) P(a | l) P(y | a, l)
$$

<!-- 

- $P(l)$: the marginal probability of the covariate $L$.
- $P(a | l)$: the conditional probability of the treatment $A$ given the covariate $L$.
- $P(y | a, l)$: the conditional probability of the outcome $Y$ given both the treatment $A$ and the covariate $L$. -->


Notice that the counterfactual outcomes to be contrasted do not appear directly on the causal directed acyclic graph. However, the corresponding counterfactual outcomes are given by Pearl's do-calculus @pearl2009a, such tha the average treatment effect for $A$ on $Y$ is identified by conditioning on $L$:

$$
P(Y(a)|A,L) = P(Y = y|do(A =a), L=l) = P(Y=y|A=a L=l)
$$


In Single World Intervention Graphs we obtain counterfactual factoriations directly from the graph. 

@tbl-swigtable $\mathcal{G}$ 2 is a Single World Intervention Template, a graph valued function, that allows us to generate separate causal diagrams for each intervention. $A = \Tilde{a}$ can take any value $A \in \mathcal{A}$, where  $\mathcal{A}$ is the set of all possible inteventions for $A$. 

The function takes inputs: 

$$
P(A = \Tilde{a}, Y(A = \Tilde{a}, L))  = P(A = \Tilde{a})P(Y = \Tilde{y}|A = \Tilde{A}, L)
$$



@tbl-swigtable $\mathcal{G}$ 3 is the graph value or Single World Intevention Graph for the Single World Intervention Template $\mathcal{G} 2$ when is set to $A =0$.  This gives us the factorisation: 

### Node-Splitting in Single World Intervention Graphs (SWIGs)

We represent the effects of hypothetical interventions by node-splitting.

Consider a template graph $\mathcal{G}$. Applying node-splitting to $A$ involves creating separate graphs for each value of $A$ to be contrasted.

1. **SWIG for $A = 0$**: Denoted as $\mathcal{G}(A=0)$, this graph shows the hypothetical scenario where $A$ is set to 0.
2. **SWIG for $A = 1$**: Denoted as $\mathcal{G}(A=1)$, this graph shows the hypothetical scenario where $A$ is set to 1.

In these graphs, the node corresponding to the outcome $Y$ is relabelled to indicate it is now a potential outcome, such as $Y(0)$ or $Y(1)$.

### d-Separation in SWIGs

The rules of d-separation in the SWIGs allow us to read independence relationships under each intervention to be compared. For example:

- In $\mathcal{G}(A=0)$, $A$ is set to 0, and $L$ is the only edge into $A$ and $Y$. Thus, conditioning on $L$ leads to $A \coprod Y(0)$.
- Similarly, in $\mathcal{G}(A=1)$, $A$ is set to 1, and $L$ is the only edge into $A$ and $Y$. Thus, conditioning on $L$ leads to $A \coprod Y(1)$.

### Factorisation and Modularity

The factorisation of the joint distribution associated with these graphs follows from the structure of the SWIGs. For the original DAG, the joint distribution $P(A, Y, L)$ can be factorised as $P(L)P(A|L)P(Y|A,L)$.

For each Single World Intervention Graph, these factorisations are:

$$
P(A = \tilde{a}, Y(\tilde{a}=0) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=0) = y|A = \tilde{a}, L = l)P(L = l)
$$
$$
P(A = \tilde{a}, Y(\tilde{a}=1) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=1) = y|A = \tilde{a}, L = l)P(L = l)
$$

These factorisations align with the standard causal directed acyclic graph factorisations, where $L$ is the only parent of $A$, $Y(\tilde{a}=0)$, and $Y(\tilde{a}=1)$ in their respective Single World Intervention Graphs.

Identification holds if:

$$
P(Y(\tilde{a}) = y) = \sum_l P(Y = y|L = l, A = \tilde{a}) P(L = l)
$$


### Interaction as a joint-intervention

Consider two treatments, denoted as $A$ and $B$, and their outcome as $Y$. A joint intervention causal interaction implies that the effect of $A$ and $B$ together on $Y$ (denoted as $Y(A,B)$) is not merely the sum of their individual effects. 



::: {#tbl-interactionpuzzle}
```{=latex}
\interactionpuzzle
```
Causal Interaction 
:::

For instance, consider the effect of beliefs in Big Gods (exposure $A$) on social complexity (outcome $Y$), potentially influenced by a culture's monumental architecture (exposure $B$). To assess the individual and combined effects of $A$ and $B$, we look for evidence of causal interaction on the difference scale. Evidence for interaction would be present if the following inequality were to hold. Where,

- $\mathbb{E}[Y(1,1)]$: Mean outcome for those jointly exposed to both treatments A and B.
- $\mathbb{E}[Y(1,0)]$: Mean outcome for those exposed to treatment A only.
- $\mathbb{E}[Y(0,1)]$: Mean outcome for those exposed to treatment B only.
- $\mathbb{E}[Y(0,1)]$: Mean outcome for those exposed to neither treatment A nor B.

We say there is evidence for interaction on the additive scale if

$$\bigg(\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) - \bigg[ \bigg(\underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) + \bigg(\underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \bigg)\bigg] \neq 0 $$

This equation simplifies to

$$ \underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} + \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \neq 0 $$


A positive value would indicate evidence for additive interaction. A negative value would indicate evidence for sub-additive interaction. A value near zero would imply no reliable evidence for interaction.


@tbl-interactionpuzzle presents each counterfactual interventions. We can read from the graphs, that identification in each $\mathcal{G}_{\Tilde{a}, \Tilde{b}}$ requires conditioning on all confounders of $A$, $L_A$ and all confounders of B, $L_B$.


As with effect-modification, evidence for causal interaction may differ depending on the measurement scale one chooses to assess it [@vanderweele2014,@vanderweele2012]. Evidence for the strength of a causal effect estimate for interaction in the presence of effect-modification will differ depending on whether the effect is measured on the ratio scale as opposed to the difference scale (see: @vanderweele2014, who recommends using the causal difference scale for most policy settings.)

Note that if $A$ and $B$ were to effect each other, we would need to collect time series data, and estimate causal effects using causal mediation analysis. The demands for causal mediation analysis are more stringent than adjusting for confounder sets for both interventions.  We consider these challenges next. 

## Causal Mediation Analysis

### Statisical structural equation models lack structure

In the human sciences, mediation analysis is often mired in confusion, a situation exacerbated by the complex nature of causal relationships it aims to reveal. However, confusion dissipates when we define our causal question in relation to the counterfactuals we hope to estimate. Beyond the intrinsic challenges of mediation analysis, much of the prevailing
confusion stems from the prevalent use of statisical structural equation models (SEMs). These models generally lack a systematic way of modelling the complex counterfactual contrasts that are relevant to evaluating causality. The widespread disconnect between the dominant modelling traditions and the demands of causal data science is a particularly worrying feature of the causal crisis that pervades many human sciences presently. We have no guarantees they that such models are interpretable. However, we can do better by clearly defining our
estimands with respect to a clearly defined target population. Causal diagrams are powerful compasses by which to clarify the conditions under which these estimands may be identified from data.

### Defining a Mediaton Estimand 

To gain a clearer understanding of what causal mediation entails, it is
helpful to deconstruct the total effect into the natural direct and
indirect effects.


::: {#tbl-medationpuzzle}
```{=latex}
\mediationpuzzle
```
Causal Mediation 
:::



The total effect of treatment $A$ on outcome $Y$ is defined as the
aggregate difference between the potential outcomes when the treatment
is applied versus when it is not. The estimand for the total effect (TE)
can be expressed as follows:

$$
TE = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
$$

The total effect can be further decomposed into direct and indirect
effects, which allow us to address questions of mediation. The potential
outcome $Y(1)$ taking into account the mediator can be expanded:

$$ 
\mathbb{E}[Y(1)] = \mathbb{E}[Y(1, M(1))]
$$

Here, the effect of the exposure, set to $A = 1$, is considered along
with the effect of the mediator at its natural value when $A = 1$.

Similarly, the potential outcome $\mathbb{E}[Y(0)]$ taking into account the mediator
can be expanded:

$$ 
\mathbb{E}[Y(0)] = \mathbb{E}[Y(0, M(0))]
$$

Here, we focus on the effect of the exposure, set to $A = 0$, along with the effect of the mediator at its natural value when $A = 0$.

Next consider these quantities of interest as they relate to causal mediation analysis. We can clarify our estimand by decomposing the Total Effect (TE, which is equivalent to the average treatment effect, or marginal effect) into the Natural Direct Effect (NDE) and the Natural Indirect Effect (NIE).

**Natural Direct Effect (NDE)** is the effect of the treatment on the outcome while maintaining the mediator at the level it would have been
if the treatment had *not* been applied. The Natural Direct Effect (NDE) is given:

$$
 NDE = \textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]
 $$

Here, the counterfactual quantities that are not directly realised in the data are highlighted in blue: $\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}$. Noticethat we add this term to the potential outcomes when $A=0$, namely, $\mathbb{E}[Y(0)]$, recalling: $\mathbb{E}[Y(0, M(0))] = Y(0)$

**Natural Indirect Effect (NIE):** is the effect of the exposure on the outcome that is mediated. To obtain these quantities we must compare the potential outcome $Y$ under treatment, where the mediator assumes its natural level under treatment with the potential outcome when the mediator assumes its natural value under no treatment is given:

$$
 NIE = \mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}
$$

Here, the counterfactual quantities that are not directly realised in the data are again highlighted in blue: $\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}$.
Notice that we subtract the term from the potential outcomes when $A=1$, namely, $\mathbb{E}[Y(1)]$, recalling: $\mathbb{E}[Y(1, M(1))] = \mathbb{E}[Y(1)]$.

Then, by rearranging this decomposition, we can demonstrate that the total effect (TE) is the sum of the NDE and NIE. We do this by adding
and subtracting the term $\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}$, highlighted in blue to our equation is given:

$$
\text{Total Effect (TE)} = \underbrace{\bigg\{\mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\bigg\}}_{\text{Natural Indirect Effect (NIE)}} + \underbrace{\bigg\{\textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]\bigg\}}_{\text{Natural Direct Effect (NDE)}}
$$

The decomposition of the total effect into natural direct and indirect effects greatly clarifies the targets of interest in causal mediation analysis where the interest is in recovering natural indirect and direct effects, see @vanderweele2015. These are the quantities that causal mediation analysis often seeks [@vansteelandt2012; @valeri2014; @vanderweele2014a;@shi2021; @steen2017]. However, to express these quantities requires conceptualising them in relation to counterfactuals. Lacking a counterfactual framework, it is unclear what our statistical analysis would be estimating. Note that @vanderweele2015 provides a full decomposition that includes causal interaction in settings of causal mediation.



Consider again the hypothesis that cultural beliefs in 'big Gods'
influence social complexity, with political authority serving as a
mediator. We assume for present purposes we have well-defined
interventions and outcomes. What requirements are necessary to answer
our causal mediation question?

1.  **No unmeasured exposure-outcome confounder**

This requirement is expressed: $Y(a,m) \coprod A | L$. After accounting
for the covariates in set $L$, there must be no unmeasured confounders
influencing cultural beliefs in Big Gods, $A$, and social complexity
$Y$. For example, if our study examines the causal effect of cultural
beliefs in Big Gods (the exposure) on social complexity (the outcome),
and the covariates in $L$ include factors such as geographic location
and historical context, we need to ensure that these covariates
effectively block any confounding paths between $A$ and $Y$.
@fig-dag-mediation-assumptions shows this confounding path in brown.

2.  **No unmeasured mediator-outcome confounder**

This requirement is expressed: $Y(a,m) \coprod M | V$. After controlling
for the covariate set $V$, we must ensure that no other unmeasured
confounders affect the political authority $M$ and social complexity
$Y$. For instance, if trade networks affect political authority and
social complexity, to obstruct the unblocked path linking our mediator
and outcome we must account for trade networks. Furthermore, we must be
entitled to assume the absence of any other confounders for the
mediator-outcome path. @fig-dag-mediation-assumptions shows this
confounding path in blue.

3.  **No unmeasured exposure-mediator confounder**

This requirement is expressed: $M(a) \coprod A | Q$. After controlling
for the covariate set $Q$, we must ensure that no additional unmeasured
confounders affect cultural beliefs in big Gods $A$ and political
authority $M$. For example, the capability to construct large ritual
theatres may influence the belief in big Gods and the level of political
authority. If we have indicators for this technology measured prior to
the emergence of big Gods (these indicators being $Q$), we must assume
that accounting for $Q$ closes the backdoor path between the exposure
and the mediator. @fig-dag-mediation-assumptions shows this confounding
path in green.

4.  **No mediator-outcome confounder affected by the exposure**

This requirement is expressed: $Y(a,m) \coprod M(a^*) | V$. We must
ensure that no variables confounding the relationship between political
authority and social complexity in $V$ are themselves influenced by the
cultural beliefs in big Gods ($A$). For example, when studying the
effect of cultural beliefs in big Gods ($A$, the exposure) on social
complexity ($Y$, the outcome) as mediated by political authority
(mediator), there can be no un-modelled factors, such as trade networks
($V$), that influence both political authority and social complexity and
are themselves affected by the belief in big Gods.
@fig-dag-mediation-assumptions shows this confounding path,
$A\to \boxed{V}\rightarrowdotted M$.

Assumption 4, that there is no exposure-induced confounding in the
mediator-outcome relationship, is often a considerable obstacle for
causal mediation analysis. Where the exposure influences a confounder of
the mediator and outcome, we face a dilemma. Without adjusting for this
confounder, a backdoor path between the mediator and the outcome would
remain open. However, by adjusting for it, we partially obstruct the
path between the exposure and the mediator, leading to bias. In this
setting, we cannot recover the natural direct and indirect effects
directly from any observational data and may need to settle for
investigating controlled direct effects, which stipulate fixed values
for the mediator; see: @vanderweele2015; @robins1992.

Notice again that the requirements for counterfactual data analysis are
considerably stricter than has been appreciated in the structural
equation modelling traditions. Natural direct effect estimates and
natural indirect effects estimates require conceptualising a
counterfactual that is never directly observed from the data, namely:
$\textcolor{blue}{Y(1, M(0))}$ see: @vanderweele2015.

Unfortunately, a generation of researchers must unlearn the habit of
leaping from a description of a statistical process as embodied in a
structural equation diagram to the analysis of the data. It has been
over three decades since Robins and Greenland demonstrated that we
cannot understand the quantities we are estimating in mediation analysis
without first specifying the estimands of interest in terms of the
targeted counterfactuals of interest [@robins1992].

#### 3.2.4 Controlled direct effects (and other estimands for mediation)

In the previous section, we focused on the assumptions necessary for decomposing natural direct and indirect effects in causal mediation analysis. It is crucial to note that consistent estimates for natural direct and indirect effects are compromised if there exists a confounder affected by the exposure, which also influences the mediator-outcome relationship. Nonetheless, if all other assumptions hold, we can fix this mediator at a specific level to estimate a 'controlled direct effect' of the exposure at different mediator levels.

Consider a scenario where estimating a controlled direct effect is of interest. Suppose we aim to understand the effect of a stringent pandemic lockdown, $A$, on psychological distress, $Y$, focusing on trust in government, $M$, as a mediator. Further, suppose that pandemic lockdowns may plausibly influence attitudes towards the government through pathways that also affect psychological distress. For instance, people might trust the government more when it provides income relief payments, which may also reduce psychological distress. Under the rules of d-separation, conditioning on income relief payments, denoted as $V$, would attenuate the natural value of the mediator, trust in the government, under exposure to the lockdowns. This blocking of the exposure's effect is represented by the causal path $A \to \boxed{V} \rightarrowdotted Y$. Additionally, the exposure's effect on the mediator is partially blocked by the causal path $A \to \boxed{V} \rightarrowdotted M$. However, if we do not condition on $V$, the path from trust in government, $M$, to psychological distress, $Y$, would be confounded by the common cause $V$, hence: $Y \leftarrowred V \rightarrowred M$.

In such a scenario, it would not be feasible to consistently decompose the total effect of the exposure (pandemic lockdowns) on the outcome (psychological distress) into natural indirect and direct effects. Nevertheless, if all other assumptions hold, we could ascertain from data the controlled direct effect of pandemic lockdowns on psychological distress under fixed levels of trust in government. 

For example, we could examine the effect of the pandemic lockdown if we were able to intervene and set everyone's trust in government to, say, one standard deviation above the baseline, compared with fixing trust in government to the average level at baseline. We might use 'shift functions' that specify interventions as functions of the data. For instance, we might investigate interventions that 'shift only those whose mistrust of government was below the mean level of trust at baseline and compare these potential outcomes with those observed.' Asking and answering precisely formulated causal questions such as this might lead to clearer policy advice, especially in situations where policymakers can influence public attitudes towards the government; see: @williams2021; @dÃ­az2021; @hoffman2022; @hoffman2023. 

In any case, I hope this brief discussion of causal mediation analysis clarifies that it would be unwise to simply examine the coefficients obtained from structural equation models and interpret them as meaningful as in statistical mediation analysis. We have no guarantees that these coefficients are interpretable. Rather, to answer any causal question, we must first state it, with respect to clearly defined counterfactual contrasts and a target population.

For those interested in estimands for causal mediation analysis, I recommend visiting the CMAverse website ([https://bs1125.github.io/CMAverse/articles/overview.html](https://bs1125.github.io/CMAverse/articles/overview.html), accessed 12 December 2023). This excellent resource provides comprehensive documentation, software, and practical examples, including sensitivity analyses. Next, we will consider more complex scenarios that involve feedback between treatments and confounders across multiple time points, settings in which traditional statistical methods also fail provide valid causal inferences.


{{< pagebreak >}}
::: {#tbl-medationassumptions}
```{=latex}
\mediationassumptionsswig
```
Assumptions of Causal Mediation 
:::


## Time-fixed and Time-Varying Treatment Regimes

Our discussion of causal mediation analysis focused on how effects from two sequential exposures may combine to influence an outcome. This
concept can be expanded to investigate the causal effects of multiple sequential exposures -- referred to as 'treatment regimes', or 'treatment strategies', or 'modified treatment policies.'  In many human sciences where longitudinal data are collected, researchers will often gravitate to longitudinal growth models and multi-level models. How shall we interpret the coefficients of these models?  To answer a causal question we must first ask it -- that is, we must first state the counterfactual contrast in which we are interested. Without stating the the treatments to be contrasted, the scale on which the contrast will be computed, and the population for whom inferences are valid, our statistical models have no clear meaning. The inscrutibility of our models remains even if there is no unmeasured confounding. However, we learned from causal mediation analysis that even if investigators were to randomise the treatment they could do not typically randomise the mediator. This raises the prospect of intermediary confounding. Moreover, we learned that even if investigators were to conduct a sequentional trial such that the mediator was randomised, there would be no arm of the trail that would yeld the cross-world quantity needed to obtain a decomposition of the total effect into the natural indirect and direct effects. The quantity -- $\mathbb{E}[Y(1, M(0))$ -- is not observed on any individual.  Causal mediation anaysis is a special case of causal inference under sequential treatments.  We next clarify how investigators may avoid the widespread confusions that pervade longtitudinal data analysis by clearly stating their causal questions and evaluating identification before reaching for any statistical model. 

### Worked Example: Does Marriage Affect Happiness?

Richard McElreath considers the question of whether marriage affects happiness, and provides a simulation to clarify how age structure complicates causal inferences @mcelreath2020.  Here, we develop this example.  We simply by considering the outcome, happiness, measured after two time intervals. Assume this outcome to be well-defined and measured without error. Assume further that positivity is satisfied, all outcomes are observed within each level of confounding co-variate. Assume that consistency is satisfied.  Multiple versions of treatment are conditionally independent of the outcomes. 


$A_t=1$ denotes the state of being married at time $t$ and $A_t = 0$ where $t \in \{0, 1, \tau\}$ where $\tau$ is the end of study and and $Y_\tau$ denotes the outcome, Happiness 

We see in @tbl-regimens-marriage reveals that there are four treatment strategies, and six causal contrasts we may estimate for the four each treatment strategy combination. 



| Type     | Description      | Counterfactual Outcome |
|----------|------------------|------------------------|
| Regime   | Always married   | $Y(1,1)$               |
| Regime   | Never married    | $Y(0,0)$               |
| Regime   | Divorced         | $Y(1,0)$               |
| Regime   | Gets married     | $Y(0,1)$               | 
| Contrast | Always married vs. Never married | $E[Y(1,1) - Y(0,0)]$   |
| Contrast | Always married vs. Divorced       | $E[Y(1,1) - Y(1,0)]$   |
| Contrast | Always married vs. Gets married   | $E[Y(1,1) - Y(0,1)]$   |
| Contrast | Never married vs. Divorced        | $E[Y(0,0) - Y(1,0)]$   |
| Contrast | Never married vs. Gets married    | $E[Y(0,0) - Y(0,1)]$   |
| Contrast | Divorced vs. Gets married         | $E[Y(1,0) - Y(0,1)]$   |

: Table outlines four fixed treatment regimens and six causal contrasts in time-series data where exposure varies. These labels apply only to the two time points. {#tbl-regimens-marriage}


The question "Does marriage affect happiness?" has no clear meaning unless we state the contrast or set of contrasts for which we hope to obtain valid causal inferences. To be scientifically meaningful, the contrasts we state should be grounded in cleary communicated scientific interests, and these interests should inform the target population for which we take inferences to be valid. The question, for example, of whether divorce makes one less happy one year later, will have different answers depending on whether we compare divorce with remaining married, with never having married, or with getting married.  Notice the estimands we state will imply different populations for whom results are meant to generalise. The marginal effect estimate of Divorce vs Always married generalises to the population who was always married. Clinicians and relationship scientists might have reasons to focus on effect-modification by gender, or sexual orientation, or birth cohort, say. The marginal estimands will not automatically align with these interests, and indeed risk erroneous policy inferences wherever the target population differs from the sample population from which marginal effects have been estimated -- even if our results obtain consistent causal estimates of the targeted estimands.  

We set further discussion about the need for clearly defined estimand and target population to the side. Suppose investigators state and clearly communicate the treatment regimes to be contrasted. Their next task will be to evaluate sequential exchangeability: they must clarify whether the potential outcomes are independent at each time point of the outcome, obtained at the end of study.


::: {#tbl-swigtabledeveloped}
```{=latex}
\swigtabledeveloped
```
Assumptions of Causal Mediation 
:::

@tbl-swigtabledeveloped  represents a two subsets of possible confounding structures for a treatment regime conducted over two intervals.  Covariates in $L_{t}$ denote measured confounders. $U$ denotes unmeasured confounders. $A_t$ denotes the treatment, "Marriage Status" at time $t$. $Y$ denotes "Happiness" measured at the end of study. We assume that conditioning on $L_{t}$ is sufficient to all backdoor paths for $A_{t+1}$. We include indicators of "Happiness" in $L_{t}$, thus controlling for happiness as a common cause of the marriage at time $t+1$ and happiness at the end of study $\tau = \bar{A}-{\tau -1}$.  @tbl-swigtabledeveloped $\mathcal{G}1$ and @tbl-swigtabledeveloped $\mathcal{G}2$ are causal DAGs that the describe these structures.  Recall when constructing causal DAGs we do not generally draw a path from treaments to outcome when our interest is in evalauating d-separation using backdoor adjustment. Here we are not concerned that $A_2$ is a mediator of the path from $A_1$ to $Y$ because our estimand refers to the combined effect of $A_1$ and $A_2$. Furthemrmore, we make no attempt to separate these effects within any treatment regime; we assume all nodes can be intervened upon.


Consider the structure of confounding presented in @tbl-swigtabledeveloped $\mathcal{G}1$. To close the backdoor path from $A_1$ to $Y$ we must condition on $L_0$. To close the backdoor path from $A_3$ to $Y$ we must likewise condition on $L_2$.  However, $L_2$ is a collider of treatment $A_1$ and unmeasured confounders, such that conditioning on $L_2$ opens a backdoor path between $A_1$ and $Y$ This path is highlighted in red: $A_1 \association L_2 \association U \association Y$. 

If @tbl-swigtabledeveloped $\mathcal{G}1$ faithfully represents causality, it might seem that we cannot obtain valid inference for any of the six causal contrasts we have defined. And indeed were we to limit ourselves to standard methods we could not obtain valid causal inferences. However, @robins1986 was the first to describe a consistent estimation function that can be constructed where there is time-varying confounding (refer to @robins2004effects,  @hernan2004STRUCTURAL). @tbl-swigtabledeveloped $\mathcal{G}3$ presents a Single World Intervention Template that clarifies how identification may be obtained in fixed treatment regimes where there is time-varying confounding of the kind we observe in @tbl-swigtabledeveloped $\mathcal{G}1$,  Recall that when constructing a Single World Intervention Graph (or Template), we obtain factorisations for counterfactual outcomes under a specific treatment regime by employing 'node-splitting' such that all nodes following an intervention are relabelled as counterfactual states under preceeding intervention. After a node-splitting, a fixed intervention is no longer a random variable. Thus, under fixed treatment regimes, the counterfactul states that follow an intervention are independent of the states that occur prior to node splitting if there are no back-door paths into the random partition of the node that has been split. If  if all backdoor paths are closed into the random partitions of the nodes on which interventions occur, then we can graphically verify that the treatment is independent of the counterfactual outcome for that intervention node. Where there are multiple interventions, we insure sequential exchangeability at the following node -- which we likewise split and relable -- by closing all backdoor paths between the random portion of the following treatment node. We have sequential independence if for each intervention node, all backdoor paths are closed (refer to @robins2010alternative; @richardson2013swigsprimer; @richardson2023potential). The Single World Intervention Template @tbl-swigtabledeveloped $\mathcal{G}3$ makes it clear that sequential identification may be obtained. $A_1$ is d-separated from $Y$ by conditioning on $L_0$; $A_3$ is d-separated from $Y$ by conditioning on $L_2$.   Suppose that the only confounder in $L$ were happiness. By estimating the effect of $L_2$ on $Y$, adjusting for $A_1, L_2, L_0$, obtain valid inference for $Y$.  By adjusting for $L_0$ we obtain valid inference for $A_1$.  We may *not* estimate the combined effect of a treatment strategy over $A_1$ and $A_2$ by employing regression, multi-level regression, statisical structural equation models, or propensity score matching. However, special estimators may be constructed (refer to @robins1986; @robins2004effects; @vanderlaan2011; @diaz2021nonparametric). Because our interest here is in identification we shall review these estimators (for recent reviews refer to @hernan2024WHATIF; @chatton2020; @vanderlaan2018; @chatton2024causal).



### Time-varying confounding without treatment-confounder feedback.

Consider how we may have time-varying confounding in the absence of treatment-confounder *feedback*.  Again we are interested in contrasts for a two treatment "marriage" treatment on "happiness" measured at the end of study.  Again we assume that these variables are well-defined, that the time intervals separating the measurements make theoretical sense and that 'marriage' can be intervened upon, that we have specified a target population, and that our questions are scientifically interesting. Our focus is on whether the estimands we state can be obtained from observational data. @tbl-swigtabledeveloped $\mathcal{G}1$ presents a structure in which there is time-varying confounding.  


$U_{AL}$ denotes ability over-confident personality, an unmeasured variable, that is causally associated with associated with decisions to marry early and with wealth. We do not suppose that $U_{AL}$ affects happiness. Therefore, on this assumption, investigators should make no adjustment for $U_{AL}$.

$U_{AY}$ denotes a common cause of variables in $L_2$ and happiness. Suppose this this is "job status" which affects wealth, and happiness. To sharpen the confounding problem, we can present it in its minimal form, assuming that job status has no effect on baseline marriage rates (whether it does make no difference to the structural features of the problem).  @tbl-swigtabledeveloped $\mathcal{G}2$ presents the structure of confounding for this problem. (To declutter, we remove baseline measurement of $L_0$, which we assume to be conditioned on, but not to block the hideen variable wealth --the ultra wealthy are unemployed, Professor with status get paid peanuts ... nor does status block the backdoor path through over-confidence). Note that there is no treatment confounder feedback in this example.  We will not imagine that marriage affects stated wealth, but only that stated wealth affects marriage (perhaps because wealth is a surrate of a latent cause of stated wealth and happiness). To obtain valid inference for the effect of $A_2$ on $Y$ we must adjust for $L_2$.  However $L_2 is a collider of $U_{AL}$ and  $U_{AY}$. We must therefore adjust for $L_2$. However $L_2$ is also a collider of $U_{AL}$ and $U_{LY}$; adjustment for $L_2$ opens the path 

$A_1 \association U_{AL} \association L_2 \association U_{AY} Y$. We have confounding. 

@tbl-swigtabledeveloped $\mathcal{G}4$ clarifes that in the in the fixed treatment regime sequential exchangeable can be obtained. To estimate the effect of $A_2$ we must condition on $L_2$.  When estimating the effect of $A_1$ on $Y$ all backdoor paths are closed because $L_2$ is a collider, and $A_0 \coprod Y$. 

If $L_2$ were not a collider, there would be unmeasured confounding.

### Dynamic Treatment Strategies (Modified Treatment Policies)

In a dynamic treatment strategy, or 'modified treatment policy', the value at which a treatment is fixed is a function of measured events leading up to the treatment.

Suppose investigators were interested in the population average effect of divorce on happiness if divorce were only permitted for those with high social status. 

This question is easy to ask but deceptively difficult to answer. For example, we cannot fit an interaction of time $\times$ social status $\times$ marriage status,  because marital status might affect social status. Yet even if marriage did not affect social status, as in 
@tbl-swigtabledeveloped $\mathcal{G}4$ and 
@tbl-swigtabledeveloped $\mathcal{G}4$   regression would not produce valid estimates for the counterfactal question we asked.

To sharpen focus, imagine that investigators obtained indicators of social status at baseline.


<!-- Among the population who has been married for at least one year before divorce, what would be the one-year effect of divorce in the following year if everyone who divorced earned at least 1.5 times more income the target population average." Note that we might restrict the sample to only those who are married at time 1 ($i.e. restrict to A_1 == 1$), and focus on the treatment effects of $A_3$ on $Y$.  Such restriction would only induce M-bias were $U_{AL} \rightarrowNEW Y$. However, such restriction would change the target population. Consider how a modified treatment policy might be developed for everyone who might have been married or unmarried at start of study.  -->

Suppose the investigators state the following fixed treatment strategy:

$g_1(\cdot)$: remain married for at least two additional years:

$$
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   a_{1} = 1 & \\ 
   a_{2} = 1 &   
    \end{cases}
$$

This regime is identified. The setting is identical to @tbl-swigtabledeveloped $\mathcal{G}3$ however with no unmeasured variables and no arrow from $A_1$ to $L_2$.


However, for a causal contrast we require a second counterfactual intervention. (A contrast requires at least two counterfactual outcomes.) 


$g_2(\cdot)$: at each measurement interval, divorce only if one;s social status is at least 50% greater than average and the individual would have divorced in the absence of intervention, otherwise enforce marriage:

$$
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   a_{1} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_1 = {0} \\ 
   a_{2} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \& A_2 = {0} \\ 
   a_{t}(\mathbf{g}) = 1 & \text{otherwise} 
   \end{cases}
$$

Notice that in this estimand, treatment is computed as a function of income at both of the natural value of $A_t$ and the social status $L_t$, for $t = \{1,2\}$ 

Template @tbl-swigtabledeveloped $\mathcal{G}5$ presents the confounding structure. To convey the dependence of the fixed node on covariate history under treatment we use  @richardson2013's conventions and draw a dashed line to convey new paths specified by the treatment regime: $\rightarrowdottedgreen$. 


Robin's and Richardson's propose the extended dynamic g-formula for identifying causality under dynamic treatment regimes: 


First we define the set of counterfacutal variables in our dynamic Single World Intervent Graph (or Template)

  - $\mathbb{A}^+(\mathbf{g})$ denotes the set of modified treatments variables under a dynamic regime $\mathbf{g}$.
  - $\mathbb{V}(\mathbf{g})$: denotes the set of counderfactual nodes following treatments.
  - $\mathbb{W}(\mathbf{g})$: denotes the combined set of all counterfactual variables under dynamic regime corresponding to $\mathcal{G}_\mathbf{g}$.  In set notation, 
$$
\mathbb{W}(\mathbf{g}) \equiv \mathbb{A}^+(\mathbf{g}) \cup \mathbb{V}(\mathbf{g}))
$$



Next, at each intervention node $t$, find all ancestors of $Y(\mathbf{g})$ in $\mathbb{W}(\mathbf{g})$ that are not in the set of current or past treatment covariates. In set notation, 


$$
\mathbb{Z}_t(\mathbf{g}) \equiv \text{an}_{\mathcal{G}(\mathbf{g})}(Y(\mathbf{g})) \setminus (\mathbb{L}_k(\mathbf{g}) \cup \mathbb{A}_k(\mathbf{g}) \cup \mathbb{A}^+(\mathbf{g})).
$$


Third, we map $\mathbb{Z}$ to a new Single World Intervention Graph $\mathcal{G}(\mathbf{a}^*)$, where the intervention $\mathbf{a}^*$ is specific value of $A = a$ assigned under $f^g(\cdot)$. This new dSWIG $\mathcal{G}(\mathbf{a}^*)$, is simply the original dSWIG $\mathcal{G}(\mathbf{g})$ in which the dashed arrows removed.  As such we may simply use dSWIG $\mathcal{G}(\mathbf{g})$ ignoring the dashed arrows -- as we do here. 


Fourth, we ensure conditional independence of the treatment $A_t = a*$ with members of the set $\mathbb{Z}_t$, if, for for all $\mathbf{a^*}$ (fixed nodes) and all time points $t \in 1...\tau$, where $\tau$ is the end of the study. 


$\mathbb{Z}_t(\mathbf{a}^*) \coprod I(A_t(\mathbf{a}^*) = a^*_t) \mid \bar{\mathbb{L}}_t(\mathbf{a}^*), \bar{\mathbb{A}}_{t-1}(\mathbf{a}^*) = \bar{\mathbf{a}^*}_{t-1}$ 


where, $I$ denotes the indicator function:


$$
I(A_k(\mathbf{a}^*) = a^*_t) = 
\begin{cases} 
1 & \text{if } A_k(\mathbf{a}^*) = a^*_t, \\
0 & \text{otherwise}.
\end{cases}
$$



Effectively this algorithm amounts to: 

    1. Find the ancestors of $\mathbb{Z}_t(\mathbf{g})$ that are not in $\bar{\mathbb{L}}_t(\mathbf{g}) \cup \bar{\mathbb{A}}_t(\mathbf{g}) \cup \bar{\mathbb{A}}^+$
    2. For each $A(\mathbold{a}^*_t)$ evalute whether $A(\mathbold{a}^*_t)$ is de-separated from members of $\mathbb{Z}_t(a)$  conditional on $\bar{\mathbb{L}}_t(\mathbf{a}) \cup \bar{\mathbb{A}}_{t-1}(\mathbf{a*}) \cup \mathbf{a*}$ in $\mathcal{G}(\mathbf{a}^*)$.

Where:

1. **$\mathbb{Z}_t(\mathbf{a}^*)$**: denotes the subset of vertices in $\mathcal{G}(\mathbf{a}^*)$ corresponding to $\mathbb{Z}_t(\mathbf{g})$.
2. **$A_t(\mathbf{a}^*) = a^*_t$**: denotes the specific value of the treatment variable at time $t$ under the intervention $\mathbf{a}^*$.
3. **$\bar{\mathbb{L}}_t(\mathbf{a}^*)$**: denotes the set of covariates up to time $k$ under the intervention $\mathbf{a}^*$.
4. **$\bar{\mathbb{A}}_{t-1}(\mathbf{a}^*)$**: denotes the set of past treatment variables up to time $t-1$ under the intervention $\mathbf{a}^*$.


In our example we can apply this formula as follows.  

First we obtain $\mathbb{Z}(\mathbf{g})_t$:

$$
\begin{aligned}
\mathbb{Z}(\mathbf{g}) &= \{A_1, L_1(\mathbf{g}), A_1(\mathbf{g}), A_2(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_1(\mathbf{g}) &= \{\mathbf{g}), L_1(\mathbf{g}), Y(\mathbf{g})\} \\
\mathbb{Z}_2(\mathbf{g}) &= \{Y(\mathbf{g})\}
\end{aligned}
$$


Then we check conditional indepencies for each treatment. Although $\mathbf{a^*}) \coprod Y | L_2(\mathbf{a^*}), A_1$,  we find that $A_1 \cancel \coprod L_1(\mathbf{a^*})$ and $A_1 \cancel \coprod A_2(\mathbf{a}^*)$;  The counfounding paths are $A \association U_{AL} \association  L_2(\mathbf{a^*})$, and $A_1 \association U_{AL} \association  L_2(\mathbf{a^*}) \association  L_2(\mathbf{a^*})$. Identification fails. 





+++

If we convert template @tbl-swigtabledeveloped $\mathcal{G}5$ by the dynamic time-varying g-formula, we gave  As shown in Template @tbl-swigtabledeveloped $\mathcal{G}4$. Alternatively we can test identification using template @tbl-swigtabledeveloped $\mathcal{G}5$ and ignoring the dashed lines. 

As shown in Template @tbl-swigtabledeveloped $\mathcal{G}4$ dynamic treatment strategy is longer identified. A path open backdoor path runs from 
$A_1 \association A^{+}_1(g) \association L_2(g) \association A^{+}_2(g)$ 


As shown in Template @tbl-swigtabledeveloped $\mathcal{G}4$ dynamic treatment strategy is longer identified. A path open backdoor path runs from 
$A_1 \association A^{+}_1(g) \association L_2(g) \association A^{+}_2(g)$ 
T


Readers should be awared that within the causal inference literatures there are debates about identification under time-varying treatments (refer to @richardson2023potential; @richardson2013; @Diaz2023; @rudolph2024mediation; @shpitser2022multivariate). However, all agree that it sufficient for identification, condition on covariate histories at interventional, all treatments - whether fixed or modified - are conditionally independent of future counterfactual outcomes. 



## Conclusions




## Funding

This work is supported by a grant from the Templeton Religion Trust (TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also received support from the Max Planck Institute for the Science of Human History. The Funders had no role in preparing the manuscript or the decision to publish it.

## Acknowledgements

Errors are my own.



## Appendix A: Glossary


::: {#tbl-gloassary}
```{=latex}
\glossaryTerms
```
Glossary
:::


## Appendix B On the Clarity of Single World Intervention Graphs


{{< pagebreak >}}
::: {#tbl-pearltable}
```{=latex}

\pearltable
```
On the limitations of causal DAGs compared to Single World Intervention Graphs. 
:::
