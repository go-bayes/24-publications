% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  single column]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{libertinus}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=30mm,left=25mm,heightrounded,headsep=22pt,headheight=11pt,footskip=33pt,ignorehead,ignorefoot]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\input{/Users/joseph/GIT/latex/latex-for-quarto.tex}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Defining Causal Estimands for Interaction, Mediation, and Treatment Confounder Feedback},
  pdfauthor={Joseph A. Bulbulia},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Defining Causal Estimands for Interaction, Mediation, and
Treatment Confounder Feedback}

\usepackage{academicons}
\usepackage{xcolor}

  \author{Joseph A. Bulbulia}
            \affil{%
             \small{     Victoria University of Wellington, New Zealand
          ORCID \textcolor[HTML]{A6CE39}{\aiOrcid} ~0000-0002-5861-2056 }
              }
      


\date{2024-05-20}
\begin{document}
\maketitle
\begin{abstract}
Despite several decades of progress in the causal data sciences,
concepts such as interaction, mediation, and longitudinal modelling
remain poorly understood. Here we use causal diagrams to clarify these
fundamental concepts.

\textbf{KEYWORDS}: \emph{Causal Inference}; \emph{SWIGs}; \emph{DAGs};*
\emph{Evolution}; \emph{Mediation}; \emph{Longitudinal Growth};
\emph{Time-varying Treatments};
\end{abstract}

\subsection{Introduction}\label{introduction}

Human scientists apply statistical models to data and report
`interaction', `moderation', `mediation' using both cross-sectional and
time-series data. What do these concepts mean? It is generally unclear.
The confidence with which investigators deploy methods and report their
findings does not make these concepts any clearer.

Here we describe when and how these concepts may be used for causal
inferences.

We begin by clarifing basic concepts and graphical conventions.

\subsubsection{Terminology}\label{terminology}

\textbf{Causality}: A cause, \(A\), is said to effect an outcome \(Y\),
if in setting the cause to one level, \(A_i = a^*\), as opposed to
another level \(A_i = a\) the outcome would be different, which we
write: \(Y_i(a^*) -  Y_i(a) \neq 0\). This quantity denotes the contrast
for individual \(i\), measured on the difference scale, between
measurable outcomes under two states of the world, one in which
\(A = a^*\) the other when \(A=a\). We call variable of interest, the
cause -- \(A\) -- a `treatment' or an `exposure'; we call the outcome
under treatment -- \(Y(A = a)\) -- the potential or counterfactual
outcome. We use the terms ``potential outcome'' and ``counterfactual
outcome'' interchangeably. The observed outcome is given \(Y|A=a\). At
the individual level, we may generally only observe at most
\(Y_i|A_i =a\) or \(Y_i|A_i =a^*\) but not both.

\textbf{Causal Inference} Although physics prevents us from observing
individual causal effects, we may compute average treatment effects by
aggregating over individual observations by treatment conditions. For a
binary treamtment we write as the difference in mean outcomes by
treatment condition: \(E[Y(1)] - E[Y(0)]\) or equivalently as the mean
difference in outcomes by treatment condition \(E[Y(1) - Y(0)]\).
Notably, this countefactual contrast is precisely the quantity (on the
difference scale) that we obtain for a sample population from an ideally
conducted randomised controlled trials -- an `experiment.' Implied by
the ideal experiment are the following assumptions:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
  causal consistency: that treatment levels are consistent within the
  treatment arms to be compared (implied by ``control'');
\item
  exchangeablity: that there is balance across all arms in the
  co-variates that might affect outcomes under treatment (implied by
  `randomisation');
\item
  for each co-variate that might affect treatment in the target
  population, there is a non-zero probability this co-variate will be
  observed within each treatment condition to be compared (implied by
  the combination of randomisation and a clearly defined target
  population.)
\end{enumerate}

Of course, the experiments investigators conduct are often not ideal,
any combination of these assumptions may fail. In observational or
``real-world'' settings, none of these assumptions are guaranteed.
Worse, only positivity may be evaluated from the data. If ou interested
is in using real-world data to understand the causal effects of
interventions we must

Step 1. State a well-defined intervention.

Step 2. State a well-defined outcome.

Step 3. Clarify the target population.

Step 4. Evaluate whether the treatments to be compared satisfy causal
consistency.

Step 5. Evaluate whether, conditional on measured covariates, the
treatment groups to be compared are exchangeable, or equivalently that
any differences are ignorable, or equivalently, that there confounding
covariates across treatment levels are balanced, or equivalently, all
backdoor paths between treatments and outcomes have been closed, or
equivalently, treatment(s) and outcome(s) are d-separated, or
equivalently there is no unmeasured confounding. Although terminology
varies, the target remains the same, to ensure non-random ``real-world''
data may be modelled to emulate a randomised controlled experiment.

Step 6. Evaluate whether the positivity assumption is satisfied.

Step 7. Transparently communicate investigator reasoning and decisions
for steps 1-6.

\textbf{Confounding}: treatment and outcome are associated independently
of causality.

\subsubsection{Meaning of Symbols}\label{meaning-of-symbols}

To clarify the concepts of interaction, moderation, and mediation, we
will use causal graphical methods. For a review of causal directed
acyclic graphs (\citeproc{ref-pearl}{\textbf{pearl?}}); McElreath
(\citeproc{ref-mcelreath2020}{2020}); Neal
(\citeproc{ref-neal2020introduction}{2020}); Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}). For a review of single world
intervention graphs see Richardson and Robins
(\citeproc{ref-richardson2013swigsprimer}{2013a}). I will assume some
familarity with causal DAGs when introducing single world interventiong
graphs.

\textbf{\(A\)}: Denotes the ``treatment'' or ``exposure'' - a random
variable. This is the variable for which we seek to understand the
effect of intervening on it. It is the ``cause.''

\textbf{\(\bar{A}\)}: Denotes a sequence of treatments.

\textbf{\(Y\)}: Denotes the outcome or response, measured at the end of
study -- the ``effect.''

\textbf{\(L\)}: Denotes a measured confounder or set of confounders --
variables required for conditional exchangeability.

\textbf{\(U\)}: Denotes an unmeasured confounder or confounders.

\textbf{\(\mathcal{R}\)}: Denotes chance assignment to treatment
condition, as when treatment assignment is randomised.

\textbf{\(\mathcal{G}\)}: Denotes a graph, here, a causal directed
acyclic graph.

Table~\ref{tbl-terminologylocalconventions} reports our graphical
conventions.

\begin{table}

\caption{\label{tbl-terminologylocalconventions}Terminology}

\centering{

\terminologylocalconventions

}

\end{table}%

\subsubsection{Elements of causal
graphs}\label{elements-of-causal-graphs}

\textbf{Node}: a node or vertex represents characteristics or features
of units within a population on a causal diagram -- that is a
``variable.'' In causal directed acyclic graphs, we draw nodes with
respect to the \emph{target population}, which is the population for
whom investigators seek causal inferences
(\citeproc{ref-suzuki2020}{Suzuki \emph{et al.} 2020}). Time-indexed
node: \(X_t\) denotes relative chronology

\textbf{Edge without an Arrow} (\(\association\)): path of association,
we do not assert causality.

\textbf{Arrow} (\(\rightarrowNEW\)): denotes causal relationship from
the node at the base of the arrow (a `parent') to the node at the tip of
the arrow (a `child'). In causal DAGS it is conventional to refrain from
drawing an arrow from treatment to outcome to avoid asserting a causal
path from \(A\) to \(Y\) because iyr purpose is to ascertain whether
causality can be identified for this path. All other nodes and paths --
including the absence of nodes and paths -- is typically assumed.

\textbf{Red Arrow} (\(\rightarrowred\)): path of non-causal association
between the treatment and outcome. Despite the arrows, this path is
associational and may flow against time.

\textbf{Dashed Arrow} (\(\rightarrowdotted\)): denotes a true
association between the treatment and outcome that becomes partially
obscured when conditioning on a mediator, assuming \(A\) causes \(Y\).

\textbf{Dashed Red Arrow} (\(\rightarrowdottedred\)): highlights
over-conditioning bias from conditioning on a mediator.

\textbf{Open Blue Arrow} (\(\rightarrowblue\)): highlights effect
modification, which occurs when the levels of the effect of treatment
vary within levels of a covariate. We do not assess the causal effect of
the effect-modifier on the outcome, recognising that it may be
incoherent to consider intervening on the effect-modifier.

\textbf{Boxed Variable} \(\boxed{X}\): conditioning or adjustment for
\(X\).

\textbf{Red-Boxed Variable} \(\boxedred{X}\): highlights the source of
confounding bias from adjustment.

\textbf{Dashed Circle} \(\circledotted{X}\): no adjustment is made for a
variable (implied for unmeasured confounders.)

\textbf{\(\big(\mathcal{R} \rightarrow A\big)\)}: randomisation into the
treatment condition.

\textbf{Node Splitting} \(\switbasic\) used in Single World Intervention
Graphs to denote counterfactual histories that arise following
interventions. Node-splitting allows investigators to separately
evaluate identification for each counterfactual to be contrasted. All
causal DAGs can be restated using Single World Intervention Graphs.
However, each Single World Intervention Graph may encode at most one
level of treatment or one sequence of treatments. To avoid proliferating
graphs, we may use a Single World Intervention Template to denote the
graph-valued function from which multiple Single World Intervention
Graphs may be generated.

\textbf{Green dashed arrow}: \(\rightarrowdottedgreen\): Indicates
dependency in dynamic sequentiental treatment strategies where the
`natural value' a treatment value under a specific treatment regime
depends on the values obtained from the counterfactual histories that
precede the node in Single World Intervention Graph. Dynamic Strategies
enable flexible, realistic causal inferences, however, they also impose
stronger identification assumtions. For example, arrows to the ``natural
value'' of the treatment may compromise sequential exchangeabilty,
threatening identification (refer to Richardson and Robins
(\citeproc{ref-richardson2013}{2013b})).

Table~\ref{tbl-terminologylocalconventions} reports our graphical
conventions.

\begin{table}

\caption{\label{tbl-terminologygeneral}Elements of Causal Graphs}

\centering{

\terminologygeneral

}

\end{table}%

\newpage{}

\subsection{Part 1 Interaction}\label{part-1-interaction}

In causal data science, we may think of interaction or moderation in one
of two ways, either as

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Interaction as effect-modification of a single intervention. We might
  be interested in heterogeneity in the magnitude of a single
  intervention with a stratum or strata of the population. For example,
  we might ask, does the effect of religious service attendance affect
  charitable giving among differently among people who were born in
  Australia differently from its effects on people who were born in
  Egypt? Here, we do not imagine any intervention on birthplace.
\item
  Interaction as the combined effect of a double intervention. We might
  ask of whether administering two treatments would affect people
  differently than each taken individually. For exampel, we might ask
  wehther the combined effect of religious service and wealth affect
  charitable giving differently from the independent effect of either
  religious service or of wealth taken alone.
\end{enumerate}

When our interest is in a single intervention we will use the terms
`effect-modification 'and 'moderation' interchangeably. When our focus
is on a double intervention we will use the term `interaction.' We note
the term `interaction' has broader scope than the analysis of
heterogeity of single effects and the analysis of double exposures. For
example the term `interaction' arises in the analysis of biological
synergisms. We shall restrict our interests to heterogeneity and double
interventions.

Note that when considering interaction as effect modification or as a
double intervention, we must state a scale at which we indent to measure
our contrasts. This is because evidence of effect-modification or of
interaction that is present at one scale may not be present at another.
Indeed ``effect-modification'' is often called ``effect-measure
modification.'' Here, we will restrict consideration of effect (measure)
modification and of interaction to causal contrasts computed on the
additive scale.

The key point to underscore up front is that before applying statistical
models to data, we must to explicitly define our causal questions, the
scale at which it will be computed, and the target population in which
we are interested. We must state whether we are intrested causal
contrasts for a single intervention at different levels a covariates (or
set of covariates) or whether we are intersted in causal contrasts
obtained for different levels of a double intervention. Indeed,
considering questions of interaction immediately claries the importance
of clearly stating our causal questions before conducting data analysis.

\subsubsection{Effect-Modification}\label{effect-modification}

The `sharp-null hypothesis' states there is no effect of the exposure on
the outcome for any unit in the target population. Unless the
`sharp-null hypothesis' is false, there may be effect-modification. For
any study worth conducting, we cannot evaluate whether the sharp-null
hypothesis is false (otherwise why conduct the study?). Therefore, we
must assume assume that treatment effects may be heterogenous.

\begin{table}

\caption{\label{tbl-terminologyeffectmodification}Conventions for
representing effect modification}

\centering{

\terminologyeffectmodification

}

\end{table}%

Table~\ref{tbl-terminologyeffectmodification} presents our graphical
conventions for describing effect modification. We assume no confounding
of the treatment on the outcome, and furthermore will assume that \(A\)
has been randomised (i.e.~\(\mathcal{R} \rightarrowNEW A\)). To simplify
we do not include randomisation in our graphs. Note that we draw an open
blue arrow to highlight our interest in effect-modification. This
convention is specific to this article; refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}) pp 126-127 for a discussion of
``noncausal'' arrows. For Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}), essentially all arrows are
non-causal until proven causal, or in their words `\ldots{} arrows
simply encode, via d-separation, the conditional independencies
satisfied by the variables on the diagram and on the associated SWIG'.
This is correct. However, our purpose here is merely to underscore that
effect-modification inherently avoids causal interpretations for the
variables investigators use to qualitatively evaluate treatment-effect
heterogeneity.

\begin{table}

\caption{\label{tbl-terminologyeffectmodificationtypes}Effect
Modification}

\centering{

\terminologyeffectmodificationtypes

}

\end{table}%

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 1,
we represent that \(Z\) is a direct effect modifier for the effect of
\(A\) on \(Y\). The open arrow indicates that we are not attributing
causality to \(Z\) as such. Because our estimand does not involve
intervening on \(Z\), there is no need to close its backdoor paths.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 2,
we represent that \(Z\) is an unobserved direct effect modifier of \(A\)
to \(Y\). Importantly, wherever the distribution of direct effect
modifiers \(Z\) differs between two populations and effect modification
is non-linear, marginal treatment effects between populations will
generally differ and will not easily transport from one population to
another (see Appendix X). The concept of an average treatment effect has
no meaning absent a population over which the effect marginalises. This
is point is perhaps obvious, yet it has profound implications for
generalisations reserch.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 3,
we present two candidate effect modifiers. Notably, whether a variable
is an effect-modifier also depends on which other variables are included
in the model. Here, \(Z\) is a direct effect-modifier and \(G\), a
descent of \(Z\), is an indirect effect modifier. Suppose we are
interested in qualitatively evaluating whether treatment effects vary
(on the difference scale) within levels of \(G\). For example, imagine
\(Z\) is childhood deprivation and \(G\) is educational achievement,
\(A\) is a government educational initiative and \(Y\) is recyling. In
this setting, we were to condition on \(Z\), we would not observe effect
modification by education \(G\) for the effect of the government
iniative \(A\) on recyling behaviour \(Y\).

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 4
presents the same causal structure. However, here we do not condition on
the direct-effect modifier \(Z\), but rather condition only on \(G\),
the indirect effect modifier. In this scenario we would find that the
effectiveness of the government initative \(A\) on recyling behaviour
\(Y\) would vary by educational acheivement \(G\). That is, we would
observe \(G\) to be an effect-modifier.

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 5,
we add another variable to our model, depression, denoted by \(B\). We
imagine \(B\) to be a stable trait or that investigators measured
childhood depression (that is \(B\) precedes \(G\)). Imagine we do not
condition on the direct-effect modifier \(Z\) (childhood depreviation).
However we condition on educational attainment (\(G\)) and depression
\(B\). In this graph, \(G\) is a collider of \(Z\) and \(B\). Thus,
conditioning on \(G\) (but not \(Z\)) would open a path from
\(B \association G \association Z  \association Y\) and investigators
would find an evidence for effect modification by depression and the
effectiveness of the government intervention \(A\) on recycling (\(Y\))

In Table~\ref{tbl-terminologyeffectmodificationtypes} \(\mathcal{G}\) 6,
we do not find evidence for effect-modification for \(B\) and \(G\)
because conditioning on \(Z\) would block the flow of information that
was open in \(\mathcal{G}\) 4 and \(\mathcal{G}\) 5.

Using causal directed acyclic graphs, it is eaasy to demonstrate that
the concept of `effect-modifier' cannot be stated without reference to
an assumed causal order and an explicit statement about which variables
within that order are modelled
(\citeproc{ref-vanderweele2012}{VanderWeele 2012}). However, lacking any
clear understand for the concept of effect modification, investigators,
and the policy makers might be the led to the wrong decisions. For
example, they might think that religious people are more receptive to
government promotion of recycling. However, the investigators have only
randomised the treatment. Estimating conditional associations between
the treatment and other variables one has measured (at baseline!) does
not address the question of whether treatment effects would vary were
investigators to intervene on other measured variables. More
fundamental, whether a variable is an `effect-modifier' cannot be stated
without reference to its position in assumed causal order
(\citeproc{ref-suzuki2013counterfactual}{Suzuki \emph{et al.} 2013};
\citeproc{ref-vanderweele2012}{VanderWeele 2012};
\citeproc{ref-vanderweele2007}{VanderWeele and Robins 2007}).

\subsubsection{Worked Example Showing Scale
Dependence}\label{worked-example-showing-scale-dependence}

We are interested in whether treatment varies across levels of another
variable, an effect modifier. Here, we explain how the presence or
absence of effect modification can depend on the scale used to measure
the effect. Specifically, an effect modifier on the ratio scale may not
be an effect modifier on the difference scale, and vice versa.

Individual treatment effects are not observed. We obtain the average
outcomes in each group as follows: \[
\mathbb{E}[Y \mid Z = 1, T = 0] = \mu_{01}, \quad \mathbb{E}[Y \mid Z = 1, T = 1] = \mu_{11}
\] \[
\mathbb{E}[Y \mid Z = 0, T = 0] = \mu_{00}, \quad \mathbb{E}[Y \mid Z = 0, T = 1] = \mu_{10}
\]

The treatment effect on the difference scale (absolute scale) for each
group is: \[
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01}
\] \[
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00}
\]

The treatment effect on the ratio scale (relative scale) for each group
is: \[
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}}
\] \[
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}}
\]

No Effect Modification on the Difference Scale: \[
\text{ATE}_{Z = 1} = \text{ATE}_{Z = 0} \implies \mu_{11} - \mu_{01} = \mu_{10} - \mu_{00}
\]

Effect Modification on the Ratio Scale: \[
\text{RR}_{Z = 1} \neq \text{RR}_{Z = 0} \implies \frac{\mu_{11}}{\mu_{01}} \neq \frac{\mu_{10}}{\mu_{00}}
\]

Next an example. C onsider the following hypothetical data:

Group 0: - \(\mu_{00} = 5\) - \(\mu_{01} = 15\)

Group 1: - \(\mu_{10} = 10\) - \(\mu_{11} = 20\)

We calculate the treatment effects on the difference and ratio scales
for each group:

Difference Scale: \[
\text{ATE}_{Z = 0} = \mu_{10} - \mu_{00} = 10 - 5 = 5
\] \[
\text{ATE}_{Z = 1} = \mu_{11} - \mu_{01} = 20 - 15 = 5
\]

Both groups have the same treatment effect on the difference scale,
\(\text{ATE}_{Z = 0} = \text{ATE}_{Z = 1} = 5\). We conclude there is no
effect modification on the difference scale.

Ratio Scale: \[
\text{RR}_{Z = 0} = \frac{\mu_{10}}{\mu_{00}} = \frac{10}{5} = 2.00
\] \[
\text{RR}_{Z = 1} = \frac{\mu_{11}}{\mu_{01}} = \frac{20}{15} \approx 1.33
\]

The treatment effect on the ratio scale is different for the two groups,
\(\text{RR}_{Z = 0} = 2 \neq \text{RR}_{Z = 1} \approx 1.33\). Hence, we
find evidence for effect modification on the ratio scale. This
discrepancy arises because the two scales measure different aspects of
the treatment effect: the absolute difference in outcomes versus the
relative change in outcomes.

\subsubsection{Introducing Single World Intevention
Graphs}\label{introducing-single-world-intevention-graphs}

Investigators are often interested in evaluating the effects of multiple
treatments. The remainder of the examples we consider below require
stating these causal quantities to be contrasted from multiple
treatments. Single World Intervention Graphs, developed by James
Richardson and Jamie Robins and colleagues, allow investigators to
clearly state the counterfactual quantities to be contrasted under
different treatments and treatment regimes. Before discussing the
concept of interaction as a double-intervention, we introduce Richardson
and Robin's graphical tool.

\begin{table}

\caption{\label{tbl-swigtable}Single World Interventions Recover
separate caual diagrams for each treatment to be contrasted.}

\centering{

\swigtable

}

\end{table}%

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 1 is a causal directed acyclic
graph, where the associated factorisation of the joint distribution is
given:

\[
P(y, a, l) = P(l) P(a | l) P(y | a, l)
\]

Notice that the counterfactual outcomes to be contrasted do not appear
directly on the causal directed acyclic graph. However, the
corresponding counterfactual outcomes are given by Pearl's do-calculus
Pearl (\citeproc{ref-pearl2009a}{2009}), such tha the average treatment
effect for \(A\) on \(Y\) is identified by conditioning on \(L\):

\[
P(Y(a)|A,L) = P(Y = y|do(A =a), L=l) = P(Y=y|A=a L=l)
\]

In Single World Intervention Graphs we obtain counterfactual
factoriations directly from the graph.

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 2 is a Single World
Intervention Template, a graph valued function, that allows us to
generate separate causal diagrams for each intervention.
\(A = \Tilde{a}\) can take any value \(A \in \mathcal{A}\), where
\(\mathcal{A}\) is the set of all possible inteventions for \(A\).

The function takes inputs:

\[
P(A = \Tilde{a}, Y(A = \Tilde{a}, L))  = P(A = \Tilde{a})P(Y = \Tilde{y}|A = \Tilde{A}, L)
\]

Table~\ref{tbl-swigtable} \(\mathcal{G}\) 3 is the graph value or Single
World Intevention Graph for the Single World Intervention Template
\(\mathcal{G} 2\) when is set to \(A =0\). This gives us the
factorisation:

\subsubsection{Node-Splitting in Single World Intervention Graphs
(SWIGs)}\label{node-splitting-in-single-world-intervention-graphs-swigs}

We represent the effects of hypothetical interventions by
node-splitting.

Consider a template graph \(\mathcal{G}\). Applying node-splitting to
\(A\) involves creating separate graphs for each value of \(A\) to be
contrasted.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{SWIG for \(A = 0\)}: Denoted as \(\mathcal{G}(A=0)\), this
  graph shows the hypothetical scenario where \(A\) is set to 0.
\item
  \textbf{SWIG for \(A = 1\)}: Denoted as \(\mathcal{G}(A=1)\), this
  graph shows the hypothetical scenario where \(A\) is set to 1.
\end{enumerate}

In these graphs, the node corresponding to the outcome \(Y\) is
relabelled to indicate it is now a potential outcome, such as \(Y(0)\)
or \(Y(1)\).

\subsubsection{d-Separation in SWIGs}\label{d-separation-in-swigs}

The rules of d-separation in the SWIGs allow us to read independence
relationships under each intervention to be compared. For example:

\begin{itemize}
\tightlist
\item
  In \(\mathcal{G}(A=0)\), \(A\) is set to 0, and \(L\) is the only edge
  into \(A\) and \(Y\). Thus, conditioning on \(L\) leads to
  \(A \coprod Y(0)\).
\item
  Similarly, in \(\mathcal{G}(A=1)\), \(A\) is set to 1, and \(L\) is
  the only edge into \(A\) and \(Y\). Thus, conditioning on \(L\) leads
  to \(A \coprod Y(1)\).
\end{itemize}

\subsubsection{Factorisation and
Modularity}\label{factorisation-and-modularity}

The factorisation of the joint distribution associated with these graphs
follows from the structure of the SWIGs. For the original DAG, the joint
distribution \(P(A, Y, L)\) can be factorised as \(P(L)P(A|L)P(Y|A,L)\).

For each Single World Intervention Graph, these factorisations are:

\[
P(A = \tilde{a}, Y(\tilde{a}=0) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=0) = y|A = \tilde{a}, L = l)P(L = l)
\] \[
P(A = \tilde{a}, Y(\tilde{a}=1) = y, L = l) = P(A = \tilde{a}|L = l)P(Y(\tilde{a}=1) = y|A = \tilde{a}, L = l)P(L = l)
\]

These factorisations align with the standard causal directed acyclic
graph factorisations, where \(L\) is the only parent of \(A\),
\(Y(\tilde{a}=0)\), and \(Y(\tilde{a}=1)\) in their respective Single
World Intervention Graphs.

Identification holds if:

\[
P(Y(\tilde{a}) = y) = \sum_l P(Y = y|L = l, A = \tilde{a}) P(L = l)
\]

\subsubsection{Interaction as a
joint-intervention}\label{interaction-as-a-joint-intervention}

Consider two treatments, denoted as \(A\) and \(B\), and their outcome
as \(Y\). A joint intervention causal interaction implies that the
effect of \(A\) and \(B\) together on \(Y\) (denoted as \(Y(A,B)\)) is
not merely the sum of their individual effects.

\begin{table}

\caption{\label{tbl-interactionpuzzle}Causal Interaction}

\centering{

\interactionpuzzle

}

\end{table}%

For instance, consider the effect of beliefs in Big Gods (exposure
\(A\)) on social complexity (outcome \(Y\)), potentially influenced by a
culture's monumental architecture (exposure \(B\)). To assess the
individual and combined effects of \(A\) and \(B\), we look for evidence
of causal interaction on the difference scale. Evidence for interaction
would be present if the following inequality were to hold. Where,

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[Y(1,1)]\): Mean outcome for those jointly exposed to both
  treatments A and B.
\item
  \(\mathbb{E}[Y(1,0)]\): Mean outcome for those exposed to treatment A
  only.
\item
  \(\mathbb{E}[Y(0,1)]\): Mean outcome for those exposed to treatment B
  only.
\item
  \(\mathbb{E}[Y(0,1)]\): Mean outcome for those exposed to neither
  treatment A nor B.
\end{itemize}

We say there is evidence for interaction on the additive scale if

\[\bigg(\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) - \bigg[ \bigg(\underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}}\bigg) + \bigg(\underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \bigg)\bigg] \neq 0 \]

This equation simplifies to

\[ \underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint exposure}} - \underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A exposed}} - \underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B exposed}} + \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither exposed}} \neq 0 \]

A positive value would indicate evidence for additive interaction. A
negative value would indicate evidence for sub-additive interaction. A
value near zero would imply no reliable evidence for interaction.

Table~\ref{tbl-interactionpuzzle} presents each counterfactual
interventions. We can read from the graphs, that identification in each
\(\mathcal{G}_{\Tilde{a}, \Tilde{b}}\) requires conditioning on all
confounders of \(A\), \(L_A\) and all confounders of B, \(L_B\).

As with effect-modification, evidence for causal interaction may differ
depending on the measurement scale one chooses to assess it VanderWeele
(\citeproc{ref-vanderweele2012}{2012}). Evidence for the strength of a
causal effect estimate for interaction in the presence of
effect-modification will differ depending on whether the effect is
measured on the ratio scale as opposed to the difference scale (see:
VanderWeele and Knol (\citeproc{ref-vanderweele2014}{2014}), who
recommends using the causal difference scale for most policy settings.)

Note that if \(A\) and \(B\) were to effect each other, we would need to
collect time series data, and estimate causal effects using causal
mediation analysis. The demands for causal mediation analysis are more
stringent than adjusting for confounder sets for both interventions. We
consider these challenges next.

\subsection{Causal Mediation Analysis}\label{causal-mediation-analysis}

\subsubsection{Statisical structural equation models lack
structure}\label{statisical-structural-equation-models-lack-structure}

In the human sciences, mediation analysis is often mired in confusion, a
situation exacerbated by the complex nature of causal relationships it
aims to reveal. However, confusion dissipates when we define our causal
question in relation to the counterfactuals we hope to estimate. Beyond
the intrinsic challenges of mediation analysis, much of the prevailing
confusion stems from the prevalent use of statisical structural equation
models (SEMs). These models generally lack a systematic way of modelling
the complex counterfactual contrasts that are relevant to evaluating
causality. The widespread disconnect between the dominant modelling
traditions and the demands of causal data science is a particularly
worrying feature of the causal crisis that pervades many human sciences
presently. We have no guarantees they that such models are
interpretable. However, we can do better by clearly defining our
estimands with respect to a clearly defined target population. Causal
diagrams are powerful compasses by which to clarify the conditions under
which these estimands may be identified from data.

\subsubsection{Defining a Mediaton
Estimand}\label{defining-a-mediaton-estimand}

To gain a clearer understanding of what causal mediation entails, it is
helpful to deconstruct the total effect into the natural direct and
indirect effects.

\begin{table}

\caption{\label{tbl-medationpuzzle}Causal Mediation}

\centering{

\mediationpuzzle

}

\end{table}%

The total effect of treatment \(A\) on outcome \(Y\) is defined as the
aggregate difference between the potential outcomes when the treatment
is applied versus when it is not. The estimand for the total effect (TE)
can be expressed as follows:

\[
TE = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]
\]

The total effect can be further decomposed into direct and indirect
effects, which allow us to address questions of mediation. The potential
outcome \(Y(1)\) taking into account the mediator can be expanded:

\[ 
\mathbb{E}[Y(1)] = \mathbb{E}[Y(1, M(1))]
\]

Here, the effect of the exposure, set to \(A = 1\), is considered along
with the effect of the mediator at its natural value when \(A = 1\).

Similarly, the potential outcome \(\mathbb{E}[Y(0)]\) taking into
account the mediator can be expanded:

\[ 
\mathbb{E}[Y(0)] = \mathbb{E}[Y(0, M(0))]
\]

Here, we focus on the effect of the exposure, set to \(A = 0\), along
with the effect of the mediator at its natural value when \(A = 0\).

Next consider these quantities of interest as they relate to causal
mediation analysis. We can clarify our estimand by decomposing the Total
Effect (TE, which is equivalent to the average treatment effect, or
marginal effect) into the Natural Direct Effect (NDE) and the Natural
Indirect Effect (NIE).

\textbf{Natural Direct Effect (NDE)} is the effect of the treatment on
the outcome while maintaining the mediator at the level it would have
been if the treatment had \emph{not} been applied. The Natural Direct
Effect (NDE) is given:

\[
 NDE = \textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]
 \]

Here, the counterfactual quantities that are not directly realised in
the data are highlighted in blue:
\(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\). Noticethat we add this
term to the potential outcomes when \(A=0\), namely,
\(\mathbb{E}[Y(0)]\), recalling: \(\mathbb{E}[Y(0, M(0))] = Y(0)\)

\textbf{Natural Indirect Effect (NIE):} is the effect of the exposure on
the outcome that is mediated. To obtain these quantities we must compare
the potential outcome \(Y\) under treatment, where the mediator assumes
its natural level under treatment with the potential outcome when the
mediator assumes its natural value under no treatment is given:

\[
 NIE = \mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}
\]

Here, the counterfactual quantities that are not directly realised in
the data are again highlighted in blue:
\(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\). Notice that we subtract
the term from the potential outcomes when \(A=1\), namely,
\(\mathbb{E}[Y(1)]\), recalling:
\(\mathbb{E}[Y(1, M(1))] = \mathbb{E}[Y(1)]\).

Then, by rearranging this decomposition, we can demonstrate that the
total effect (TE) is the sum of the NDE and NIE. We do this by adding
and subtracting the term \(\textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\),
highlighted in blue to our equation is given:

\[
\text{Total Effect (TE)} = \underbrace{\bigg\{\mathbb{E}[Y(1, M(1))] - \textcolor{blue}{\mathbb{E}[Y(1, M(0))]}\bigg\}}_{\text{Natural Indirect Effect (NIE)}} + \underbrace{\bigg\{\textcolor{blue}{\mathbb{E}[Y(1, M(0))]} - \mathbb{E}[Y(0, M(0))]\bigg\}}_{\text{Natural Direct Effect (NDE)}}
\]

The decomposition of the total effect into natural direct and indirect
effects greatly clarifies the targets of interest in causal mediation
analysis where the interest is in recovering natural indirect and direct
effects, see VanderWeele (\citeproc{ref-vanderweele2015}{2015}). These
are the quantities that causal mediation analysis often seeks
(\citeproc{ref-shi2021}{Shi \emph{et al.} 2021};
\citeproc{ref-steen2017}{Steen \emph{et al.} 2017};
\citeproc{ref-valeri2014}{Valeri \emph{et al.} 2014};
\citeproc{ref-vanderweele2014a}{VanderWeele and Vansteelandt 2014};
\citeproc{ref-vansteelandt2012}{Vansteelandt \emph{et al.} 2012}).
However, to express these quantities requires conceptualising them in
relation to counterfactuals. Lacking a counterfactual framework, it is
unclear what our statistical analysis would be estimating. Note that
VanderWeele (\citeproc{ref-vanderweele2015}{2015}) provides a full
decomposition that includes causal interaction in settings of causal
mediation.

Consider again the hypothesis that cultural beliefs in `big Gods'
influence social complexity, with political authority serving as a
mediator. We assume for present purposes we have well-defined
interventions and outcomes. What requirements are necessary to answer
our causal mediation question?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{No unmeasured exposure-outcome confounder}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod A | L\). After
accounting for the covariates in set \(L\), there must be no unmeasured
confounders influencing cultural beliefs in Big Gods, \(A\), and social
complexity \(Y\). For example, if our study examines the causal effect
of cultural beliefs in Big Gods (the exposure) on social complexity (the
outcome), and the covariates in \(L\) include factors such as geographic
location and historical context, we need to ensure that these covariates
effectively block any confounding paths between \(A\) and \(Y\).
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
brown.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{No unmeasured mediator-outcome confounder}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod M | V\). After
controlling for the covariate set \(V\), we must ensure that no other
unmeasured confounders affect the political authority \(M\) and social
complexity \(Y\). For instance, if trade networks affect political
authority and social complexity, to obstruct the unblocked path linking
our mediator and outcome we must account for trade networks.
Furthermore, we must be entitled to assume the absence of any other
confounders for the mediator-outcome path.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
blue.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{No unmeasured exposure-mediator confounder}
\end{enumerate}

This requirement is expressed: \(M(a) \coprod A | Q\). After controlling
for the covariate set \(Q\), we must ensure that no additional
unmeasured confounders affect cultural beliefs in big Gods \(A\) and
political authority \(M\). For example, the capability to construct
large ritual theatres may influence the belief in big Gods and the level
of political authority. If we have indicators for this technology
measured prior to the emergence of big Gods (these indicators being
\(Q\)), we must assume that accounting for \(Q\) closes the backdoor
path between the exposure and the mediator.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path in
green.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{No mediator-outcome confounder affected by the exposure}
\end{enumerate}

This requirement is expressed: \(Y(a,m) \coprod M(a^*) | V\). We must
ensure that no variables confounding the relationship between political
authority and social complexity in \(V\) are themselves influenced by
the cultural beliefs in big Gods (\(A\)). For example, when studying the
effect of cultural beliefs in big Gods (\(A\), the exposure) on social
complexity (\(Y\), the outcome) as mediated by political authority
(mediator), there can be no un-modelled factors, such as trade networks
(\(V\)), that influence both political authority and social complexity
and are themselves affected by the belief in big Gods.
\textbf{?@fig-dag-mediation-assumptions} shows this confounding path,
\(A\to \boxed{V}\rightarrowdotted M\).

Assumption 4, that there is no exposure-induced confounding in the
mediator-outcome relationship, is often a considerable obstacle for
causal mediation analysis. Where the exposure influences a confounder of
the mediator and outcome, we face a dilemma. Without adjusting for this
confounder, a backdoor path between the mediator and the outcome would
remain open. However, by adjusting for it, we partially obstruct the
path between the exposure and the mediator, leading to bias. In this
setting, we cannot recover the natural direct and indirect effects
directly from any observational data and may need to settle for
investigating controlled direct effects, which stipulate fixed values
for the mediator; see: VanderWeele
(\citeproc{ref-vanderweele2015}{2015}); Robins and Greenland
(\citeproc{ref-robins1992}{1992}).

Notice again that the requirements for counterfactual data analysis are
considerably stricter than has been appreciated in the structural
equation modelling traditions. Natural direct effect estimates and
natural indirect effects estimates require conceptualising a
counterfactual that is never directly observed from the data, namely:
\(\textcolor{blue}{Y(1, M(0))}\) see: VanderWeele
(\citeproc{ref-vanderweele2015}{2015}).

Unfortunately, a generation of researchers must unlearn the habit of
leaping from a description of a statistical process as embodied in a
structural equation diagram to the analysis of the data. It has been
over three decades since Robins and Greenland demonstrated that we
cannot understand the quantities we are estimating in mediation analysis
without first specifying the estimands of interest in terms of the
targeted counterfactuals of interest (\citeproc{ref-robins1992}{Robins
and Greenland 1992}).

\paragraph{3.2.4 Controlled direct effects (and other estimands for
mediation)}\label{controlled-direct-effects-and-other-estimands-for-mediation}

In the previous section, we focused on the assumptions necessary for
decomposing natural direct and indirect effects in causal mediation
analysis. It is crucial to note that consistent estimates for natural
direct and indirect effects are compromised if there exists a confounder
affected by the exposure, which also influences the mediator-outcome
relationship. Nonetheless, if all other assumptions hold, we can fix
this mediator at a specific level to estimate a `controlled direct
effect' of the exposure at different mediator levels.

Consider a scenario where estimating a controlled direct effect is of
interest. Suppose we aim to understand the effect of a stringent
pandemic lockdown, \(A\), on psychological distress, \(Y\), focusing on
trust in government, \(M\), as a mediator. Further, suppose that
pandemic lockdowns may plausibly influence attitudes towards the
government through pathways that also affect psychological distress. For
instance, people might trust the government more when it provides income
relief payments, which may also reduce psychological distress. Under the
rules of d-separation, conditioning on income relief payments, denoted
as \(V\), would attenuate the natural value of the mediator, trust in
the government, under exposure to the lockdowns. This blocking of the
exposure's effect is represented by the causal path
\(A \to \boxed{V} \rightarrowdotted Y\). Additionally, the exposure's
effect on the mediator is partially blocked by the causal path
\(A \to \boxed{V} \rightarrowdotted M\). However, if we do not condition
on \(V\), the path from trust in government, \(M\), to psychological
distress, \(Y\), would be confounded by the common cause \(V\), hence:
\(Y \leftarrowred V \rightarrowred M\).

In such a scenario, it would not be feasible to consistently decompose
the total effect of the exposure (pandemic lockdowns) on the outcome
(psychological distress) into natural indirect and direct effects.
Nevertheless, if all other assumptions hold, we could ascertain from
data the controlled direct effect of pandemic lockdowns on psychological
distress under fixed levels of trust in government.

For example, we could examine the effect of the pandemic lockdown if we
were able to intervene and set everyone's trust in government to, say,
one standard deviation above the baseline, compared with fixing trust in
government to the average level at baseline. We might use `shift
functions' that specify interventions as functions of the data. For
instance, we might investigate interventions that `shift only those
whose mistrust of government was below the mean level of trust at
baseline and compare these potential outcomes with those observed.'
Asking and answering precisely formulated causal questions such as this
might lead to clearer policy advice, especially in situations where
policymakers can influence public attitudes towards the government; see:
Williams and Daz (\citeproc{ref-williams2021}{2021}); Daz \emph{et
al.} (\citeproc{ref-duxedaz2021}{2021}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2022}{2022}); Hoffman \emph{et al.}
(\citeproc{ref-hoffman2023}{2023}).

In any case, I hope this brief discussion of causal mediation analysis
clarifies that it would be unwise to simply examine the coefficients
obtained from structural equation models and interpret them as
meaningful as in statistical mediation analysis. We have no guarantees
that these coefficients are interpretable. Rather, to answer any causal
question, we must first state it, with respect to clearly defined
counterfactual contrasts and a target population.

For those interested in estimands for causal mediation analysis, I
recommend visiting the CMAverse website
(\url{https://bs1125.github.io/CMAverse/articles/overview.html},
accessed 12 December 2023). This excellent resource provides
comprehensive documentation, software, and practical examples, including
sensitivity analyses. Next, we will consider more complex scenarios that
involve feedback between treatments and confounders across multiple time
points, settings in which traditional statistical methods also fail
provide valid causal inferences.

\newpage{}

\begin{table}

\caption{\label{tbl-medationassumptions}Assumptions of Causal Mediation}

\centering{

\mediationassumptionsswig

}

\end{table}%

\subsection{Time-fixed and Time-Varying Treatment
Regimes}\label{time-fixed-and-time-varying-treatment-regimes}

Our discussion of causal mediation analysis focused on how effects from
two sequential exposures may combine to influence an outcome. This
concept can be expanded to investigate the causal effects of multiple
sequential exposures -- referred to as `treatment regimes', or
`treatment strategies', or `modified treatment policies.' In many human
sciences where longitudinal data are collected, researchers will often
gravitate to longitudinal growth models and multi-level models. How
shall we interpret the coefficients of these models? To answer a causal
question we must first ask it -- that is, we must first state the
counterfactual contrast in which we are interested. Without stating the
the treatments to be contrasted, the scale on which the contrast will be
computed, and the population for whom inferences are valid, our
statistical models have no clear meaning. The inscrutibility of our
models remains even if there is no unmeasured confounding. However, we
learned from causal mediation analysis that even if investigators were
to randomise the treatment they could do not typically randomise the
mediator. This raises the prospect of intermediary confounding.
Moreover, we learned that even if investigators were to conduct a
sequentional trial such that the mediator was randomised, there would be
no arm of the trail that would yeld the cross-world quantity needed to
obtain a decomposition of the total effect into the natural indirect and
direct effects. The quantity -- \(\mathbb{E}[Y(1, M(0))\) -- is not
observed on any individual. Causal mediation anaysis is a special case
of causal inference under sequential treatments. We next clarify how
investigators may avoid the widespread confusions that pervade
longtitudinal data analysis by clearly stating their causal questions
and evaluating identification before reaching for any statistical model.

\subsubsection{Worked Example: Does Marriage Affect
Happiness?}\label{worked-example-does-marriage-affect-happiness}

Richard McElreath considers the question of whether marriage affects
happiness, and provides a simulation to clarify how age structure
complicates causal inferences McElreath
(\citeproc{ref-mcelreath2020}{2020}). Here, we develop this example. We
simply by considering the outcome, happiness, measured after two time
intervals. Assume this outcome to be well-defined and measured without
error. Assume further that positivity is satisfied, all outcomes are
observed within each level of confounding co-variate. Assume that
consistency is satisfied. Multiple versions of treatment are
conditionally independent of the outcomes.

\(A_t=1\) denotes the state of being married at time \(t\) and
\(A_t = 0\) where \(t \in \{0, 1, \tau\}\) where \(\tau\) is the end of
study and and \(Y_\tau\) denotes the outcome, Happiness

We see in Table~\ref{tbl-regimens-marriage} reveals that there are four
treatment strategies, and six causal contrasts we may estimate for the
four each treatment strategy combination.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1923}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3462}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4615}}@{}}
\caption{Table outlines four fixed treatment regimens and six causal
contrasts in time-series data where exposure varies. These labels apply
only to the two time
points.}\label{tbl-regimens-marriage}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Counterfactual Outcome
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Regime & Always married & \(Y(1,1)\) \\
Regime & Never married & \(Y(0,0)\) \\
Regime & Divorced & \(Y(1,0)\) \\
Regime & Gets married & \(Y(0,1)\) \\
Contrast & Always married vs.~Never married & \(E[Y(1,1) - Y(0,0)]\) \\
Contrast & Always married vs.~Divorced & \(E[Y(1,1) - Y(1,0)]\) \\
Contrast & Always married vs.~Gets married & \(E[Y(1,1) - Y(0,1)]\) \\
Contrast & Never married vs.~Divorced & \(E[Y(0,0) - Y(1,0)]\) \\
Contrast & Never married vs.~Gets married & \(E[Y(0,0) - Y(0,1)]\) \\
Contrast & Divorced vs.~Gets married & \(E[Y(1,0) - Y(0,1)]\) \\
\end{longtable}

The question ``Does marriage affect happiness?'' has no clear meaning
unless we state the contrast or set of contrasts for which we hope to
obtain valid causal inferences. To be scientifically meaningful, the
contrasts we state should be grounded in cleary communicated scientific
interests, and these interests should inform the target population for
which we take inferences to be valid. The question, for example, of
whether divorce makes one less happy one year later, will have different
answers depending on whether we compare divorce with remaining married,
with never having married, or with getting married. Notice the estimands
we state will imply different populations for whom results are meant to
generalise. The marginal effect estimate of Divorce vs Always married
generalises to the population who was always married. Clinicians and
relationship scientists might have reasons to focus on
effect-modification by gender, or sexual orientation, or birth cohort,
say. The marginal estimands will not automatically align with these
interests, and indeed risk erroneous policy inferences wherever the
target population differs from the sample population from which marginal
effects have been estimated -- even if our results obtain consistent
causal estimates of the targeted estimands.

We set further discussion about the need for clearly defined estimand
and target population to the side. Suppose investigators state and
clearly communicate the treatment regimes to be contrasted. Their next
task will be to evaluate sequential exchangeability: they must clarify
whether the potential outcomes are independent at each time point of the
outcome, obtained at the end of study.

\begin{table}

\caption{\label{tbl-swigtabledeveloped}Assumptions of Causal Mediation}

\centering{

\swigtabledeveloped

}

\end{table}%

Table~\ref{tbl-swigtabledeveloped} represents a two subsets of possible
confounding structures for a treatment regime conducted over two
intervals. Covariates in \(L_{t}\) denote measured confounders. \(U\)
denotes unmeasured confounders. \(A_t\) denotes the treatment,
``Marriage Status'' at time \(t\). \(Y\) denotes ``Happiness'' measured
at the end of study. We assume that conditioning on \(L_{t}\) is
sufficient to all backdoor paths for \(A_{t+1}\). We include indicators
of ``Happiness'' in \(L_{t}\), thus controlling for happiness as a
common cause of the marriage at time \(t+1\) and happiness at the end of
study \(\tau = \bar{A}-{\tau -1}\). Table~\ref{tbl-swigtabledeveloped}
\(\mathcal{G}1\) and Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}2\)
are causal DAGs that the describe these structures. Recall when
constructing causal DAGs we do not generally draw a path from treaments
to outcome when our interest is in evalauating d-separation using
backdoor adjustment. Here we are not concerned that \(A_2\) is a
mediator of the path from \(A_1\) to \(Y\) because our estimand refers
to the combined effect of \(A_1\) and \(A_2\). Furthemrmore, we make no
attempt to separate these effects within any treatment regime; we assume
all nodes can be intervened upon.

Consider the structure of confounding presented in
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\). To close the
backdoor path from \(A_1\) to \(Y\) we must condition on \(L_0\). To
close the backdoor path from \(A_3\) to \(Y\) we must likewise condition
on \(L_2\). However, \(L_2\) is a collider of treatment \(A_1\) and
unmeasured confounders, such that conditioning on \(L_2\) opens a
backdoor path between \(A_1\) and \(Y\) This path is highlighted in red:
\(A_1 \association L_2 \association U \association Y\). If
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\) faithfully
represents causality, it would seem that we cannot obtain valid
inference for any of the six causal contrasts we have defined.

However, there is hope. Robins (\citeproc{ref-robins1986}{1986}) showed
that consistent estimators can be constructed where there is
time-varying confounding (refer to Robins \emph{et al.}
(\citeproc{ref-robins2004effects}{2004}), Hernn \emph{et al.}
(\citeproc{ref-hernan2004STRUCTURAL}{2004})).
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}3\) presents a Single
World Intervention Template that clarifies how investigators may obtain
identification for fixed treatment regimes for time-varying confounding
presented in Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}1\), Recall
that when constructing a Single World Intervention Graph (or Template),
we obtain factorisations for counterfactual outcomes under a specific
treatment regime by employing `node-splitting' such that all nodes
following an intervention are relabelled as counterfactual states under
preceeding intervention. After a node-splitting, a fixed intervention is
no longer a random variable. Thus, under fixed treatment regimes, the
counterfactul states that follow an intervention are independent of the
states that occur prior to node splitting if there are no back-door
paths into the random partition of the node that has been split. If if
all backdoor paths are closed into the random partitions of the nodes on
which interventions occur, then we can graphically verify that the
treatment is independent of the counterfactual outcome for that
intervention node. Where there are multiple interventions, we insure
sequential exchangeability at the following node -- which we likewise
split and relable -- by closing all backdoor paths between the random
portion of the following treatment node. We have sequential independence
if for each intervention node, all backdoor paths are closed (refer to
Robins and Richardson (\citeproc{ref-robins2010alternative}{2010});
Richardson and Robins (\citeproc{ref-richardson2013swigsprimer}{2013a});
Richardson and Robins (\citeproc{ref-richardson2023potential}{2023})).
The Single World Intervention Template
Table~\ref{tbl-swigtabledeveloped} \(\mathcal{G}3\) makes it clear that
sequential identification may be obtained. \(A_1\) is d-separated from
\(Y\) by conditioning on \(L_0\); \(A_3\) is d-separated from \(Y\) by
conditioning on \(L_2\). Suppose that the only confounder in \(L\) were
happiness. By estimating the effect of \(L_2\) on \(Y\), adjusting for
\(A_1, L_2, L_0\), obtain valid inference for \(Y\). By adjusting for
\(L_0\) we obtain valid inference for \(A_1\). We may \emph{not}
estimate the combined effect of a treatment strategy over \(A_1\) and
\(A_2\) by employing regression, multi-level regression, statisical
structural equation models, or propensity score matching. However,
special estimators may be constructed (refer to Robins
(\citeproc{ref-robins1986}{1986}); Robins \emph{et al.}
(\citeproc{ref-robins2004effects}{2004}); Van Der Laan and Rose
(\citeproc{ref-vanderlaan2011}{2011}); Daz \emph{et al.}
(\citeproc{ref-diaz2021nonparametric}{2021})). Because our interest here
is in identification we shall review these estimators, however, for
reviews refer to Hernan and Robins
(\citeproc{ref-hernan2024WHATIF}{2024}); Chatton \emph{et al.}
(\citeproc{ref-chatton2020}{2020}); Van Der Laan and Rose
(\citeproc{ref-vanderlaan2018}{2018}).

\paragraph{Time-varying Treatment
Strategies.}\label{time-varying-treatment-strategies.}

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   A_{0}  & \text{set all} ~ A_{0} ~ \text{to} ~ 1 \\
   A(\mathbf{g})_{1} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \\ 
   A(\mathbf{g})_{1} =  A(\mathbf{g})_{1}& \text{otherwise} 
   \end{cases}
\]

\(U_{AL}\) denotes ability to delusional personality, an unmeasured
variable, that is causally associated with associated with decisions to
marriage early and wealth \(U_{AY}\) denotes one's true state of
happiness, which is measured by \(L\). To declutter, we remove baseline
measurement of \(L_0\), which we assume to be conditioned on. For
simplicity in the exposition, suppose \(L_t\) is the only confounder of
A\_\{t+1\}.

Suppose that investigators are interested in whether the causal effect
of marriage on happiness is affected by wealth. Note that we cannot
easily assess this question in the context of two measurement intervals.
For example, taking the interaction of time \(\times\) wealth \(\times\)
marriage status will produce coefficients that are interpretable if
marriage and health can effect each other over time.

Drawing on a diverse array of expert advice, the investigators develop
the following estimate

They contrast this this intervention with strategy 1: happiness if
always married.

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   A_{0} = 1 & \\ 
   A_{1} = 1 & \\ 
   A_{t}(\mathbf{g}) = A_{t}(\mathbf{g}) & \text{otherwise} 
   \end{cases}
\]

Strategy 2: happiness if never married.

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   A_{0} = 0 & \\ 
   A_{1} = 0 & \\ 
   A_{t}(\mathbf{g}) = A_{t}(\mathbf{g}) & \text{otherwise} 
   \end{cases}
\]

Strategy 3: happiness if wealth and unmarried.

\[
A_t^{+}(\mathbf{g}) = \mathbf{g}(A_{t}) = \begin{cases} 
   A_{0} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \\ 
   A_{1} = 0 & \text{if income} > 1.5 \times  \mu_{\text{income}} \text{and one is married} \\ 
   A_{t}(\mathbf{g}) = A_{t}(\mathbf{g}) & \text{otherwise} 
   \end{cases}
\]

In the fixed strategy
\(A_t^{+}(\mathbf{g})  \equiv g(A_t)  \equiv a_t = 1\).

Suppose that education does not affect happiness and so is not a common
cause of marriage and happiness. However, suppose that education affects
marriage and wealth, and furthermore, suppose education is unmeasured.
In causal DAG \(\mathcal{3}\) and Single World Interention Template
\(\mathcal{4}\), wealth is in the confounder set \(L\) and we represent
education using \$U\_\{AL\}. Suppose further there is an umeasured
common cause of wealth and happiness such as childhood deprivation,
which in causal DAG \(\mathcal{3}\) and template \(\mathcal{4}\) we
represent using node \$U\_\{AY\}. Causal DAG \(\mathcal{3}\) underscores
the time-varying confounding \(L\) is a collider of \(A_1\) and the
unmeasured confounders \$U\_\{AL\} and \$U\_\{AY\}, which opens the path
\(A_1 \association L_2 \association U_{AY} \association Y\) and the path
\(A_1 \association L_2 \association U_{AL}\association U_{AY} \association Y\).

Again causal DAG \(\mathcal{3}\) is useful for diagnosing a problem yet
less useful for clarifying idenification.

\subsection{Conclusions}\label{conclusions}

\subsection{Funding}\label{funding}

This work is supported by a grant from the Templeton Religion Trust
(TRT0418) and RSNZ Marsden 3721245, 20-UOA-123; RSNZ 19-UOO-090. I also
received support from the Max Planck Institute for the Science of Human
History. The Funders had no role in preparing the manuscript or the
decision to publish it.

\subsection{Acknowledgements}\label{acknowledgements}

Errors are my own.

\subsection{Appendix A: Glossary}\label{appendix-a-glossary}

\begin{table}

\caption{\label{tbl-gloassary}Glossary}

\centering{

\glossaryTerms

}

\end{table}%

\subsection{Appendix B On the Clarity of Single World Intervention
Graphs}\label{appendix-b-on-the-clarity-of-single-world-intervention-graphs}

\newpage{}

\begin{table}

\caption{\label{tbl-pearltable}On the limitations of causal DAGs
compared to Single World Intervention Graphs.}

\centering{

\pearltable

}

\end{table}%

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-chatton2020}
Chatton, A, Le Borgne, F, Leyrat, C, \ldots{} Foucher, Y (2020)
G-computation, propensity score-based methods, and targeted maximum
likelihood estimator for causal inference with different covariates
sets: a comparative simulation study. \emph{Scientific Reports},
\textbf{10}(1), 9219.
doi:\href{https://doi.org/10.1038/s41598-020-65917-x}{10.1038/s41598-020-65917-x}.

\bibitem[\citeproctext]{ref-duxedaz2021}
Daz, I, Williams, N, Hoffman, KL, and Schenck, EJ (2021) Non-parametric
causal effects based on longitudinal modified treatment policies.
\emph{Journal of the American Statistical Association}.
doi:\href{https://doi.org/10.1080/01621459.2021.1955691}{10.1080/01621459.2021.1955691}.

\bibitem[\citeproctext]{ref-diaz2021nonparametric}
Daz, I, Hejazi, NS, Rudolph, KE, and Der Laan, MJ van (2021)
Nonparametric efficient causal mediation with intermediate confounders.
\emph{Biometrika}, \textbf{108}(3), 627--641.

\bibitem[\citeproctext]{ref-hernan2024WHATIF}
Hernan, MA, and Robins, JM (2024) \emph{Causal inference: What if?},
Taylor \& Francis. Retrieved from
\url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}

\bibitem[\citeproctext]{ref-hernan2004STRUCTURAL}
Hernn, MA, Hernndez-Daz, S, and Robins, JM (2004) A structural
approach to selection bias. \emph{Epidemiology}, \textbf{15}(5),
615--625. Retrieved from \url{https://www.jstor.org/stable/20485961}

\bibitem[\citeproctext]{ref-hoffman2023}
Hoffman, KL, Salazar-Barreto, D, Rudolph, KE, and Daz, I (2023)
Introducing longitudinal modified treatment policies: A unified
framework for studying complex exposures.
doi:\href{https://doi.org/10.48550/arXiv.2304.09460}{10.48550/arXiv.2304.09460}.

\bibitem[\citeproctext]{ref-hoffman2022}
Hoffman, KL, Schenck, EJ, Satlin, MJ, \ldots{} Daz, I (2022) Comparison
of a target trial emulation framework vs cox regression to estimate the
association of corticosteroids with COVID-19 mortality. \emph{JAMA
Network Open}, \textbf{5}(10), e2234425.
doi:\href{https://doi.org/10.1001/jamanetworkopen.2022.34425}{10.1001/jamanetworkopen.2022.34425}.

\bibitem[\citeproctext]{ref-mcelreath2020}
McElreath, R (2020) \emph{Statistical rethinking: A {B}ayesian course
with examples in r and stan}, CRC press.

\bibitem[\citeproctext]{ref-neal2020introduction}
Neal, B (2020) Introduction to causal inference from a machine learning
perspective. \emph{Course Lecture Notes (Draft)}. Retrieved from
\url{https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf}

\bibitem[\citeproctext]{ref-pearl2009a}
Pearl, J (2009) \emph{Causality}, Cambridge University Press.

\bibitem[\citeproctext]{ref-richardson2013}
Richardson, TS, and Robins, JM (2013b) Single world intervention graphs:
A primer. In, Citeseer.

\bibitem[\citeproctext]{ref-richardson2013swigsprimer}
Richardson, TS, and Robins, JM (2013a) Single world intervention graphs:
A primer. In \emph{Second UAI workshop on causal structure learning,
{B}ellevue, {W}ashington}, Citeseer. Retrieved from
\url{https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=07bbcb458109d2663acc0d098e8913892389a2a7}

\bibitem[\citeproctext]{ref-richardson2023potential}
Richardson, TS, and Robins, JM (2023) Potential outcome and decision
theoretic foundations for statistical causality. \emph{Journal of Causal
Inference}, \textbf{11}(1), 20220012.

\bibitem[\citeproctext]{ref-robins1986}
Robins, J (1986) A new approach to causal inference in mortality studies
with a sustained exposure period---application to control of the healthy
worker survivor effect. \emph{Mathematical Modelling}, \textbf{7}(9-12),
1393--1512.

\bibitem[\citeproctext]{ref-robins1992}
Robins, JM, and Greenland, S (1992) Identifiability and exchangeability
for direct and indirect effects. \emph{Epidemiology}, \textbf{3}(2),
143--155.

\bibitem[\citeproctext]{ref-robins2004effects}
Robins, JM, Hernn, MA, and SiEBERT, U (2004) Effects of multiple
interventions. \emph{Comparative Quantification of Health Risks: Global
and Regional Burden of Disease Attributable to Selected Major Risk
Factors}, \textbf{1}, 2191--2230.

\bibitem[\citeproctext]{ref-robins2010alternative}
Robins, JM, and Richardson, TS (2010) Alternative graphical causal
models and the identification of direct effects. \emph{Causality and
Psychopathology: Finding the Determinants of Disorders and Their Cures},
\textbf{84}, 103--158.

\bibitem[\citeproctext]{ref-shi2021}
Shi, B, Choirat, C, Coull, BA, VanderWeele, TJ, and Valeri, L (2021)
CMAverse: A suite of functions for reproducible causal mediation
analyses. \emph{Epidemiology}, \textbf{32}(5), e20--e22.

\bibitem[\citeproctext]{ref-steen2017}
Steen, J, Loeys, T, Moerkerke, B, and Vansteelandt, S (2017) Medflex: An
{R} package for flexible mediation analysis using natural effect models.
\emph{Journal of Statistical Software}, \textbf{76}, 1--46.

\bibitem[\citeproctext]{ref-suzuki2013counterfactual}
Suzuki, E, Mitsuhashi, T, Tsuda, T, and Yamamoto, E (2013) A
counterfactual approach to bias and effect modification in terms of
response types. \emph{BMC Medical Research Methodology}, \textbf{13}(1),
1--17.

\bibitem[\citeproctext]{ref-suzuki2020}
Suzuki, E, Shinozaki, T, and Yamamoto, E (2020) Causal Diagrams:
Pitfalls and Tips. \emph{Journal of Epidemiology}, \textbf{30}(4),
153--162.
doi:\href{https://doi.org/10.2188/jea.JE20190192}{10.2188/jea.JE20190192}.

\bibitem[\citeproctext]{ref-valeri2014}
Valeri, L, Lin, X, and VanderWeele, TJ (2014) Mediation analysis when a
continuous mediator is measured with error and the outcome follows a
generalized linear model. \emph{Statistics in Medicine},
\textbf{33}(28), 4875--4890.

\bibitem[\citeproctext]{ref-vanderlaan2011}
Van Der Laan, MJ, and Rose, S (2011) \emph{Targeted Learning: Causal
Inference for Observational and Experimental Data}, New York, NY:
Springer. Retrieved from
\url{https://link.springer.com/10.1007/978-1-4419-9782-1}

\bibitem[\citeproctext]{ref-vanderlaan2018}
Van Der Laan, MJ, and Rose, S (2018) \emph{Targeted Learning in Data
Science: Causal Inference for Complex Longitudinal Studies}, Cham:
Springer International Publishing. Retrieved from
\url{http://link.springer.com/10.1007/978-3-319-65304-4}

\bibitem[\citeproctext]{ref-vanderweele2012}
VanderWeele, TJ (2012) Confounding and Effect Modification: Distribution
and Measure. \emph{Epidemiologic Methods}, \textbf{1}(1), 55--82.
doi:\href{https://doi.org/10.1515/2161-962X.1004}{10.1515/2161-962X.1004}.

\bibitem[\citeproctext]{ref-vanderweele2015}
VanderWeele, TJ (2015) \emph{Explanation in causal inference: Methods
for mediation and interaction}, Oxford University Press.

\bibitem[\citeproctext]{ref-vanderweele2014}
VanderWeele, TJ, and Knol, MJ (2014) A tutorial on interaction.
\emph{Epidemiologic Methods}, \textbf{3}(1), 33--72.

\bibitem[\citeproctext]{ref-vanderweele2007}
VanderWeele, TJ, and Robins, JM (2007) Four types of effect
modification: a classification based on directed acyclic graphs.
\emph{Epidemiology (Cambridge, Mass.)}, \textbf{18}(5), 561--568.
doi:\href{https://doi.org/10.1097/EDE.0b013e318127181b}{10.1097/EDE.0b013e318127181b}.

\bibitem[\citeproctext]{ref-vanderweele2014a}
VanderWeele, T, and Vansteelandt, S (2014) Mediation analysis with
multiple mediators. \emph{Epidemiologic Methods}, \textbf{2}(1),
95--115.

\bibitem[\citeproctext]{ref-vansteelandt2012}
Vansteelandt, S, Bekaert, M, and Lange, T (2012) Imputation strategies
for the estimation of natural direct and indirect effects.
\emph{Epidemiologic Methods}, \textbf{1}(1), 131--158.

\bibitem[\citeproctext]{ref-williams2021}
Williams, NT, and Daz, I (2021) \emph{{l}mtp: Non-parametric causal
effects of feasible interventions based on modified treatment policies}.
doi:\href{https://doi.org/10.5281/zenodo.3874931}{10.5281/zenodo.3874931}.

\end{CSLReferences}



\end{document}
